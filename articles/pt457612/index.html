<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçüíº ‚úâÔ∏è ü§¥üèæ Como acelerar a descompress√£o LZ4 no ClickHouse? üëÅÔ∏è üßùüèª üë©üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ao executar consultas no ClickHouse , voc√™ pode perceber que o criador de perfil geralmente mostra a fun√ß√£o LZ_decompress_fast na parte superior. O qu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como acelerar a descompress√£o LZ4 no ClickHouse?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/457612/"> Ao executar consultas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ClickHouse</a> , voc√™ pode perceber que o criador de perfil geralmente mostra a fun√ß√£o <code>LZ_decompress_fast</code> na parte superior.  O que est√° havendo?  Essa pergunta nos fez pensar em como escolher o melhor algoritmo de compacta√ß√£o. <br><br>  ClickHouse armazena dados em formato compactado.  Ao executar consultas, o ClickHouse tenta fazer o m√≠nimo poss√≠vel, a fim de conservar os recursos da CPU.  Em muitos casos, todos os c√°lculos potencialmente demorados j√° est√£o bem otimizados, e o usu√°rio escreveu uma consulta bem pensada.  Tudo o que resta a fazer √© realizar a descompress√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/302/aba/057302aba5041790af404c2c781c4dd3.png"><br><br>  Ent√£o, por que a descompress√£o do LZ4 se torna um gargalo?  O LZ4 parece um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">algoritmo extremamente leve</a> : a taxa de descompress√£o de dados geralmente √© de 1 a 3 GB / s por n√∫cleo do processador, dependendo dos dados.  Isso √© muito mais r√°pido que o subsistema de disco t√≠pico.  Al√©m disso, usamos todos os n√∫cleos de CPU dispon√≠veis e as escalas de descompress√£o linearmente em todos os n√∫cleos f√≠sicos. <br><a name="habracut"></a><br>  No entanto, h√° dois pontos a serem lembrados.  Primeiro, os dados compactados s√£o lidos no disco, mas a velocidade de descompress√£o √© fornecida em termos da quantidade de dados n√£o compactados.  Se a taxa de compacta√ß√£o for grande o suficiente, n√£o haver√° quase nada para ler nos discos.  Mas haver√° muitos dados descompactados, e isso afeta naturalmente a utiliza√ß√£o da CPU: no caso do LZ4, a quantidade de trabalho necess√°ria para descomprimir dados √© quase proporcional ao volume dos dados descomprimidos. <br><br>  Segundo, se os dados estiverem armazenados em cache, talvez voc√™ n√£o precise ler os dados dos discos.  Voc√™ pode confiar no cache da p√°gina ou usar seu pr√≥prio cache.  O armazenamento em cache √© mais eficiente em bancos de dados orientados a colunas, pois apenas as colunas usadas com frequ√™ncia permanecem no cache.  √â por isso que o LZ4 geralmente parece ser um gargalo em termos de carga da CPU. <br><br>  Isso traz mais duas perguntas.  Primeiro, se a descompress√£o est√° nos atrasando, vale a pena compactar os dados para come√ßar?  Mas essa especula√ß√£o √© irrelevante na pr√°tica.  At√© recentemente, a configura√ß√£o do ClickHouse oferecia apenas duas op√ß√µes de compacta√ß√£o de dados - LZ4 e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zstandard</a> .  LZ4 √© usado por padr√£o.  Mudar para Zstandard torna a compacta√ß√£o mais forte e mais lenta.  Mas n√£o havia uma op√ß√£o para desativar completamente a compacta√ß√£o, pois sup√µe-se que o LZ4 forne√ßa uma compacta√ß√£o m√≠nima razo√°vel que sempre pode ser usada.  (√â exatamente por isso que eu amo LZ4.) <br><br>  Mas um estranho misterioso apareceu no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bate-papo internacional de suporte ClickHouse,</a> que disse que ele tem um subsistema de disco muito r√°pido (com NVMe SSD) e descompacta√ß√£o √© a √∫nica coisa que desacelera suas consultas, por isso seria bom poder armazenar dados sem compress√£o  Respondi que n√£o temos essa op√ß√£o, mas seria f√°cil adicionar.  Alguns dias depois, recebemos uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">solicita√ß√£o pull</a> implementando o m√©todo de compacta√ß√£o <code>none</code> .  Pedi ao colaborador para informar sobre o quanto essa op√ß√£o ajudou a acelerar as consultas.  A resposta foi que esse novo recurso acabou sendo in√∫til na pr√°tica, pois os dados n√£o compactados come√ßaram a ocupar muito espa√ßo em disco e n√£o se encaixavam nessas unidades NVMe. <br><br>  A segunda pergunta que surge √© que, se houver um cache, por que n√£o us√°-lo para armazenar dados que j√° est√£o descompactados?  Esta √© uma possibilidade vi√°vel que eliminar√° a necessidade de descompress√£o em muitos casos.  O ClickHouse tamb√©m possui um cache como este: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o cache dos blocos descomprimidos</a> .  Mas √© uma pena desperdi√ßar muita RAM nisso.  Portanto, geralmente faz sentido usar em consultas pequenas e seq√ºenciais que usam dados quase id√™nticos. <br><br>  Nossa conclus√£o √© que √© sempre prefer√≠vel armazenar dados em formato compactado.  Sempre grave dados no disco em formato compactado.  Transmitir dados pela rede tamb√©m com compacta√ß√£o.  Na minha opini√£o, a compacta√ß√£o padr√£o √© justific√°vel mesmo quando a transfer√™ncia de dados em um √∫nico datacenter em uma rede de 10 GB sem excesso de assinaturas, enquanto a transfer√™ncia de dados n√£o compactados entre datacenters √© inaceit√°vel. <br><br><h3>  Por que LZ4? </h3><br>  Por que escolher LZ4?  N√£o poder√≠amos escolher algo ainda mais leve?  Teoricamente, poder√≠amos, e este √© um bom pensamento.  Mas vejamos a classe de algoritmos aos quais o LZ4 pertence. <br><br>  Primeiro de tudo, √© gen√©rico e n√£o adapta o tipo de dados.  Por exemplo, se voc√™ souber antecipadamente que ter√° uma matriz de n√∫meros inteiros, poder√° usar um dos algoritmos VarInt e isso usar√° a CPU com mais efici√™ncia.  Segundo, o LZ4 n√£o depende excessivamente das suposi√ß√µes do modelo de dados.  Digamos que voc√™ tenha uma s√©rie temporal ordenada de valores de sensores, uma matriz de n√∫meros de ponto flutuante.  Se voc√™ levar isso em conta, poder√° calcular deltas entre esses n√∫meros e depois compact√°-los com o algoritmo gen√©rico, o que resultar√° em uma taxa de compacta√ß√£o mais alta. <br><br>  Voc√™ n√£o ter√° problemas ao usar o LZ4 com matrizes de bytes ou arquivos.  √â claro que ele tem uma especializa√ß√£o (mais sobre isso mais tarde) e, em alguns casos, seu uso √© in√∫til.  Mas se o chamarmos de algoritmo de uso geral, estaremos bastante pr√≥ximos da verdade.  Devemos observar que, gra√ßas ao seu design interno, o LZ4 implementa automaticamente o algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RLE</a> como um caso especial. <br><br>  No entanto, a quest√£o mais importante √© se o LZ4 √© o algoritmo mais ideal dessa classe em termos de velocidade geral e for√ßa de compacta√ß√£o.  Os algoritmos ideais s√£o chamados de fronteira de Pareto, o que significa que n√£o h√° outro algoritmo que seja definitivamente melhor de uma maneira e nem pior de outras (e tamb√©m em uma ampla variedade de conjuntos de dados).  Alguns algoritmos s√£o mais r√°pidos, mas resultam em uma taxa de compacta√ß√£o menor, enquanto outros t√™m uma compacta√ß√£o mais forte, mas s√£o mais lentos para compactar ou descomprimir. <br><br>  Para ser honesto, o LZ4 n√£o √© realmente a fronteira de Pareto - existem algumas op√ß√µes dispon√≠veis que s√£o um pouco melhores.  Por exemplo, veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LZTURBO</a> de um desenvolvedor chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">powturbo</a> .  N√£o h√° d√∫vida sobre a confiabilidade dos resultados, gra√ßas √† comunidade <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">encode.ru</a> (o maior e possivelmente o √∫nico f√≥rum sobre compacta√ß√£o de dados).  Infelizmente, o desenvolvedor n√£o distribui o c√≥digo fonte ou os bin√°rios;  eles est√£o dispon√≠veis apenas para um n√∫mero limitado de pessoas para testes ou por muito dinheiro (embora pare√ßa que ainda ningu√©m pagou por isso).  Veja tamb√©m <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lizard</a> (anteriormente LZ5) e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Density</a> .  Eles podem funcionar um pouco melhor que o LZ4 quando voc√™ seleciona um determinado n√≠vel de compacta√ß√£o.  Outra op√ß√£o realmente interessante √© o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LZSSE</a> .  Mas termine de ler este artigo antes de conferir. <br><br><h3>  Como o lz4 funciona </h3><br>  Vamos ver como o LZ4 funciona em geral.  Esta √© uma das implementa√ß√µes do algoritmo LZ77.  L e Z representam os nomes dos desenvolvedores (Lempel e Ziv), e 77 √© para o ano de 1977 quando o algoritmo foi publicado.  Possui muitas outras implementa√ß√µes: QuickLZ, FastLZ, BriefLZ, LZF, LZO e gzip e zip se forem usados ‚Äã‚Äãbaixos n√≠veis de compacta√ß√£o. <br><br>  Um bloco de dados compactado usando LZ4 cont√©m uma sequ√™ncia de entradas (comandos ou instru√ß√µes) de dois tipos: <br><br><ol><li>  Literais: "Pegue os N bytes a seguir como est√£o e copie-os para o resultado". </li><li>  Correspond√™ncia: "Retire N bytes do resultado descompactado, come√ßando no valor de deslocamento em rela√ß√£o √† posi√ß√£o atual". </li></ol><br>  Exemplo  Antes da compacta√ß√£o: <br><br><pre> <code class="plaintext hljs">Hello world Hello</code> </pre> <br>  Ap√≥s a compacta√ß√£o: <br><br><pre> <code class="plaintext hljs">literals 12 "Hello world " match 5 12</code> </pre> <br>  Se pegarmos um bloco compactado e iterarmos o cursor durante a execu√ß√£o desses comandos, obteremos os dados originais n√£o compactados como resultado. <br><br>  Ent√£o √© assim que os dados s√£o descompactados.  A id√©ia b√°sica √© clara: para realizar a compacta√ß√£o, o algoritmo codifica uma sequ√™ncia repetida de bytes usando correspond√™ncias. <br><br>  Algumas caracter√≠sticas tamb√©m s√£o claras.  Esse algoritmo orientado a bytes n√£o disseca bytes individuais;  apenas os copia na √≠ntegra.  √â assim que difere da codifica√ß√£o de entropia.  Por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">zstd</a> √© uma combina√ß√£o de LZ77 e codifica√ß√£o de entropia. <br><br>  Observe que o tamanho do bloco compactado n√£o deve ser muito grande.  O tamanho √© escolhido para evitar o desperd√≠cio de muita RAM durante a descompress√£o, para evitar a lentid√£o do acesso aleat√≥rio demais no arquivo compactado (que consiste em um grande n√∫mero de blocos compactados) e, √†s vezes, para que o bloco caiba no cache da CPU.  Por exemplo, voc√™ pode escolher 64 KB para que os buffers para dados compactados e n√£o compactados caibam no cache L2 com metade ainda livre. <br><br>  Se precisarmos compactar um arquivo maior, podemos concatenar os blocos compactados.  Isso tamb√©m √© conveniente para armazenar dados adicionais (como uma soma de verifica√ß√£o) com cada bloco compactado. <br><br>  O deslocamento m√°ximo para a partida √© limitado.  No LZ4, o limite √© de 64 kilobytes.  Esse valor √© chamado de janela deslizante.  Isso significa que as correspond√™ncias podem ser encontradas em uma janela de 64 kilobytes que precede o cursor, que desliza com o cursor √† medida que avan√ßa. <br><br>  Agora vamos ver como compactar dados ou, em outras palavras, como encontrar seq√º√™ncias correspondentes em um arquivo.  Voc√™ sempre pode usar um sufixo trie (√© √≥timo se voc√™ realmente ouviu isso).  Existem m√©todos que garantem que a correspond√™ncia mais longa esteja localizada nos bytes anteriores ap√≥s a compacta√ß√£o.  Isso √© chamado de an√°lise ideal e fornece <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">quase</a> a melhor taxa de compacta√ß√£o para um bloco compactado de formato fixo.  Mas existem abordagens melhores, como encontrar uma correspond√™ncia suficientemente boa que n√£o seja necessariamente a mais longa.  A maneira mais eficiente de encontr√°-lo √© usando uma tabela de hash. <br><br>  Para fazer isso, iteramos o cursor no bloco de dados original e pegamos alguns bytes depois do cursor (digamos 4 bytes).  N√≥s os misturamos e colocamos o deslocamento desde o in√≠cio do bloco (de onde foram retirados os 4 bytes) na tabela de hash.  O valor 4 √© chamado "min-match" - usando esta tabela de hash, podemos encontrar correspond√™ncias de pelo menos 4 bytes. <br><br>  Se observarmos a tabela de hash e ela j√° tiver um registro correspondente, e o deslocamento n√£o exceder a janela deslizante, verificamos quantos bytes mais correspondem ap√≥s esses 4 bytes.  Talvez haja muito mais correspond√™ncias.  Tamb√©m √© poss√≠vel que haja uma colis√£o na tabela de hash e nada corresponda, mas isso n√£o √© grande coisa.  Voc√™ pode apenas substituir o valor na tabela de hash por um novo.  As colis√µes na tabela de hash simplesmente levar√£o a uma taxa de compacta√ß√£o mais baixa, pois haver√° menos correspond√™ncias.  A prop√≥sito, esse tipo de tabela de hash (com um tamanho fixo e sem resolu√ß√£o de colis√µes) √© chamado de "tabela de cache".  Esse nome faz sentido porque, no caso de uma colis√£o, a tabela de cache simplesmente esquece a entrada antiga. <br><br><blockquote>  Um desafio para o leitor cuidadoso.  Vamos supor que os dados sejam uma matriz de n√∫meros UInt32 no formato little endian que represente parte de uma sequ√™ncia de n√∫meros naturais: 0, 1, 2 ... Explique por que esses dados n√£o s√£o compactados ao usar LZ4 (o tamanho dos dados compactados n√£o √© menor em compara√ß√£o com os dados n√£o compactados). </blockquote><br><h3>  Como acelerar tudo </h3><br>  Ent√£o, eu quero acelerar a descompress√£o LZ4.  Vamos ver como √© o loop de descompress√£o.  Aqui est√° no pseudoc√≥digo: <br><br><pre> <code class="plaintext hljs">while (...) {    read(input_pos, literal_length, match_length);    copy(output_pos, input_pos, literal_length);    output_pos += literal_length;    read(input_pos, match_offset);    copy(output_pos, output_pos - match_offset,        match_length);    output_pos += match_length; }</code> </pre> <br>  O formato LZ4 √© projetado para que literais e correspond√™ncias se alternem em um arquivo compactado.  Obviamente, o literal sempre vem em primeiro lugar (porque n√£o h√° nenhum lugar para se combinar desde o in√≠cio).  Portanto, seus comprimentos s√£o codificados juntos. <br><br>  Na verdade, √© um pouco mais complicado que isso.  Um byte √© lido do arquivo e, em seguida, √© dividido em dois nibbles (meio bytes) que cont√™m os n√∫meros codificados de 0 a 15. Se o n√∫mero correspondente n√£o for 15, presume-se que seja o comprimento do literal e da correspond√™ncia, respectivamente.  E se tiver 15 anos, o comprimento ser√° maior e ser√° codificado nos seguintes bytes.  Em seguida, o pr√≥ximo byte √© lido e seu valor √© adicionado ao comprimento.  Se for igual a 255, o mesmo ser√° feito com o pr√≥ximo byte. <br><br>  Observe que a taxa m√°xima de compacta√ß√£o para o formato LZ4 n√£o atinge 255. E outra observa√ß√£o in√∫til √© que, se seus dados forem muito redundantes, o uso do LZ4 duas vezes melhorar√° a taxa de compacta√ß√£o. <br><br>  Quando lemos o comprimento de um literal (e, em seguida, o comprimento e o deslocamento da correspond√™ncia), basta copiar dois blocos de mem√≥ria para descompact√°-lo. <br><br><h3>  Como copiar um bloco de mem√≥ria </h3><br>  Parece que voc√™ poderia apenas usar a fun√ß√£o <code>memcpy</code> , projetada para copiar blocos de mem√≥ria.  Mas essa n√£o √© a abordagem ideal e n√£o √© realmente apropriada. <br><br>  O uso do memcpy n√£o √© ideal porque: <br><br><ol><li>  Ele geralmente est√° localizado na biblioteca libc (e a biblioteca libc geralmente √© vinculada dinamicamente, portanto a chamada memcpy ser√° feita indiretamente via PLT). </li><li>  N√£o √© incorporado pelo compilador se o argumento de tamanho for desconhecido no momento da compila√ß√£o. </li><li>  Faz muito esfor√ßo para processar corretamente as sobras de um bloco de mem√≥ria que n√£o s√£o m√∫ltiplos do comprimento ou registro de palavras da m√°quina. </li></ol><br>  O √∫ltimo ponto √© o mais importante.  Digamos que pedimos √† fun√ß√£o memcpy para copiar exatamente 5 bytes.  Seria √≥timo copiar 8 bytes imediatamente, usando duas instru√ß√µes movq. <br><br> <code>Hello world <font color="#0fc000">Hello</font> <font color="#ff0000">wo</font> ... <br> ^^^^^ <font color="#ff0000">^^^</font> - src <br> ^^^^^ <font color="#ff0000">^^^</font> - dst</code> <br> <br>  Mas, em seguida, copiaremos tr√™s bytes extras, e escreveremos fora dos limites do buffer.  A fun√ß√£o <code>memcpy</code> n√£o tem permiss√£o para fazer isso, porque pode sobrescrever alguns dados em nosso programa e levar a um erro de mem√≥ria.  E se escrev√™ssemos em um endere√ßo n√£o alinhado, esses bytes extras poderiam pousar em uma p√°gina n√£o alocada de mem√≥ria virtual ou em uma p√°gina sem acesso de grava√ß√£o.  Isso nos daria uma falha de segmenta√ß√£o (isso √© bom). <br><br>  Mas, no nosso caso, quase sempre podemos escrever bytes extras.  Podemos ler bytes extras no buffer de entrada, desde que os bytes extras estejam localizados inteiramente dentro dele.  Sob as mesmas condi√ß√µes, podemos gravar os bytes extras no buffer de sa√≠da, porque ainda os substituiremos na pr√≥xima itera√ß√£o. <br><br>  Essa otimiza√ß√£o j√° est√° na implementa√ß√£o original do LZ4: <br><br><pre> <code class="plaintext hljs">inline void copy8(UInt8 * dst, const UInt8 * src) {    memcpy(dst, src, 8); /// Note that memcpy isn't actually called here. } inline void wildCopy8(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy8(dst, src);        dst += 8;        src += 8;    } while (dst &lt; dst_end); }</code> </pre> <br>  Para tirar proveito dessa otimiza√ß√£o, precisamos apenas garantir que estamos longe o suficiente dos limites do buffer.  Isso n√£o deve custar nada, porque j√° estamos verificando o estouro de buffer.  E o processamento dos √∫ltimos bytes, os dados "restantes", pode ser feito ap√≥s o loop principal. <br><br>  No entanto, ainda existem algumas nuances.  A c√≥pia ocorre duas vezes no loop: com um literal e uma correspond√™ncia.  No entanto, ao usar a fun√ß√£o <code>LZ4_decompress_fast</code> (em vez de <code>LZ4_decompress_safe</code> ), a verifica√ß√£o √© realizada apenas uma vez, quando √© necess√°rio copiar o literal.  A verifica√ß√£o n√£o √© realizada ao copiar a partida, mas a <a href="">especifica√ß√£o para o formato LZ4</a> possui condi√ß√µes que permitem evit√°-la: <br><br><blockquote>  Os √∫ltimos 5 bytes s√£o sempre literais. <br>  A √∫ltima correspond√™ncia deve iniciar pelo menos 12 bytes antes do final do bloco. <br>  Conseq√ºentemente, um bloco com menos de 13 bytes n√£o pode ser compactado. </blockquote><br>  Dados de entrada especialmente selecionados podem levar √† corrup√ß√£o de mem√≥ria.  Se voc√™ usar a fun√ß√£o <code>LZ4_decompress_fast</code> , precisar√° de prote√ß√£o contra dados incorretos.  No m√≠nimo, voc√™ deve calcular somas de verifica√ß√£o para os dados compactados.  Se voc√™ precisar de prote√ß√£o contra hackers, use a fun√ß√£o <code>LZ4_decompress_safe</code> .  Outras op√ß√µes: use uma fun√ß√£o hash criptogr√°fica como soma de verifica√ß√£o (embora isso provavelmente destrua o desempenho);  alocar mais mem√≥ria para buffers;  aloque mem√≥ria para buffers com uma chamada <code>mmap</code> separada e crie uma p√°gina de prote√ß√£o. <br><br>  Quando vejo o c√≥digo que copia 8 bytes de dados, pergunto-me imediatamente por que exatamente 8 bytes.  Voc√™ pode copiar 16 bytes usando registros SSE: <br><br><pre> <code class="plaintext hljs">inline void copy16(UInt8 * dst, const UInt8 * src) { #if __SSE2__    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(dst),        _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(src))); #else    memcpy(dst, src, 16); #endif } inline void wildCopy16(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy16(dst, src);        dst += 16;        src += 16;    } while (dst &lt; dst_end); }</code> </pre> <br>  O mesmo funciona para copiar 32 bytes para o AVX e 64 bytes para o AVX-512.  Al√©m disso, voc√™ pode desenrolar o loop v√°rias vezes.  Se voc√™ j√° examinou como o <code>memcpy</code> √© implementado, essa √© exatamente a abordagem usada.  (A prop√≥sito, o compilador n√£o desenrolar√° ou vetorizar√° o loop nesse caso, porque isso exigir√° a inser√ß√£o de verifica√ß√µes volumosas.) <br><br>  Por que a implementa√ß√£o original do LZ4 n√£o fez isso?  Primeiro, n√£o est√° claro se isso √© melhor ou pior.  O ganho resultante depende do tamanho dos blocos a serem copiados; portanto, se todos forem curtos, isso criaria trabalho extra por nada.  E segundo, arruina as disposi√ß√µes no formato LZ4 que ajudam a evitar uma ramifica√ß√£o desnecess√°ria no loop interno. <br><br>  No entanto, manteremos essa op√ß√£o em mente por enquanto. <br><br><h3>  C√≥pia complicada </h3><br>  Vamos voltar √† quest√£o de se √© sempre poss√≠vel copiar dados dessa maneira.  Digamos que precisamos copiar uma correspond√™ncia, ou seja, pegar um peda√ßo de mem√≥ria do buffer de sa√≠da localizado em algum deslocamento atr√°s do cursor e copi√°-lo para a posi√ß√£o do cursor. <br><br>  Imagine um caso simples quando voc√™ precisa copiar 5 bytes em um deslocamento de 12: <br><br> <code><font color="#0fc000">Hello</font> world ........... <br> ^^^^^ - src <br> ^^^^^ - dst <br> <br> Hello world <font color="#0fc000">Hello</font> <font color="#a8a8a8">wo</font> ... <br> ^^^^^ - src <br> ^^^^^ - dst</code> <br> <br>  Mas h√° um caso mais dif√≠cil, quando precisamos copiar um bloco de mem√≥ria maior que o deslocamento.  Em outras palavras, inclui alguns dados que ainda n√£o foram gravados no buffer de sa√≠da. <br><br>  Copie 10 bytes com um deslocamento de 3: <br><br> <code><font color="#0fc000">abc</font> ............. <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst <br> <br> abc <font color="#0fc000">abcabcabca</font> ... <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst</code> <br> <br>  Temos todos os dados durante o processo de compacta√ß√£o e √© poss√≠vel encontrar essa correspond√™ncia.  A fun√ß√£o <code>memcpy</code> n√£o √© adequada para copi√°-la, porque n√£o suporta o caso quando faixas de blocos de mem√≥ria se sobrep√µem.  A fun√ß√£o <code>memmove</code> tamb√©m n√£o funcionar√°, porque o bloco de mem√≥ria que os dados devem ser extra√≠dos ainda n√£o foi totalmente inicializado.  Precisamos copiar da mesma maneira como se estiv√©ssemos copiando byte a byte. <br><br><pre> <code class="plaintext hljs">op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; ...</code> </pre> <br>  Veja como funciona: <br><br> <code><font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ............ <br> ^ - src <br> ^ - dst <br> <br> a <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........... <br> ^ - src <br> ^ - dst <br> <br> ab <font color="#0fc000">c</font> ab <font color="#0fc000">c</font> .......... <br> ^ - src <br> ^ - dst <br> <br> abc <font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ......... <br> ^ - src <br> ^ - dst <br> <br> abca <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........ <br> ^ - src <br> ^ - dst</code> <br> <br>  Em outras palavras, devemos criar uma sequ√™ncia repetida.  A implementa√ß√£o original do LZ4 usou um c√≥digo surpreendentemente estranho para fazer isso: <br><br><pre> <code class="plaintext hljs">const unsigned dec32table[] = {0, 1, 2, 1, 4, 4, 4, 4}; const int dec64table[] = {0, 0, 0, -1, 0, 1, 2, 3}; const int dec64 = dec64table[offset]; op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; match += dec32table[offset]; memcpy(op+4, match, 4); match -= dec64;</code> </pre> <br>  Ele copia os 4 primeiros bytes, um por um, avan√ßa por algum n√∫mero m√°gico, copia completamente os pr√≥ximos 4 bytes e move o cursor para uma correspond√™ncia usando outro n√∫mero m√°gico.  O autor do c√≥digo ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Yan Collet</a> ) se esqueceu de deixar um coment√°rio sobre o que isso significa.  Al√©m disso, os nomes das vari√°veis ‚Äã‚Äãs√£o confusos.  Ambos s√£o nomeados dec ... table, mas um √© adicionado e o outro √© subtra√≠do.  Al√©m disso, um deles n√£o √© assinado e o outro √© int.  No entanto, o autor melhorou recentemente esse lugar no c√≥digo. <br><br>  Aqui est√° como ele realmente funciona.  Copiamos os 4 primeiros bytes, um de cada vez: <br><br> <code>abc <font color="#0fc000">abca</font> ......... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Agora podemos copiar 4 bytes de uma vez: <br><br> <code>abcabca <font color="#0fc000">bcab</font> ..... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Podemos continuar como de costume, copiando 8 bytes de uma vez: <br><br> <code>abcabcabcab <font color="#0fc000">cabcabca</font> ..... <br> ^^^^^^^^ - src <br> ^^^^^^^^ - dst</code> <br> <br>  Como todos sabemos por experi√™ncia pr√≥pria, √†s vezes a melhor maneira de entender o c√≥digo √© reescrev√™-lo.  Aqui est√° o que descobrimos: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap8(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    /// Or if 4 % n is zero, we use n.    /// It gives an equivalent result, but is more CPU friendly for unknown reasons.    static constexpr int shift1[] = { 0, 1, 2, 1, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[] = { 0, 0, 0, 1, 0, -1, -2, -3 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset]; }</code> </pre> <br>  Como esperado, isso n√£o altera o desempenho.  Eu realmente queria tentar otimiza√ß√£o para copiar 16 bytes de uma s√≥ vez. <br><br>  No entanto, isso complica o "caso especial" e faz com que seja chamado com mais frequ√™ncia (a condi√ß√£o de <code>offset &lt; 16</code> √© realizada pelo menos com a mesma frequ√™ncia que o <code>offset &lt; 8</code> ).  A c√≥pia de intervalos sobrepostos com c√≥pia de 16 bytes se parece com isso (apenas o come√ßo mostrado): <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    static constexpr int shift1[]        = { 0, 1, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[]        = { 0, 0, 0, 1, 0, -1, -2, -3, -4, 4, 4, 4, 4, 4, 4, 4 };    /// 16 % n - 8 % n    static constexpr int shift3[]        = { 0, 0, 0, -1, 0, -2, 2, 1, 8, -1, -2, -3, -4, -5, -6, -7 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset];    memcpy(op + 8, match, 8);    match += shift3[offset]; }</code> </pre> <br>  Esta fun√ß√£o pode ser implementada de forma mais eficaz?  Gostar√≠amos de encontrar uma instru√ß√£o SIMD m√°gica para um c√≥digo t√£o complexo, porque tudo o que queremos fazer √© escrever 16 bytes, que consiste inteiramente em alguns bytes de dados de entrada (de 1 a 15).  Ent√£o eles s√≥ precisam ser repetidos na ordem correta. <br><br>  Existe uma instru√ß√£o como esta chamada <code>pshufb</code> (bytes de embaralhamento compactado) que faz parte do SSSE3 (tr√™s S).  Ele aceita dois registros de 16 bytes.  Um dos registros cont√©m os dados de origem.  O outro possui o "seletor": cada byte cont√©m um n√∫mero de 0 a 15, dependendo do byte do registro de origem para obter o resultado.  Se o valor do byte do seletor for maior que 127, o byte correspondente do resultado ser√° preenchido com zero. <br><br>  Aqui est√° um exemplo: <br><br><pre>  xmm0: abc .............
 xmm1: 0120120120120120<font></font>
<font></font>
 pshufb% xmm1,% xmm0<font></font>
<font></font>
 xmm0: abcabcabcabcabca </pre><br>  Cada byte do resultado √© preenchido com o byte selecionado dos dados de origem - √© exatamente isso que precisamos!  Aqui est√° a apar√™ncia do c√≥digo no resultado: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16Shuffle(UInt8 * op, const UInt8 *&amp; match, const size_t offset) { #ifdef __SSSE3__    static constexpr UInt8 __attribute__((__aligned__(16))) masks[] =    {        0, 1, 2, 1, 4, 1, 4, 2, 8, 7, 6, 5, 4, 3, 2, 1, /* offset = 0, not used as mask, but for shift amount instead */        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, /* offset = 1 */        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,        0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,        0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,        0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1, 2,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0,    };    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(op),        _mm_shuffle_epi8(            _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(match)),            _mm_load_si128(reinterpret_cast&lt;const __m128i *&gt;(masks) + offset)));    match += masks[offset]; #else    copyOverlap16(op, match, offset); #endif }</code> </pre> <br>  Aqui <code>_mm_shuffle_epi8</code> √© um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">intr√≠nseco</a> , que √© compilado com as instru√ß√µes da CPU <code>pshufb</code> . <br><br>  Podemos executar esta opera√ß√£o para mais bytes de uma vez usando instru√ß√µes mais recentes?  Afinal, o SSSE3 √© um conjunto de instru√ß√µes muito antigo que existe desde 2006. O AVX2 possui uma instru√ß√£o que faz isso por 32 bytes de uma vez, mas separadamente para faixas individuais de 16 bytes.  Isso √© chamado de bytes permute de vetor, em vez de bytes aleat√≥rios compactados - as palavras s√£o diferentes, mas o significado √© o mesmo.  O AVX-512 VBMI possui outra instru√ß√£o que funciona para 64 bytes de uma vez, mas os processadores que o suportam apareceram apenas recentemente.  O ARM NEON possui instru√ß√µes semelhantes chamadas vtbl (pesquisa de tabela de vetores), mas elas permitem apenas a grava√ß√£o de 8 bytes. <br><br>  Al√©m disso, existe uma vers√£o da instru√ß√£o <code>pshufb</code> com registros MMX de 64 bits para formar 8 bytes.  √â o ideal para substituir a vers√£o original do c√≥digo.  No entanto, decidi usar a op√ß√£o de 16 bytes (por motivos s√©rios). <br><br>  Na confer√™ncia Highload ++ Siberia, um participante veio at√© mim ap√≥s a minha apresenta√ß√£o e mencionou que, para o caso de 8 bytes, voc√™ pode simplesmente usar a multiplica√ß√£o por uma constante especialmente selecionada (voc√™ tamb√©m precisar√° de um deslocamento) - isso nem havia ocorrido. para mim antes! <br><br><h3>  Como remover uma declara√ß√£o if sup√©rflua </h3><br>  Digamos que eu queira usar uma variante que copie 16 bytes.  Como evitar a verifica√ß√£o adicional do estouro de buffer? <br><br>  Eu decidi que simplesmente n√£o faria essa verifica√ß√£o.  Os coment√°rios sobre a fun√ß√£o dir√£o que o desenvolvedor deve alocar um bloco de mem√≥ria para um n√∫mero especificado de bytes mais do que o necess√°rio, para que possamos ler e gravar lixo desnecess√°rio l√°.  A interface da fun√ß√£o ser√° mais dif√≠cil de usar, mas esse √© um problema diferente. <br><br>  Na verdade, pode haver consequ√™ncias negativas.  Digamos que os dados que precisamos descomprimir foram formados a partir de blocos de 65.536 bytes cada.  Em seguida, o usu√°rio nos fornece um peda√ßo de mem√≥ria com 65.536 bytes para os dados descomprimidos.  Por√©m, com a nova interface de fun√ß√£o, o usu√°rio precisar√° alocar um bloco de mem√≥ria com 65.551 bytes, por exemplo.  Em seguida, o alocador pode ser for√ßado a alocar 96 ou mesmo 128 kilobytes, dependendo de sua implementa√ß√£o.  Se o alocador estiver muito ruim, pode parar subitamente em cache a mem√≥ria no "heap" e come√ßar a usar o <code>mmap</code> e o <code>munmap</code> sempre para aloca√ß√£o de mem√≥ria (ou liberar mem√≥ria usando <code>madvice</code> ).  Esse processo ser√° extremamente lento devido a falhas na p√°gina.  Como resultado, esse pouco de otimiza√ß√£o pode acabar atrasando tudo. <br><br><h3>  Existe alguma acelera√ß√£o? </h3><br>  Ent√£o, eu fiz uma vers√£o do c√≥digo que usa tr√™s otimiza√ß√µes: <br><br><ol><li>  Copiando 16 bytes em vez de 8. </li><li>  Usando as instru√ß√µes de reprodu√ß√£o aleat√≥ria para o caso de <code>offset &lt; 16</code> . </li><li>  Removido um extra se. </li></ol><br>  Comecei a testar esse c√≥digo em diferentes conjuntos de dados e obtive resultados inesperados. <br><br>  Exemplo 1: <br>  Xeon E2650v2, dados do Yandex Browser, coluna AppVersion. <br>  Refer√™ncia: 1,67 GB / seg. <br>  16 bytes, aleat√≥rio: 2,94 GB / s (76% mais r√°pido). <br><br>  Exemplo 2: <br>  Xeon E2650v2, dados Yandex Direct, coluna ShowsSumPosition. <br>  Refer√™ncia: 2,30 GB / seg. <br>  16 bytes, aleat√≥rio: 1,91 GB / s (20% mais lento). <br><br>  Fiquei muito feliz no come√ßo, quando vi que tudo havia acelerado em uma porcentagem t√£o grande.  Ent√£o vi que nada era mais r√°pido com outros arquivos.  Foi um pouco mais lento para alguns deles.  Conclu√≠ que os resultados dependem da taxa de compress√£o.  Quanto mais compactado o arquivo, maior a vantagem de mudar para 16 bytes.  Isso parece natural: quanto maior a taxa de compacta√ß√£o, maior o comprimento m√©dio dos fragmentos a serem copiados. <br><br>  Para investigar, usei modelos C ++ para fazer op√ß√µes de c√≥digo para quatro casos: usando peda√ßos de 8 ou 16 bytes e com ou sem a instru√ß√£o de reprodu√ß√£o aleat√≥ria. <br><br><pre> <code class="plaintext hljs">template &lt;size_t copy_amount, bool use_shuffle&gt; void NO_INLINE decompressImpl(    const char * const source,    char * const dest,    size_t dest_size)</code> </pre> <br>  Variantes completamente diferentes do c√≥digo tiveram um desempenho melhor em arquivos diferentes, mas ao testar em uma √°rea de trabalho, a vers√£o com shuffle sempre venceu.  Testar em uma √°rea de trabalho √© inconveniente porque voc√™ precisa fazer isso: <br><br><pre> <code class="plaintext hljs">sudo echo 'performance' | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor kill -STOP $(pidof firefox) $(pidof chromium)</code> </pre> <br>  Ent√£o eu fui em um dos antigos servidores de "desenvolvimento" (com o processador Xeon E5645), peguei ainda mais conjuntos de dados e obtive resultados quase opostos, o que me confundiu totalmente.  Acontece que a escolha do algoritmo ideal depende do modelo do processador, al√©m da taxa de compress√£o.  O processador determina quando √© melhor usar a instru√ß√£o aleat√≥ria, bem como o limite para quando come√ßar a usar a c√≥pia de 16 bytes. <br><br>  A prop√≥sito, ao testar em nossos servidores, faz sentido fazer isso: <br><br><pre> <code class="plaintext hljs">sudo kill -STOP $(pidof python) $(pidof perl) $(pgrep -u skynet) $(pidof cqudp-client)</code> </pre> <br>  Caso contr√°rio, os resultados ser√£o inst√°veis.  Tamb√©m tenha cuidado com a acelera√ß√£o t√©rmica e o limite de pot√™ncia. <br><br><h3>  Como escolher o melhor algoritmo </h3><br>  Portanto, temos quatro variantes do algoritmo e precisamos escolher a melhor para as condi√ß√µes.  Poder√≠amos criar um conjunto representativo de dados e hardware, realizar testes de carga s√©rios e escolher o melhor m√©todo, em m√©dia.  Mas n√£o temos um conjunto de dados representativo.  Para o teste, usei uma amostra de dados do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Yandex Metrica</a> , Yandex Direct, Yandex Browser e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">voos nos Estados Unidos</a> .  Mas isso n√£o √© suficiente, porque o ClickHouse √© usado por centenas de empresas em todo o mundo.  Ao otimizar demais um conjunto de dados, podemos causar uma queda no desempenho com outros dados e nem perceb√™-lo.  E se os resultados dependerem do modelo do processador, teremos que escrever explicitamente as condi√ß√µes no c√≥digo e test√°-lo em cada modelo (ou consultar o manual de refer√™ncia sobre instru√ß√µes de tempo, o que voc√™ acha?).  Em ambos os casos, isso consome muito tempo. <br><br>  Por isso, decidi usar outro m√©todo, o que √© √≥bvio para os colegas que estudaram em nossa Escola de An√°lise de Dados: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"bandidos armados"</a> .  O ponto √© que a variante do algoritmo √© escolhida aleatoriamente e, em seguida, usamos a estat√≠stica para escolher progressivamente mais frequentemente as op√ß√µes com melhor desempenho. <br><br>  Como temos muitos blocos de dados que precisam ser descompactados, precisamos de chamadas de fun√ß√£o independentes para descomprimir dados.  Poder√≠amos escolher um dos quatro algoritmos para cada bloco e medir seu tempo de execu√ß√£o.  Uma opera√ß√£o como essa geralmente n√£o custa nada em compara√ß√£o com o processamento de um bloco de dados e, no ClickHouse, um bloco de dados n√£o compactados tem pelo menos 64 KB.  (Leia este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> sobre como medir o tempo.) <br><br>  Para entender melhor como o algoritmo de "bandidos multi-armados" funciona, vejamos de onde vem o nome.  Esta √© uma analogia com as m√°quinas ca√ßa-n√≠queis em um cassino que possuem v√°rias alavancas que um jogador pode usar para obter uma quantia aleat√≥ria de dinheiro.  O jogador pode puxar as alavancas v√°rias vezes em qualquer ordem.  Cada alavanca tem uma probabilidade fixa para a quantidade correspondente de dinheiro distribu√≠da, mas o jogador n√£o sabe como funciona e s√≥ pode aprender com a experi√™ncia de jogar o jogo.  Depois de descobrir, eles podem maximizar seus ganhos. <br><br>  Uma abordagem para maximizar a recompensa √© avaliar a distribui√ß√£o de probabilidade de cada alavanca em cada etapa, com base nas estat√≠sticas do jogo das etapas anteriores.  Ent√£o "mentalmente" ganhamos uma recompensa aleat√≥ria para cada alavanca, com base nas distribui√ß√µes recebidas.  Finalmente, puxamos a alavanca que teve o melhor resultado em nosso jogo mental.  Essa abordagem √© chamada Thompson Sampling. <br><br>  Mas estamos escolhendo um algoritmo de descompress√£o.  O resultado √© o tempo de execu√ß√£o em picossegundos por byte: quanto menos, melhor.  Vamos considerar o tempo de execu√ß√£o como uma vari√°vel aleat√≥ria e avaliar sua distribui√ß√£o usando estat√≠sticas matem√°ticas.  A abordagem bayesiana √© frequentemente usada para tarefas como essa, mas seria complicado inserir f√≥rmulas complexas no c√≥digo C ++.  Podemos usar uma abordagem param√©trica e dizer que uma vari√°vel aleat√≥ria pertence a uma fam√≠lia param√©trica de vari√°veis ‚Äã‚Äãaleat√≥rias e depois avaliar seus par√¢metros. <br><br>  Como selecionamos a fam√≠lia de vari√°veis ‚Äã‚Äãaleat√≥rias?  Como exemplo, podemos supor que o tempo de execu√ß√£o do c√≥digo tenha distribui√ß√£o normal.  Mas isso est√° absolutamente errado.  Primeiro, o tempo de execu√ß√£o n√£o pode ser negativo e a distribui√ß√£o normal leva valores para todos os lugares da linha num√©rica.  Segundo, presumo que o tempo de execu√ß√£o ter√° uma "cauda" pesada na extremidade direita. <br><br>  No entanto, existem fatores que podem tornar uma boa id√©ia estimar a distribui√ß√£o normal apenas para os fins da Thompson Sampling (apesar do fato de que a distribui√ß√£o da vari√°vel de destino n√£o √© necessariamente normal).  A raz√£o para isso √© que √© muito f√°cil calcular a expectativa matem√°tica e a varia√ß√£o e, ap√≥s um n√∫mero suficiente de itera√ß√µes, uma distribui√ß√£o normal se torna bastante estreita, n√£o muito diferente das distribui√ß√µes que ter√≠amos obtido usando outros m√©todos.  Se n√£o estamos muito preocupados com a taxa de converg√™ncia nas primeiras etapas, esses detalhes podem ser ignorados. <br><br> This may seem like a somewhat ignorant approach. Experience has shown us that the average time for query execution, website page loading, and so on is "garbage" that isn't worth calculating. It would be better to calculate the median, which is a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">robust statistic</a> . But this is a little more difficult, and as I will show later, the described method justifies itself for practical purposes. <br><br> At first I implemented calculation of the mathematical expectation and variance, but then I decided that this is too good, and I need to simplify the code to make it "worse": <br><br><pre> <code class="plaintext hljs">/// For better convergence, we don't use proper estimate of stddev. /// We want to eventually separate the two algorithms even in cases /// when there is no statistical significant difference between them. double sigma() const {    return mean() / sqrt(adjustedCount()); } double sample(pcg64 &amp; rng) const {    ...    return std::normal_distribution&lt;&gt;(mean(), sigma())(rng); }</code> </pre> <br> I wrote it so that the first few iterations were not taken into account, to eliminate the effect of memory latencies. <br><br> The result is a test program that can select the best algorithm for the input data, with optional modes that use the reference implementation of LZ4 or a specific version of the algorithm. <br><br> So there are six options: <br> ‚Äî Reference (baseline): original LZ4 without our modifications. <br> ‚Äî Variant 0: copy 8 bytes at a time without shuffle. <br> ‚Äî Variant 1: copy 8 bytes at a time with shuffle. <br> ‚Äî Variant 2: copy 16 bytes at a time without shuffle. <br> ‚Äî Variant 3: copy 16 bytes at a time with shuffle. <br> ‚Äî The "bandit" option, which selects the best of the four optimized variants. <br><br><h3> Testing on different CPUs </h3><br> If the result strongly depends on the CPU model, it would be interesting to find out exactly how it is affected. There might be an exceptionally large difference on certain CPUs. <br><br> I prepared a set of datasets from different tables in ClickHouse with real data, for a total of 256 different files each with 100 MB of uncompressed data (the number 256 was coincidental). Then I looked at the CPUs of the servers where I can run benchmarks. I found servers with the following CPUs: <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2650 v2 @ 2.60GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 v4 @ 2.00GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 0 @ 2.20GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5645 @ 2.40GHz <br> ‚Äî Intel Xeon E312xx (Sandy Bridge) <br> ‚Äî AMD Opteron(TM) Processor 6274 <br> ‚Äî AMD Opteron(tm) Processor 6380 <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2683 v4 @ 2.10GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5530 @ 2.40GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5440 @ 2.83GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2667 v2 @ 3.30GHz <br><br> The most interesting part comes next ‚Äî the processors provided by the R&amp;D department: <br> ‚Äî AMD EPYC 7351 16-Core Processor, a new AMD server processor. <br> ‚Äî Cavium ThunderX2, which is AArch64, not x86. For these, my SIMD optimization needed to be reworked a bit. The server has 224 logical and 56 physical cores. <br><br> There are 13 servers in total, and each of them runs the test on 256 files in 6 variants (reference, 0, 1, 2, 3, adaptive). The test is run 10 times, alternating between the options in random order. It outputs 199,680 results that we can compare. <br><br> For example, we can compare different CPUs with each other. But we shouldn't jump to conclusions from these results, because we are only testing the LZ4 decompression algorithm on a single core (this is a very narrow case, so we only get a micro-benchmark). For example, the Cavium has the lowest performance per single core. But I tested ClickHouse on it myself, and it wins out over Xeon E5-2650 v2 on heavy queries due to the greater number of cores, even though it is missing many optimizations that are made in ClickHouse specifically for the x86. <br><br><pre> ‚îå‚îÄcpu‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄref‚îÄ‚î¨‚îÄadapt‚îÄ‚î¨‚îÄ‚îÄmax‚îÄ‚î¨‚îÄbest‚îÄ‚î¨‚îÄadapt_boost‚îÄ‚î¨‚îÄmax_boost‚îÄ‚î¨‚îÄadapt_over_max‚îÄ‚îê<font></font>
‚îÇ E5-2667 v2 @ 3.30GHz ‚îÇ 2.81 ‚îÇ 3.19 ‚îÇ 3.15 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2650 v2 @ 2.60GHz ‚îÇ 2.5 ‚îÇ 2.84 ‚îÇ 2.81 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2683 v4 @ 2.10GHz ‚îÇ 2.26 ‚îÇ 2.63 ‚îÇ 2.59 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.15 ‚îÇ 1.02 ‚îÇ<font></font>
‚îÇ E5-2660 v4 @ 2.00GHz ‚îÇ 2.15 ‚îÇ 2.49 ‚îÇ 2.46 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.14 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD EPYC 7351 ‚îÇ 2.03 ‚îÇ 2.44 ‚îÇ 2.35 ‚îÇ 3 ‚îÇ 1.20 ‚îÇ 1.16 ‚îÇ 1.04 ‚îÇ<font></font>
‚îÇ E5-2660 0 @ 2.20GHz ‚îÇ 2.13 ‚îÇ 2.39 ‚îÇ 2.37 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E312xx (Sandy Bridge) ‚îÇ 1.97 ‚îÇ 2.2 ‚îÇ 2.18 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5530 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.93 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.17 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ E5645 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.92 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ AMD Opteron 6380 ‚îÇ 1.47 ‚îÇ 1.58 ‚îÇ 1.56 ‚îÇ 1 ‚îÇ 1.07 ‚îÇ 1.06 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD Opteron 6274 ‚îÇ 1.15 ‚îÇ 1.35 ‚îÇ 1.35 ‚îÇ 1 ‚îÇ 1.17 ‚îÇ 1.17 ‚îÇ 1 ‚îÇ<font></font>
‚îÇ E5440 @ 2.83GHz ‚îÇ 1.35 ‚îÇ 1.33 ‚îÇ 1.42 ‚îÇ 1 ‚îÇ 0.99 ‚îÇ 1.05 ‚îÇ 0.94 ‚îÇ<font></font>
‚îÇ Cavium ThunderX2 ‚îÇ 0.84 ‚îÇ 0.87 ‚îÇ 0.87 ‚îÇ 0 ‚îÇ 1.04 ‚îÇ 1.04 ‚îÇ 1 ‚îÇ<font></font>
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò </pre><br><ul><li> ref, adapt, max ‚Äî The speed in gigabytes per second (the value that is the reverse of the arithmetic mean of time for all launches on all datasets). </li><li> best ‚Äî The number of the best algorithm among the optimized variants, from 0 to 3. </li><li> adapt_boost ‚Äî The relative advantage of the adaptive algorithm compared to the baseline. </li><li> max_boost ‚Äî The relative advantage of the best of the non-adaptive variants compared to the baseline. </li><li> adapt_over_max ‚Äî The relative advantage of the adaptive algorithm over the best non-adaptive one. </li></ul><br> The results show that we were able to speed up decompression by 12-20% on modern x86 processors. Even on ARM we saw 4% improvement, despite the fact that we didn't optimize much for this architecture. It is also clear that on average for different datasets, the "bandit" algorithm comes out ahead of the pre-selected best variant on all processors (except for very old Intel CPUs). <br><br><h3>  Conclus√£o </h3><br> In practice, the usefulness of this work is dubious. Yes, LZ4 decompression was accelerated on average by 12-20%, and on some datasets the performance more than doubled. But in general, this doesn't have much effect on query execution time. It's difficult to find real queries that gain more than a couple percent in speed. <br><br> We decided to use ZStandard level 1 instead of LZ4 on several Yandex Metrica clusters intended for executing long queries, because it is more important to save IO and disk space on cold data. Keep this in mind if you have similar workload. <br><br> We observed the greatest benefits from optimizing decompression in highly compressible data, such as columns with mostly duplicate string values. However, we have developed a separate solution specifically for this scenario that allows us to significantly speed up queries over this kind of data. <br><br> Another point to remember is that optimization of decompression speed is often limited by the format of the compressed data. LZ4 uses a very good format, but Lizard, Density and LZSSE have other formats that can work faster. Perhaps instead of trying to accelerate LZ4, it would be better to just integrate LZSSE into ClickHouse. <br><br> It's unlikely that these optimizations will be implemented in the mainstream LZ4 library: in order to use them, the library interface would have to be modified. In fact, this is often the case with improving algorithms ‚Äî optimizations don't fit into old abstractions and they have to be revised. However, variable names have already been corrected in the original implementation. For instance, inc and dec tables have been <a href="">corrected</a> . In addition, about a month ago, the original implementation accelerated decompression by the same 12-15% by copying 32 bytes instead of 16, as discussed above. We tried the 32-byte option ourselves and the results were not that great, but they were still <a href="">faster</a> . <br><br> If you look at the profile at the beginning of the article, you may notice that we could have removed one extra copying operation from the page cache to userspace (either using <code>mmap</code> , or using <code>O_DIRECT</code> and userspace page cache, but both options are problematic). We also could have slightly improved the checksum calculation (CityHash128 is currently used without CRC32-C, but we could use HighwayHash, FARSH or XXH3). Acceleration of these two operations is useful for weakly compressed data, since they are performed on compressed data. <br><br> In any case, the changes have already been added to master more than a year ago, and the ideas that resulted from this research have been applied in other tasks. You can also watch the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">video</a> from HighLoad++ Siberia, or view the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">presentation</a> (both in Russian). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt457612/">https://habr.com/ru/post/pt457612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt457600/index.html">Vis√£o geral dos fones de ouvido Snom A150, Snom A100M e D</a></li>
<li><a href="../pt457602/index.html">Pesquisando o desempenho do DBMS MS SQL Server Developer 2016 e PostgreSQL 10.5 para 1C</a></li>
<li><a href="../pt457606/index.html">Alan Kay: O que pode ser chamado a coisa mais incr√≠vel que os computadores tornaram poss√≠vel</a></li>
<li><a href="../pt457608/index.html">Como visualizar dados em uma hist√≥ria atraente</a></li>
<li><a href="../pt457610/index.html">An√°lise de vulnerabilidades do Evil Parcel</a></li>
<li><a href="../pt457614/index.html">Segredos de encontrar um emprego no exterior de um headhunter praticante</a></li>
<li><a href="../pt457616/index.html">Meu "Uau, eu n√£o sabia disso!" momentos com brincadeira</a></li>
<li><a href="../pt457618/index.html">Ser um desenvolvedor full-stack moderno</a></li>
<li><a href="../pt457622/index.html">Medindo o desempenho do Qt</a></li>
<li><a href="../pt457624/index.html">Como quebramos a velha cabana e constru√≠mos um arranha-c√©u em seu lugar</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
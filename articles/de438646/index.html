<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî∫ üìò üë®üèº‚Äçüåæ Informationen zum Erstellen von Budget-Stereobildern auf Fingern (Stereogramm, Anaglyphe, Stereoskop) üéè üòπ üßïüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Am n√§chsten Wochenende m√ºssen Sie ein paar Dutzend Codezeilen schreiben und ein Bild zeichnen, aber keines ist besser. Also habe ich letztes vorletzte...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Informationen zum Erstellen von Budget-Stereobildern auf Fingern (Stereogramm, Anaglyphe, Stereoskop)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438646/">  Am n√§chsten Wochenende m√ºssen Sie ein paar Dutzend Codezeilen schreiben und ein Bild zeichnen, aber keines ist besser.  Also habe ich letztes vorletztes Wochenende gezeigt, wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">man Raytracing macht</a> und sogar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">alles in die Luft jagt.</a>  Dies ist f√ºr viele √ºberraschend, aber Computergrafik ist eine sehr einfache Sache. Ein paar hundert Zeilen nacktes C ++ reichen aus, um interessante Bilder zu erstellen. <br><br>  Das Thema des heutigen Gespr√§chs ist das binokulare Sehen, und heute k√∂nnen wir nicht einmal hundert Codezeilen erreichen.  In der Lage zu sein, dreidimensionale Szenen zu rendern, w√§re es dumm, Stereopaare zu passieren. Heute werden wir so etwas zeichnen: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br>  Die Torheit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Magic Carpet-</a> Entwickler verfolgt mich.  F√ºr diejenigen, die es nicht gefunden haben, erm√∂glichte dieses Spiel das 3D-Rendering sowohl in Anaglyphen als auch in Stereogrammen <b>in den Haupteinstellungen, die nur im Men√º verf√ºgbar sind!</b>  Dieses Gehirn explodierte nur speziell. <br><br><h1>  Parallaxe </h1><br>  Also fangen wir an.  Warum erlaubt uns unser visueller Apparat f√ºr den Anfang, Tiefe wahrzunehmen?  Es gibt so ein kluges Wort "Parallaxe".  Wenn an den Fingern, dann konzentrieren wir uns auf den Bildschirm.  Alles, was sich in der Ebene des Bildschirms f√ºr unser Gehirn befindet, ist in einer einzigen Kopie vorhanden.  Aber wenn pl√∂tzlich eine Fliege vor dem Bildschirm fliegt, dann (wenn wir unsere Augen nicht √§ndern!) Wird unser Gehirn sie doppelt registrieren.  Gleichzeitig teilt sich auch die Spinne an der Wand hinter dem Bildschirm, und die Richtung der Gabelung h√§ngt davon ab, ob sich das Objekt vor oder hinter dem Brennpunkt befindet: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Unser Gehirn ist eine sehr effiziente Maschine zur Analyse leicht unterschiedlicher Bilder.  Es verwendet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Disparit√§t</a> , um Tiefeninformationen aus zweidimensionalen Netzhautbildern f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stereopsis zu erhalten</a> .  Nun, Gott segne sie mit den Worten, lasst uns besser Bilder zeichnen! <br><br>  Nehmen wir an, unser Bildschirm ist ein Fenster in die virtuelle Welt :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Unsere Aufgabe ist es, zwei Bilder mit dem zu zeichnen, was durch dieses ‚ÄûFenster‚Äú sichtbar wird.  Es gibt zwei Bilder, eines f√ºr jedes Auge. In der Abbildung oben habe ich sie mit einem rot-blauen ‚ÄûSandwich‚Äú gezeigt.  Lassen Sie uns noch nicht st√∂ren, wie genau wir diese Bilder dem visuellen Apparat zuf√ºhren, wir m√ºssen nur zwei Dateien speichern.  Ich bin speziell daran interessiert, wie diese Bilder mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unserem Raytracer erhalten werden k√∂nnen</a> . <br><br>  Angenommen, die Blickrichtung √§ndert sich nicht, es handelt sich um einen Vektor (0,0, -1).  Angenommen, wir k√∂nnen die Position der Kamera um den Augenabstand verschieben. Was noch?  Es gibt eine kleine Subtilit√§t: Der Sichtkegel durch unser ‚ÄûFenster‚Äú ist asymmetrisch.  Und unser Raytracer kann nur einen symmetrischen Blickkegel rendern: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  Was tun?  Lesen :) <br>  Tats√§chlich k√∂nnen wir die Bilder breiter als n√∂tig rendern und nur den √úberschuss zuschneiden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyphe </h1><br>  Mit dem allgemeinen Rendering-Mechanismus sollte klar sein, dass es jetzt an der Zeit ist, uns die Frage der Bildlieferung an unser Gehirn zu stellen.  Eine der einfachsten Optionen ist die rot-blaue Brille: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Wir machen nur die beiden Pre-Renderings nicht schwarz, sondern wei√ü, schreiben das linke Bild in den roten Kanal und das rechte Bild in blau.  Sie erhalten folgendes Bild: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  Rotes Glas schneidet einen Kanal ab und blaues Glas schneidet einen anderen ab, so dass jedes Auge sein eigenes Bild erh√§lt und wir die Welt in 3D betrachten k√∂nnen.  Hier sind die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√Ñnderungen am Haupt-Commit des ersten Artikels</a> , in denen sowohl die Kameraeinstellungen f√ºr beide Augen als auch die Kanalbaugruppe angezeigt werden. <br><br>  Anaglyphen-Renderings sind eine der √§ltesten M√∂glichkeiten, (Computer!) Stereobilder anzuzeigen.  Sie haben viele M√§ngel, zum Beispiel eine schlechte Farbwiedergabe (versuchen Sie √ºbrigens, den gr√ºnen Kanal des rechten Auges im gr√ºnen Kanal des endg√ºltigen Bildes aufzuzeichnen).  Ein Vorteil: Solche Gl√§ser lassen sich leicht aus improvisierten Materialien herstellen. <br><br><h1>  Stereoskop </h1><br>  Mit der Verbreitung von Smartphones erinnerten wir uns daran, was Stereoskope sind (die f√ºr eine Sekunde im 19. Jahrhundert erfunden wurden)!  Vor einigen Jahren schlug <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google vor</a> , zwei Penny-Objektive (leider nicht am Knie), Pappe (√ºberall herumliegend) und ein Smartphone (in der Tasche liegend) zu verwenden, um eine ziemlich ertr√§gliche Virtual-Reality-Brille zu erhalten: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Auf aliexpress waren es Haufen, hundert Rubel pro St√ºck.  Im Vergleich zur Anaglyphe m√ºssen Sie √ºberhaupt nichts tun. Nehmen Sie einfach zwei Bilder auf und komponieren Sie sie nebeneinander. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist das Commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  Genau genommen kann je nach Objektiv eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Korrektur</a> der Objektivverzerrung erforderlich sein, aber ich habe mich √ºberhaupt nicht darum gek√ºmmert und sie sieht auf meiner Brille gro√üartig aus.  Wenn Sie jedoch wirklich eine tonnenf√∂rmige Vorverzerrung anwenden m√ºssen, die die Verzerrung des Objektivs ausgleicht, sieht dies f√ºr mein Smartphone und meine Brille folgenderma√üen aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br><h1>  Stereogramme </h1><br>  Was aber, wenn Sie keine zus√§tzlichen Ger√§te verwenden m√∂chten?  Dann gibt es nur eine Option - zu bet√§uben.  Im Allgemeinen reicht das vorherige Bild aus, um Stereo anzusehen. Verwenden Sie einfach den Trick, um Stereo anzusehen.  Es gibt zwei Prinzipien zum Anzeigen von Stereogrammen: Bewegen Sie entweder Ihre Augen oder bewegen Sie Ihre Augen auseinander.  Also habe ich ein Diagramm gezeichnet, in dem ich zeige, wie Sie das vorherige Bild betrachten k√∂nnen.  Das vorherige Bild ist doppelt, zwei rote Balken im Diagramm zeigen zwei Bilder auf der linken Netzhaut, zwei blaue auf der rechten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Wenn wir unsere Augen auf den Bildschirm richten, erhalten wir von vier Bildern zwei.  Wenn wir unsere Augen zur Nase blinzeln, ist es durchaus m√∂glich, dem Gehirn ‚Äûdrei‚Äú Bilder zu zeigen.  Und umgekehrt, wenn Sie Ihre Augen √∂ffnen, k√∂nnen Sie auch "drei" Bilder erhalten.  Durch √úberlagerung zentraler Bilder erh√§lt das Gehirn einen Stereoeffekt. <br><br>  Diese Methoden werden verschiedenen Menschen auf unterschiedliche Weise gegeben, zum Beispiel wei√ü ich √ºberhaupt nicht, wie ich meine Augen bewegen soll, aber ich z√ºchte leicht.  Es ist wichtig, dass das f√ºr eine Methode erstellte Stereogramm auf die gleiche Weise betrachtet wird, da sonst eine invertierte Tiefenkarte erhalten wird (siehe negative und positive Parallaxe).  Das Problem bei dieser Methode zum Betrachten von Stereo ist, dass es sehr schwierig ist <b>,</b> Ihre Augen relativ zum Normalzustand <b>stark zu</b> bewegen, sodass Sie sich mit kleinen Bildern zufrieden geben m√ºssen.  Und was ist, wenn Sie gro√üe wollen?  Lassen Sie uns die Farbe vollst√§ndig opfern und nur eine Wahrnehmung der Tiefe wollen.  Mit Blick auf die Zukunft sehen Sie hier das Bild am Ende dieses Teils: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Dieses Stereogramm dient zum ‚ÄûVerd√ºnnen‚Äú der Augen (Stereogramm mit Wandaugen).  F√ºr diejenigen, die die umgekehrte Sichtweise bevorzugen, machen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier ein Bild</a> .  Wenn Sie nicht an Stereogramme gew√∂hnt sind, probieren Sie verschiedene Bedingungen aus: ein Vollbild, ein kleines Bild, helles Licht, Dunkelheit.  Die Aufgabe besteht darin, die Augen so zu √∂ffnen, dass die beiden benachbarten Wirbelstreifen zusammenfallen.  Der einfachste Weg, sich oben links zu konzentrieren, ist  Sie ist flach.  Zum Beispiel bin ich von der Umgebung des Habr umgeben, ich √∂ffne das Bild im Vollbildmodus.  Vergessen Sie nicht, die Maus davon zu entfernen! <br><br>  Geben Sie sich nicht mit dem fehlerhaften 3D-Effekt zufrieden.  Wenn Sie sich der abgerundeten Formen in der Mitte zuf√§lliger Punkte und einiger schwacher 3D-Effekte nur vage bewusst sind, ist dies sicherlich eine unvollst√§ndige Illusion!  Wenn Sie richtig aussehen, sollten die Kugeln f√ºr den Betrachter deutlich aus der Bildschirmebene herausgehen. Der Effekt sollte stabil sein und erhalten bleiben, da jeder Teil des Bildes, sowohl der Vordergrund als auch der Hintergrund, st√§ndig und detailliert untersucht wird.  Stereopsis hat Hysterese: Sobald Sie ein stabiles Bild erhalten, wird es klarer, je l√§nger Sie schauen.  Je weiter der Bildschirm von den Augen entfernt ist, desto gr√∂√üer ist der Tiefeneffekt. <br><br>  Dieses Stereogramm wurde nach der vor einem Vierteljahrhundert von Thimbleby et al. Vorgeschlagenen Methode gezeichnet. In ihrem Artikel ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anzeigen von 3D-Bildern: Algorithmen f√ºr Einzelbild-Zufallspunktstereogramme</a> ‚Äú. <br><br><h3>  Ausgangspunkt </h3><br>  Der Ausgangspunkt f√ºr das Rendern von Stereogrammen ist eine Tiefenkarte (wir haben die Farbe vergessen).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist ein Commit</a> , das ein solches Bild <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ergibt</a> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Die Tiefen in unserem Render werden durch die nahen und fernen Ebenen abgeschnitten, dh der am weitesten entfernte Punkt in meiner Karte hat eine Tiefe von 0, der n√§chste. <br><br><h3>  Grundprinzip </h3><br>  Lassen Sie unsere Augen in einem Abstand d vom Bildschirm sein.  Platzieren Sie die (imagin√§re) Fernebene (z = 0) im gleichen Abstand hinter dem Bildschirm.  Wir w√§hlen eine Konstante Œº, die die Position der nahen Ebene bestimmt (z = 0): Sie befindet sich in einem Abstand Œºd von der fernen.  Ich habe in meinem Code Œº = 1/3 gew√§hlt.  Insgesamt lebt unsere ganze Welt in einer Entfernung von d-Œºd bis d hinter dem Bildschirm.  Lassen Sie uns einen Abstand e zwischen den Augen definieren (in Pixel, in meinem Code habe ich 400 Pixel gew√§hlt). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Wenn wir den Punkt unseres Objekts betrachten, der im Diagramm rot markiert ist, sollten zwei gr√ºn markierte Pixel im Stereogramm dieselbe Farbe haben.  Wie finde ich den Abstand zwischen diesen Pixeln?  Sehr einfach.  Wenn der aktuell projizierte Punkt eine Tiefe von z hat, ist das Verh√§ltnis der Parallaxe zum Abstand zwischen den Augen gleich dem Verh√§ltnis der entsprechenden Tiefen: p / e = (d-dŒºz) / (2d-dŒºz).  Beachten Sie √ºbrigens, dass d schrumpft und nirgendwo anders involviert ist!  Das hei√üt, p / e = (1 Œºz) / (2 Œºz), was bedeutet, dass die Parallaxe gleich p = e * (1 Œºz) / (2 Œºz) Pixel ist. <br><br>  Das hei√üt, das Grundprinzip der Erstellung eines Stereogramms: Wir gehen die gesamte Tiefenkarte durch, bestimmen f√ºr jeden Tiefenwert, welche Pixel dieselbe Farbe haben sollen, und schreiben dies in unser Beschr√§nkungssystem.  Dann gehen wir von einem beliebigen Bild aus und versuchen, alle zuvor auferlegten Einschr√§nkungen zu erf√ºllen. <br><br><h3>  Bereiten Sie das Originalbild vor </h3><br>  In diesem Stadium werden wir ein Bild vorbereiten, auf das wir sp√§ter Parallaxenbeschr√§nkungen auferlegen werden. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier, nimm ein Commit</a> , er zeichnet dieses Bild: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Beachten Sie, dass die Farben im Allgemeinen nur zuf√§llig sind, au√üer dass ich rand () * sin in den roten Kanal setze, um periodische Wellen bereitzustellen.  Diese Wellen werden mit einem Abstand von 200 Pixeln erzeugt. Dies (mit ausgew√§hlten Œº = 1/3 und e = 400) ist der maximale Parallaxenwert in unserer Welt, es ist auch eine entfernte Ebene.  Diese Wellen sind optional, erleichtern jedoch den notwendigen Fokus des Sehens. <br><br><h3>  Stereogramm rendern </h3><br>  Tats√§chlich sieht der vollst√§ndige Code f√ºr das Stereogramm folgenderma√üen aus: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br>  Wenn √ºberhaupt, dann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verpflichten Sie sich hier</a> .  Die Funktion int parallax (const float z) gibt den Abstand zwischen Pixeln derselben Farbe f√ºr den aktuellen Tiefenwert an.  Wir rendern das Stereogramm zeilenweise, da die Linien unabh√§ngig voneinander sind (wir haben keine vertikale Parallaxe).  Daher verl√§uft die Hauptschleife einfach durch alle Zeilen.  F√ºr jeden von ihnen beginnen wir mit einem vollst√§ndigen, unbegrenzten Satz von Pixeln, denen wir dann paarweise Gleichheitsbeschr√§nkungen auferlegen, und am Ende werden wir eine bestimmte Anzahl von Clustern von (nicht verbundenen) Pixeln derselben Farbe haben.  Beispielsweise sollten ein Pixel mit dem Index links und ein Pixel mit dem Index rechts am Ende identisch sein. <br><br>  Wie speichere ich diese Einschr√§nkungen?  Die einfachste Antwort ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Union - Datenstruktur finden</a> .  Ich werde es nicht beschreiben, dies sind nur drei Codezeilen, Sie k√∂nnen es auf Wikipedia lesen.  Die Hauptidee ist, dass wir f√ºr jeden Cluster einen bestimmten ‚ÄûVerantwortlichen‚Äú daf√ºr haben, es ist auch ein Wurzelpixel, wir werden es in der gleichen Farbe wie im Originalbild belassen und alle anderen Pixel im Cluster neu streichen: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><h1>  Fazit </h1><br>  Nun, eigentlich ist das alles.  Zwanzig Codezeilen - und unser Stereogramm ist fertig, brechen Sie Augen und K√∂pfe, zeichnen Sie Bilder!  √úbrigens sind nur zuf√§llige Farben in einem Stereogramm im Allgemeinen ein Luxus. Wenn Sie es versuchen, k√∂nnen Sie im Prinzip auch die Farbe unseres Bildes teilweise √ºbertragen. <br><br>  Andere Stereo-Betrachtungssysteme, zum Beispiel im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenhang mit der Polarisation</a> , habe ich aus der Diskussion herausgenommen, da sie √ºber das Budget von einhundert Rubel hinausgehen.  Wenn Sie etwas verpassen, f√ºgen Sie hinzu und korrigieren Sie! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438646/">https://habr.com/ru/post/de438646/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438636/index.html">Fehlerhafte Einbettung von Funktionen in Go</a></li>
<li><a href="../de438638/index.html">Wir analysieren das Protokoll der Pager-Nachrichten POCSAG, Teil 2</a></li>
<li><a href="../de438640/index.html">Offene elektronische Hochgeschwindigkeitsw√§hrung</a></li>
<li><a href="../de438642/index.html">Die Grundlagen der reaktiven Programmierung mit RxJS</a></li>
<li><a href="../de438644/index.html">Die Sicherheit von Algorithmen f√ºr maschinelles Lernen. Sch√ºtzen und Testen von Modellen mit Python</a></li>
<li><a href="../de438648/index.html">Vergleich von BI-Systemen (Tableau, Power BI, Oracle, Qlik)</a></li>
<li><a href="../de438650/index.html">Rakete 9M729. Ein paar Worte zum ‚ÄûVersto√ü‚Äú gegen den INF-Vertrag</a></li>
<li><a href="../de438652/index.html">Portabelization IDA</a></li>
<li><a href="../de438654/index.html">OpenSceneGraph: Integration mit dem Qt Framework</a></li>
<li><a href="../de438658/index.html">Wie man lernt zu lernen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
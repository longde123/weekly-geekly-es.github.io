<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔺 📘 👨🏼‍🌾 Informationen zum Erstellen von Budget-Stereobildern auf Fingern (Stereogramm, Anaglyphe, Stereoskop) 🎏 😹 🧕🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Am nächsten Wochenende müssen Sie ein paar Dutzend Codezeilen schreiben und ein Bild zeichnen, aber keines ist besser. Also habe ich letztes vorletzte...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Informationen zum Erstellen von Budget-Stereobildern auf Fingern (Stereogramm, Anaglyphe, Stereoskop)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438646/">  Am nächsten Wochenende müssen Sie ein paar Dutzend Codezeilen schreiben und ein Bild zeichnen, aber keines ist besser.  Also habe ich letztes vorletztes Wochenende gezeigt, wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">man Raytracing macht</a> und sogar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">alles in die Luft jagt.</a>  Dies ist für viele überraschend, aber Computergrafik ist eine sehr einfache Sache. Ein paar hundert Zeilen nacktes C ++ reichen aus, um interessante Bilder zu erstellen. <br><br>  Das Thema des heutigen Gesprächs ist das binokulare Sehen, und heute können wir nicht einmal hundert Codezeilen erreichen.  In der Lage zu sein, dreidimensionale Szenen zu rendern, wäre es dumm, Stereopaare zu passieren. Heute werden wir so etwas zeichnen: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br>  Die Torheit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Magic Carpet-</a> Entwickler verfolgt mich.  Für diejenigen, die es nicht gefunden haben, ermöglichte dieses Spiel das 3D-Rendering sowohl in Anaglyphen als auch in Stereogrammen <b>in den Haupteinstellungen, die nur im Menü verfügbar sind!</b>  Dieses Gehirn explodierte nur speziell. <br><br><h1>  Parallaxe </h1><br>  Also fangen wir an.  Warum erlaubt uns unser visueller Apparat für den Anfang, Tiefe wahrzunehmen?  Es gibt so ein kluges Wort "Parallaxe".  Wenn an den Fingern, dann konzentrieren wir uns auf den Bildschirm.  Alles, was sich in der Ebene des Bildschirms für unser Gehirn befindet, ist in einer einzigen Kopie vorhanden.  Aber wenn plötzlich eine Fliege vor dem Bildschirm fliegt, dann (wenn wir unsere Augen nicht ändern!) Wird unser Gehirn sie doppelt registrieren.  Gleichzeitig teilt sich auch die Spinne an der Wand hinter dem Bildschirm, und die Richtung der Gabelung hängt davon ab, ob sich das Objekt vor oder hinter dem Brennpunkt befindet: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Unser Gehirn ist eine sehr effiziente Maschine zur Analyse leicht unterschiedlicher Bilder.  Es verwendet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Disparität</a> , um Tiefeninformationen aus zweidimensionalen Netzhautbildern für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stereopsis zu erhalten</a> .  Nun, Gott segne sie mit den Worten, lasst uns besser Bilder zeichnen! <br><br>  Nehmen wir an, unser Bildschirm ist ein Fenster in die virtuelle Welt :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Unsere Aufgabe ist es, zwei Bilder mit dem zu zeichnen, was durch dieses „Fenster“ sichtbar wird.  Es gibt zwei Bilder, eines für jedes Auge. In der Abbildung oben habe ich sie mit einem rot-blauen „Sandwich“ gezeigt.  Lassen Sie uns noch nicht stören, wie genau wir diese Bilder dem visuellen Apparat zuführen, wir müssen nur zwei Dateien speichern.  Ich bin speziell daran interessiert, wie diese Bilder mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unserem Raytracer erhalten werden können</a> . <br><br>  Angenommen, die Blickrichtung ändert sich nicht, es handelt sich um einen Vektor (0,0, -1).  Angenommen, wir können die Position der Kamera um den Augenabstand verschieben. Was noch?  Es gibt eine kleine Subtilität: Der Sichtkegel durch unser „Fenster“ ist asymmetrisch.  Und unser Raytracer kann nur einen symmetrischen Blickkegel rendern: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  Was tun?  Lesen :) <br>  Tatsächlich können wir die Bilder breiter als nötig rendern und nur den Überschuss zuschneiden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyphe </h1><br>  Mit dem allgemeinen Rendering-Mechanismus sollte klar sein, dass es jetzt an der Zeit ist, uns die Frage der Bildlieferung an unser Gehirn zu stellen.  Eine der einfachsten Optionen ist die rot-blaue Brille: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Wir machen nur die beiden Pre-Renderings nicht schwarz, sondern weiß, schreiben das linke Bild in den roten Kanal und das rechte Bild in blau.  Sie erhalten folgendes Bild: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  Rotes Glas schneidet einen Kanal ab und blaues Glas schneidet einen anderen ab, so dass jedes Auge sein eigenes Bild erhält und wir die Welt in 3D betrachten können.  Hier sind die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Änderungen am Haupt-Commit des ersten Artikels</a> , in denen sowohl die Kameraeinstellungen für beide Augen als auch die Kanalbaugruppe angezeigt werden. <br><br>  Anaglyphen-Renderings sind eine der ältesten Möglichkeiten, (Computer!) Stereobilder anzuzeigen.  Sie haben viele Mängel, zum Beispiel eine schlechte Farbwiedergabe (versuchen Sie übrigens, den grünen Kanal des rechten Auges im grünen Kanal des endgültigen Bildes aufzuzeichnen).  Ein Vorteil: Solche Gläser lassen sich leicht aus improvisierten Materialien herstellen. <br><br><h1>  Stereoskop </h1><br>  Mit der Verbreitung von Smartphones erinnerten wir uns daran, was Stereoskope sind (die für eine Sekunde im 19. Jahrhundert erfunden wurden)!  Vor einigen Jahren schlug <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google vor</a> , zwei Penny-Objektive (leider nicht am Knie), Pappe (überall herumliegend) und ein Smartphone (in der Tasche liegend) zu verwenden, um eine ziemlich erträgliche Virtual-Reality-Brille zu erhalten: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Auf aliexpress waren es Haufen, hundert Rubel pro Stück.  Im Vergleich zur Anaglyphe müssen Sie überhaupt nichts tun. Nehmen Sie einfach zwei Bilder auf und komponieren Sie sie nebeneinander. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist das Commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  Genau genommen kann je nach Objektiv eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Korrektur</a> der Objektivverzerrung erforderlich sein, aber ich habe mich überhaupt nicht darum gekümmert und sie sieht auf meiner Brille großartig aus.  Wenn Sie jedoch wirklich eine tonnenförmige Vorverzerrung anwenden müssen, die die Verzerrung des Objektivs ausgleicht, sieht dies für mein Smartphone und meine Brille folgendermaßen aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br><h1>  Stereogramme </h1><br>  Was aber, wenn Sie keine zusätzlichen Geräte verwenden möchten?  Dann gibt es nur eine Option - zu betäuben.  Im Allgemeinen reicht das vorherige Bild aus, um Stereo anzusehen. Verwenden Sie einfach den Trick, um Stereo anzusehen.  Es gibt zwei Prinzipien zum Anzeigen von Stereogrammen: Bewegen Sie entweder Ihre Augen oder bewegen Sie Ihre Augen auseinander.  Also habe ich ein Diagramm gezeichnet, in dem ich zeige, wie Sie das vorherige Bild betrachten können.  Das vorherige Bild ist doppelt, zwei rote Balken im Diagramm zeigen zwei Bilder auf der linken Netzhaut, zwei blaue auf der rechten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Wenn wir unsere Augen auf den Bildschirm richten, erhalten wir von vier Bildern zwei.  Wenn wir unsere Augen zur Nase blinzeln, ist es durchaus möglich, dem Gehirn „drei“ Bilder zu zeigen.  Und umgekehrt, wenn Sie Ihre Augen öffnen, können Sie auch "drei" Bilder erhalten.  Durch Überlagerung zentraler Bilder erhält das Gehirn einen Stereoeffekt. <br><br>  Diese Methoden werden verschiedenen Menschen auf unterschiedliche Weise gegeben, zum Beispiel weiß ich überhaupt nicht, wie ich meine Augen bewegen soll, aber ich züchte leicht.  Es ist wichtig, dass das für eine Methode erstellte Stereogramm auf die gleiche Weise betrachtet wird, da sonst eine invertierte Tiefenkarte erhalten wird (siehe negative und positive Parallaxe).  Das Problem bei dieser Methode zum Betrachten von Stereo ist, dass es sehr schwierig ist <b>,</b> Ihre Augen relativ zum Normalzustand <b>stark zu</b> bewegen, sodass Sie sich mit kleinen Bildern zufrieden geben müssen.  Und was ist, wenn Sie große wollen?  Lassen Sie uns die Farbe vollständig opfern und nur eine Wahrnehmung der Tiefe wollen.  Mit Blick auf die Zukunft sehen Sie hier das Bild am Ende dieses Teils: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Dieses Stereogramm dient zum „Verdünnen“ der Augen (Stereogramm mit Wandaugen).  Für diejenigen, die die umgekehrte Sichtweise bevorzugen, machen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier ein Bild</a> .  Wenn Sie nicht an Stereogramme gewöhnt sind, probieren Sie verschiedene Bedingungen aus: ein Vollbild, ein kleines Bild, helles Licht, Dunkelheit.  Die Aufgabe besteht darin, die Augen so zu öffnen, dass die beiden benachbarten Wirbelstreifen zusammenfallen.  Der einfachste Weg, sich oben links zu konzentrieren, ist  Sie ist flach.  Zum Beispiel bin ich von der Umgebung des Habr umgeben, ich öffne das Bild im Vollbildmodus.  Vergessen Sie nicht, die Maus davon zu entfernen! <br><br>  Geben Sie sich nicht mit dem fehlerhaften 3D-Effekt zufrieden.  Wenn Sie sich der abgerundeten Formen in der Mitte zufälliger Punkte und einiger schwacher 3D-Effekte nur vage bewusst sind, ist dies sicherlich eine unvollständige Illusion!  Wenn Sie richtig aussehen, sollten die Kugeln für den Betrachter deutlich aus der Bildschirmebene herausgehen. Der Effekt sollte stabil sein und erhalten bleiben, da jeder Teil des Bildes, sowohl der Vordergrund als auch der Hintergrund, ständig und detailliert untersucht wird.  Stereopsis hat Hysterese: Sobald Sie ein stabiles Bild erhalten, wird es klarer, je länger Sie schauen.  Je weiter der Bildschirm von den Augen entfernt ist, desto größer ist der Tiefeneffekt. <br><br>  Dieses Stereogramm wurde nach der vor einem Vierteljahrhundert von Thimbleby et al. Vorgeschlagenen Methode gezeichnet. In ihrem Artikel „ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anzeigen von 3D-Bildern: Algorithmen für Einzelbild-Zufallspunktstereogramme</a> “. <br><br><h3>  Ausgangspunkt </h3><br>  Der Ausgangspunkt für das Rendern von Stereogrammen ist eine Tiefenkarte (wir haben die Farbe vergessen).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist ein Commit</a> , das ein solches Bild <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ergibt</a> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Die Tiefen in unserem Render werden durch die nahen und fernen Ebenen abgeschnitten, dh der am weitesten entfernte Punkt in meiner Karte hat eine Tiefe von 0, der nächste. <br><br><h3>  Grundprinzip </h3><br>  Lassen Sie unsere Augen in einem Abstand d vom Bildschirm sein.  Platzieren Sie die (imaginäre) Fernebene (z = 0) im gleichen Abstand hinter dem Bildschirm.  Wir wählen eine Konstante μ, die die Position der nahen Ebene bestimmt (z = 0): Sie befindet sich in einem Abstand μd von der fernen.  Ich habe in meinem Code μ = 1/3 gewählt.  Insgesamt lebt unsere ganze Welt in einer Entfernung von d-μd bis d hinter dem Bildschirm.  Lassen Sie uns einen Abstand e zwischen den Augen definieren (in Pixel, in meinem Code habe ich 400 Pixel gewählt). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Wenn wir den Punkt unseres Objekts betrachten, der im Diagramm rot markiert ist, sollten zwei grün markierte Pixel im Stereogramm dieselbe Farbe haben.  Wie finde ich den Abstand zwischen diesen Pixeln?  Sehr einfach.  Wenn der aktuell projizierte Punkt eine Tiefe von z hat, ist das Verhältnis der Parallaxe zum Abstand zwischen den Augen gleich dem Verhältnis der entsprechenden Tiefen: p / e = (d-dμz) / (2d-dμz).  Beachten Sie übrigens, dass d schrumpft und nirgendwo anders involviert ist!  Das heißt, p / e = (1 μz) / (2 μz), was bedeutet, dass die Parallaxe gleich p = e * (1 μz) / (2 μz) Pixel ist. <br><br>  Das heißt, das Grundprinzip der Erstellung eines Stereogramms: Wir gehen die gesamte Tiefenkarte durch, bestimmen für jeden Tiefenwert, welche Pixel dieselbe Farbe haben sollen, und schreiben dies in unser Beschränkungssystem.  Dann gehen wir von einem beliebigen Bild aus und versuchen, alle zuvor auferlegten Einschränkungen zu erfüllen. <br><br><h3>  Bereiten Sie das Originalbild vor </h3><br>  In diesem Stadium werden wir ein Bild vorbereiten, auf das wir später Parallaxenbeschränkungen auferlegen werden. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier, nimm ein Commit</a> , er zeichnet dieses Bild: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Beachten Sie, dass die Farben im Allgemeinen nur zufällig sind, außer dass ich rand () * sin in den roten Kanal setze, um periodische Wellen bereitzustellen.  Diese Wellen werden mit einem Abstand von 200 Pixeln erzeugt. Dies (mit ausgewählten μ = 1/3 und e = 400) ist der maximale Parallaxenwert in unserer Welt, es ist auch eine entfernte Ebene.  Diese Wellen sind optional, erleichtern jedoch den notwendigen Fokus des Sehens. <br><br><h3>  Stereogramm rendern </h3><br>  Tatsächlich sieht der vollständige Code für das Stereogramm folgendermaßen aus: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br>  Wenn überhaupt, dann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verpflichten Sie sich hier</a> .  Die Funktion int parallax (const float z) gibt den Abstand zwischen Pixeln derselben Farbe für den aktuellen Tiefenwert an.  Wir rendern das Stereogramm zeilenweise, da die Linien unabhängig voneinander sind (wir haben keine vertikale Parallaxe).  Daher verläuft die Hauptschleife einfach durch alle Zeilen.  Für jeden von ihnen beginnen wir mit einem vollständigen, unbegrenzten Satz von Pixeln, denen wir dann paarweise Gleichheitsbeschränkungen auferlegen, und am Ende werden wir eine bestimmte Anzahl von Clustern von (nicht verbundenen) Pixeln derselben Farbe haben.  Beispielsweise sollten ein Pixel mit dem Index links und ein Pixel mit dem Index rechts am Ende identisch sein. <br><br>  Wie speichere ich diese Einschränkungen?  Die einfachste Antwort ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Union - Datenstruktur finden</a> .  Ich werde es nicht beschreiben, dies sind nur drei Codezeilen, Sie können es auf Wikipedia lesen.  Die Hauptidee ist, dass wir für jeden Cluster einen bestimmten „Verantwortlichen“ dafür haben, es ist auch ein Wurzelpixel, wir werden es in der gleichen Farbe wie im Originalbild belassen und alle anderen Pixel im Cluster neu streichen: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><h1>  Fazit </h1><br>  Nun, eigentlich ist das alles.  Zwanzig Codezeilen - und unser Stereogramm ist fertig, brechen Sie Augen und Köpfe, zeichnen Sie Bilder!  Übrigens sind nur zufällige Farben in einem Stereogramm im Allgemeinen ein Luxus. Wenn Sie es versuchen, können Sie im Prinzip auch die Farbe unseres Bildes teilweise übertragen. <br><br>  Andere Stereo-Betrachtungssysteme, zum Beispiel im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zusammenhang mit der Polarisation</a> , habe ich aus der Diskussion herausgenommen, da sie über das Budget von einhundert Rubel hinausgehen.  Wenn Sie etwas verpassen, fügen Sie hinzu und korrigieren Sie! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438646/">https://habr.com/ru/post/de438646/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438636/index.html">Fehlerhafte Einbettung von Funktionen in Go</a></li>
<li><a href="../de438638/index.html">Wir analysieren das Protokoll der Pager-Nachrichten POCSAG, Teil 2</a></li>
<li><a href="../de438640/index.html">Offene elektronische Hochgeschwindigkeitswährung</a></li>
<li><a href="../de438642/index.html">Die Grundlagen der reaktiven Programmierung mit RxJS</a></li>
<li><a href="../de438644/index.html">Die Sicherheit von Algorithmen für maschinelles Lernen. Schützen und Testen von Modellen mit Python</a></li>
<li><a href="../de438648/index.html">Vergleich von BI-Systemen (Tableau, Power BI, Oracle, Qlik)</a></li>
<li><a href="../de438650/index.html">Rakete 9M729. Ein paar Worte zum „Verstoß“ gegen den INF-Vertrag</a></li>
<li><a href="../de438652/index.html">Portabelization IDA</a></li>
<li><a href="../de438654/index.html">OpenSceneGraph: Integration mit dem Qt Framework</a></li>
<li><a href="../de438658/index.html">Wie man lernt zu lernen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ›ï¸ ğŸšƒ ğŸ¤´ğŸ½ Pedoman konfigurasi AFA AccelStor untuk VMware vSphere ğŸ–•ğŸ½ ğŸ† ğŸ‘©ğŸ¿â€ğŸ’»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pada artikel ini, saya ingin berbicara tentang fitur-fitur dari semua array Flash AccelStor yang bekerja dengan salah satu platform virtualisasi palin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pedoman konfigurasi AFA AccelStor untuk VMware vSphere</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/accelstor/blog/447390/"><p>  Pada artikel ini, saya ingin berbicara tentang fitur-fitur dari semua array Flash AccelStor yang bekerja dengan salah satu platform virtualisasi paling populer - VMware vSphere.  Secara khusus, untuk fokus pada parameter-parameter yang akan membantu untuk mendapatkan efek maksimum dari menggunakan alat yang kuat seperti All Flash. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/di/xc/nq/dixcnqzpdskxe4whal3u7wyxcnw.jpeg"></div><a name="habracut"></a><br><p>  Semua array Flash AccelStor NeoSapphire â„¢ adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">satu</a> atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dua</a> perangkat node berdasarkan SSD dengan pendekatan yang berbeda secara mendasar untuk menerapkan konsep menyimpan data dan mengatur akses ke sana menggunakan teknologi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FlexiRemapÂ®</a> sendiri alih-alih algoritma RAID yang sangat populer.  Array menyediakan akses blokir untuk host melalui antarmuka Fibre Channel atau iSCSI.  Dalam keadilan, kami mencatat bahwa model dengan antarmuka ISCSI juga memiliki akses file sebagai bonus yang bagus.  Namun dalam artikel ini, kami akan fokus pada penggunaan protokol blok sebagai yang paling produktif untuk Semua Flash. </p><br><p>  Seluruh proses penggelaran dan kemudian mengatur kolaborasi antara array AccelStor dan sistem virtualisasi VMware vSphere dapat dibagi menjadi beberapa tahap: </p><br><p></p><ul><li>  Implementasi topologi koneksi dan konfigurasi jaringan SAN; </li><li>  Menyiapkan Semua Flash array; </li><li>  Konfigurasikan host ESXi; </li><li>  Konfigurasikan mesin virtual. </li></ul><br><p>  Rangkaian AccelStor NeoSapphire â„¢ dengan Fibre Channel dan iSCSI digunakan sebagai peralatan contoh.  Perangkat lunak dasarnya adalah VMware vSphere 6.7U1. </p><br><p>  Sebelum menggunakan sistem yang dijelaskan dalam artikel ini, sangat disarankan agar Anda membiasakan diri dengan dokumentasi dari VMware mengenai masalah kinerja ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Performance Best Practices untuk VMware vSphere 6.7</a> ) dan pengaturan iSCSI ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Praktik Terbaik Untuk Menjalankan VMware vSphere Pada iSCSI</a> ) </p><br><h3>  <i><b>Topologi Koneksi dan Konfigurasi SAN</b></i> </h3><br><p>  Komponen utama jaringan SAN adalah HBA pada host ESXi, SAN switch, dan node array.  Topologi tipikal dari jaringan seperti itu akan terlihat seperti ini: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/ci/wt/lg/ciwtlgk31rhm06xplvzbbwkxu0y.png"></div><br><p>  Istilah Switch di sini mengacu pada switch fisik tunggal atau serangkaian switch (Fabric), atau perangkat yang digunakan bersama antara berbagai layanan (VSAN dalam kasus Fibre Channel dan VLAN dalam kasus iSCSI).  Menggunakan dua sakelar independen / Fabric menghilangkan kemungkinan titik kegagalan. </p><br><p>  Koneksi langsung host ke array, meskipun didukung, sangat tidak disarankan.  Kinerja semua array Flash cukup tinggi.  Dan untuk kecepatan maksimum, Anda harus menggunakan semua port array.  Karena itu, diperlukan setidaknya satu sakelar antara host dan NeoSapphire â„¢. </p><br><p>  Memiliki dua port pada host HBA juga merupakan prasyarat untuk kinerja maksimum dan toleransi kesalahan. </p><br><p>  Jika Anda menggunakan antarmuka Fibre Channel, Anda perlu mengonfigurasi zonasi untuk menghindari kemungkinan konflik antara pemrakarsa dan target.  Zona dibangun berdasarkan prinsip "satu port inisiator - satu atau lebih port array". </p><br><p>  Jika Anda menggunakan koneksi iSCSI jika Anda menggunakan sakelar yang dibagikan dengan layanan lain, maka Anda harus mengisolasi lalu lintas iSCSI di dalam VLAN terpisah.  Anda juga sangat disarankan untuk mengaktifkan dukungan Jumbo Frames (MTU = 9000) untuk meningkatkan ukuran paket pada jaringan dan, dengan demikian, mengurangi jumlah overhead selama transmisi.  Namun, perlu diingat bahwa untuk operasi yang benar diperlukan untuk mengubah parameter MTU pada semua komponen jaringan di sepanjang rantai inisiator-switch-target. </p><br><h3>  <i><b>Menyiapkan Semua Array Flash</b></i> </h3><br><p>  Array dikirimkan ke pelanggan dengan grup <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FlexiRemapÂ® yang</a> sudah terbentuk.  Oleh karena itu, tidak diperlukan tindakan untuk mengintegrasikan drive ke dalam struktur tunggal.  Cukup untuk membuat volume dari ukuran yang dibutuhkan dan dalam kuantitas yang dibutuhkan. </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/zn/x9/nc/znx9ncuyd2rgm8-jfvwf620zaqg.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/wx/8l/ua/wx8lualewtdkixfwg0petpxbsre.png"></div><p></p><br><p>  Untuk kenyamanan, ada fungsi untuk pembuatan batch dari beberapa volume volume yang diberikan sekaligus.  Volume "Tipis" dibuat secara default, karena ini memungkinkan penggunaan ruang penyimpanan yang lebih rasional (termasuk berkat dukungan Reklamasi Ruang).  Dalam hal kinerja, perbedaan antara volume tipis dan tebal tidak melebihi 1%.  Namun, jika Anda ingin "memeras semua jus" dari array, Anda selalu dapat mengubah volume "tipis" menjadi "tebal".  Tetapi harus diingat bahwa operasi semacam itu tidak dapat diubah. </p><br><p>  Kemudian tetap "mempublikasikan" volume yang dibuat dan mengatur hak akses kepada mereka dari host menggunakan ACL (alamat IP untuk iSCSI dan WWPN untuk FC) dan pemisahan fisik port pada array.  Untuk model iSCSI, ini dilakukan melalui pembuatan Target. </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/mw/8y/cg/mw8ycgqngghoyuelortgysofswi.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/py/xe/28/pyxe28gnrsxh_cx4ltjleogwsmw.png"></div><p></p><br><p>  Untuk model FC, publikasi terjadi melalui pembuatan LUN untuk setiap port dalam array. </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/qh/u3/bx/qhu3bxhm-kqinygguz298izbw7e.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/oh/al/ey/ohaleyllpb-0bmot9kawc4-ssyg.png"></div><p></p><br><p>  Untuk mempercepat proses konfigurasi, host dapat dikelompokkan.  Selain itu, jika tuan rumah menggunakan multi-port HBA FC (yang dalam praktiknya paling sering terjadi), sistem secara otomatis menentukan bahwa port-port HBA tersebut milik tuan rumah yang sama karena WWPN, yang berbeda satu per satu.  Juga, pembuatan batch Target / LUN didukung untuk kedua antarmuka. </p><br><p>  Poin penting ketika menggunakan antarmuka iSCSI adalah untuk membuat beberapa target volume sekaligus untuk meningkatkan kinerja, karena antrian target tidak dapat diubah, dan itu sebenarnya akan menjadi hambatan. </p><br><p></p><h3>  Konfigurasikan host ESXi </h3><p></p><br><p>  Di sisi ESXi, konfigurasi dasar dilakukan sesuai dengan skenario yang sangat diharapkan.  Prosedur untuk koneksi iSCSI: </p><br><p></p><ol><li>  Tambah Perangkat Lunak iSCSI Adapter (tidak wajib jika sudah ditambahkan, atau jika menggunakan Perangkat Keras iSCSI Adapter); </li><li>  Membuat vSwitch, di mana lalu lintas iSCSI akan pergi, dan menambahkan uplink fisik dan VMkernal ke dalamnya; </li><li>  Menambahkan alamat array ke Dynamic Discovery; </li><li>  Membuat Datastore </li></ol><br><p>  <b>Beberapa catatan penting:</b> </p><br><blockquote><ul><li>  Dalam kasus umum, tentu saja, Anda dapat menggunakan vSwitch yang ada, tetapi dalam kasus vSwitch yang terpisah, mengelola pengaturan host akan jauh lebih sederhana. </li><li>  Penting untuk memisahkan traffic Manajemen dan iSCSI menjadi tautan fisik dan / atau VLAN yang terpisah untuk menghindari masalah kinerja. </li><li>  Alamat IP VMkernal dan port yang sesuai dari array Semua Flash harus berada di subnet yang sama, sekali lagi karena masalah kinerja. </li><li>  Untuk memastikan toleransi kesalahan VMware, vSwitch harus memiliki setidaknya dua uplink fisik </li><li>  Jika menggunakan Jumbo Frames, Anda harus mengubah MTU dari vSwitch dan VMkernal </li><li>  Tidak akan salah untuk mengingat bahwa sesuai dengan rekomendasi VMware untuk adapter fisik yang akan digunakan untuk bekerja dengan lalu lintas iSCSI, perlu untuk mengkonfigurasi Teaming dan Failover.  Secara khusus, setiap VMkernal harus bekerja hanya melalui satu uplink, uplink kedua harus dialihkan ke mode yang tidak digunakan.  Untuk toleransi kesalahan, Anda perlu menambahkan dua VMkernal, yang masing-masing akan bekerja melalui uplink-nya. </li></ul><br></blockquote><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/_h/jb/va/_hjbvatnuhjwts4duy2epgb7bbi.png"></div><p></p><br><table><tbody><tr><th>  VMkernel Adapter (vmk #) </th><th>  Adaptor Jaringan Fisik (vmnic #) </th></tr><tr><td>  vmk1 (Storage01) </td><td>  Adaptor aktif <br>  vmnic2 <br>  Adaptor yang tidak digunakan <br>  vmnic3 <br></td></tr><tr><td>  vmk2 (Storage02) </td><td>  Adaptor aktif <br>  vmnic3 <br>  Adaptor yang tidak digunakan <br>  vmnic2 <br></td></tr></tbody></table><br><p>  Tidak diperlukan koneksi Fibre Channel.  Anda dapat segera membuat datastore. </p><br><p>  Setelah membuat Datastore, Anda perlu memastikan bahwa kebijakan Round Robin digunakan untuk jalur ke Target / LUN sebagai yang paling produktif. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/zh/zr/t1/zhzrt15baoc1qlp0w6ds-mys3hu.png"></div><p></p><br><p>  Secara default, pengaturan VMware menyediakan untuk penggunaan kebijakan ini sesuai dengan skema: 1000 permintaan melalui jalur pertama, 1000 permintaan berikutnya melalui jalur kedua, dll.  Interaksi host ini dengan array pengontrol ganda akan tidak seimbang.  Oleh karena itu, kami menyarankan pengaturan kebijakan Round Robin = 1 parameter melalui Esxcli / PowerCLI. </p><br><div class="spoiler">  <b class="spoiler_title">Parameter</b> <div class="spoiler_text"><p>  Untuk Esxcli: </p><br><ul><li>  Cetak LUN yang Tersedia </li></ul><br><p>  <b>daftar perangkat nmp penyimpanan esxcli</b> </p><br><ul><li>  Salin Nama Perangkat </li><li>  Ubah Kebijakan Round Robin </li></ul><br><p>  <b>penyimpanan esxcli nmp psp roundrobin deviceconfig set --type = iops --iops = 1 --device = "Device_ID"</b> </p></div></div><br><p>  Sebagian besar aplikasi modern dirancang untuk bertukar paket data besar untuk memaksimalkan pemanfaatan bandwidth dan mengurangi beban CPU.  Oleh karena itu, ESXi secara default mentransfer permintaan I / O ke perangkat penyimpanan dalam batch hingga 32767KB.  Namun, untuk sejumlah skenario, bertukar porsi yang lebih kecil akan lebih produktif.  Untuk array AccelStor, ini adalah skenario berikut: </p><br><ul><li>  Mesin virtual menggunakan UEFI, bukan Legacy BIOS </li><li>  Digunakan oleh Replikasi vSphere </li></ul><br><p>  Untuk skenario seperti itu, Anda disarankan untuk mengubah nilai parameter Disk.DiskMaxIOSize ke 4096. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/1g/et/3g/1get3g8odkem1onrpkwjdilbnsi.png"></div><p></p><br><p>  Untuk koneksi iSCSI, disarankan untuk mengubah parameter Login Timeout ke 30 (default 5) untuk meningkatkan stabilitas koneksi dan mematikan penundaan penerimaan paket DelayedAck yang diteruskan.  Kedua opsi ada di vSphere Client: Host â†’ Configure â†’ Storage â†’ Adapters Storage â†’ Advanced Options untuk adaptor iSCSI </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/1y/5_/c8/1y5_c80zsijgqtngo-9vt2zbbo8.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/bh/yi/tv/bhyitvuujofnioaunwhzypx3fe0.png"></div><p></p><br><p>  Titik yang agak halus adalah jumlah volume yang digunakan untuk datastore.  Jelas bahwa untuk kemudahan manajemen ada keinginan untuk membuat satu volume besar untuk seluruh volume array.  Namun, kehadiran beberapa volume dan, karenanya, datastore memiliki efek menguntungkan pada kinerja keseluruhan (lebih banyak pada antrian sedikit kemudian dalam teks).  Karena itu, kami sarankan untuk membuat setidaknya dua volume. </p><br><p>  Baru-baru ini, VMware menyarankan untuk membatasi jumlah mesin virtual pada satu datastore, sekali lagi untuk mendapatkan kinerja terbaik.  Namun, sekarang, terutama dengan penyebaran VDI, masalah ini tidak lagi begitu akut.  Tapi ini tidak membatalkan aturan lama - untuk mendistribusikan mesin virtual yang membutuhkan IO intensif atas data yang berbeda.  Tidak ada yang lebih baik untuk menentukan jumlah optimal mesin virtual per volume selain <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memuat test array All Flash AccelStor</a> dalam infrastrukturnya. </p><br><h3>  <i><b>Konfigurasikan mesin virtual</b></i> </h3><br><p>  Tidak ada persyaratan khusus saat menyiapkan mesin virtual, atau lebih tepatnya, mereka cukup biasa: </p><br><ul><li>  Menggunakan versi VM tertinggi (kompatibilitas) </li><li>  Lebih akurat untuk mengatur ukuran RAM ketika mesin virtual ditempatkan secara padat, misalnya, di VDI (karena secara default, pada saat startup, file halaman dibuat yang sebanding dengan ukuran RAM, yang mengkonsumsi kapasitas yang bermanfaat dan memiliki efek pada kinerja akhir) </li><li>  Gunakan versi IO adaptor yang paling efisien: tipe jaringan VMXNET 3 dan tipe SCSI PVSCSI </li><li>  Gunakan tipe drive Thick Provision Eager Zeroed untuk kinerja maksimum dan Thin Provisioning untuk pemanfaatan penyimpanan maksimum </li><li>  Jika memungkinkan, batasi pekerjaan mesin I / O non-kritis menggunakan Batas Disk Virtual </li><li>  Pastikan untuk menginstal VMware Tools </li></ul><br><h3>  <i><b>Catatan antrian</b></i> </h3><br><p>  Antrian (atau I / O Luar Biasa) adalah jumlah permintaan I / O (perintah SCSI) yang menunggu untuk diproses pada waktu tertentu dari perangkat / aplikasi tertentu.  Dalam hal terjadi antrian melimpah, kesalahan QFULL dihasilkan, yang akhirnya menghasilkan peningkatan dalam parameter latensi.  Saat menggunakan sistem penyimpanan disk (spindle), secara teoritis, semakin tinggi antrian, semakin tinggi kinerjanya.  Namun, Anda tidak boleh menyalahgunakannya, karena mudah dijalankan ke QFULL.  Dalam kasus semua sistem Flash, di satu sisi, semuanya agak lebih sederhana: array telah menunda beberapa urutan besarnya lebih rendah dan oleh karena itu paling sering tidak perlu secara terpisah menyesuaikan ukuran antrian.  Tetapi di sisi lain, dalam beberapa skenario penggunaan (bias kuat dalam persyaratan untuk IO untuk mesin virtual tertentu, tes untuk kinerja maksimum, dll.), Jika Anda tidak mengubah parameter antrian, maka setidaknya pahami indikator apa yang dapat dicapai, dan, yang paling penting, dengan cara apa. </p><br><p>  AccelStor's All Flash Array sendiri tidak memiliki batasan volume atau port I / O.  Jika perlu, bahkan satu volume bisa mendapatkan semua sumber daya array.  Satu-satunya batasan antrian adalah dengan target iSCSI.  Karena alasan inilah kebutuhan untuk membuat beberapa target (idealnya hingga 8 buah) untuk setiap volume untuk mengatasi batas ini ditunjukkan di atas.  Juga, array AccelStor adalah solusi yang sangat produktif.  Karena itu, Anda harus menggunakan semua port antarmuka sistem untuk mencapai kecepatan maksimum. </p><br><p>  Di sisi ESXi dari tuan rumah, situasinya benar-benar berbeda.  Tuan rumah itu sendiri menerapkan praktik akses yang sama ke sumber daya untuk semua peserta.  Oleh karena itu, ada antrian IO terpisah untuk OS tamu dan HBA.  Antrian untuk OS tamu digabungkan dari antrian ke adaptor SCSI virtual dan disk virtual: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/gu/sk/pvguskcy3y4yo7whrx8jiuggtdm.png"></div><br><p>  Antrean untuk HBA tergantung pada jenis / vendor tertentu: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/tn/hs/6h/tnhs6h0wpivfrb5xfv2qms4tzjy.png"></div><br><p>  Kinerja akhir dari mesin virtual akan ditentukan oleh batas Kedalaman Antrian terendah di antara komponen host. </p><br><p>  Berkat nilai-nilai ini, Anda dapat mengevaluasi indikator kinerja yang dapat kami peroleh dalam satu atau beberapa konfigurasi lainnya.  Sebagai contoh, kami ingin mengetahui kinerja teoritis mesin virtual (tanpa mengikat ke blok) dengan latensi 0,5 ms.  Kemudian IOPS = (1.000 / latensi) * I / O Luar Biasa (Batas Kedalaman Antrian) </p><br><div class="spoiler">  <b class="spoiler_title">Contohnya</b> <div class="spoiler_text"><p>  <b>Contoh 1</b> </p><br><ul><li>  Adaptor HBA FC Emulex </li><li>  Satu VM di datastore </li><li>  VMware Paravirtual SCSI Adapter </li></ul><br><p>  Di sini batas Kedalaman Antrian ditentukan oleh Emulex HBA.  Oleh karena itu, IOPS = (1000 / 0,5) * 32 = 64K </p><br><p>  <b>Contoh 2</b> </p><br><ul><li>  Adapter Perangkat Lunak VMware iSCSI </li><li>  Satu VM di datastore </li><li>  VMware Paravirtual SCSI Adapter </li></ul><br><p>  Di sini batas Kedalaman Antrian sudah ditentukan oleh Adapter SCSI Paravirtual.  Oleh karena itu, IOPS = (1000 / 0.5) * 64 = 128K </p></div></div><br><p>  Array All AccelStor All Flash teratas (seperti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">P710</a> ) mampu memberikan kinerja 700K IOPS untuk perekaman dalam blok 4K.  Dengan ukuran blok seperti itu, jelas bahwa mesin virtual tunggal tidak mampu memuat array seperti itu.  Untuk melakukan ini, Anda memerlukan 11 (misalnya 1) atau 6 (misalnya 2) mesin virtual. </p><br><p>  Hasilnya, dengan konfigurasi yang benar dari semua komponen yang dijelaskan dari pusat data virtual, Anda bisa mendapatkan hasil yang sangat mengesankan dalam hal kinerja. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/uj/xy/cs/ujxycs-_fo-zworv8wds9kgp1j4.jpeg"></div><br><p>  <i>Acak 4K, Baca 70% / 30% Tulis</i> </p><br><p>  Faktanya, dunia nyata jauh lebih sulit untuk digambarkan dengan formula sederhana.  Satu host selalu memiliki banyak mesin virtual dengan konfigurasi dan persyaratan IO yang berbeda.  Ya, dan prosesor host terlibat dalam pemrosesan input / output, kekuatannya tidak terbatas.  Jadi, untuk membuka potensi penuh dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model P710 yang</a> sama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> pada kenyataannya, tiga host diperlukan.  Plus, aplikasi yang berjalan di dalam mesin virtual membuat penyesuaian.  Oleh karena itu, untuk pengukuran yang akurat, kami sarankan untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menggunakan uji dalam kasus model uji</a> semua array Flash <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AccelStor</a> di dalam infrastruktur pelanggan untuk tugas aktual saat ini. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id447390/">https://habr.com/ru/post/id447390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id447376/index.html">SNA Hackathon 2019</a></li>
<li><a href="../id447380/index.html">Pengecualian Kotlin dan fitur-fiturnya</a></li>
<li><a href="../id447382/index.html">Buku "Persatuan dan C #. Gamedev dari ide hingga implementasi. 2nd ed</a></li>
<li><a href="../id447384/index.html">Semikonduktor daya jaga ekologi</a></li>
<li><a href="../id447388/index.html">TL; DR-digest dari ITMO University: penerimaan non-klasik ke universitas, acara mendatang dan materi yang paling menarik</a></li>
<li><a href="../id447392/index.html">Tiga masalah layanan untuk memeriksa tata bahasa Inggris, dan apakah itu bisa diselesaikan</a></li>
<li><a href="../id447394/index.html">Wawancara dengan Vladimir Likhachev, ayah Nikolai Likhachev, lebih dikenal sebagai Chris Kaspersky</a></li>
<li><a href="../id447396/index.html">Apakah data perusahaan Anda berharga di era AI?</a></li>
<li><a href="../id447398/index.html">Otomatisasi Proses Robot - Pandangan Baru di Teknologi Lama</a></li>
<li><a href="../id447402/index.html">Splunk Universal Forwarder di docker sebagai logger sistem</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
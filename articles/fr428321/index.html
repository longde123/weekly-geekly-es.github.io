<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📖 🏒 👊🏾 Analyse prédictive des données - modélisation et validation 🛀🏽 🥠 👸🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Je vous présente la traduction d'un chapitre du livre Hands-On Data Science with Anaconda 
 «Analyse prédictive des données - modélisation et validati...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse prédictive des données - modélisation et validation</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428321/">  Je vous présente la traduction d'un chapitre du livre Hands-On Data Science with Anaconda <br>  <b>«Analyse prédictive des données - modélisation et validation»</b> <br><br><img src="https://habrastorage.org/webt/eg/b0/jk/egb0jk10gh3cnlxzozestcagccc.png" height="500" width="300"><br><br>  Notre objectif principal dans la réalisation de diverses analyses de données est de rechercher des modèles pour prédire ce qui pourrait se produire à l'avenir.  Pour le marché boursier, les chercheurs et les experts effectuent divers tests pour comprendre les mécanismes du marché.  Dans ce cas, vous pouvez poser beaucoup de questions.  Quel sera le niveau de l'indice de marché au cours des cinq prochaines années?  Quelle sera la prochaine fourchette de prix pour IBM?  La volatilité du marché augmentera-t-elle ou diminuera-t-elle à l'avenir?  Quel pourrait être l'effet si les gouvernements modifient leurs politiques fiscales?  Quels sont les gains et les pertes potentiels si un pays déclenche une guerre commerciale avec un autre?  Comment prédisons-nous le comportement des consommateurs en analysant certaines variables connexes?  Peut-on prédire la probabilité qu'un étudiant diplômé réussisse?  Pouvons-nous trouver un lien entre le comportement spécifique d'une maladie particulière? <br><br>  Par conséquent, nous examinerons les sujets suivants: <br><br><ul><li>  Comprendre l'analyse prédictive des données </li><li>  Ensembles de données utiles </li><li>  Prévision des événements futurs </li><li>  Sélection du modèle </li><li>  Test de causalité de Granger </li></ul><a name="habracut"></a><br><h2>  Comprendre l'analyse prédictive des données </h2><br>  Les gens peuvent avoir de nombreuses questions concernant les événements futurs. <br><br><ul><li>  Un investisseur, s'il peut prédire le mouvement futur des cours boursiers, il peut faire un gros profit. </li><li>  Les entreprises, si elles pouvaient prédire la tendance de leurs produits, pourraient augmenter le prix de leurs actions et leur part de marché. </li><li>  Les gouvernements, s'ils pouvaient prédire l'impact du vieillissement de la population sur la société et l'économie, seraient davantage incités à élaborer de meilleures politiques en termes de budget de l'État et d'autres décisions stratégiques pertinentes. </li><li>  Les universités, si elles pouvaient bien comprendre la demande du marché en termes de qualité et de compétences pour leurs diplômés, elles pourraient développer un ensemble de meilleurs programmes ou lancer de nouveaux programmes pour répondre aux besoins futurs de la main-d'œuvre. </li></ul><br>  Pour un meilleur pronostic, les chercheurs devraient considérer de nombreuses questions.  Par exemple, les données d'exemple sont-elles trop petites?  Comment supprimer les variables manquantes?  Cet ensemble de données est-il biaisé en termes de procédures de collecte de données?  Que pensons-nous des extrêmes ou des émissions?  Qu'est-ce que la saisonnalité et comment la gérer?  Quels modèles devons-nous utiliser?  Ce chapitre abordera certains de ces problèmes.  Commençons par un ensemble de données utile. <br><br><h1>  Ensembles de données utiles </h1><br>  L'une des meilleures sources de données est le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">référentiel d'apprentissage automatique UCI</a> .  Après avoir visité le site, nous verrons la liste suivante: <br><br><img src="https://habrastorage.org/webt/p2/sa/47/p2sa47ajhhmjdwnigi4vg19raue.png"><br><br>  Par exemple, si vous sélectionnez le premier jeu de données (Abalone), nous verrons ce qui suit.  Pour économiser de l'espace, seul le haut est affiché: <br><br><img src="https://habrastorage.org/webt/g2/6i/u4/g26iu42u1yln7fvxz4oj_cybzxm.png"><br><br>  De là, les utilisateurs peuvent télécharger l'ensemble de données et trouver des définitions de variables.  Le code suivant peut être utilisé pour charger un ensemble de données: <br><br><pre><code class="bash hljs">dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"UCIdatasets"</span></span> path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) dim(.UCIdatasets) head(.UCIdatasets)</code> </pre> <br>  La sortie correspondante est affichée ici: <br><br><img src="https://habrastorage.org/webt/sk/rn/8j/skrn8jh3kygkqwxfvpzza2xnnzk.png"><br><br>  De la conclusion précédente, nous savons que dans l'ensemble de données il y a 427 observations (ensembles de données).  Pour chacun d'eux, nous avons 7 fonctions liées, telles que <i>Nom, Data_Types, Default_Task, Attribute_Types, N_Instances</i> (nombre d'instances), <i>N_Attributes</i> (nombre d'attributs) et <i>Year</i> .  Une variable appelée <i>Default_Task</i> peut être interprétée comme l'utilisation principale de chaque ensemble de données.  Par exemple, un premier ensemble de données appelé <i>Abalone</i> peut être utilisé pour la <i>classification</i> .  La fonction <i>unique ()</i> peut être utilisée pour rechercher toutes les <i>Default_Task</i> possibles affichées ici: <br><br><img src="https://habrastorage.org/webt/ul/4-/fj/ul4-fjckb20uvcz1iif9yup4wem.png"><br><br><h3>  Package R AppliedPredictiveModeling </h3><br>  Ce package comprend de nombreux jeux de données utiles qui peuvent être utilisés pour ce chapitre et d'autres.  La façon la plus simple de trouver ces ensembles de données est d'utiliser la fonction <i>help ()</i> illustrée ici: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(package=AppliedPredictiveModeling)</code> </pre><br>  Ici, nous montrons quelques exemples de chargement de ces jeux de données.  Pour charger un ensemble de données, nous utilisons la fonction <i>data ()</i> .  Pour le premier ensemble de données appelé <i>abalone</i> , nous avons le code suivant: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) data(abalone) dim(abalone) head(abalone)</code> </pre><br>  La sortie est la suivante: <br><br><img src="https://habrastorage.org/webt/wb/ah/sb/wbahsbbuw2teuts6nhjhiqawm4g.png"><br><br>  Parfois, un grand ensemble de données comprend plusieurs sous-ensembles de données: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) data(solubility) ls(pattern=<span class="hljs-string"><span class="hljs-string">"sol"</span></span>)</code> </pre><br><pre> <code class="bash hljs">[1] <span class="hljs-string"><span class="hljs-string">"solTestX"</span></span> <span class="hljs-string"><span class="hljs-string">"solTestXtrans"</span></span> <span class="hljs-string"><span class="hljs-string">"solTestY"</span></span> [4] <span class="hljs-string"><span class="hljs-string">"solTrainX"</span></span> <span class="hljs-string"><span class="hljs-string">"solTrainXtrans"</span></span> <span class="hljs-string"><span class="hljs-string">"solTrainY"</span></span></code> </pre><br>  Pour charger chaque ensemble de données, nous pourrions utiliser les fonctions <i>dim ()</i> , <i>head ()</i> , <i>tail ()</i> et <i>summary ()</i> . <br><br><h3>  Analyse des séries chronologiques </h3><br>  Les séries chronologiques peuvent être définies comme un ensemble de valeurs obtenues à des moments consécutifs, souvent avec des intervalles égaux entre eux.  Il existe différentes périodes, telles que annuelle, trimestrielle, mensuelle, hebdomadaire et quotidienne.  Pour les séries chronologiques du PIB (produit intérieur brut), nous utilisons généralement des données trimestrielles ou annuelles.  Pour les devis - fréquences annuelles, mensuelles et quotidiennes.  En utilisant le code suivant, nous pouvons obtenir des données sur le PIB américain à la fois trimestriellement et pour une période annuelle: <br><br><pre> <code class="bash hljs">ath&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPannual"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) head(.usGDPannual)</code> </pre> <br><pre> <code class="bash hljs">YEAR GDP 1 1930 92.2 2 1931 77.4 3 1932 59.5 4 1933 57.2 5 1934 66.8 6 1935 74.3</code> </pre><br><pre> <code class="bash hljs">dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPquarterly"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) head(.usGDPquarterly)</code> </pre><br><pre> <code class="bash hljs"> DATE GDP_CURRENT GDP2009DOLLAR 1 1947Q1 243.1 1934.5 2 1947Q2 246.3 1932.3 3 1947Q3 250.1 1930.3 4 1947Q4 260.3 1960.7 5 1948Q1 266.2 1989.5 6 1948Q2 272.9 2021.9</code> </pre><br>  Cependant, nous avons de nombreuses questions pour l'analyse des séries chronologiques.  Par exemple, du point de vue de la macroéconomie, nous avons des cycles économiques ou économiques.  Les industries ou les entreprises peuvent avoir une saisonnalité.  Par exemple, en utilisant l'industrie agricole, les agriculteurs dépenseront plus au printemps et à l'automne et moins en hiver.  Pour les détaillants, ils auraient un énorme afflux d'argent à la fin de l'année. <br><br>  Pour manipuler les séries chronologiques, nous pourrions utiliser les nombreuses fonctionnalités utiles incluses dans le package R, appelées <i>timeSeries</i> .  Dans l'exemple, nous prenons les données moyennes quotidiennes avec une fréquence hebdomadaire: <br><br><pre> <code class="bash hljs">library(timeSeries) data(MSFT) x &lt;- MSFT by &lt;- timeSequence(from = start(x), to = end(x), by = <span class="hljs-string"><span class="hljs-string">"week"</span></span>) y&lt;-aggregate(x,by,mean)</code> </pre><br>  Nous pourrions également utiliser la fonction <i>head ()</i> pour voir quelques observations: <br><pre> <code class="bash hljs">head(x)</code> </pre><br><pre> <code class="bash hljs">GMT Open High Low Close Volume 2000-09-27 63.4375 63.5625 59.8125 60.6250 53077800 2000-09-28 60.8125 61.8750 60.6250 61.3125 26180200 2000-09-29 61.0000 61.3125 58.6250 60.3125 37026800 2000-10-02 60.5000 60.8125 58.2500 59.1250 29281200 2000-10-03 59.5625 59.8125 56.5000 56.5625 42687000 2000-10-04 56.3750 56.5625 54.5000 55.4375 68226700</code> </pre><br><pre> <code class="bash hljs">head(y)</code> </pre> <br><pre> <code class="bash hljs">GMT Open High Low Close Volume 2000-09-27 63.4375 63.5625 59.8125 60.6250 53077800 2000-10-04 59.6500 60.0750 57.7000 58.5500 40680380 2000-10-11 54.9750 56.4500 54.1625 55.0875 36448900 2000-10-18 53.0375 54.2500 50.8375 52.1375 50631280 2000-10-25 61.7875 64.1875 60.0875 62.3875 86457340 2000-11-01 66.1375 68.7875 65.8500 67.9375 53496000</code> </pre> <br><br><h2>  Prévision des événements futurs </h2><br>  Il existe de nombreuses méthodes que nous pourrions utiliser pour essayer de prédire l'avenir, telles que la moyenne mobile, la régression, l'autorégression, etc. Commençons par la plus simple pour la moyenne mobile: <br><br><pre> <code class="bash hljs">movingAverageFunction&lt;- <span class="hljs-keyword"><span class="hljs-keyword">function</span></span>(data,n=10){ out= data <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> n:length(data)){ out[i] = mean(data[(i-n+1):i]) } <span class="hljs-built_in"><span class="hljs-built_in">return</span></span>(out) }</code> </pre> <br>  Dans le code précédent, la valeur par défaut pour le nombre de périodes est 10. Nous pourrions utiliser un ensemble de données appelé MSFT inclus dans le package R appelé <i>timeSeries</i> (voir le code suivant): <br><br><pre> <code class="bash hljs">library(timeSeries) data(MSFT) p&lt;-MSFT<span class="hljs-variable"><span class="hljs-variable">$Close</span></span> <span class="hljs-comment"><span class="hljs-comment"># ma&lt;-movingAverageFunction(p,3) head(p)</span></span></code> </pre> <br><pre> <code class="bash hljs">[1] 60.6250 61.3125 60.3125 59.1250 56.5625 55.4375</code> </pre> <br><pre> <code class="bash hljs">head(ma)</code> </pre> <br><pre> <code class="bash hljs">[1] 60.62500 61.31250 60.75000 60.25000 58.66667 57.04167</code> </pre> <br><pre> <code class="bash hljs">mean(p[1:3])</code> </pre> <br><pre> <code class="bash hljs">[1] 60.75</code> </pre> <br><pre> <code class="bash hljs">mean(p[2:4])</code> </pre> <br><pre> <code class="bash hljs">[1] 60.25</code> </pre> <br>  En mode manuel, nous constatons que la moyenne des trois premières valeurs de <i>x</i> correspond à la troisième valeur de <i>y</i> .  D'une certaine manière, nous pourrions utiliser une moyenne mobile pour prédire l'avenir. <br><br>  Dans l'exemple suivant, nous montrerons comment évaluer les rendements attendus du marché l'année prochaine.  Ici, nous utilisons l'indice S &amp; P500 et la valeur annuelle moyenne historique comme valeurs attendues.  Les premières commandes sont utilisées pour charger un jeu de données associé appelé <i>.sp500monthly</i> .  Le but du programme est d'évaluer la moyenne annuelle moyenne et l'intervalle de confiance à 90%: <br><br><pre> <code class="bash hljs">library(data.table) path&lt;-<span class="hljs-string"><span class="hljs-string">'http://canisius.edu/~yany/RData/'</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">'sp500monthly.RData'</span></span> link&lt;-paste(path,dataSet,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(link)) <span class="hljs-comment"><span class="hljs-comment">#head(.sp500monthly,2) p&lt;-.sp500monthly$ADJ.CLOSE n&lt;-length(p) logRet&lt;-log(p[2:n]/p[1:(n-1)]) years&lt;-format(.sp500monthly$DATE[2:n],"%Y") y&lt;-data.frame(.sp500monthly$DATE[2:n],years,logRet) colnames(y)&lt;-c("DATE","YEAR","LOGRET") y2&lt;- data.table(y) z&lt;-y2[,sum(LOGRET),by=YEAR] z2&lt;-na.omit(z) annualRet&lt;-data.frame(z2$YEAR,exp(z2[,2])-1) n&lt;-nrow(annualRet) std&lt;-sd(annualRet[,2]) stdErr&lt;-std/sqrt(n) ourMean&lt;-mean(annualRet[,2]) min2&lt;-ourMean-2*stdErr max2&lt;-ourMean+2*stdErr cat("[min mean max ]\n")</span></span></code> </pre> <br><pre> <code class="bash hljs">[min mean max ]</code> </pre><br><pre> <code class="bash hljs">cat(min2,ourMean,max2,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">0.05032956 0.09022369 0.1301178</code> </pre><br>  Comme vous pouvez le voir sur les résultats, le rendement annuel moyen historique du S &amp; P500 est de 9%.  Mais on ne peut pas dire que la rentabilité de l’indice l’année prochaine sera de 9%, car  cela peut aller de 5% à 13%, et ce sont d'énormes fluctuations. <br><br><h3>  Saisonnalité </h3><br>  Dans l'exemple suivant, nous montrons l'utilisation de l'autocorrélation.  Tout d'abord, nous téléchargeons un package R appelé <i>astsa</i> , qui signifie analyse statistique des séries chronologiques.  Ensuite, nous chargeons le PIB américain avec une fréquence trimestrielle: <br><br><pre> <code class="bash hljs">library(astsa) path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPquarterly"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) x&lt;-.usGDPquarterly<span class="hljs-variable"><span class="hljs-variable">$DATE</span></span> y&lt;-.usGDPquarterly<span class="hljs-variable"><span class="hljs-variable">$GDP_CURRENT</span></span> plot(x,y) diff4 = diff(y,4) acf2(diff4,24)</code> </pre> <br>  Dans le code ci-dessus, la fonction <i>diff ()</i> accepte la différence, par exemple, la valeur actuelle moins la valeur précédente.  Une deuxième valeur d'entrée indique un retard.  Une fonction appelée <i>acf2 ()</i> est utilisée pour créer et imprimer les séries chronologiques ACF et PACF.  ACF signifie fonction d'autocovariance et PACF signifie fonction d'autocorrélation partielle.  Les graphiques pertinents sont présentés ici: <br><br><img src="https://habrastorage.org/webt/n6/89/sv/n689svzvvvik4co4abbgzeobtnw.png" height="400" width="300"><br><br><h3>  <b>Visualisation des composants</b> </h3><br>  De toute évidence, les concepts et les ensembles de données seraient beaucoup plus compréhensibles si nous pouvions utiliser des graphiques.  Le premier exemple montre les fluctuations du PIB américain au cours des cinq dernières décennies: <br><br><pre> <code class="bash hljs">path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPannual"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) title&lt;-<span class="hljs-string"><span class="hljs-string">"US GDP"</span></span> xTitle&lt;-<span class="hljs-string"><span class="hljs-string">"Year"</span></span> yTitle&lt;-<span class="hljs-string"><span class="hljs-string">"US annual GDP"</span></span> x&lt;-.usGDPannual<span class="hljs-variable"><span class="hljs-variable">$YEAR</span></span> y&lt;-.usGDPannual<span class="hljs-variable"><span class="hljs-variable">$GDP</span></span> plot(x,y,main=title,xlab=xTitle,ylab=yTitle)</code> </pre> <br>  L'horaire correspondant est affiché ici: <br><br><img src="https://habrastorage.org/webt/rz/9z/h8/rz9zh8qa22budzolcuushzzgwow.png" height="400" width="300"><br><br>  Si nous utilisions l'échelle logarithmique du PIB, nous aurions le code et le graphique suivants: <br><br><pre> <code class="bash hljs">yTitle&lt;-<span class="hljs-string"><span class="hljs-string">"Log US annual GDP"</span></span> plot(x,<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>(y),main=title,xlab=xTitle,ylab=yTitle)</code> </pre> <br>  Le graphique suivant est proche d'une ligne droite: <br><br><img src="https://habrastorage.org/webt/ae/f_/a6/aef_a6iuo4ielgslci9ry0vf1c8.png" height="400" width="300"><br><br><h3>  Forfait R - LiblineaR </h3><br>  Ce package est un modèle prédictif linéaire basé sur la bibliothèque LIBLINEAR C / C ++.  Voici un exemple d'utilisation du jeu de données <i>iris</i> .  Le programme essaie de prédire à quelle catégorie une plante appartient en utilisant les données de formation: <br><br><pre> <code class="bash hljs">library(LiblineaR) data(iris) attach(iris) x=iris[,1:4] y=factor(iris[,5]) train=sample(1:dim(iris)[1],100) xTrain=x[train,];xTest=x[-train,] yTrain=y[train]; yTest=y[-train] s=scale(xTrain,center=TRUE,scale=TRUE) <span class="hljs-comment"><span class="hljs-comment"># tryTypes=c(0:7) tryCosts=c(1000,1,0.001) bestCost=NA bestAcc=0 bestType=NA # for(ty in tryTypes){ for(co in tryCosts){ acc=LiblineaR(data=s,target=yTrain,type=ty,cost=co,bias=1,cross=5,verbose=FALSE) cat("Results for C=",co,": ",acc," accuracy.\n",sep="") if(acc&gt;bestAcc){ bestCost=co bestAcc=acc bestType=ty } } } cat("Best model type is:",bestType,"\n") cat("Best cost is:",bestCost,"\n") cat("Best accuracy is:",bestAcc,"\n") # Re-train best model with best cost value. m=LiblineaR(data=s,target=yTrain,type=bestType,cost=bestCost,bias=1,verbose=FALSE) # Scale the test data s2=scale(xTest,attr(s,"scaled:center"),attr(s,"scaled:scale")) pr=FALSE; # Make prediction if(bestType==0 || bestType==7) pr=TRUE p=predict(m,s2,proba=pr,decisionValues=TRUE) res=table(p$predictions,yTest) # Display confusion matrix print(res) # Compute Balanced Classification Rate BCR=mean(c(res[1,1]/sum(res[,1]),res[2,2]/sum(res[,2]),res[3,3]/sum(res[,3]))) print(BCR)</span></span></code> </pre><br>  La conclusion est la suivante.  BCR est un taux de classification équilibré.  Pour ce pari, plus haut est le mieux: <br><br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best model type is:"</span></span>,bestType,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best model <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> is: 4</code> </pre> <br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best cost is:"</span></span>,bestCost,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best cost is: 1</code> </pre> <br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best accuracy is:"</span></span>,bestAcc,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best accuracy is: 0.98</code> </pre> <br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(res) yTest setosa versicolor virginica setosa 16 0 0 versicolor 0 17 0 virginica 0 3 14 <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(BCR)</code> </pre><br><pre> <code class="bash hljs">[1] 0.95</code> </pre> <br><h3>  Forfait R - eclust </h3><br>  Ce package est un cluster orienté moyen pour les modèles prédictifs interprétés dans les données de haute dimension.  Tout d'abord, regardons un ensemble de données appelé <i>simdata</i> qui contient des données simulées pour un package: <br><br><pre> <code class="bash hljs">library(eclust) data(<span class="hljs-string"><span class="hljs-string">"simdata"</span></span>) dim(simdata)</code> </pre><br><pre> <code class="bash hljs">[1] 100 502</code> </pre> <br><pre> <code class="bash hljs">simdata[1:5, 1:6]</code> </pre><br><pre> <code class="bash hljs"> YE Gene1 Gene2 Gene3 Gene4 [1,] -94.131497 0 -0.4821629 0.1298527 0.4228393 0.36643188 [2,] 7.134990 0 -1.5216289 -0.3304428 -0.4384459 1.57602830 [3,] 1.974194 0 0.7590055 -0.3600983 1.9006443 -1.47250061 [4,] -44.855010 0 0.6833635 1.8051352 0.1527713 -0.06442029 [5,] 23.547378 0 0.4587626 -0.3996984 -0.5727255 -1.75716775</code> </pre><br><pre> <code class="bash hljs">table(simdata[,<span class="hljs-string"><span class="hljs-string">"E"</span></span>])</code> </pre><br><pre> <code class="bash hljs">0 1 50 50</code> </pre><br>  La conclusion précédente montre que la dimension des données est de 100 sur 502. <b>Y</b> est le vecteur de réponse continue et <b>E</b> est la variable d'environnement binaire pour la méthode ECLUST.  <b>E = 0</b> pour non exposé (n = 50) et <b>E = 1</b> pour exposé (n = 50). <br><br>  Le programme R suivant évalue la transformée z de Fisher: <br><br><pre> <code class="bash hljs">library(eclust) data(<span class="hljs-string"><span class="hljs-string">"simdata"</span></span>) X = simdata[,c(-1,-2)] firstCorr&lt;-cor(X[1:50,]) secondCorr&lt;-cor(X[51:100,]) score&lt;-u_fisherZ(n0=100,cor0=firstCorr,n1=100,cor1=secondCorr) dim(score)</code> </pre> <br><pre> <code class="bash hljs">[1] 500 500</code> </pre><br><pre> <code class="bash hljs">score[1:5,1:5]</code> </pre><br><pre> <code class="bash hljs"> Gene1 Gene2 Gene3 Gene4 Gene5 Gene1 1.000000 -8.062020 6.260050 -8.133437 -7.825391 Gene2 -8.062020 1.000000 9.162208 -7.431822 -7.814067 Gene3 6.260050 9.162208 1.000000 8.072412 6.529433 Gene4 -8.133437 -7.431822 8.072412 1.000000 -5.099261 Gene5 -7.825391 -7.814067 6.529433 -5.099261 1.000000</code> </pre><br>  Nous définissons la transformée z de Fisher.  En supposant que nous ayons un ensemble de <b>n</b> paires <b>x</b> <i>i</i> et <b>y</b> <i>i</i> , nous pourrions estimer leur corrélation en utilisant la formule suivante: <br><br><img src="https://habrastorage.org/webt/rn/7c/gq/rn7cgq57sb0htzxqrypdk20keqo.png"><br><br>  Ici <b>p</b> est la corrélation entre deux variables, et <img src="https://habrastorage.org/webt/f5/uq/fm/f5uqfmo1am-aj0zhkkrswmlglka.png" height="30" width="20">  et <img src="https://habrastorage.org/webt/ew/sg/o0/ewsgo0q-nftlketprnpqlgvxgw4.png" height="20" width="20">  sont des moyennes d'échantillonnage pour les variables aléatoires <b>x</b> et <b>y</b> .  La valeur de <b>z</b> est définie comme: <br><br><img src="https://habrastorage.org/webt/se/u4/-t/seu4-tahwcqhc9iz0sgcw7lnmsi.png" height="400" width="500"><br><br>  <b>ln</b> est la fonction de logarithme naturel, et <b>arctanh ()</b> est la fonction tangente hyperbolique inverse. <br><br><h1>  Sélection du modèle </h1><br>  Lors de la recherche d'un bon modèle, nous sommes parfois confrontés à un manque / excès de données.  L'exemple suivant est emprunté <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Il démontre les problèmes de travailler avec cela et comment nous pouvons utiliser la régression linéaire avec des caractéristiques polynomiales pour approximer les fonctions non linéaires.  Fonction spécifiée: <br><br><img src="https://habrastorage.org/webt/s8/cx/ey/s8cxeys7x5so7oet9x1gywgjle4.png" height="200" width="300"><br><br>  Dans le programme suivant, nous essayons d'utiliser des modèles linéaires et polynomiaux pour approximer une équation.  Un code légèrement modifié est affiché ici.  Le programme illustre l'effet de la pénurie / surabondance de données sur le modèle: <br><br><pre> <code class="bash hljs">import sklearn import numpy as np import matplotlib.pyplot as plt from sklearn.pipeline import Pipeline from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.model_selection import cross_val_score <span class="hljs-comment"><span class="hljs-comment"># np.random.seed(123) n= 30 # number of samples degrees = [1, 4, 15] def true_fun(x): return np.cos(1.5*np.pi*x) x = np.sort(np.random.rand(n)) y = true_fun(x) + np.random.randn(n) * 0.1 plt.figure(figsize=(14, 5)) title="Degree {}\nMSE = {:.2e}(+/- {:.2e})" name1="polynomial_features" name2="linear_regression" name3="neg_mean_squared_error" # for i in range(len(degrees)): ax=plt.subplot(1,len(degrees),i+1) plt.setp(ax, xticks=(), yticks=()) pFeatures=PolynomialFeatures(degree=degrees[i],include_bias=False) linear_regression = LinearRegression() pipeline=Pipeline([(name1,pFeatures),(name2,linear_regression)]) pipeline.fit(x[:,np.newaxis],y) scores=cross_val_score(pipeline,x[:,np.newaxis],y,scoring=name3,cv=10) xTest = np.linspace(0, 1, 100) plt.plot(xTest,pipeline.predict(xTest[:,np.newaxis]),label="Model") plt.plot(xTest,true_fun(xTest),label="True function") plt.scatter(x,y,edgecolor='b',s=20,label="Samples") plt.xlabel("x") plt.ylabel("y") plt.xlim((0,1)) plt.ylim((-2,2)) plt.legend(loc="best") plt.title(title.format(degrees[i],-scores.mean(),scores.std())) plt.show()</span></span></code> </pre><br>  Les graphiques résultants sont présentés ici: <br><br><img src="https://habrastorage.org/webt/nz/4q/io/nz4qioulhxn9jmgwprxj2e_zffo.png"><br><br><h3>  Paquet Python - Model-Catwalk </h3><br>  Un exemple peut être trouvé <a href="">ici</a> . <br><br>  Les premières lignes de code sont affichées ici: <br><br><pre> <code class="bash hljs">import datetime import pandas from sqlalchemy import create_engine from metta import metta_io as metta from catwalk.storage import FSModelStorageEngine, CSVMatrixStore from catwalk.model_trainers import ModelTrainer from catwalk.predictors import Predictor from catwalk.evaluation import ModelEvaluator from catwalk.utils import save_experiment_and_get_hash <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(FSModelStorageEngine)</code> </pre> <br>  La conclusion correspondante est montrée ici.  Pour économiser de l'espace, seule la partie supérieure est présentée: <br><br><pre> <code class="bash hljs">Help on class FSModelStorageEngine <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> module catwalk.storage: class FSModelStorageEngine(ModelStorageEngine) | Method resolution order: | FSModelStorageEngine | ModelStorageEngine | builtins.object | | Methods defined here: | | __init__(self, *args, **kwargs) | Initialize self. See <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>(self)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> accurate signature. | | get_store(self, model_hash) | | ----------------------------------------------------------------------</code> </pre><br><pre> <code class="bash hljs">| Data descriptors inherited from ModelStorageEngine: | | __dict__ | dictionary <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> instance variables (<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> defined) | | __weakref__ | list of weak references to the object (<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> defined)</code> </pre><br><h3>  Paquet Python - sklearn </h3><br>  Étant donné que <i>sklearn</i> est un package très utile, il vaut la peine de montrer plus d'exemples d'utilisation de ce package.  L'exemple donné ici montre comment utiliser le package pour classer les documents par sujet en utilisant l'approche du sac de mots. <br>  Cet exemple utilise la matrice <i>scipy.sparse</i> pour stocker des objets et illustre divers classificateurs qui peuvent traiter efficacement des matrices clairsemées.  Cet exemple utilise un ensemble de données de 20 groupes de discussion.  Il sera automatiquement téléchargé puis mis en cache.  Le fichier zip contient des fichiers d'entrée et peut être téléchargé <a href="">ici</a> .  Le code est disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Pour économiser de l'espace, seules les premières lignes sont affichées: <br><br><pre> <code class="bash hljs">import logging import numpy as np from optparse import OptionParser import sys from time import time import matplotlib.pyplot as plt from sklearn.datasets import fetch_20newsgroups from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.feature_extraction.text import HashingVectorizer from sklearn.feature_selection import SelectFromModel</code> </pre><br>  La sortie correspondante est affichée ici: <br><br><img src="https://habrastorage.org/webt/i-/tb/sv/i-tbsvgaud04-iz5chghtgp2zqq.png"><br><br>  Il existe trois indicateurs pour chaque méthode: évaluation, temps de formation et temps de test. <br><br><h3>  Package Julia - QuantEcon </h3><br>  Prenons, par exemple, l'utilisation de chaînes de Markov: <br><br><pre> <code class="bash hljs">using QuantEcon P = [0.4 0.6; 0.2 0.8]; mc = MarkovChain(P) x = simulate(mc, 100000); mean(x .== 1) <span class="hljs-comment"><span class="hljs-comment"># mc2 = MarkovChain(P, ["employed", "unemployed"]) simulate(mc2, 4)</span></span></code> </pre> <br>  Résultat: <br><br><img src="https://habrastorage.org/webt/6x/ru/4p/6xru4ppkn3ebq_sa6etrwlefdeu.png"><br><br>  Le but de l'exemple est de voir comment une personne d'un statut économique à l'avenir se transforme en un autre.  Tout d'abord, regardons le tableau suivant: <br><br><img src="https://habrastorage.org/webt/1y/so/ho/1ysoho1nccj6fr7_zyh_ebvrcbu.png"><br><br>  Regardons l'ovale le plus à gauche avec le statut «pauvre».  0,9 signifie qu'une personne avec ce statut a 90% de chances de rester pauvre et 10% va dans la classe moyenne.  Il peut être représenté par la matrice suivante, les zéros sont là où il n'y a pas de bord entre les nœuds: <br><br><img src="https://habrastorage.org/webt/5o/cn/m4/5ocnm45t6i6i_nalizeusknyjxi.png" height="200" width="400"><br><br>  On dit que deux états, x et y, sont liés l'un à l'autre s'il y a des entiers positifs j et k, tels que: <br><br><img src="https://habrastorage.org/webt/rb/d9/_l/rbd9_lo7hsj78rafch1eposdsgy.png"><br><br>  Une chaîne de Markov <i>P</i> est appelée irréductible si tous les états sont connectés;  c'est-à-dire, si <i>x</i> et <i>y sont</i> déclarés pour chacun (x, y).  Le code suivant le confirmera: <br><br><pre> <code class="bash hljs">using QuantEcon P = [0.9 0.1 0.0; 0.4 0.4 0.2; 0.1 0.1 0.8]; mc = MarkovChain(P) is_irreducible(mc)</code> </pre><br>  Le graphique suivant représente un cas extrême, car le statut futur d'une personne pauvre sera 100% pauvre: <br><br><img src="https://habrastorage.org/webt/xj/1h/u_/xj1hu_jmqywzhb1plv68dvy0sgk.png" height="600" width="400"><br><br>  Le code suivant le confirmera également, car le résultat sera <i>faux</i> : <br><br><pre> <code class="bash hljs">using QuantEcon P2 = [1.0 0.0 0.0; 0.1 0.8 0.1; 0.0 0.2 0.8]; mc2 = MarkovChain(P2) is_irreducible(mc2)</code> </pre><br><h1>  Test de causalité de Granger </h1><br>  Le test de causalité de Granger est utilisé pour déterminer si une série chronologique est un facteur et fournit des informations utiles pour prédire la seconde.  Le code suivant utilise un <i>ensemble de données</i> nommé <i>ChickEgg</i> comme illustration.  L'ensemble de données comprend deux colonnes, le nombre de poulets et le nombre d'oeufs, avec un horodatage: <br><br><pre> <code class="bash hljs">library(lmtest) data(ChickEgg) dim(ChickEgg)</code> </pre><br><pre> <code class="bash hljs">[1] 54 2</code> </pre> <br><pre> <code class="bash hljs">ChickEgg[1:5,]</code> </pre> <br><pre> <code class="bash hljs">chicken egg [1,] 468491 3581 [2,] 449743 3532 [3,] 436815 3327 [4,] 444523 3255 [5,] 433937 3156</code> </pre> <br>  La question est, pouvons-nous utiliser le nombre d'œufs cette année pour prédire le nombre de poulets l'année prochaine? <br><br>  Si c'est le cas, le nombre de poulets sera la raison de Granger pour le nombre d'oeufs.  Si ce n'est pas le cas, nous disons que le nombre de poulets n'est pas une raison Granger pour le nombre d'oeufs.  Voici le code pertinent: <br><br><pre> <code class="bash hljs">library(lmtest) data(ChickEgg) grangertest(chicken~egg, order = 3, data = ChickEgg)</code> </pre> <br><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: chicken ~ Lags(chicken, 1:3) + Lags(egg, 1:3) Model 2: chicken ~ Lags(chicken, 1:3) Res.Df Df F Pr(&gt;F) 1 44 2 47 -3 5.405 0.002966 ** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  Dans le modèle 1, nous essayons d'utiliser des décalages de poussins et des décalages d'oeufs pour expliquer le nombre de poussins. <br><br>  Parce que  la valeur de <b>P est</b> assez faible (elle est significative à 0,01), nous disons que le nombre d'oeufs est la raison de Granger pour le nombre de poulets. <br><br>  Le test suivant montre que les données sur les poulets ne peuvent pas être utilisées pour prédire la période suivante: <br><br><pre> <code class="bash hljs">grangertest(egg~chicken, order = 3, data = ChickEgg)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: egg ~ Lags(egg, 1:3) + Lags(chicken, 1:3) Model 2: egg ~ Lags(egg, 1:3) Res.Df Df F Pr(&gt;F) 1 44 2 47 -3 0.5916 0.6238</code> </pre><br>  Dans l'exemple suivant, nous vérifions la rentabilité d'IBM et du S &amp; P500 afin de découvrir qu'ils sont la raison de Granger pour un autre. <br><br>  Tout d'abord, nous définissons la fonction de rendement: <br><br><pre> <code class="bash hljs">ret_f&lt;-<span class="hljs-keyword"><span class="hljs-keyword">function</span></span>(x,ticker=<span class="hljs-string"><span class="hljs-string">""</span></span>){ n&lt;-nrow(x) p&lt;-x[,6] ret&lt;-p[2:n]/p[1:(n-1)]-1 output&lt;-data.frame(x[2:n,1],ret) name&lt;-paste(<span class="hljs-string"><span class="hljs-string">"RET_"</span></span>,toupper(ticker),sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) colnames(output)&lt;-c(<span class="hljs-string"><span class="hljs-string">"DATE"</span></span>,name) <span class="hljs-built_in"><span class="hljs-built_in">return</span></span>(output) }</code> </pre><br><pre> <code class="bash hljs">&gt;x&lt;-read.csv(<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/data/ibmDaily.csv"</span></span>,header=T) ibmRet&lt;-ret_f(x,<span class="hljs-string"><span class="hljs-string">"ibm"</span></span>) x&lt;-read.csv(<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/data/^gspcDaily.csv"</span></span>,header=T) mktRet&lt;-ret_f(x,<span class="hljs-string"><span class="hljs-string">"mkt"</span></span>) final&lt;-merge(ibmRet,mktRet) head(final)</code> </pre><br><pre> <code class="bash hljs"> DATE RET_IBM RET_MKT 1 1962-01-03 0.008742545 0.0023956877 2 1962-01-04 -0.009965497 -0.0068887673 3 1962-01-05 -0.019694350 -0.0138730891 4 1962-01-08 -0.018750380 -0.0077519519 5 1962-01-09 0.011829467 0.0004340133 6 1962-01-10 0.001798526 -0.0027476933</code> </pre><br>  Maintenant, la fonction peut être appelée avec des valeurs d'entrée.  L'objectif du programme est de tester si nous pouvons utiliser les décalages du marché pour expliquer la rentabilité d'IBM.  De la même manière, nous vérifions pour expliquer le retard d'IBM dans les revenus du marché: <br><br><pre> <code class="bash hljs">library(lmtest) grangertest(RET_IBM ~ RET_MKT, order = 1, data =final)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: RET_IBM ~ Lags(RET_IBM, 1:1) + Lags(RET_MKT, 1:1) Model 2: RET_IBM ~ Lags(RET_IBM, 1:1) Res.Df Df F Pr(&gt;F) 1 14149 2 14150 -1 24.002 9.729e-07 *** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  Les résultats montrent que le S &amp; P500 peut être utilisé pour expliquer la rentabilité d'IBM pour la prochaine période, car il est statistiquement significatif à 0,1%.  Le code suivant vérifiera si le décalage d'IBM explique le changement dans le S &amp; P500: <br><br><pre> <code class="bash hljs">grangertest(RET_MKT ~ RET_IBM, order = 1, data =final)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: RET_MKT ~ Lags(RET_MKT, 1:1) + Lags(RET_IBM, 1:1) Model 2: RET_MKT ~ Lags(RET_MKT, 1:1) Res.Df Df F Pr(&gt;F) 1 14149 2 14150 -1 7.5378 0.006049 ** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  Le résultat suggère que pendant cette période, les rendements d'IBM peuvent être utilisés pour expliquer l'indice S &amp; P500 pour la période suivante. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428321/">https://habr.com/ru/post/fr428321/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428307/index.html">Java Challengers # 1: surcharge de méthode dans la machine virtuelle Java</a></li>
<li><a href="../fr428311/index.html">TrustZone: OS de confiance et ses applications</a></li>
<li><a href="../fr428313/index.html">Telegram sur MacOS [vraisemblablement] stocke également localement la correspondance sous une forme accessible</a></li>
<li><a href="../fr428315/index.html">5 peurs des développeurs que nous avons surmontées</a></li>
<li><a href="../fr428317/index.html">React hooks - gagner ou perdre?</a></li>
<li><a href="../fr428327/index.html">Que rechercher: Règlement européen sur l'identification électronique eIDAS</a></li>
<li><a href="../fr428329/index.html">Formation de renforcement: analyse des jeux vidéo</a></li>
<li><a href="../fr428333/index.html">Résultats du Hackathon AI RAIF Hackathon 2018</a></li>
<li><a href="../fr428335/index.html">Mise à jour du raccourci Siri</a></li>
<li><a href="../fr428337/index.html">JavaScript divertissant: sans accolades</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
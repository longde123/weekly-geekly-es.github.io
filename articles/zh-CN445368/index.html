<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤞🏻 🏴 🙆🏼 使用成千上万的虚拟用户对游戏进行负载测试 ◀️ 💪🏽 ☕️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="哈Ha！ 

 我在一家开发在线游戏的游戏公司工作。 目前，我们所有的游戏都被划分为多个“市场”（每个国家/地区一个“市场”），并且在每个“市场”中都有十几个世界，玩家在注册时可以在这些世界之间进行分配（当然，有时他们可以自己选择）。 每个世界都有一个数据库和一个或多个Web /应用程序服务器。 因...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>使用成千上万的虚拟用户对游戏进行负载测试</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445368/"> 哈Ha！ <br><br> 我在一家开发在线游戏的游戏公司工作。 目前，我们所有的游戏都被划分为多个“市场”（每个国家/地区一个“市场”），并且在每个“市场”中都有十几个世界，玩家在注册时可以在这些世界之间进行分配（当然，有时他们可以自己选择）。 每个世界都有一个数据库和一个或多个Web /应用程序服务器。 因此，负载几乎均匀地分布在世界/服务器之间，结果，我们获得了最大的在线6K-8K播放器（这是最大数量，多数情况下少了几倍），每个世界每个黄金时段有200-300个请求。 <br><br> 这种将参与者分为市场和世界的结构已经过时；参与者希望获得全球化的东西。 在上一届的比赛中，我们停止了按国家/地区划分人员，只留下了一个/两个市场（美国和欧洲），但每个市场仍然有很多世界。 下一步将是开发具有新架构的游戏，并通过<b>一个数据库</b>将所有玩家统一在一个世界中。 <br><br> 今天，我想谈谈我的任务是如何检查一个流行游戏的整个网络（一次是50-200,000个用户）是否“发送”以玩基于新架构的下一款游戏，以及是否整个系统，特别是数据库（ <b>PostgreSQL 11</b> ）实际上可以承受这样的负载，如果不能承受，则找出最大值。 我将告诉您一些有关已出现的问题以及准备测试如此多的用户的决定，过程本身以及有关结果的信息。 <br><a name="habracut"></a><br><h2> 前言 </h2><br> 过去，在<b>InnoGames GmbH，</b>每个游戏团队经常使用不同的技术，编程语言和数据库来根据自己的口味和肤色创建一个游戏项目。 此外，我们有许多外部系统负责付款，发送推送通知，营销等。 为了与这些系统一起使用，开发人员还尽可能地创建了他们独特的界面。 <br><br> 当前在移动游戏业务中有很多<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">钱</a> ，因此竞争也很多。 在这里，从营销上花费的每一美元以及从上面获得的更多钱取回都是非常重要的，因此，即使所有游戏公司都不满足分析期望，即使在封闭测试阶段，它们也经常“关闭”游戏。 因此，在下一轮发明上浪费时间是无利可图的，因此决定创建一个统一的平台，该平台将为开发人员提供一个现成的解决方案，用于与所有外部系统，带有复制的数据库和所有最佳实践的集成。 开发人员所需要做的就是在此基础上开发和“投放”一款出色的游戏，而不是在与游戏本身无关的开发上浪费时间。 <br><br> 这个平台叫做<b>GameStarter</b> ： <br><br><img src="https://habrastorage.org/webt/fz/go/g3/fzgog3jsz4rzjqi0zvbwzysz-po.jpeg" alt="图片"><br><br> 所以，到了重点。 将来所有InnoGames游戏都将在此平台上构建，该平台具有两个数据库-master和game（PostgreSQL 11）。  Master会存储有关玩家的基本信息（登录名，密码等），并且主要仅参与游戏本身的登录/注册过程。 游戏-游戏本身的数据库，相应地，所有游戏数据和实体都存储在该数据库中，这是游戏的核心，整个负载将在此存储。 <br> 因此，出现了一个问题，即整个结构是否可以承受这样一个潜在的用户数量，该数量等于我们最受欢迎的游戏之一的最大在线人数。 <br><br><h2> 挑战赛 </h2><br> 任务本身是这样的：检查启用了复制的数据库（PostgreSQL 11）是否可以承受整个PowerEdge M630系统管理程序（HV）所承受的当前负载最大的游戏中的所有负载。 <br> 我要澄清的是，目前的任务<b>只是</b>使用现有的数据库配置<b>来验证</b> ，我们是根据最佳做法和我们自己的经验形成的。 <br><br> 我马上要说数据库，整个系统显示得很好，除了几点。 但是，这个特定的游戏项目处于原型阶段，并且在将来，随着游戏机制的复杂化，对数据库的请求将变得更加复杂，负载本身可能会显着增加，并且其性质可能会发生变化。 为避免这种情况，有必要对每个或多或少重要的里程碑进行迭代测试。 在数十万名用户中自动化运行这些测试的能力已成为现阶段的主要任务。 <br><br><h2> 个人资料 </h2><br> 像任何负载测试一样，这一切都从负载配置文件开始。 <br> 我们的潜在价值CCU60（CCU是特定时间段内的最大用户数，在这种情况下为60分钟）为<b>250,000个</b>用户。 竞争性虚拟用户（VU）的数量低于CCU60，分析家建议可以将其安全地分为两个。 汇总并接受<b>150,000个</b>竞争性VU。 <br><br> 每秒的总请求数来自一个负载比较大的游戏： <br><br><img src="https://habrastorage.org/webt/lv/te/69/lvte69rifceelurn7r3t7trbgs4.png"><br><br> 因此，我们的目标负载为<b>150,000</b> VU时〜20,000 <b>个请求/秒</b> 。 <br><br><h2> 结构形式 </h2><br><h3>  “看台”的特征 </h3><br> 在上<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">一篇文章中，</a>我已经讨论了自动化负载测试的整个过程。 此外，我可能会再说一遍，但我会更详细地告诉您一些要点。 <br><br><img src="https://habrastorage.org/webt/zh/hz/eo/zhhzeorw5_gboyuocu9ajmb3ulo.png"><br><br> 在图中，蓝色方块是我们的虚拟机管理程序（HV），它是由许多服务器（Dell M620-M640）组成的云。 在每个HV上，通过KVM（混合的Web /应用程序和数据库）启动了十二个虚拟机（VM）。 创建任何新的VM时，会在适当的HV的参数集中进行平衡和搜索，并且最初不知道它将在哪个服务器上运行。 <br><br><h4> 数据库（游戏数据库）： </h4><br> 但出于db1的目的，我们基于<b>M630</b>保留了单独的HV targer_hypervisor。 <br><br>  targer_hypervisor的简要特征： <br><br> 戴尔M_630 <br> 型号名称：英特尔®至强®CPU E5-2680 v3 @ 2.50GHz <br>  CPU（s）：48 <br> 每个核心线程数：2 <br> 每个插槽的芯数：12 <br> 插座：2 <br> 内存：128 GB <br>  Debian GNU / Linux 9（延伸） <br>  4.9.0-8-amd64＃1 SMP Debian 4.9.130-2（2018-10-27） <br><br><div class="spoiler">  <b class="spoiler_title">详细规格</b> <div class="spoiler_text">  Debian GNU / Linux 9（延伸） <br>  4.9.0-8-amd64＃1 SMP Debian 4.9.130-2（2018-10-27） <br>  lscpu <br> 架构：x86_64 <br>  CPU操作模式：32位，64位 <br> 字节顺序：小尾数 <br>  CPU（s）：48 <br> 在线CPU列表：0-47 <br> 每个核心线程数：2 <br> 每个插槽的芯数：12 <br> 插座：2 <br>  NUMA个节点：2 <br> 供应商ID：正版英特尔 <br>  CPU系列：6 <br> 型号：63 <br> 型号名称：英特尔®至强®CPU E5-2680 v3 @ 2.50GHz <br> 步进：2 <br>  CPU MHz：1309.356 <br>  CPU最大MHz：3300.0000 <br>  CPU最低MHz：1200.0000 <br>  BogoMIPS：4988.42 <br> 虚拟化：VT-x <br>  L1d快取：32K <br>  L1i缓存：32K <br>  L2快取：256K <br> 三级缓存：30720K <br>  NUMA node0 CPU（s）：0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42 44.46 <br>  NUMA node1 CPU：1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43 ，45.47 <br> 标志：fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm常数qtsopmooptoptsoptsoptsoptsoptsoptsoptsoptsopts SMX EST TM2 SSSE3 SDBG FMA CX16 xtpr PDCM PCID DCA sse4_1 sse4_2 x2apic movbe POPCNT tsc_deadline_timer AES XSAVE AVX F16C rdrand lahf_lm ABM EPB invpcid_single SSBD IBRS ibpb stibp凯泽tpr_shadow vnmi FlexPriority可EPT VPID fsgsbase tsc_adjust BMI1 AVX2 SMEP bmi2 ERMS invpcid CQM xsaveopt cqm_llc cqm_occup_llc dtherm IDA阿拉特pln积分flush_l1d <br><br>  / usr / bin / qemu-system-x86_64 --version <br>  QEMU仿真器版本2.8.1（Debian 1：2.8 + dfsg-6 + deb9u5） <br> 版权所有©2003-2016 Fabrice Bellard和QEMU项目开发人员 <br></div></div><br>  db1的简要特征： <br> 架构：x86_64 <br>  CPU（s）：48 <br> 内存：64 GB <br>  4.9.0-8-amd64＃1 SMP Debian 4.9.144-3.1（2019-02-19）x86_64 GNU / Linux <br>  Debian GNU / Linux 9（延伸） <br>  psql（PostgreSQL）11.2（Debian 11.2-1.pgdg90 +1） <br><br><div class="spoiler">  <b class="spoiler_title">PostgreSQL配置和一些解释</b> <div class="spoiler_text">  seq_page_cost = 1.0 <br>  random_page_cost = 1.1＃我们有SSD <br> 包括'/etc/postgresql/11/main/extension.conf' <br>  log_line_prefix ='％t [％p-％l]％q％u @％h' <br>  log_checkpoints =开启 <br>  log_lock_waits =开 <br>  log_statement = ddl <br>  log_min_duration_statement = 100 <br>  log_temp_files = 0 <br>  autovacuum_max_workers = 5 <br>  autovacuum_naptime = 10秒 <br>  autovacuum_vacuum_cost_delay = 20ms <br>  vacuum_cost_limit = 2000 <br>  maintenance_work_mem = 128MB <br>  sync_commit =关 <br>  checkpoint_timeout = 30分钟 <br>  listen_addresses ='*' <br>  work_mem = 32MB <br>  Effective_cache_size = 26214MB＃50％的可用内存 <br>  shared_buffers = 16384MB＃可用内存的25％ <br>  max_wal_size = 15GB <br>  min_wal_size = 80MB <br>  wal_level = hot_standby <br>  max_wal_senders = 10 <br>  wal_compression =开启 <br>  archive_mode =开 <br>  archive_command ='/ bin / true' <br>  archive_timeout = 1800 <br>  hot_standby =开启 <br>  wal_log_hints =开启 <br>  hot_standby_feedback =开启 <br></div></div><br>  <b>hot_standby_feedback</b>默认为关闭，我们已将其打开，但后来必须将其关闭才能进行成功的测试。 稍后我将解释原因。 <br><br> 数据库中的主要活动表（构造，生产，游戏实体，建筑物，core_inventory_player_resource，幸存者）使用bash脚本预先填充了数据（大约80GB）。 <br><br><div class="spoiler">  <b class="spoiler_title">db-fill-script.sh</b> <div class="spoiler_text"><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash --clean TRUNCATE TABLE production CASCADE; TRUNCATE TABLE construction CASCADE; TRUNCATE TABLE building CASCADE; TRUNCATE TABLE grid CASCADE; TRUNCATE TABLE core_inventory_player_resource CASCADE; TRUNCATE TABLE survivor CASCADE; TRUNCATE TABLE city CASCADE; TRUNCATE TABLE game_entity CASCADE; TRUNCATE TABLE player CASCADE; TRUNCATE TABLE core_player CASCADE; TRUNCATE TABLE core_client_device CASCADE; --core_client_device INSERT INTO core_client_device (id, creation_date, modification_date, device_model, device_name, locale, platform, user_agent, os_type, os_version, network_type, device_type) SELECT (1000000000+generate_series(0,999999)) AS id, now(), now(), 'device model', 'device name', 'en_DK', 'ios', 'ios user agent', 'android', '8.1', 'wlan', 'browser'; --core_player INSERT INTO core_player (id, guest, name, nickname, premium_points, soft_deleted, session_id, tracking_device_data_id) SELECT (1000000000+generate_series(0,999999)) AS id, true, 'guest0000000000000000000', null, 100, false, '00000000-0000-0000-0000-000000000000', (1000000000+generate_series(0,999999)) ; --player INSERT INTO player (id, creation_date, modification_date, core_player_id) SELECT (1000000000+generate_series(0,999999)) , now(), now(), (1000000000+generate_series(0,999999)) ; --city INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1000000000+generate_series(0,999999)) , 'city', now(), now(); INSERT INTO city (id, game_design, player_id) SELECT (1000000000+generate_series(0,999999)) , 'city.default', (1000000000+generate_series(0,999999)) ; --survivor INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1001000000+generate_series(0,999999)) , 'survivor', now(), now(); INSERT INTO survivor (id, game_design, owning_entity_id, type) SELECT (1001000000+generate_series(0,999999)) , 'survivor.prod_1', (1000000000+generate_series(0,999999)) , 'survivor'; --core_inventory_player_resource INSERT INTO core_inventory_player_resource (id, creation_date, modification_date, amount, player_id, resource_key) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 1000, (1000000000+generate_series(0,1999999)/2) , CONCAT('resource_', (1000000000+generate_series(0,1999999)) % 2); --grid DROP INDEX grid_area_idx; INSERT INTO grid (id, creation_date, modification_date, area, city_id) SELECT (1000000000+generate_series(0,19999999)) , NOW(), NOW(), BOX '0,0,4,4', (1000000000+generate_series(0,19999999)/20) ; create index on grid using gist (area box_ops); --building INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1002000000+generate_series(0,99999999)) , 'building', now(), now(); INSERT INTO building (id, game_design, owning_entity_id, x, y, rotation, type) SELECT (1002000000+generate_series(0,99999999)) , 'building.building_prod_1', (1000000000+generate_series(0,99999999)/100) , 0, 0, 'DEGREES_0', 'building'; --construction INSERT INTO construction (id, creation_date, modification_date, definition, entity_id, start) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 'construction.building_prod_1-construction', (1002000000+generate_series(0,1999999)*50) , NOW(); --production INSERT INTO production (id, creation_date, modification_date, active, definition, entity_id, start_time) SELECT (1000000000+generate_series(0,49999999)) , NOW(), NOW(), true, 'production.building_prod_1_production_1', (1002000000+generate_series(0,49999999)*2) , NOW();</span></span></code> </pre> <br></div></div><br> 复制： <br><br><pre> <code class="plaintext hljs">SELECT * FROM pg_stat_replication; pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_lsn | write_lsn | flush_lsn | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state -----+----------+---------+---------------------+--------------+---------------------+-------------+-------------------------------+--------------+-----------+------------+------------+------------+------------+-----------------+-----------------+-----------------+---------------+------------ 759 | 17035 | repmgr | xl1db2 | xxxx | xl1db2 | 51142 | 2019-01-27 08:56:44.581758+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000393 | 00:00:00.001159 | 00:00:00.001313 | 0 | async 977 | 17035 | repmgr | xl1db3 |xxxxx | xl1db3 | 42888 | 2019-01-27 08:57:03.232969+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000373 | 00:00:00.000798 | 00:00:00.000919 | 0 | async</code> </pre><br><h4> 应用服务器 </h4><br> 然后，在各种配置和容量的生产性HV（prod_hypervisors）上，启动了15个应用程序服务器：8个内核，4GB。 可以说的最主要的事情：openjdk 11.0.1 2018-10-16，春季，通过<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">hikari</a>与数据库交互（hikari.maximum-pool-size：50） <br><br><h4> 压力测试环境 </h4><br> 整个负载测试环境由一台主服务器<b>admin.loadtest</b>和几<b>台generatorN.loadtest</b>服务器组成（本例中有14台）。 <br><br>  <b>generatorN.loadtest-</b> “裸机” VM Debian Linux 9，已安装Java8。32个内核/ 32 GB。 它们位于“非生产型” HV上，以免意外破坏重要VM的性能。 <br><br>  <b>admin.loadtest</b> -Debian Linux 9 <b>虚拟机</b> ，16个核心/ 16个演出，它运行Jenkins，JLTC和其他其他不重要的软​​件。 <br><br>  JLTC- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">jmeter负载测试中心</a> 。  Py / Django中的一个系统，用于控制和自动化测试的启动以及结果的分析。 <br><br><h3> 测试启动方案 </h3><br><img src="https://habrastorage.org/webt/pb/f_/th/pbf_thx7mwuois96bffvbeehtxk.png"><br><br> 运行测试的过程如下所示： <br><br><ul><li> 该测试从<b>詹金斯（Jenkins</b> ）启动。 选择所需的作业，然后您需要输入所需的测试参数： <ul><li> 持续时间-测试持续时间 </li><li>  <b>RAMPUP-</b> “热身”时间 </li><li>  <b>THREAD_COUNT_TOTAL-</b>所需的虚拟用户数（VU）或线程 </li><li>  <b>TARGET_RESPONSE_TIME</b>是一个重要的参数，因此为了避免整个系统过载，我们设置了所需的响应时间，因此该测试会将负载保持在整个系统的响应时间不超过指定响应时间的水平。 </li></ul></li><li> 发射 </li><li>  Jenkins从Gitlab克隆了测试计划，并将其发送给JLTC。 </li><li>  JLTC可以配合测试计划工作（例如，插入CSV简单编写器）。 </li><li>  JLTC计算所需数量的Jmeter服务器以运行所需数量的VU（THREAD_COUNT_TOTAL）。 </li><li>  JLTC连接到每个loadgeneratorN生成器并启动jmeter服务器。 </li></ul><br> 在测试期间， <b>JMeter客户端会</b>生成一个包含结果的CSV文件。 因此，在测试过程中，数据量和该文件的大小以惊人的速度增长，并且在测试<b>Daemon</b>发明出来（作为实验）后就无法用于分析， <b>Daemon</b>可以<i>“动态”</i>解析它。 <br><br><h3> 测试计划 </h3><br> 您可以在<a href="">此处</a>下载测试计划。 <br><br> 注册/登录后，用户将在“ <b>行为”</b>模块中工作，该模块由几个<b>吞吐量控制器</b>组成，这些<b>控制器</b>指定特定游戏功能的可能性。 在每个吞吐量控制器中，都有一个<b>模块控制器</b> ，它引用实现该功能的相应模块。 <br><br><img src="https://habrastorage.org/webt/t0/ws/qp/t0wsqpbkgo-w6dt55gvxd6aw9pm.png"><br><br><h4> 离题 </h4><br> 在脚本的开发过程中，我们尝试最大程度地使用Groovy，并且由于我们的Java程序员，我为自己找到了一些技巧（也许对某人有用）： <br><br><ul><li> 您可以在测试计划开始的某个地方声明一个函数，然后在其他预处理器，后处理器和采样器中使用它。 更好的特性<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">：将方法转变为闭包</a> ： <br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//     - def sum(Integer x, Integer y) { return x + y } vars.putObject('sum', this.&amp;sum) //      closure.   . //     sampler`       def sum= vars.getObject('sum'); println sum(2, 2);</span></span></code> </pre> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">groovy.json.JsonSlurper</a>是一个很棒的快速JSON解析器。 与groovy一起，它使您可以优雅地解析和处理数据： <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> groovy.json.JsonSlurper def canBuild = vars.getObject(canBuild); <span class="hljs-comment"><span class="hljs-comment">// ""       def content = jsonSlurper.parseText(response).content def buildings = content[0].buildings //         //               def constructableBuildingDefs = buildings .collect { k,v -&gt; v } .grep{ it.definitions .grep { it2 -&gt; it2['@type'] == 'type.googleapis.com/ConstructionDefinitionDTO'} .grep { it2 -&gt; canBuild(it2) } //   .size() &gt; 0 } if (!constructableBuildingDefs) { return; } Collections.shuffle(constructableBuildingDefs) //       </span></span></code> </pre></li></ul><br><h3>  VU /线程 </h3><br> 在Jenkins中配置作业时，当用户使用THREAD_COUNT_TOTAL参数输入所需数量的VU时，有必要以某种方式启动所需数量的Jmeter服务器并在它们之间分配最终VU数量。 这部分与JLTC一起位于称为<b>控制器/配置</b>的部分中。 <br><br> 本质上，算法如下： <br><br><ul><li> 我们将所需数量的<b>VUthreads_num划分</b>为200-300个线程，并根据或多或少的适当大小<b>-Xmsm -Xmxm</b>确定一个<i>jmeter-server</i> <b>required_memory_for_jri</b> （JRI-我称为Jmeter远程实例，而不是Jmeter-server）的所需内存值。 </li><li> 从threads_num和<b>Required_memory_for_jri中</b> ，我们找到了jmeter服务器的总数： <b>target_amount_jri</b>和所需内存的总数： <b>required_memory_total</b> 。 </li><li> 我们将所有loadgeneratorN生成器一一分类，并根据其上的可用内存启动最大数量的jmeter服务器。 只要正在运行的current_amount_jri实例数<b>不等于</b> target_amount_jri。 </li><li>  （如果生成器数和总内存不足，请向池中添加一个新的） </li><li> 我们使用<b>netstat</b>连接到每个生成器， <b>我们会</b>记住所有繁忙的端口，并在所需数量的jmeter服务器上的随机端口（未占用的端口）上运行： <br><br><pre> <code class="python hljs"> netstat_cmd= <span class="hljs-string"><span class="hljs-string">'netstat -tulpn | grep LISTEN'</span></span> stdin, stdout, stderr = ssh.exec_command(cmd1) used_ports = [] netstat_output = str(stdout.readlines()) ports = re.findall(<span class="hljs-string"><span class="hljs-string">'\d+\.\d+\.\d+\.\d+\:(\d+)'</span></span>, netstat_output) ports_ipv6 = re.findall(<span class="hljs-string"><span class="hljs-string">'\:\:\:(\d+)'</span></span>, netstat_output) p.wait() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports: used_ports.append(int(port)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports_ipv6: used_ports.append(int(port)) ssh.close() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, possible_jris_on_host + <span class="hljs-number"><span class="hljs-number">1</span></span>): port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> used_ports: port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-comment"><span class="hljs-comment"># ...  Jmeter-    </span></span></code> </pre></li><li> 我们一次收集所有正在运行的jmeter服务器，其格式为地址：端口，例如<b>generator13：15576，generator9：14015，generator11：19152，generator14：12125，generator2：17602</b> </li><li> 测试开始时，结果列表和threads_per_host将发送到JMeter客户端： <br><br><pre> <code class="bash hljs">REMOTE_TESTING_FLAG=<span class="hljs-string"><span class="hljs-string">" -R </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$REMOTE_HOSTS_STRING</span></span></span><span class="hljs-string">"</span></span> java -jar -Xms7g -Xmx7g -Xss228k <span class="hljs-variable"><span class="hljs-variable">$JMETER_DIR</span></span>/bin/ApacheJMeter.jar -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -n -t <span class="hljs-variable"><span class="hljs-variable">$TEST_PLAN</span></span> -j <span class="hljs-variable"><span class="hljs-variable">$WORKSPACE</span></span>/loadtest.log -GTHREAD_COUNT=<span class="hljs-variable"><span class="hljs-variable">$THREADS_PER_HOST</span></span> <span class="hljs-variable"><span class="hljs-variable">$OTHER_VARS</span></span> <span class="hljs-variable"><span class="hljs-variable">$REMOTE_TESTING_FLAG</span></span> -Jjmeter.save.saveservice.default_delimiter=,</code> </pre></li></ul><br> 在我们的案例中，测试是同时从300个Jmeter服务器进行的，每个服务器500个线程，一台带有Java参数的Jmeter服务器的启动格式如下所示： <br><br><pre> <code class="bash hljs">nohup java -server -Xms1200m -Xmx1200m -Xss228k -XX:+DisableExplicitGC -XX:+CMSClassUnloadingEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -Djava.net.preferIPv6Addresses=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -Djava.net.preferIPv4Stack=<span class="hljs-literal"><span class="hljs-literal">false</span></span> -jar <span class="hljs-string"><span class="hljs-string">"/tmp/jmeter-JwKse5nY/bin/ApacheJMeter.jar"</span></span> -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> <span class="hljs-string"><span class="hljs-string">"-Djava.rmi.server.hostname=generator12.loadtest.ig.local"</span></span> -Duser.dir=/tmp/jmeter-JwKse5nY/bin/ -Dserver_port=13114 -s -Jpoll=49 &gt; /dev/null 2&gt;&amp;1</code> </pre> <br><h3>  50毫秒 </h3><br> 任务是确定我们的数据库可以承受的负载量，而不是使数据库以及整个系统整体过载到临界状态。 拥有如此多的Jmeter服务器，您需要以某种方式将负载保持在一定水平，而不是杀死整个系统。 开始测试时指定的<b>TARGET_RESPONSE_TIME</b>参数对此负责。 我们同意<b>50ms</b>是系统应负责的最佳响应时间。 <br><br> 在JMeter中，默认情况下，有许多不同的计时器可让您控制吞吐量，但是在我们的情况下，从何处获取它是未知的。 但是有<b>JSR223-Timer</b> ，您可以使用它使用<b>当前的</b>系统<b>响应时间提出一些建议</b> 。 计时器本身位于主要的<b>Behavior</b>块中： <br><br><img src="https://habrastorage.org/webt/uv/o8/rb/uvo8rb9ph7mr1xhxkzxccsfa06a.png"><br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      = 0 vars.put('samples', '20'); vars.putObject('respAvg', ${TARGET_RESPONSE_TIME}.0); vars.putObject('sleep', 0.0); //  JSR223-Timer           "" double sleep = vars.getObject('sleep'); double respAvg = vars.getObject('respAvg'); double previous = sleep; double target = ${TARGET_RESPONSE_TIME}; if (respAvg &lt; target) { sleep /= 1.5; } if (respAvg &gt; target) { sleep *= 1.1; } sleep = Math.max(10, sleep); //      sleep = Math.min(20000, sleep); vars.putObject('sleep', sleep); return (int)sleep;</span></span></code> </pre><br><h3> 结果分析（守护程序） </h3><br> 除了Grafana中的图形外，还必须具有汇总的测试结果，以便随后可以在JLTC中对测试进行比较。 <br><br> 一个这样的测试每秒生成16k-20k个请求，很容易计算出它在4小时内会生成一个大小为数百GB的CSV文件，因此有必要提出一项每分钟解析一次数据，将其发送到数据库并清理主文件的作业。 <br><br><img src="https://habrastorage.org/webt/pb/mj/kc/pbmjkcwgjcxupnihgzpzmqd0nvq.png"><br><br> 算法如下： <br><br><ul><li> 我们从jmeter-client生成的CSV文件<b>result.jtl中</b>读取数据，将其保存并清理文件（您需要正确清理它，否则，空文件将具有相同的FD，且大小相同）： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(jmeter_results_file, <span class="hljs-string"><span class="hljs-string">'r+'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: rows = f.readlines() f.seek(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.truncate(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.writelines(rows[<span class="hljs-number"><span class="hljs-number">-1</span></span>])</code> </pre></li><li> 我们将读取的数据写入临时文件<b>temp_result.jtl中</b> ： <br><br><pre> <code class="python hljs">rows_num = len(rows) open(temp_result_filename, <span class="hljs-string"><span class="hljs-string">'w'</span></span>).writelines(rows[<span class="hljs-number"><span class="hljs-number">0</span></span>:rows_num]) <span class="hljs-comment"><span class="hljs-comment"># avoid last line</span></span></code> </pre> </li><li> 我们读取了文件<b>temp_result.jtl</b> 。 我们以分钟为单位分发读取的数据： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.readlines(): row = r.split(<span class="hljs-string"><span class="hljs-string">','</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) == <span class="hljs-number"><span class="hljs-number">13</span></span>: ts_c = int(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) dt_c = datetime.datetime.fromtimestamp(ts_c/<span class="hljs-number"><span class="hljs-number">1000</span></span>) minutes_data.setdefault(dt_c.strftime(<span class="hljs-string"><span class="hljs-string">'%Y_%m_%d_%H_%M'</span></span>), []).append(r)</code> </pre></li><li>  <b>minutes_data中</b>每分钟的数据<b>将</b>写入<b>to_parse /</b>文件夹中的相应文件。  （因此，目前，测试的每一分钟都有其自己的数据文件，然后在聚合过程中，数据按什么顺序进入每个文件<b>都</b>无关紧要）： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> key, value <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> minutes_data.iteritems(): <span class="hljs-comment"><span class="hljs-comment">#      timestamp (key) temp_ts_file = os.path.join(temp_to_parse_path, key) open(temp_ts_file, 'a+').writelines(value)</span></span></code> </pre></li><li> 在此过程中，我们分析了to_parse文件夹中的文件，如果它们在一分钟之内没有变化，那么该文件是数据分析，聚合并发送到JLTC数据库的候选文件： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(temp_to_parse_path): data_file = os.path.join(temp_to_parse_path, filename) file_mod_time = os.stat(data_file).st_mtime last_time = (time.time() - file_mod_time) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> last_time &gt; <span class="hljs-number"><span class="hljs-number">60</span></span>: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON] File {} was not modified since 1min, adding to parse list.'</span></span>.format(data_file)) files_to_parse.append(data_file)</code> </pre></li><li> 如果有这样的文件（一个或多个），那么我们将它们解析后发送到<b>parse_csv_data</b>函数（每个文件并行）： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> files_to_parse: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON THREAD] Parse {}.'</span></span>.format(f)) t = threading.Thread( target=parse_csv_data, args=( f, jmeter_results_file_fields, test, data_resolution)) t.start() threads.append(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> threads: t.join()</code> </pre></li></ul><br>  cron.d中的守护进程本身每分钟启动一次： <br><br> 守护进程每分钟从cron.d开始： <br><br><pre> <code class="bash hljs">* * * * * root sleep 21 &amp;&amp; /usr/bin/python /var/lib/jltc/manage.py daemon</code> </pre> <br> 因此，具有结果的文件不会膨胀到无法想象的大小，而是会进行动态分析并清除。 <br><br><h2> 结果 </h2><br><h3> 该应用程序 </h3><br> 我们的150,000名虚拟玩家： <br><br><img src="https://habrastorage.org/webt/sv/ex/ep/svexepi9ikzy0unpxur96mty5q8.png"><br><br> 该测试试图“匹配” 50ms的响应时间，因此负载本身在16k-18k个请求/ c之间的区域中不断跳跃： <br><br><img src="https://habrastorage.org/webt/-z/98/oi/-z98oi-_8a41hkqbrmz2rvzmryk.png"><br><br> 应用程序服务器负载（15个应用程序）。 速度较慢的M620上有两台服务器是“不幸的”： <br><br><img src="https://habrastorage.org/webt/nc/xy/et/ncxyetqyk_a8mbhjocndd-yxgkm.png"><br><br> 数据库响应时间（对于应用服务器）： <br><br><img src="https://habrastorage.org/webt/zr/a-/gw/zra-gwtq_vqhtfhlrjzzy1osisg.png"><br><br><h3> 资料库 </h3><br>  db1（VM）上的CPU util： <br><br><img src="https://habrastorage.org/webt/ej/hn/in/ejhnin0jo_7rrzhlj7pqko6udnq.png"><br><br> 系统管理程序上的CPU util： <br><br><img src="https://habrastorage.org/webt/uw/ik/tz/uwiktzvcdzydlsjaoexqfbr3tay.png"><br><br> 虚拟机上的负载较低，因为它认为虚拟机上有48个实际内核可供使用，实际上，虚拟机管理程序上有24个<b>超线程</b>内核。 <br><br>  <b>最多〜25万次查询/秒</b>进入数据库，包括（83％选择，3％-插入，11.6％-更新（90％HOT），1.6％删除）： <br><br><img src="https://habrastorage.org/webt/lx/lu/bl/lxlublobhm4nm3c45g9jikcstc4.png"><br><br><img src="https://habrastorage.org/webt/18/jw/gp/18jwgpmebrkyot3ngvarsl_3ysu.png"><br><br> 在默认值<b>autovacuum_vacuum_scale_factor</b> = 0.2的情况下，随着测试的进行，死元组的数量增长非常快（表大小不断增加），这多次导致数据库性能出现问题，从而使整个测试多次崩溃。 我必须通过为此参数分配个人值autovacuum_vacuum_scale_factor来“控制”某些表的增长： <br><br><div class="spoiler">  <b class="spoiler_title">ALTER TABLE ... SET（autovacuum_vacuum_scale_factor = ...）</b> <div class="spoiler_text">  ALTER TABLE构造集（autovacuum_vacuum_scale_factor = 0.10）; <br>  ALTER TABLE生产设置（autovacuum_vacuum_scale_factor = 0.01）; <br>  ALTER TABLE game_entity SET（autovacuum_vacuum_scale_factor = 0.01）; <br>  ALTER TABLE game_entity SET（autovacuum_analyze_scale_factor = 0.01）; <br>  ALTER TABLE建筑物设置（autovacuum_vacuum_scale_factor = 0.01）; <br>  ALTER TABLE建筑设置（autovacuum_analyze_scale_factor = 0.01）; <br>  ALTER TABLE core_inventory_player_resource SET（autovacuum_vacuum_scale_factor = 0.10）; <br>  ALTER TABLE Survivor SET（autovacuum_vacuum_scale_factor = 0.01）; <br>  ALTER TABLE幸存者集（autovacuum_analyze_scale_factor = 0.01）; <br></div></div><br><img src="https://habrastorage.org/webt/0s/ja/1e/0sja1e1m3-2gitbmhh8j24t2ktu.png"><br><br> 理想情况下，rows_fetched应​​该接近rows_returned，幸运的是，我们观察到： <br><br><img src="https://habrastorage.org/webt/e4/k6/zo/e4k6zobp25h5asrmxhmficoea3a.png"><br><br><h4>  hot_standby_feedback </h4><br> 问题在于<b>hot_standby_feedback</b>参数，如果<b>主</b>服务器的<b>备用</b>服务器没有时间应用来自WAL文件的更改，则该参数会极大地影响<b>主</b>服务器的性能。 该文档（https://postgrespro.ru/docs/postgrespro/11/runtime-config-replication）指出，它“确定热备用服务器是将当前正在执行的请求通知主服务器还是上级从服务器。” 默认情况下它是关闭的，但是在我们的配置中它是打开的。 导致可悲的后果，如果有2个备用服务器，并且加载期间的复制滞后不同于零（出于各种原因），则可以观察到这样的情况，这可能导致整个测试崩溃： <br><br><img src="https://habrastorage.org/webt/vl/1l/jd/vl1ljdockxrjlfsoiybq751vo9y.png"><br><br><img src="https://habrastorage.org/webt/qh/4s/m_/qh4sm_hpnunb2w0axzhk90lmf6u.png"><br><br> 这是由于以下事实：启用hot_standby_feedback时，VACUUM不想删除备用服务器的事务ID中的无效元组，以防止复制冲突。 详细的文章<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">PostgreSQL中的hot_standby_feedback实际上是做什么的</a> ： <br><br><pre> <code class="plaintext hljs">xl1_game=# VACUUM VERBOSE core_inventory_player_resource; INFO: vacuuming "public.core_inventory_player_resource" INFO: scanned index "core_inventory_player_resource_pkey" to remove 62869 row versions DETAIL: CPU: user: 1.37 s, system: 0.58 s, elapsed: 4.20 s ………... INFO: "core_inventory_player_resource": found 13682 removable, 7257082 nonremovable row versions in 71842 out of 650753 pages &lt;b&gt;DETAIL: 3427824 dead row versions cannot be removed yet, oldest xmin: 3810193429&lt;/b&gt; There were 1920498 unused item pointers. Skipped 8 pages due to buffer pins, 520953 frozen pages. 0 pages are entirely empty. CPU: user: 4.55 s, system: 1.46 s, elapsed: 11.74 s.</code> </pre><br> 如此大量的死元组导致了上面的图片。 这是两个测试，分别打开和关闭hot_standby_feedback： <br><br><img src="https://habrastorage.org/webt/8f/od/n6/8fodn60lohgzsu-twheqysldjzy.png"><br><br> 这是我们在测试过程中的复制滞后，将来有必要做一些事情： <br><br><img src="https://habrastorage.org/webt/et/s0/7h/ets07hkl8skkv5wexxjrgi-3x7m.png"><br><br><h2> 结论 </h2><br> 幸运的是，此测试（或不幸的是，对于本文的内容而言）表明，在游戏原型的现阶段，很有可能吸收用户方面的期望负载，这足以为进一步的原型开发提供开绿灯。 在后续的开发阶段，有必要遵循基本规则（以保持所执行查询的简单性，防止索引过多以及未索引的读数等），最重要的是，在开发的每个重要阶段都要对项目进行测试，以发现并解决问题。可以早些。 也许很快，我将写一篇文章，因为我们已经解决了特定的问题。 <br><br> 祝大家好运！ <br><br> 我们的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">GitHub</a>以防万一;） </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN445368/">https://habr.com/ru/post/zh-CN445368/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN445356/index.html">DUMP-2019的移动部分概述：在日常工作中得到最大应用和帮助</a></li>
<li><a href="../zh-CN445358/index.html">在Unity中组织事件系统-通过游戏设计师的眼光</a></li>
<li><a href="../zh-CN445360/index.html">JavaScript采访的5个典型任务：解析和解决方案</a></li>
<li><a href="../zh-CN445362/index.html">《分布式系统》一书。 设计模式</a></li>
<li><a href="../zh-CN445366/index.html">由于SIMD块，如何根据Baikal-T1处理器上的GOST 28147-89加快加密速度</a></li>
<li><a href="../zh-CN445370/index.html">Prometheus 2中的TSDB分析</a></li>
<li><a href="../zh-CN445372/index.html">机器视觉与人类直觉：破坏对象识别程序操作的算法</a></li>
<li><a href="../zh-CN445378/index.html">迷宫：分类，生成，寻找解决方案</a></li>
<li><a href="../zh-CN445380/index.html">现代PHP美丽而高效</a></li>
<li><a href="../zh-CN445384/index.html">e娥四号任务-着陆模块和中继卫星上的科学设备</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
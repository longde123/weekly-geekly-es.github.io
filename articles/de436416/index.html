<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéå ü§üüèæ üêÄ Migration von Mongo nach Postgres: Das Guardian-Zeitungserlebnis üéá üé° üê´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The Guardian ist eine der gr√∂√üten britischen Zeitungen und wurde 1821 gegr√ºndet. Seit fast 200 Jahren hat das Archiv eine ganze Menge angesammelt. Gl√º...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Migration von Mongo nach Postgres: Das Guardian-Zeitungserlebnis</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/436416/"><img src="https://habrastorage.org/webt/4w/zu/h3/4wzuh3ik2zdn_awvt9l2rhd4oia.jpeg" alt="Bild"><br><br>  The Guardian ist eine der gr√∂√üten britischen Zeitungen und wurde 1821 gegr√ºndet.  Seit fast 200 Jahren hat das Archiv eine ganze Menge angesammelt.  Gl√ºcklicherweise wird nicht alles auf der Website gespeichert - in den letzten Jahrzehnten.  Die Datenbank, die die Briten selbst als "Quelle der Wahrheit" f√ºr alle Online-Inhalte bezeichneten, enth√§lt etwa 2,3 Millionen Elemente.  Und irgendwann erkannten sie die Notwendigkeit einer Migration von Mongo zu Postgres SQL - nach einem hei√üen Julitag im Jahr 2015 wurden die Failover-Verfahren streng getestet.  Die Migration dauerte fast 3 Jahre! .. <br><br>  Wir haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel</a> √ºbersetzt, der beschreibt, wie der Migrationsprozess verlaufen ist und mit welchen Schwierigkeiten Administratoren konfrontiert sind.  Der Prozess ist lang, aber die Zusammenfassung ist einfach: Kommen Sie zur gro√üen Aufgabe und vereinbaren Sie, dass Fehler notwendig sind.  Am Ende, drei Jahre sp√§ter, gelang es den britischen Kollegen, das Ende der Migration zu feiern.  Und schlafen. <br><a name="habracut"></a><br><h4>  <b>Erster Teil: Der Anfang</b> </h4><br>  Bei Guardian wird der gr√∂√üte Teil des Inhalts, einschlie√ülich Artikeln, Blogs, Fotogalerien und Videos, in unserem eigenen CMS, Composer, produziert.  Bis vor kurzem arbeitete Composer mit der AWS-basierten Mongo DB zusammen.  Diese Datenbank war im Wesentlichen eine "Quelle der Wahrheit" f√ºr alle Online-Inhalte von Guardian - etwa 2,3 Millionen Elemente.  Und wir haben gerade die Migration von Mongo zu Postgres SQL abgeschlossen. <br><br>  Composer und seine Datenbanken wurden urspr√ºnglich in der Guardian Cloud gehostet, einem Rechenzentrum im Keller unseres B√ºros in der N√§he von Kings Cross, mit einem Failover an anderer Stelle in London.  An einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hei√üen Julitag im Jahr 2015 wurden</a> unsere Failover-Verfahren einem ziemlich strengen Test unterzogen. <br><br><img src="https://habrastorage.org/webt/ij/nu/wx/ijnuwxcxdtlrnupaxikvcqq7ofe.jpeg" alt="Bild"><br>  <i>Hitze: gut zum Tanzen am Brunnen, katastrophal f√ºr das Rechenzentrum.</i>  <i>Foto: Sarah Lee / W√§chter</i> <br><br>  Seitdem ist die Migration von Guardian zu AWS eine Frage von Leben und Tod.  F√ºr die Migration in die Cloud haben wir uns f√ºr den Kauf von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpsManager</a> , der Mongo DB-Verwaltungssoftware, entschieden und einen Vertrag √ºber den technischen Support von Mongo unterzeichnet.  Wir haben OpsManager verwendet, um Backups zu verwalten, unseren Datenbankcluster zu orchestrieren und zu √ºberwachen. <br><br>  Aufgrund redaktioneller Anforderungen mussten wir den Datenbankcluster und OpsManager auf unserer eigenen Infrastruktur in AWS ausf√ºhren und nicht die von Mongo verwaltete L√∂sung verwenden.  Wir mussten schwitzen, da Mongo keine Tools f√ºr die einfache Konfiguration in AWS bereitstellte: Wir haben die gesamte Infrastruktur manuell entworfen und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hunderte von Ruby-Skripten geschrieben</a> , um √úberwachungs- / Automatisierungsagenten zu installieren und neue Datenbankinstanzen zu orchestrieren.  Infolgedessen mussten wir im Team ein Team von Schulungsprogrammen zum Datenbankmanagement organisieren - was wir uns von OpsManager erhofft hatten. <br><br>  Seit dem √úbergang zu AWS sind zwei erhebliche Fehler aufgrund von Datenbankproblemen aufgetreten, von denen jeder mindestens eine Stunde lang keine Ver√∂ffentlichung auf theguardian.com zulie√ü.  In beiden F√§llen konnten uns weder die Mitarbeiter des technischen Supports von OpsManager noch der technische Support von Mongo ausreichend unterst√ºtzen, und wir haben das Problem selbst gel√∂st - in einem Fall dank eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mitglieds unseres Teams</a> , das es geschafft hat, die Situation telefonisch aus der W√ºste am Stadtrand von Abu Dhabi zu bew√§ltigen. <br><br>  Jedes der problematischen Probleme verdient einen eigenen Beitrag, aber hier sind die allgemeinen Punkte: <br><br><ul><li>  Achten Sie genau auf die Zeit - blockieren Sie den Zugriff auf Ihre VPC nicht so stark, dass NTP nicht mehr funktioniert. </li><li>  Das automatische Erstellen von Datenbankindizes beim Start der Anwendung ist eine schlechte Idee. </li><li>  Das Datenbankmanagement ist √§u√üerst wichtig und schwierig - und wir m√∂chten es nicht selbst tun. </li></ul><br>  OpsManager hat sein Versprechen einer einfachen Datenbankverwaltung nicht eingehalten.  Zum Beispiel erforderte die eigentliche Verwaltung von OpsManager selbst - insbesondere das Upgrade von OpsManager Version 1 auf Version 2 - viel Zeit und spezielle Kenntnisse √ºber unser OpsManager-Setup.  Aufgrund von √Ñnderungen im Authentifizierungsschema zwischen verschiedenen Versionen von Mongo DB konnte er sein Versprechen von ‚ÄûOne-Click-Updates‚Äú nicht einhalten.  Wir haben mindestens zwei Monate an Ingenieuren pro Jahr verloren, die die Datenbank verwalten. <br><br>  All diese Probleme, zusammen mit der erheblichen j√§hrlichen Geb√ºhr, die wir f√ºr den Supportvertrag und OpsManager gezahlt haben, zwangen uns, nach einer alternativen Datenbankoption mit den folgenden Merkmalen zu suchen: <br><br><ul><li>  Minimaler Aufwand f√ºr die Verwaltung der Datenbank. </li><li>  Verschl√ºsselung in Ruhe. </li><li>  Ein akzeptabler Migrationspfad mit Mongo. </li></ul><br>  Da auf allen anderen Diensten AWS ausgef√ºhrt wird, ist Dynamo, die NoSQL-Datenbank von Amazon, die naheliegende Wahl.  Leider unterst√ºtzte Dynamo zu diesem Zeitpunkt keine Verschl√ºsselung im Ruhezustand.  Nachdem wir ungef√§hr neun Monate auf das Hinzuf√ºgen dieser Funktion gewartet hatten, gaben wir diese Idee auf, indem wir uns f√ºr die Verwendung von Postgres auf AWS RDS entschieden. <br>  "Aber Postgres ist kein Dokumenten-Repository!"  - Sie sind emp√∂rt ... Nun ja, dies ist kein Repository von Docks, aber es enth√§lt Tabellen, die JSONB-Spalten √§hneln und Indizes in den Feldern des JSON-Blob-Tools unterst√ºtzen.  Wir hofften, dass wir mit JSONB mit minimalen √Ñnderungen an unserem Datenmodell von Mongo nach Postgres migrieren k√∂nnen.  Wenn wir in Zukunft zu einem relationaleren Modell √ºbergehen wollten, h√§tten wir dar√ºber hinaus eine solche Chance.  Eine weitere gro√üartige Sache bei Postgres ist, wie gut es funktioniert hat: F√ºr jede Frage, die wir hatten, wurde die Antwort in den meisten F√§llen bereits in Stack Overflow gegeben. <br><br>  In Bezug auf die Leistung waren wir uns sicher, dass Postgres dies tun k√∂nnte: Composer ist ein Tool ausschlie√ülich zum Aufzeichnen von Inhalten (es schreibt jedes Mal, wenn ein Journalist den Druck beendet, in die Datenbank), und normalerweise √ºberschreitet die Anzahl der gleichzeitigen Benutzer mehrere Hundert nicht - was das System nicht erfordert super hohe Leistung! <br><br><h4>  <b>Teil zwei: Die Content-Migration von zwei Jahrzehnten verlief ohne Ausfallzeiten</b> </h4><br>  <b>Planen</b> <br><br>  Die meisten Datenbankmigrationen implizieren dieselben Aktionen, und unsere war keine Ausnahme.  Folgendes haben wir getan: <br><br><ul><li>  Neue Datenbank erstellt. </li><li>  Sie haben eine M√∂glichkeit zum Schreiben in eine neue Datenbank (neue API) erstellt. </li><li>  Wir haben einen Proxyserver erstellt, der Datenverkehr sowohl an die alte als auch an die neue Datenbank sendet, wobei die alte als Hauptdatenbank verwendet wird. </li><li>  Datens√§tze aus der alten Datenbank in die neue verschoben. </li><li>  Sie machten die neue Datenbank zur Hauptdatenbank. </li><li>  Die alte Datenbank wurde entfernt. </li></ul><br>  Angesichts der Tatsache, dass die Datenbank, in die wir migriert haben, die Funktionsweise unseres CMS erm√∂glichte, war es wichtig, dass die Migration unseren Journalisten so wenig Probleme wie m√∂glich bereitet.  Am Ende enden die Nachrichten nie. <br><br>  <b>Neue API</b> <br><br>  Die Arbeiten an der neuen Postgres-basierten API begannen Ende Juli 2017.  Dies war der Beginn unserer Reise.  Aber um zu verstehen, wie es war, m√ºssen wir zuerst kl√§ren, wo wir angefangen haben. <br><br>  Unsere vereinfachte CMS-Architektur sah ungef√§hr so ‚Äã‚Äãaus: eine Datenbank, eine API und mehrere damit verbundene Anwendungen (z. B. eine Benutzeroberfl√§che).  Der Stack wurde gebaut und arbeitet seit 4 Jahren auf der Basis von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scala</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scalatra Framework</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Angular.js</a> . <br><br>  Nach einigen Analysen kamen wir zu dem Schluss, dass wir vor der Migration des vorhandenen Inhalts eine M√∂glichkeit ben√∂tigen, die neue PostgreSQL-Datenbank zu kontaktieren, um die alte API betriebsbereit zu halten.  Schlie√ülich ist Mongo DB unsere ‚ÄûQuelle der Wahrheit‚Äú.  Sie diente uns als Lebensader, w√§hrend wir mit der neuen API experimentierten. <br><br>  Dies ist einer der Gr√ºnde, warum es nicht Teil unserer Pl√§ne war, auf der alten API aufzubauen.  Die Trennung der Funktionen in der urspr√ºnglichen API war minimal, und die spezifischen Methoden, die f√ºr die Arbeit mit Mongo DB erforderlich sind, konnten sogar auf Controller-Ebene gefunden werden.  Infolgedessen war die Aufgabe, einer vorhandenen API einen anderen Datenbanktyp hinzuzuf√ºgen, zu riskant. <br><br>  Wir sind in die andere Richtung gegangen und haben die alte API dupliziert.  So wurde APIV2 geboren.  Es war eine mehr oder weniger genaue Kopie der alten Mongo-bezogenen API und enthielt dieselben Endpunkte und Funktionen.  Wir haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">doobie verwendet</a> , die reine JDBC-Feature-Layer f√ºr Scala, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docker</a> zum lokalen Ausf√ºhren und Testen hinzugef√ºgt und die Protokollierung von Vorg√§ngen und die Aufteilung der Verantwortung verbessert.  APIV2 sollte eine schnelle und moderne Version der API sein. <br><br>  Ende August 2017 wurde eine neue API bereitgestellt, die PostgreSQL als Datenbank verwendete.  Das war aber nur der Anfang.  Es gibt Artikel in Mongo DB, die vor √ºber zwei Jahrzehnten erstellt wurden und alle in die Postgres-Datenbank migriert werden mussten. <br><br>  <b>Die Migration</b> <br><br>  Wir sollten in der Lage sein, jeden Artikel auf der Website zu bearbeiten, unabh√§ngig davon, wann er ver√∂ffentlicht wurde. Daher existieren alle Artikel in unserer Datenbank als eine einzige ‚ÄûQuelle der Wahrheit‚Äú. <br><br>  Obwohl alle Artikel in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Guardian Content API (CAPI) enthalten sind</a> , die die Anwendungen und die Website bedient, war es f√ºr uns √§u√üerst wichtig, ohne St√∂rungen zu migrieren, da unsere Datenbank unsere ‚ÄûQuelle der Wahrheit‚Äú ist.  Wenn etwas mit dem Elasticsearch CAPI-Cluster passiert ist, w√ºrden wir es aus der Composer-Datenbank neu indizieren. <br>  Daher mussten wir vor dem Deaktivieren von Mongo sicherstellen, dass dieselbe Anforderung f√ºr die auf Postgres ausgef√ºhrte API und die auf Mongo ausgef√ºhrte API identische Antworten zur√ºckgibt. <br>  Dazu mussten wir den gesamten Inhalt in die neue Postgres-Datenbank kopieren.  Dies wurde mithilfe eines Skripts durchgef√ºhrt, das direkt mit den alten und neuen APIs interagierte.  Der Vorteil dieser Methode war, dass beide APIs bereits eine gut getestete Schnittstelle zum Lesen und Schreiben von Artikeln in und aus Datenbanken bereitstellten, anstatt etwas zu schreiben, das direkt auf die jeweiligen Datenbanken zugegriffen hat. <br><br>  Die grundlegende Migrationsreihenfolge war wie folgt: <br><br><ul><li>  Holen Sie sich Inhalte von Mongo. </li><li>  Poste Inhalte auf Postgres. </li><li>  Holen Sie sich Inhalte von Postgres. </li><li>  Stellen Sie sicher, dass die Antworten von ihnen identisch sind. </li></ul><br>  Eine Datenbankmigration kann nur dann als erfolgreich angesehen werden, wenn Endbenutzer nicht bemerkt haben, dass dies geschehen ist, und ein gutes Migrationsskript immer der Schl√ºssel zu einem solchen Erfolg ist.  Wir brauchten ein Skript, das: <br><br><ul><li>  F√ºhren Sie HTTP-Anforderungen aus. </li><li>  Stellen Sie sicher, dass nach der Migration eines Teils des Inhalts die Antwort beider APIs gleich ist. </li><li>  Beenden Sie, wenn ein Fehler auftritt. </li><li>  Erstellen Sie ein detailliertes Betriebsprotokoll, um Probleme zu diagnostizieren. </li><li>  Starten Sie nach einem Fehler an der richtigen Stelle neu. </li></ul><br>  Wir haben mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ammonite begonnen</a> .  Sie k√∂nnen damit Skripte in der Scala-Sprache schreiben, die den Kern unseres Teams bildet.  Es war eine gute Gelegenheit, mit etwas zu experimentieren, das wir vorher nicht benutzt hatten, um zu sehen, ob es f√ºr uns n√ºtzlich sein w√ºrde.  Obwohl Ammonite es uns erlaubte, eine vertraute Sprache zu verwenden, fanden wir einige M√§ngel bei der Arbeit daran.  Intellij <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unterst√ºtzt</a> derzeit Ammonite, hat dies jedoch w√§hrend unserer Migration nicht getan, und wir haben die automatische Vervollst√§ndigung und den automatischen Import verloren.  Dar√ºber hinaus konnte das Ammonite-Skript lange Zeit nicht ausgef√ºhrt werden. <br>  Letztendlich war Ammonite nicht das richtige Werkzeug f√ºr diesen Job, sondern wir haben das sbt-Projekt f√ºr die Migration verwendet.  Dies erm√∂glichte es uns, in einer Sprache zu arbeiten, in der wir uns sicher waren, und mehrere Testmigrationen durchzuf√ºhren, bevor wir in der Hauptarbeitsumgebung starteten. <br><br>  Unerwartet war, wie n√ºtzlich es war, die Version der API zu √ºberpr√ºfen, die auf Postgres ausgef√ºhrt wird.  Wir haben einige schwer zu findende Fehler und Grenzf√§lle gefunden, die wir zuvor nicht gefunden haben. <br><br>  Schneller Vorlauf bis Januar 2018, wenn es Zeit ist, die vollst√§ndige Migration in unserer vorgefertigten CODE-Umgebung zu testen. <br><br>  Wie bei den meisten unserer Systeme besteht die einzige √Ñhnlichkeit zwischen CODE und PROD in der Version der Anwendung, die gestartet wird.  Die AWS-Infrastruktur, die CODE unterst√ºtzt, war viel weniger leistungsf√§hig als PROD, einfach weil sie viel weniger Arbeitsbelastung verursacht. <br><br>  Wir hofften, dass die Testmigration in der CODE-Umgebung uns helfen w√ºrde: <br><br><ul><li>  Sch√§tzen Sie, wie lange die Migration in der PROD-Umgebung dauern wird. </li><li>  Bewerten Sie, wie sich die Migration (wenn √ºberhaupt) auf die Produktivit√§t auswirkt. </li></ul><br>  Um genaue Messungen dieser Indikatoren zu erhalten, mussten wir die beiden Umgebungen in v√∂llige gegenseitige √úbereinstimmung bringen.  Dies beinhaltete die Wiederherstellung einer Mongo DB-Sicherung von PROD auf CODE und die Aktualisierung der von AWS unterst√ºtzten Infrastruktur. <br><br>  Die Migration von etwas mehr als 2 Millionen Datenelementen h√§tte viel l√§nger dauern m√ºssen, als es ein normaler Arbeitstag zul√§sst.  Deshalb haben wir das Skript f√ºr die Nacht auf dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildschirm ausgef√ºhrt</a> . <br><br>  Um den Fortschritt der Migration zu messen, haben wir strukturierte Abfragen (mithilfe von Token) an unseren ELK-Stack (Elasticsearch, Logstash und Kibana) gesendet.  Von dort aus konnten wir detaillierte Dashboards erstellen, indem wir die Anzahl der erfolgreich √ºbertragenen Artikel, die Anzahl der Abst√ºrze und den Gesamtfortschritt verfolgten.  Au√üerdem wurden alle Indikatoren auf dem gro√üen Bildschirm angezeigt, sodass das gesamte Team die Details sehen konnte. <br><br><img src="https://habrastorage.org/webt/wk/zh/uj/wkzhujequqzbqpf65ewnt4zcfbg.png" alt="Bild"><br>  <i>Dashboard mit dem Fortschritt der Migration: Editorial Tools / Guardian</i> <br><br>  Nach Abschluss der Migration haben wir in Postgres und Mongo nach √úbereinstimmungen f√ºr jedes Dokument gesucht. <br><br><h4>  <b>Dritter Teil: Proxies und Start auf Prod</b> </h4><br>  <b>Proxies</b> <br><br>  Nachdem die neue API, die auf Postgres ausgef√ºhrt wird, gestartet wurde, mussten wir sie mit realen Verkehrs- und Datenzugriffsmustern testen, um ihre Zuverl√§ssigkeit und Stabilit√§t sicherzustellen.  Es gab zwei M√∂glichkeiten, dies zu tun: Aktualisieren Sie jeden Client, der auf die Mongo-API zugreift, so, dass er auf beide APIs zugreift.  oder f√ºhren Sie einen Proxy aus, der dies f√ºr uns erledigt.  Wir haben Proxies auf Scala mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Akka Streams geschrieben</a> . <br><br>  Der Proxy war ganz einfach: <br><br><ul><li>  Empfangen Sie Datenverkehr vom Load Balancer. </li><li>  Leiten Sie den Datenverkehr zur Haupt-API um und umgekehrt. </li><li>  Leiten Sie denselben Datenverkehr asynchron an eine zus√§tzliche API weiter. </li><li>  Berechnen Sie die Abweichungen zwischen den beiden Antworten und zeichnen Sie sie in einem Protokoll auf. </li></ul><br>  Anf√§nglich verzeichnete der Proxy viele Diskrepanzen, einschlie√ülich einiger schwer zu findender, aber wichtiger Verhaltensunterschiede in den beiden APIs, die behoben werden mussten. <br><br>  <b>Strukturierte Protokollierung</b> <br><br>  Bei Guardian protokollieren wir mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ELK-</a> Stack (Elasticsearch, Logstash und Kibana).  Die Verwendung von Kibana gab uns die M√∂glichkeit, das Magazin auf die f√ºr uns bequemste Weise zu visualisieren.  Kibana verwendet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Abfragesyntax von Lucene</a> , die ziemlich einfach zu erlernen ist.  Wir stellten jedoch schnell fest, dass es unm√∂glich war, die Journaleintr√§ge im aktuellen Setup zu filtern oder zu gruppieren.  Beispielsweise konnten wir diejenigen nicht herausfiltern, die aufgrund von GET-Anforderungen gesendet wurden. <br><br>  Wir haben uns entschieden, strukturiertere Daten an Kibana zu senden, nicht nur Nachrichten.  Ein Protokolleintrag enth√§lt mehrere Felder, z. B. den Zeitstempel und den Namen des Stapels oder der Anwendung, die die Anforderung gesendet hat.  Das Hinzuf√ºgen neuer Felder ist sehr einfach.  Diese strukturierten Felder werden als Marker bezeichnet und k√∂nnen mithilfe der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Logstash-Logback-Encoder-</a> Bibliothek implementiert werden.  F√ºr jede Anforderung haben wir n√ºtzliche Informationen (z. B. Route, Methode, Statuscode) extrahiert und eine Karte mit zus√§tzlichen Informationen erstellt, die f√ºr das Protokoll erforderlich sind.  Hier ist ein Beispiel: <br><br><pre><code class="plaintext hljs">import akka.http.scaladsl.model.HttpRequest import ch.qos.logback.classic.{Logger =&gt; LogbackLogger} import net.logstash.logback.marker.Markers import org.slf4j.{LoggerFactory, Logger =&gt; SLFLogger} import scala.collection.JavaConverters._ object Logging { val rootLogger: LogbackLogger = LoggerFactory.getLogger(SLFLogger.ROOT_LOGGER_NAME).asInstanceOf[LogbackLogger] private def setMarkers(request: HttpRequest) = { val markers = Map( "path" -&gt; request.uri.path.toString(), "method" -&gt; request.method.value ) Markers.appendEntries(markers.asJava) } def infoWithMarkers(message: String, akkaRequest: HttpRequest) = rootLogger.info(setMarkers(akkaRequest), message) }</code> </pre> <br>  Zus√§tzliche Felder in unseren Protokollen erm√∂glichten es uns, informative Dashboards zu erstellen und den Diskrepanzen mehr Kontext hinzuzuf√ºgen, wodurch wir einige kleinere Inkonsistenzen zwischen den beiden APIs identifizieren konnten. <br><br>  <b>Verkehrsreplikation und Proxy-Refactoring</b> <br><br>  Nach dem √úbertragen des Inhalts in die CODE-Datenbank haben wir eine fast exakte Kopie der PROD-Datenbank erhalten.  Der Hauptunterschied war, dass CODE keinen Verkehr hatte.  Um den tats√§chlichen Datenverkehr in die CODE-Umgebung zu replizieren, haben wir das Open-Source-Tool <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GoReplay</a> (im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Folgenden</a> als gor bezeichnet) verwendet.  Es ist sehr einfach zu installieren und flexibel an Ihre Anforderungen anzupassen. <br><br>  Da der gesamte Datenverkehr zu unseren APIs zuerst an Proxys ging, war es sinnvoll, gor auf Proxy-Containern zu installieren.  Im Folgenden erfahren Sie, wie Sie gor in Ihren Container laden und wie Sie den Datenverkehr auf Port 80 √ºberwachen und an einen anderen Server senden. <br><br><pre> <code class="plaintext hljs"> wget https://github.com/buger/goreplay/releases/download/v0.16.0.2/gor_0.16.0_x64.tar.gz tar -xzf gor_0.16.0_x64.tar.gz gor sudo gor --input-raw :80 --output-http http://apiv2.code.co.uk</code> </pre><br>  F√ºr eine Weile funktionierte alles einwandfrei, aber sehr bald gab es eine Fehlfunktion, als der Proxy f√ºr einige Minuten nicht mehr verf√ºgbar war.  In der Analyse haben wir festgestellt, dass alle drei Proxy-Container regelm√§√üig gleichzeitig h√§ngen.  Zuerst dachten wir, der Proxy st√ºrze ab, weil gor zu viele Ressourcen verwendet.  Bei einer weiteren Analyse der AWS-Konsole stellten wir fest, dass Proxy-Container regelm√§√üig, jedoch nicht gleichzeitig hingen. <br><br>  Bevor wir uns n√§her mit dem Problem befassten, versuchten wir, einen Weg zu finden, um gor auszuf√ºhren, diesmal jedoch ohne zus√§tzliche Belastung des Proxys.  Die L√∂sung kam von unserem sekund√§ren Stack f√ºr Composer.  Dieser Stapel wird nur im Notfall verwendet und von unserem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeits√ºberwachungstool</a> st√§ndig getestet.  Diesmal funktionierte die Wiedergabe des Datenverkehrs von diesem Stapel zu CODE mit doppelter Geschwindigkeit problemlos. <br><br>  Neue Erkenntnisse haben viele Fragen aufgeworfen.  Der Proxy wurde als tempor√§res Tool erstellt, sodass er m√∂glicherweise nicht so sorgf√§ltig entwickelt wurde wie andere Anwendungen.  Dar√ºber hinaus wurde es mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://doc.akka.io/docs/akka-">Akka Http erstellt</a> , mit dem keiner unserer Mitarbeiter vertraut war.  Der Code war chaotisch und voller schneller L√∂sungen.  Wir haben beschlossen, viele Umgestaltungen vorzunehmen, um die Lesbarkeit zu verbessern.  Dieses Mal haben wir For-Generatoren anstelle der wachsenden verschachtelten Logik verwendet, die wir zuvor verwendet haben.  Und noch mehr Protokollierungsmarker hinzugef√ºgt. <br><br>  Wir hofften, dass wir das Einfrieren der Proxy-Container verhindern k√∂nnen, wenn wir uns eingehend mit den Ereignissen im System befassen und die Logik des Betriebs vereinfachen.  Das hat aber nicht funktioniert.  Nachdem wir zwei Wochen lang versucht hatten, den Proxy zuverl√§ssiger zu machen, f√ºhlten wir uns gefangen.  Es war notwendig, eine Entscheidung zu treffen.  Wir haben uns entschlossen, das Risiko einzugehen und den Proxy so zu belassen, wie er ist, da es besser ist, Zeit f√ºr die Migration selbst zu verwenden, als zu versuchen, eine Software zu reparieren, die in einem Monat unn√∂tig wird.  Wir haben diese L√∂sung mit zwei weiteren Fehlern bezahlt - jeweils fast zwei Minuten -, aber es musste getan werden. <br><br>  Schneller Vorlauf bis M√§rz 2018, als wir die Migration zu CODE bereits abgeschlossen haben, ohne die API-Leistung oder die Client-Erfahrung in CMS zu beeintr√§chtigen.  Jetzt k√∂nnten wir dar√ºber nachdenken, Proxies von CODE abzuschreiben. <br><br>  Der erste Schritt bestand darin, die Priorit√§ten der API so zu √§ndern, dass der Proxy zuerst mit Postgres interagierte.  Wie oben erw√§hnt, wurde dies durch eine √Ñnderung der Einstellungen entschieden.  Es gab jedoch eine Schwierigkeit. <br><br>  Composer sendet nach dem Aktualisieren des Dokuments Nachrichten an den Kinesis-Stream.  Zum Senden von Nachrichten ist nur eine API erforderlich, um eine Duplizierung zu verhindern.  Zu diesem Zweck haben die APIs in der Konfiguration ein Flag: true f√ºr die von Mongo unterst√ºtzte API und false f√ºr die unterst√ºtzten Postgres.  Es reichte nicht aus, den Proxy so zu √§ndern, dass er zuerst mit Postgres interagierte, da die Nachricht erst an den Kinesis-Stream gesendet wurde, wenn die Anfrage Mongo erreichte.  Es ist zu lange her. <br><br>  Um dieses Problem zu l√∂sen, haben wir HTTP-Endpunkte erstellt, um die Konfiguration aller Instanzen des Load Balancers im laufenden Betrieb sofort zu √§ndern.  Dadurch konnten wir die Haupt-API sehr schnell verbinden, ohne die Konfigurationsdatei bearbeiten und erneut bereitstellen zu m√ºssen.  Dar√ºber hinaus kann dies automatisiert werden, wodurch die menschliche Interaktion und die Wahrscheinlichkeit von Fehlern verringert werden. <br><br>  Jetzt wurden alle Anfragen zuerst an Postgres gesendet und API2 interagierte mit Kinesis.  Ersetzungen k√∂nnen durch Konfigurations√§nderungen und erneute Bereitstellung dauerhaft vorgenommen werden. <br><br>  Der n√§chste Schritt bestand darin, den Proxy vollst√§ndig zu entfernen und die Clients zu zwingen, ausschlie√ülich auf die Postgres-API zuzugreifen.  Da wir viele Kunden haben, war es nicht m√∂glich, jeden von ihnen einzeln zu aktualisieren.  Daher haben wir diese Aufgabe auf die DNS-Ebene angehoben.  Das hei√üt, wir haben einen CNAME in DNS erstellt, der zuerst auf den ELB-Proxy verweist und dann auf die ELB-API verweist.  Dadurch konnte eine einzelne √Ñnderung vorgenommen werden, anstatt jeden einzelnen API-Client zu aktualisieren. <br><br>  Es ist Zeit, den PROD zu bewegen.  Obwohl es ein wenig be√§ngstigend war, ist dies das Hauptarbeitsumfeld.  Der Vorgang war relativ einfach, da alles durch √Ñndern der Einstellungen entschieden wurde.  Durch Hinzuf√ºgen einer Stufenmarkierung zu den Protokollen wurde es au√üerdem m√∂glich, zuvor erstellte Dashboards durch einfaches Aktualisieren des Kibana-Filters neu zu profilieren. <br><br>  <b>Proxys und Mongo DB deaktivieren</b> <br><br>  Nach 10 Monaten und 2,4 Millionen migrierten Artikeln konnten wir endlich die gesamte Infrastruktur im Zusammenhang mit Mongo deaktivieren.  Aber zuerst mussten wir das tun, worauf wir alle gewartet hatten: den Proxy t√∂ten. <br><br><img src="https://habrastorage.org/webt/6q/g5/ck/6qg5cksqesrnoig3gxnu7kfea-i.png" alt="Bild"><br>  <i>Protokolle zum Deaktivieren des flexiblen API-Proxys.</i>  <i>Foto: Editorial Tools / Guardian</i> <br><br>  Diese kleine Software verursachte uns so viele Probleme, dass wir uns danach sehnten, sie bald zu trennen!  Wir mussten lediglich den CNAME-Datensatz aktualisieren, um direkt auf den APIV2-Load-Balancer zu verweisen. <br>  Das gesamte Team versammelte sich um einen Computer.  Es war nur ein Tastendruck erforderlich.  Alle hielten den Atem an!  V√∂llige Stille ... Klick!  Die Arbeit ist erledigt.  Und nichts flog!  Wir alle atmeten freudig aus. <br><br>  Das Entfernen der alten Mongo DB-API war jedoch mit einem weiteren Test verbunden.  Wir wollten unbedingt den alten Code entfernen und stellten fest, dass unsere Integrationstests nie an die Verwendung der neuen API angepasst wurden.  Alles wurde schnell rot.  Gl√ºcklicherweise waren die meisten Probleme mit der Konfiguration verbunden und wir konnten sie leicht beheben.  Es gab mehrere Probleme mit PostgreSQL-Abfragen, die von den Tests erfasst wurden.  Als wir dar√ºber nachdachten, was getan werden k√∂nnte, um diesen Fehler zu vermeiden, haben wir eine Lektion gelernt: Wenn Sie eine gro√üe Aufgabe starten, vers√∂hnen Sie sich damit, dass es Fehler geben wird. <br><br>  Danach funktionierte alles reibungslos.  Wir haben alle Instanzen von Mongo von OpsManager getrennt und sie dann getrennt.  Das einzige was noch zu tun war, war zu feiern.  Und schlafen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de436416/">https://habr.com/ru/post/de436416/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de436400/index.html">Konfigurieren Sie die Entwicklungsumgebung zum Erlernen von HTML, CSS und PHP in Windows</a></li>
<li><a href="../de436404/index.html">Fehlertoleranter VoIP-Verkehrsausgleich. Lastwechsel zwischen Rechenzentren zur Spitzenzeit</a></li>
<li><a href="../de436406/index.html">Wie man ein Spieleentwickler wird, wenn Sie ein Makler sind</a></li>
<li><a href="../de436408/index.html">Numerische Modellierung - die Geschichte eines Projekts</a></li>
<li><a href="../de436412/index.html">Fototour durch Bostons neues Facebook-B√ºro</a></li>
<li><a href="../de436420/index.html">Die gr√∂√üte M√ºllkippe in der Geschichte: 2,7 Milliarden Konten, von denen 773 Millionen einzigartig sind</a></li>
<li><a href="../de436422/index.html">Nachahmung kann keine Produktentwicklungsstrategie sein.</a></li>
<li><a href="../de436424/index.html">Kleine Kreaturen, gro√üe Taten: Die Rolle von Blattschneidern im Treibhauseffekt von Neotropika</a></li>
<li><a href="../de436426/index.html">Unterbrechen Sie die Anwendung, wenn die Netzwerkverbindung unterbrochen wird</a></li>
<li><a href="../de436428/index.html">Warum jubeln wir dem Sportprogramm zu?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
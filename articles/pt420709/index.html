<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòí üñåÔ∏è ü§≤üèø T2F: um projeto para converter texto em desenho facial com aprendizado profundo üñêüèæ üëãüèº üîâ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O c√≥digo do projeto est√° dispon√≠vel no reposit√≥rio. 

 1. Introdu√ß√£o 
 Quando leio as descri√ß√µes da apar√™ncia dos personagens nos livros, sempre me in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>T2F: um projeto para converter texto em desenho facial com aprendizado profundo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420709/"><img src="https://habrastorage.org/getpro/habr/post_images/5ae/703/0df/5ae7030df8270466b01b81aad0ace49f.jpg"><br><br>  <i>O c√≥digo do projeto est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reposit√≥rio.</a></i> <br><br><h2>  1. Introdu√ß√£o </h2><br>  Quando leio as descri√ß√µes da apar√™ncia dos personagens nos livros, sempre me interessei em como eles eram na vida.  √â bem poss√≠vel imaginar uma pessoa como um todo, mas a descri√ß√£o dos detalhes mais vis√≠veis √© uma tarefa dif√≠cil, e os resultados variam de pessoa para pessoa.  Muitas vezes eu n√£o conseguia imaginar nada al√©m de um rosto muito emba√ßado do personagem at√© o final do trabalho.  Somente quando o livro se transforma em filme √© que o rosto desfocado se enche de detalhes.  Por exemplo, eu nunca poderia imaginar como o rosto de Rachel se parece com o livro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Garota no trem</a> ".  Mas quando o filme saiu, eu pude combinar o rosto de Emily Blunt com o personagem de Rachel.  Certamente, as pessoas envolvidas na sele√ß√£o de atores levam muito tempo para retratar corretamente os personagens do roteiro. <br><a name="habracut"></a><br>  Esse problema me inspirou e me motivou a encontrar uma solu√ß√£o.  Depois disso, comecei a estudar a literatura sobre aprendizado profundo em busca de algo semelhante.  Felizmente, existem muitos estudos sobre a s√≠ntese de imagens a partir de texto.  Aqui est√£o alguns dos que eu constru√≠: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arxiv.org/abs/1605.05396</a> ‚ÄúTexto contradit√≥rio generativo para s√≠ntese de imagens‚Äù </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arxiv.org/abs/1612.03242</a> ‚ÄúStackGAN: s√≠ntese de imagem texto-foto-realista com redes adversas generativas empilhadas‚Äù </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arxiv.org/abs/1710.10916</a> ‚ÄúStackGAN ++: s√≠ntese realista de imagens com redes adversas generativas empilhadas‚Äù </li></ul><br>  [os <i>projetos usam redes advers√°rias generativas, GSS (rede advers√°ria generativa, GAN) / aprox.</i>  <i>perev.</i>  ] <br><br>  Depois de estudar a literatura, escolhi uma arquitetura simplificada em compara√ß√£o ao StackGAN ++ e lida muito bem com o meu problema.  Nas se√ß√µes a seguir, explicarei como resolvi esse problema e compartilhei resultados preliminares.  Tamb√©m descreverei alguns dos detalhes de programa√ß√£o e treinamento nos quais passei muito tempo. <br><br><h2>  An√°lise de dados </h2><br>  Sem d√∫vida, o aspecto mais importante do trabalho s√£o os dados usados ‚Äã‚Äãpara treinar o modelo.  Como o professor Andrew Eun disse em seus cursos deeplearning.ai: "No campo do aprendizado de m√°quina, n√£o √© quem tem o melhor algoritmo, mas quem tem os melhores dados".  Assim come√ßou minha busca por um conjunto de dados sobre rostos com boas, ricas e variadas descri√ß√µes textuais.  Me deparei com diferentes conjuntos de dados - eram apenas rostos, ou rostos com nomes ou rostos com uma descri√ß√£o da cor dos olhos e do formato do rosto.  Mas n√£o havia nada que eu precisasse.  Minha √∫ltima op√ß√£o foi usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um projeto inicial</a> - gerando uma descri√ß√£o dos dados estruturais em uma linguagem natural.  Mas essa op√ß√£o adicionaria ru√≠do extra a um conjunto de dados j√° bastante barulhento. <br><br>  O tempo passou e, em algum momento, um novo projeto do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Face2Text apareceu</a> .  Era uma cole√ß√£o de um banco de dados com descri√ß√µes detalhadas de textos de pessoas.  Agrade√ßo aos autores do projeto pelo conjunto de dados fornecido. <br><br>  O conjunto de dados continha descri√ß√µes textuais de 400 imagens selecionadas aleatoriamente no banco de dados LFW (faces marcadas).  As descri√ß√µes foram limpas para eliminar caracter√≠sticas amb√≠guas e menores.  Algumas descri√ß√µes continham n√£o apenas informa√ß√µes sobre os rostos, mas tamb√©m algumas conclus√µes feitas com base nas imagens - por exemplo, ‚Äúa pessoa na foto √© provavelmente um criminoso‚Äù.  Todos esses fatores, bem como o pequeno tamanho do conjunto de dados, levaram ao fato de que meu projeto at√© agora apenas demonstra evid√™ncias da operacionalidade da arquitetura.  Posteriormente, esse modelo pode ser dimensionado para um conjunto de dados maior e mais diversificado. <br><br><h2>  Arquitetura </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/c70/ea1/6de/c70ea16de2bbfb674e618fa556cfc9ff.jpg"><br><br>  A arquitetura do projeto T2F combina duas arquiteturas stackGAN para codificar texto incrementado condicionalmente e o ProGAN ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">crescimento progressivo do GSS</a> ) para sintetizar imagens de rosto.  A arquitetura stackgan ++ original usava v√°rios GSSs com diferentes resolu√ß√µes espaciais, e eu decidi que essa era uma abordagem muito s√©ria para qualquer tarefa de distribui√ß√£o de correspond√™ncia.  Mas o ProGAN usa apenas um GSS, treinado progressivamente em resolu√ß√µes cada vez mais detalhadas.  Eu decidi combinar essas duas abordagens. <br><br>  H√° uma explica√ß√£o do fluxo de dados: descri√ß√µes de texto s√£o codificadas no vetor final incorporando-se √† rede LSTM (Incorpora√ß√£o) (psy_t) (veja o diagrama).  Em seguida, a incorpora√ß√£o √© transmitida atrav√©s do bloco de Aumento de Condicionamento (uma camada linear) para obter a parte de texto do vetor pr√≥prio (usando a t√©cnica de reparameteriza√ß√£o VAE) para o GSS como entrada.  A segunda parte do vetor pr√≥prio √© o ru√≠do gaussiano aleat√≥rio.  O vetor pr√≥prio resultante √© alimentado ao gerador GSS e a incorpora√ß√£o √© alimentada √† √∫ltima camada discriminadora para distribui√ß√£o condicional da correspond√™ncia.  O treinamento dos processos GSS √© exatamente igual ao do artigo ProGAN - em camadas, com um aumento na resolu√ß√£o espacial.  Uma nova camada √© introduzida usando a t√©cnica fade-in para evitar a exclus√£o de resultados de aprendizado anteriores. <br><br><h2>  Implementa√ß√£o e outros detalhes </h2><br>  O aplicativo foi escrito em python usando a estrutura PyTorch.  Eu trabalhava com pacotes tensorflow e keras, mas agora queria experimentar o PyTorch.  Gostei de usar o depurador python embutido para trabalhar com a arquitetura de rede - tudo gra√ßas √† estrat√©gia de execu√ß√£o antecipada.  O Tensorflow tamb√©m ativou recentemente o modo de execu√ß√£o ansioso.  No entanto, n√£o quero julgar qual estrutura √© melhor, s√≥ quero enfatizar que o c√≥digo deste projeto foi escrito usando o PyTorch. <br><br>  Algumas partes do projeto me parecem reutiliz√°veis, especialmente o ProGAN.  Portanto, escrevi um c√≥digo separado para eles como uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">extens√£o do</a> m√≥dulo PyTorch e tamb√©m pode ser usado em outros conjuntos de dados.  √â necess√°rio apenas indicar a profundidade e o tamanho dos recursos do GSS.  O GSS pode ser treinado progressivamente para qualquer conjunto de dados. <br><br><h2>  Detalhes do treinamento </h2><br>  Treinei algumas vers√µes da rede usando diferentes hiperpar√¢metros.  Os detalhes do trabalho s√£o os seguintes: <br><br><ol><li>  O discriminador n√£o possui opera√ß√µes de lote ou norma, portanto a perda de WGAN-GP pode crescer explosivamente.  Eu usei penalidade de deriva com lambda igual a 0,001. </li><li>  Para controlar sua pr√≥pria diversidade, obtida a partir do texto codificado, √© necess√°rio usar a dist√¢ncia Kullback - Leibler nas perdas do Gerador. </li><li>  Para fazer com que as imagens resultantes correspondam melhor √† distribui√ß√£o de texto recebida, √© melhor usar a vers√£o WGAN do discriminador correspondente (compat√≠vel com correspond√™ncia). </li><li>  O tempo de espera para os n√≠veis superiores deve exceder o tempo de espera para os n√≠veis inferiores.  Eu usei 85% como o valor do fade-in durante o treinamento. </li><li>  Descobri que exemplos de alta resolu√ß√£o (32 x 32 e 64 x 64) produzem mais ru√≠do de fundo do que exemplos de baixa resolu√ß√£o.  Eu acho que isso √© devido √† falta de dados. </li><li>  Durante um treino progressivo, √© melhor gastar mais tempo em resolu√ß√µes mais baixas e reduzir o tempo gasto trabalhando com resolu√ß√µes mais altas. </li></ol><br>  O v√≠deo mostra o lapso de tempo do gerador.  O v√≠deo √© compilado a partir de imagens com diferentes resolu√ß√µes espaciais obtidas durante o treinamento do GSS. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/NO_l87rPDb8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Conclus√£o </h2><br>  De acordo com resultados preliminares, pode-se julgar que o projeto T2F √© vi√°vel e tem aplica√ß√µes interessantes.  Suponha que ele possa ser usado para compor photobots.  Ou para os casos em que √© necess√°rio aumentar a imagina√ß√£o.  Continuarei trabalhando no dimensionamento deste projeto em conjuntos de dados como Flicker8K, legendas do Coco e assim por diante. <br><br>  O crescimento progressivo do GSS √© uma tecnologia fenomenal para um treinamento mais r√°pido e mais est√°vel do GSS.  Pode ser combinado com v√°rias tecnologias modernas mencionadas em outros artigos.  O GSS pode ser usado em diferentes √°reas do MO. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt420709/">https://habr.com/ru/post/pt420709/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt420697/index.html">O eterno tema com PHP e MySQL</a></li>
<li><a href="../pt420701/index.html">HSBI convida para uma noite de palestras sobre design de jogos em 29 de agosto</a></li>
<li><a href="../pt420703/index.html">Sinopse do livro ‚ÄúNegocia√ß√µes sem derrota. M√©todo Harvard</a></li>
<li><a href="../pt420705/index.html">8 id√©ias profundas da Tribo de Mentores de Tim Ferris</a></li>
<li><a href="../pt420707/index.html">Inicializa√ß√£o da JITX usa IA para automatizar o desenvolvimento de placas de circuito impresso complexas</a></li>
<li><a href="../pt420711/index.html">Moscow Data Science Major: an√∫ncio e registro</a></li>
<li><a href="../pt420713/index.html">Como Chuck Hull inventou a impress√£o 3D</a></li>
<li><a href="../pt420715/index.html">A dura verdade sobre a gravidade da aprendizagem</a></li>
<li><a href="../pt420725/index.html">Como eu ensinei AI a jogar Tetris para NES. Parte 1: an√°lise do c√≥digo do jogo</a></li>
<li><a href="../pt420729/index.html">Semin√°rio on-line aberto "Naive Bayes Classifier"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
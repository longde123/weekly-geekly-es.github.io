<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí∏ ‚ñ´Ô∏è ü¶å Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC üë®üèø‚Äçüîß üë©‚Äçüëß‚Äçüëß ‚òùüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es gibt viele Tools zum Debuggen von Kernel- und Userspace-Programmen unter Linux. Die meisten von ihnen haben Auswirkungen auf die Leistung und k√∂nne...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/450818/"><img src="https://habrastorage.org/webt/-8/ok/na/-8okna9qfyroicvgoz-zenv7-si.png"><br><br>  Es gibt viele Tools zum Debuggen von Kernel- und Userspace-Programmen unter Linux.  Die meisten von ihnen haben Auswirkungen auf die Leistung und k√∂nnen nicht einfach in Produktionsumgebungen ausgef√ºhrt werden.  Vor einigen Jahren wurde eBPF <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">entwickelt</a> , mit dem der Kernel und der Benutzerbereich mit geringem Overhead verfolgt werden k√∂nnen, ohne dass Programme neu kompiliert oder Kernelmodule geladen werden m√ºssen. <br><br>  Es gibt jetzt viele Tools, die eBPF verwenden. In diesem Artikel wird erl√§utert, wie Sie Ihr eigenes Profiling-Tool mithilfe der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PythonBCC-Bibliothek</a> schreiben.  Dieser Artikel basiert auf einem echten Problem aus der Produktionsumgebung.  Wir werden Sie durch die L√∂sung des Problems f√ºhren und zeigen, wie vorhandene bcc-Tools in einigen F√§llen verwendet werden k√∂nnen. <br><a name="habracut"></a><br><h2>  Ceph ist langsam </h2><br>  Eine neue Plattform wurde einem Ceph-Cluster hinzugef√ºgt.  Nach der Migration einiger Daten auf die Plattform war die Latenz f√ºr Schreibanforderungen h√∂her als auf den anderen Servern. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/de/-l/ukde-lsu9sjqnmci1ix942xzgie.png"></div><br><br>  Diese Plattform verf√ºgt √ºber ein neues virtuelles Caching-Ger√§t - bcache, das wir in diesem Cluster noch nicht verwendet haben - und einen neuen Kernel - 4.15, der noch nirgendwo anders in diesem Cluster verwendet wird.  Die Wurzel des Problems k√∂nnte √ºberall liegen, also schauen wir uns das genauer an. <br><br><h3>  Untersuchung des Gastgebers </h3><br>  Schauen wir uns an, was im ceph-osd-Prozess vor sich geht.  Wir verwenden das Verfolgungswerkzeug <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">perf</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">flamescope</a> , um Flammengraphen zu erstellen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ch/5k/nn/ch5knn22cmukd1oldmcozpxe98i.png"></div><br><br>  Wie aus dem Flammengraphen hervorgeht, hat <b>fdatasync ()</b> viel Zeit damit verbracht, Bio in der Funktion <b>generic_make_request () einzureichen</b> .  Daher liegt die Wurzel unseres Problems irgendwo au√üerhalb des Ceph-Daemons.  M√∂glicherweise handelt es sich um ein Kernel-, Bcache- oder Festplattenproblem.  Die iostat-Ausgabe zeigte eine hohe Latenz f√ºr bcache-Ger√§te. <br><br>  Ein weiterer verd√§chtiger Befund ist, dass der systemd-udevd-Daemon CPU verbraucht.  ca. 20% auf mehreren CPUs.  Das ist seltsames Verhalten, also m√ºssen wir herausfinden, was los ist.  Da systemd-udevd mit uevents zusammenarbeitet, m√ºssen wir den <b>udevadm-Monitor verwenden</b> , um herauszufinden, ob im System uevents vorhanden sind.  Nach der √úberpr√ºfung haben wir festgestellt, dass f√ºr jedes Blockger√§t im System viele "√Ñnderungsereignisse" generiert wurden. <br><br>  Dies ist ungew√∂hnlich, daher werden wir herausfinden, warum all diese Ereignisse gesendet werden. <br><br>
<h3>  Verwenden des BCC Toolkit </h3><br>  Wie wir bereits wissen, verbringt der Kernel (und der Ceph-Daemon) viel Zeit mit der Ausf√ºhrung von <b>generic_make_requst ()</b> -Funktionen.  Lassen Sie uns die Latenz mithilfe der <b>Funclatency</b> aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC-Toolkit</a> messen, um sicherzustellen, dass wir auf dem richtigen Weg sind.  Wir verfolgen die PID (-p) des Ceph-Daemons in Intervallen von 1 Sekunde (-i) und drucken die Latenz in Millisekunden (-m). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4c/cj/za/4ccjza8x8bq0vqkxfol2j5d9sva.png"></div><br><br>  Diese Funktion arbeitet normalerweise sehr schnell.  Es wird lediglich die Biostruktur an die Warteschlange des Ger√§tetreibers gesendet. <br><br>  <b>Bcache</b> ist ein komplexes Ger√§t.  Tats√§chlich besteht es aus 3 Ger√§ten: einem Sicherungsger√§t, das in unserem Fall eine langsame Festplatte ist;  ein Caching-Ger√§t, bei dem es sich um die Partition des NVMe-Laufwerks handelt;  und ein virtuelles bcache-Ger√§t, das von der Anwendung verwendet wird.  Wir wissen, dass die √úbermittlung langsam ist, aber f√ºr welches Ger√§t?  Dies ist etwas, worauf wir sp√§ter noch eingehen werden. <br><br>  Im Moment wissen wir, dass Ereignisse Ereignisse in Ceph-D√§monen verursachen, und wir m√ºssen die Software finden, die Ereignisse ausl√∂st. Es ist nicht einfach zu finden, welche Ursachen Ereignisse verursachen.  Wir gehen davon aus, dass es sich um Software handelt, die nur in regelm√§√üigen Abst√§nden ausgef√ºhrt wird.  Um zu sehen, was auf dem System ausgef√ºhrt wird, verwenden wir <b>execsnoop</b> aus dem BCC-Toolkit.  Wir k√∂nnen es ausf√ºhren und <b>stdout</b> in eine Datei umleiten. <br><br>  Zum Beispiel: <br><br><pre><code class="bash hljs">/usr/share/bcc/tools/execsnoop | tee ./execdump</code> </pre> <br>  Wir werden hier nicht die vollst√§ndige Execsnoop-Ausgabe geben, aber eine interessante Zeichenfolge, die wir dort gefunden haben, war: <br><br><pre> <code class="bash hljs">sh 1764905 5802 0 sudo arcconf getconfig 1 AD | grep Temperature | awk -F <span class="hljs-string"><span class="hljs-string">'[:/]'</span></span> <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/^ \([0-9]*\) C.*/\1/'</span></span></code> </pre> <br>  Die dritte Spalte ist die PPID des Prozesses.  Wir haben √ºberpr√ºft, was 5802 ist, und festgestellt, dass es sich um einen unserer √úberwachungs-Daemon-Threads handelt.  Bei n√§herer Betrachtung der Konfiguration des √úberwachungssystems haben wir einen fehlerhaften Parameter gefunden.  Die HBA-Temperatur wurde alle 30 Sekunden abgerufen, was zu oft ist.  Nachdem wir das Pr√ºfintervall auf einen angemesseneren Wert ge√§ndert hatten, stellten wir fest, dass unsere Ceph-Latenz mit den anderen Plattformen √ºbereinstimmte. <br><br>  Wir wissen aber immer noch nicht, warum die Bcache-Latenz hoch war.  Wir haben eine Testplattform mit derselben Konfiguration eingerichtet und versucht, das Problem mit fio auf dem bcache-Ger√§t zu reproduzieren, w√§hrend wir gleichzeitig udev mit dem Befehl udevadm trigger ausl√∂sen. <br><br><h3>  Schreiben von BCC-basierten Tools </h3><br>  Was wir hier tun werden, ist ein einfaches Tool zu schreiben, das die langsamsten generic_make_request () -Aufrufe verfolgt und den Namen der Festplatte druckt, f√ºr die die Funktion aufgerufen wurde. <br><br>  Der Plan ist einfach: <br><br><ul><li>  Registrieren Sie <b>kprobe</b> auf <b>generic_make_request ()</b> : <br><ul><li>  Speichern Sie den im Argument der Funktion verf√ºgbaren Datentr√§gernamen </li><li>  Speichern Sie den aktuellen Zeitstempel </li></ul></li><li>  Registrieren Sie <b>kretprobe</b> in der return-Anweisung <b>generic_make_request ()</b> : <br><ul><li>  Rufen Sie den aktuellen Zeitstempel ab </li><li>  Suchen Sie nach zuvor gespeicherten Zeitstempeln und vergleichen Sie diese mit den aktuellen </li><li>  Wenn das Ergebnis h√∂her als der Schwellenwert ist, suchen Sie nach zuvor gespeicherten Datentr√§gernamen und drucken Sie diese mit zus√§tzlichen Informationen auf dem Terminal aus </li></ul></li></ul><br>  <b>Kprobes</b> und <b>kretprobes</b> verwenden Haltepunkte, um den Code einer Funktion zur Laufzeit zu √§ndern.  Hier finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> sowie einen guten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> dazu.  Wenn Sie sich den Code f√ºr verschiedene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC-Tools</a> ansehen, werden Sie feststellen, dass alle eine identische Struktur haben.  Wir √ºberspringen das Parsen von Argumenten und konzentrieren uns auf das BPF-Programm selbst. <br><br>  Der Text unseres Programms wird in Python wie folgt definiert: <br><br><pre> <code class="python hljs">bpf_text = ‚Äú‚Äù‚Äù <span class="hljs-comment"><span class="hljs-comment"># Here will be the bpf program code ‚Äú‚Äù‚Äù</span></span></code> </pre> <br>  BPF-Programme verwenden <a href="">Hashmaps</a> , um Daten zwischen verschiedenen Funktionen <a href="">auszutauschen</a> .  Wir werden PID als Schl√ºssel und eine selbst definierte Struktur als Wert verwenden. <br><br><pre> <code class="python hljs">struct data_t { u64 pid; u64 ts; char comm[TASK_COMM_LEN]; u64 lat; char disk[DISK_NAME_LEN]; }; BPF_HASH(p, u64, struct data_t); BPF_PERF_OUTPUT(events);</code> </pre> <br>  Hier registrieren wir eine Hashmap namens <b>p</b> mit einem <b>u64-</b> Schl√ºsseltyp und einem <b>struct data_t-Werttyp</b> .  Diese Karte ist √ºber unseren BPF-Programmkontext zug√§nglich.  Das Makro <b>BPF_PERF_OUTPUT</b> registriert eine andere Zuordnung namens <b>Ereignisse</b> , mit der <a href="">Daten</a> in den Benutzerbereich √ºbertragen werden. <br><br>  Wenn Sie die Latenz zwischen dem Funktionsaufruf und seiner R√ºckgabe oder zwischen einem Funktionsaufruf und einem anderen messen, m√ºssen Sie sicherstellen, dass sich die Daten, die Sie gespeichert haben und auf die Sie sp√§ter zugreifen, auf denselben Kontext beziehen.  Mit anderen Worten, Sie m√ºssen alle anderen parallelen Ausf√ºhrungen derselben Funktion kennen.  Es ist m√∂glich, die Latenz zwischen dem Funktionsaufruf eines Prozesses und den R√ºckgaben derselben Funktion von einem anderen Prozess zu verfolgen, aber das hilft uns nicht.  Ein gutes Beispiel ist das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Biolatency-Tool,</a> bei dem der Zeiger auf die <b>Strukturanforderung</b> als Hashmap-Schl√ºssel verwendet wird. <br><br>  Als n√§chstes m√ºssen wir einen Code schreiben, der bei Funktionsaufrufen √ºber einen kprobe-Mechanismus ausgef√ºhrt wird: <br><br><pre> <code class="python hljs">void start(struct pt_regs *ctx, struct bio *bio) { u64 pid = bpf_get_current_pid_tgid(); struct data_t data = {}; u64 ts = bpf_ktime_get_ns(); data.pid = pid; data.ts = ts; bpf_probe_read_str(&amp;data.disk, sizeof(data.disk), (void*)bio-&gt;bi_disk-&gt;disk_name); p.update(&amp;pid, &amp;data); }</code> </pre> <br>  Hier haben wir das erste <a href="">Argument generic_make_request ()</a> als zweites Argument unserer Funktion.  Dann erhalten wir die PID und den aktuellen Zeitstempel in Nanosekunden und schreiben sie in die neu zugewiesenen <b>struct data_t-Daten</b> .  Wir erhalten den Datentr√§gernamen aus der <b>Biostruktur</b> , die an <b>generic_make_request () √ºbergeben wird</b> , und speichern ihn in unseren <b>Daten</b> .  Der letzte Schritt besteht darin, der zuvor beschriebenen Hashmap einen Eintrag hinzuzuf√ºgen. <br><br>  Diese Funktion wird ausgef√ºhrt, <b>wenn generic_make_request () Folgendes</b> zur√ºckgibt: <br><br><pre> <code class="python hljs">void stop(struct pt_regs *ctx) { u64 pid = bpf_get_current_pid_tgid(); u64 ts = bpf_ktime_get_ns(); struct data_t* data = p.lookup(&amp;pid); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data != <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; data-&gt;ts &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { bpf_get_current_comm(&amp;data-&gt;comm, sizeof(data-&gt;comm)); data-&gt;lat = (ts - data-&gt;ts)/<span class="hljs-number"><span class="hljs-number">1000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data-&gt;lat &gt; MIN_US) { FACTOR data-&gt;pid &gt;&gt;= <span class="hljs-number"><span class="hljs-number">32</span></span>; events.perf_submit(ctx, data, sizeof(struct data_t)); } p.delete(&amp;pid); } }</code> </pre> <br>  Wir erhalten die PID und den Zeitstempel von der vorherigen Ausgabe und suchen in der Hashmap nach dem Wert, bei dem <b>key == current PID ist</b> .  Wenn es gefunden wird, erhalten wir den Namen des laufenden Prozesses und f√ºgen ihn der <b>Datenstruktur hinzu</b> .  Was wir hier mit <b>data-&gt; pid machen</b> , gibt uns die Thread-Gruppen-ID.  Die zuvor aufgerufene <a href="">Funktion bpf_get_current_pid_tgid ()</a> gibt die Thread-GID und -PID des Prozesses in demselben 64-Bit-Wert zur√ºck. <br><br>  Wir sind nicht an der ID jedes Threads interessiert, aber wir m√∂chten die PID des Hauptthreads kennen.  Nachdem wir √ºberpr√ºft haben, ob die Latenz √ºber dem Schwellenwert liegt, senden wir unsere <b>Datenstruktur</b> √ºber die <b>Ereigniskarte</b> an den Benutzerbereich und l√∂schen am Ende den Hashmap-Eintrag. <br><br>  In unserem Python-Skript m√ºssen wir <b>MIN_US</b> und <b>FACTOR</b> entsprechend dem gew√ºnschten Schwellenwert und der Zeiteinheit ersetzen, die wir in unserem Ergebnis sehen m√∂chten: <br><br><pre> <code class="python hljs">bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'MIN_US'</span></span>,str(min_usec)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> args.milliseconds: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">'data-&gt;lat /= 1000;'</span></span>) label = <span class="hljs-string"><span class="hljs-string">"msec"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) label = <span class="hljs-string"><span class="hljs-string">"usec"</span></span></code> </pre><br>  Dann m√ºssen wir das BPF-Programm mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BPF () -Makro</a> vorbereiten und Sonden registrieren: <br><br><pre> <code class="python hljs">b = BPF(text=bpf_text) b.attach_kprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"start"</span></span>) b.attach_kretprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"stop"</span></span>)</code> </pre><br>  Wir m√ºssen auch die gleiche Struktur wie <b>struct data_t</b> in unserem Skript definieren, um die Daten aus dem BPF-Programm zu lesen: <br><br><pre> <code class="python hljs">TASK_COMM_LEN = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-comment"><span class="hljs-comment"># linux/sched.h DISK_NAME_LEN = 32 # linux/genhd.h class Data(ct.Structure): _fields_ = [("pid", ct.c_ulonglong), ("ts", ct.c_ulonglong), ("comm", ct.c_char * TASK_COMM_LEN), ("lat", ct.c_ulonglong), ("disk",ct.c_char * DISK_NAME_LEN)]</span></span></code> </pre> <br>  Der letzte Schritt besteht darin, die gew√ºnschten Daten auszudrucken: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_event</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cpu, data, size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> start event = ct.cast(data, ct.POINTER(Data)).contents <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> start == <span class="hljs-number"><span class="hljs-number">0</span></span>: start = event.ts time_s = (float(event.ts - start)) / <span class="hljs-number"><span class="hljs-number">1000000000</span></span> print(<span class="hljs-string"><span class="hljs-string">"%-18.9f %-16s %-6d %-1s %s %s"</span></span> % (time_s, event.comm, event.pid, event.lat, label, event.disk)) b[<span class="hljs-string"><span class="hljs-string">"events"</span></span>].open_perf_buffer(print_event) <span class="hljs-comment"><span class="hljs-comment"># format output start = 0 while 1: try: b.perf_buffer_poll() except KeyboardInterrupt: exit()</span></span></code> </pre><br>  Das vollst√§ndige Skript ist auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> verf√ºgbar.  Lassen Sie uns das Skript ausf√ºhren und udev-Ereignisse ausl√∂sen, w√§hrend fio auf ein bcache-Ger√§t schreibt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tk/ly/vf/tklyvf6i8rws0xu4gy3jothbxbi.png"></div><br><br>  Erfolg!  Jetzt sehen wir, dass eine hohe Latenz f√ºr bcache die <b>generische</b> Latenz von <b>make_request ()</b> f√ºr das Sicherungsger√§t ist. <br><br><h3>  Grabe dich in den Kernel </h3><br>  Was zieht sich bei der Einreichung von Anfragen hin?  Wir sehen, dass eine Latenzspitze aufgetreten ist, bevor die Anforderungsabrechnung √ºberhaupt gestartet wurde.  Dies kann leicht √ºberpr√ºft werden, indem entweder iostat w√§hrend des Problems oder das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Biolatency-BCC-Skript ausgef√ºhrt wird</a> , das auf dem Start der Abrechnungsanforderung basiert, sodass keines der Tools das Festplattenproblem anzeigt. <br><br>  Wenn wir uns <b>generic_make_request () ansehen</b> , sehen wir, dass zwei Funktionen ausgef√ºhrt werden, bevor die Abrechnung beginnt.  Das erste ist <b>generic_make_request_checks ()</b> , das leichtgewichtig ist und die Bio- <b>Daten</b> gem√§√ü den Ger√§teeinstellungen usw. √ºberpr√ºft.  Der zweite ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_queue_enter ()</a> , der einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wait_event_interruptible () -Aufruf</a> hat: <br><br><pre> <code class="python hljs">ret = wait_event_interruptible(q-&gt;mq_freeze_wq, (atomic_read(&amp;q-&gt;mq_freeze_depth) == <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; (preempt || !blk_queue_preempt_only(q))) || blk_queue_dying(q));</code> </pre><br>  Hier wartet der Kernel, bis die Warteschlange nicht mehr gefroren ist.  Lassen Sie uns die Latenz von blk_queue_enter () messen: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/funclatency blk_queue_enter -i 1 -m Tracing 1 functions for "blk_queue_enter"... Hit Ctrl-C to end. msecs : count distribution 0 -&gt; 1 : 341 |****************************************| msecs : count distribution 0 -&gt; 1 : 316 |****************************************| msecs : count distribution 0 -&gt; 1 : 255 |****************************************| 2 -&gt; 3 : 0 | | 4 -&gt; 7 : 0 | | 8 -&gt; 15 : 1 | |</span></span></code> </pre><br>  Es sieht so aus, als w√§ren wir nah dran.  Die Funktionen zum Einfrieren / Auftauen der Warteschlange sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_freeze_queue</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_unfreeze_queue</a> .  Sie werden verwendet, um die Einstellungen der Warteschlange zu √§ndern, was sich auf die derzeit im Flug befindlichen Io-Anforderungen auswirken kann.  Wenn <b>blk_mq_freeze_queue ()</b> aufgerufen wird, wird <b>q-&gt; mq_freeze_depth</b> in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_freeze_queue_start () erh√∂ht</a> .  Danach wartet der Kernel darauf, dass die Warteschlange in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_freeze_queue_wait ()</a> leer ist. <br><br>  Diese Wartezeit entspricht der Festplattenlatenz, da der Kernel warten muss, bis alle Io-Vorg√§nge abgeschlossen sind.  Wenn die Warteschlange leer ist, k√∂nnen √Ñnderungen vorgenommen werden.  Der letzte Schritt besteht darin, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_unfreeze_queue () aufzurufen</a> , wodurch der Z√§hler <b>freeze_depth</b> verringert wird. <br><br>  Jetzt wissen wir genug, um das Problem zu beheben.  Der Befehl udevadm trigger √§ndert die Einstellungen f√ºr Blockger√§te.  Diese Einstellungen werden in den udev-Regeln beschrieben.  Wir k√∂nnen herausfinden, welche Einstellungen die Warteschlange einfrieren, indem wir sie √ºber sysfs √§ndern oder den Kernel-Quellcode betrachten.  Alternativ k√∂nnen wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ablaufverfolgung</a> aus dem BCC-Toolkit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aufrufen</a> , um Kernel- und Benutzerstapel f√ºr jeden Aufruf von <b>blk_freeze_queue</b> zu drucken: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/trace blk_freeze_queue -K -U PID TID COMM FUNC 3809642 3809642 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] elevator_switch+0x29 [kernel] elv_iosched_store+0x197 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown] 3809631 3809631 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] queue_requests_store+0xb6 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown]</span></span></code> </pre> <br>  Udev-Regeln √§ndern sich nicht oft, sodass selbst das Zuweisen bereits vorhandener Werte zu bestimmten Parametern zu einem Anstieg der √úbermittlungslatenz f√ºr die Anwendung f√ºhrt.  Das Generieren von udev-Ereignissen, wenn sich die Konfiguration eines Ger√§ts nicht √§ndert (kein Ger√§t ist angeschlossen oder getrennt), ist nat√ºrlich keine gute Vorgehensweise.  Trotzdem k√∂nnen wir verhindern, dass der Kernel die Warteschlange einfriert, wenn es keinen Grund daf√ºr gibt.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drei</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kleine</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Commits</a> beheben das Problem. <br><br><h2>  Fazit </h2><br>  eBPF ist ein hochflexibles und leistungsstarkes Instrument.  In diesem Artikel haben wir uns nur einen Fall angesehen und ein wenig gezeigt, wozu er in der Lage ist.  Wenn Sie an der Entwicklung von BCC-basierten Tools interessiert sind, sollten Sie sich das <a href="">offizielle Tutorial</a> ansehen, in dem die grundlegenden Konzepte beschrieben werden. <br><br>  Es gibt auch andere interessante eBPF-basierte Tools zum Profilieren und Debuggen.  Eines davon ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bpftrace</a> , mit dem Sie leistungsstarke Oneliner und kleine Programme in einer awk-√§hnlichen Sprache schreiben k√∂nnen.  Ein weiteres Beispiel ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ebpf_exporter</a> , mit dem Sie hochaufl√∂sende Metriken auf niedriger Ebene auf Ihrem Prometheus-Server mit hervorragenden Visualisierungs- und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Warnfunktionen</a> erfassen k√∂nnen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450818/">https://habr.com/ru/post/de450818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450806/index.html">Wenn eine Umgebungsvariable den Prozess um das 40-fache beschleunigt</a></li>
<li><a href="../de450810/index.html">Top 7 M√∂glichkeiten, um die Kompetenzen von IT-Spezialisten vor dem Interview schnell zu √ºberpr√ºfen</a></li>
<li><a href="../de450812/index.html">PSR-14 - das Hauptereignis in PHP</a></li>
<li><a href="../de450814/index.html">Wie BGP funktioniert</a></li>
<li><a href="../de450816/index.html">HTTP-Header f√ºr den verantwortlichen Entwickler</a></li>
<li><a href="../de450820/index.html">FrontendConf-Programmkomitee: Rahmenbedingungen, Horizonte, Welterfahrung und Mission der Konferenz</a></li>
<li><a href="../de450822/index.html">Verschwindende Rahmenbedingungen</a></li>
<li><a href="../de450824/index.html">Der Zustand von CSS</a></li>
<li><a href="../de450826/index.html">Wie man mit dem Mikrocontroller von JS spricht</a></li>
<li><a href="../de450828/index.html">Wenn die Stadt einschl√§ft ...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
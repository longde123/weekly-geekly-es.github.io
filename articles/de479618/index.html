<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÜ üè° üòÖ Postgres Pro Standard 12.1 ver√∂ffentlicht üë®üèº‚Äçüåæ üë®üèª‚Äç‚úàÔ∏è üå∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Postgres Pro Standard DBMS wurde entwickelt, um Benutzern unsere Produkte schneller als √ºber PostgreSQL zur Verf√ºgung zu stellen. Die Funktionen, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Postgres Pro Standard 12.1 ver√∂ffentlicht</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/479618/">  Das Postgres Pro Standard DBMS wurde entwickelt, um Benutzern unsere Produkte schneller als √ºber PostgreSQL zur Verf√ºgung zu stellen.  Die Funktionen, die noch nicht in PostgreSQL enthalten sind, sich aber auf einem soliden Pfad befinden, sind in Postgres Pro Standard enthalten.  Au√üerdem enth√§lt Postgres Pro Standard einige Erweiterungen, die von unseren Kunden angefordert werden, aber in der PostgreSQL-Standarddistribution nicht verf√ºgbar sind. <br><br>  Manchmal gibt es Ausnahmen, wenn in Postgres Pro Standard auf Wunsch der Benutzer und um diese zu befriedigen, weniger triviale Funktionen enthalten sind, die nur in Postgres Pro Enterprise sinnvoll sind.  Insbesondere ist es PTRACK, dar√ºber weiter unten. <br><br>  Nicht alle, aber ein angemessener Teil der in Standard enthaltenen zus√§tzlichen Erweiterungen und Dienstprogramme wurden von Postgres Professional entwickelt.  Alle Postgres Pro-Patches wurden von uns selbst erfunden und implementiert.  Beginnen wir mit den Verbesserungen, die Eingriffe in das Datenbankmodul erforderlich machten. <br><a name="habracut"></a><br>  Postgres Pro Standard unterscheidet sich von PostgreSQL auf zwei Ebenen: der Satz der Erweiterungen und Dienstprogramme, die in der Assembly enthalten sind, und der Kernel selbst.  Auf den Kernel wurden einige n√ºtzliche Patches angewendet, die die Leistung optimieren (z. B. ein nicht bremsender Sperrdetektor), und Patches, die die Effizienz von Dienstprogrammen und Erweiterungen erh√∂hen (z. B. wird der PTRACK 2.0-Patch angewendet, damit pg_probackup mit voller St√§rke funktioniert).  Die Unterschiede zwischen der Kernversion von Standard und PostgreSQL werden f√ºr eine gr√∂√ütm√∂gliche Kompatibilit√§t minimiert.  Angenommen, die Erweiterung pg_pathman ist in Standard enthalten, kann aber vom Github heruntergeladen werden, der auf dem Vanille-PostgreSQL-Server erstellt und installiert wurde. Es treten keine Kompatibilit√§tsprobleme auf. <br>  Beginnen wir mit den √Ñnderungen im Kernel. <br><br><h3>  √úberpr√ºfen der ICU-Versionen </h3><br>  In PostgreSQL werden sie standardm√§√üig zum Vergleichen von Zeichenfolgen mithilfe der Standardbibliothek C verwendet, es besteht jedoch auch die M√∂glichkeit, die von IBM entwickelte <a href="http://site.icu-project.org/">ICU-</a> Bibliothek f√ºr denselben Zweck zu verwenden.  Diese Bibliothek ist f√ºr uns vor allem deshalb wertvoll, weil sie eine plattformunabh√§ngige Sortierung erm√∂glicht.  Aus diesem Grund wird es beispielsweise in 1C verwendet, und PostgreSQL "for one-es" -Assemblys arbeiten seit langer Zeit mit dieser Bibliothek. <br><br>  Au√üerdem sind Zeichenfolgenvergleiche √ºber die Intensivstation manchmal schneller als √ºber libc, und die Anzahl der ihr bekannten Zeichen ist gr√∂√üer.  Im Allgemeinen eine n√ºtzliche Bibliothek.  Postgres Pro Standard arbeitet seit der ersten Version (9.5) damit.  In PostgreSQL ist das Arbeiten mit der Intensivstation seit Version 10 m√∂glich. <br><br>  Die Bibliothek ist n√ºtzlich, aber Sie m√ºssen einige Notfallsituationen ber√ºcksichtigen.  Angenommen, ein DBMS-Benutzer hat beschlossen, das Betriebssystem zu aktualisieren.  Zusammen mit dem Betriebssystem kann auch die ICU-Bibliothek aktualisiert werden, und die Reihenfolge der W√∂rter in der Sortierung √§ndert sich.  Danach werden alle Indizes sofort unbrauchbar: Die Indexsuche liefert falsche Ergebnisse.  In solchen F√§llen teilte die Basis mit, dass die Version der Intensivstation ge√§ndert und gestoppt wurde. <br><br>  Aber das ist eine schmerzlich schwierige Entscheidung.  Nach Gespr√§chen und einer Kundenbefragung wurde beschlossen, das Verhalten zu mildern.  Jetzt werden nur noch Versionen von COLLATION (Sortierregeln) gepr√ºft.  Wenn sich die in der Datenbank verwendeten Versionen von COLLATION ge√§ndert haben, gibt die Datenbank beim Starten des DBMS eine Warnung aus, die jedoch nicht beendet wird.  Es erinnert den Benutzer auch am Anfang jeder Sitzung. <br><br><h3>  Optimierung von Sperren, Verkn√ºpfungen und GROUP BY </h3><br>  Der Deadlock-Erkennungsmechanismus kann die Leistung beeintr√§chtigen.  Standard kann nicht mehr: Der Kernel-Patch erm√∂glicht es, ohne Bremsen zu arbeiten.  Nach erheblichen Verbesserungen des √úberpr√ºfungsmechanismus treten diese Probleme nur bei einer gro√üen Anzahl von Kernen und Verbindungen auf. <br><br>  Verbesserte Sch√§tzung der Anzahl der Verkn√ºpfungsergebnisse bei Vorhandensein geeigneter Indizes. <br><br>  Jetzt k√∂nnen Sie mit geeigneten Indizes Felder gruppieren und sortieren.  Diese Funktion war erstmals in Standard 11.1.1 und Enterprise 11.2.1 enthalten.  Unser Standard 12 hat auch einen. <br><br>  Fedor Sigaev, CTO von Postgres Professional, hat der Community diese n√ºtzlichen Patches angeboten. Sie werden derzeit gepr√ºft und werden hoffentlich in Version PG 13 enthalten sein. <br><br>  Wir veranschaulichen die Optimierung der GROUP BY-Operation anhand von Beispielen: Sie sind klar und leicht reproduzierbar. <br><br>  Der Punkt dieses Patches ist, dass Postgres die Reihenfolge der in GROUP BY aufgelisteten Felder nicht optimiert hat.  Die Ausf√ºhrungszeit h√§ngt von der Reihenfolge der Gruppierung ab (mit demselben Abfrageergebnis).  Es gibt Details in der <a href="https://postgrespro.ru/list/thread-id/2388982">Diskussion</a> auf der <a href="https://postgrespro.ru/list/pgsql-hackers">Hacker-</a> Mailingliste. <br><br>  Wenn der Wert in der ersten zu verarbeitenden Spalte eindeutig ist, muss nichts anderes verglichen werden.  Wenn Sie von einer anderen Spalte ausgehen, m√ºssen Sie vergleichen. <br><br><br>  So kommen Sie zum Test: <br><br><pre><code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">DROP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">IF</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXISTS</span></span> btg; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> id, i/<span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> p, format(<span class="hljs-string"><span class="hljs-string">'%60s'</span></span>, i%<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> btg <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1000000</span></span>) i;</code> </pre> <br><br>  Im Textfeld v werden 60 Leerzeichen generiert, gefolgt von den Zahlen 0 oder 1. Die Eintr√§ge sehen folgenderma√üen aus: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> btg <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> id <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span>; id | p | v <span class="hljs-comment"><span class="hljs-comment">---------+--------+-------------------------------------------------------------- 1000000 | 500000 | 0 999999 | 499999 | 1 999998 | 499999 | 0 (3 rows)</span></span></code> </pre> <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">VACUUM</span></span> btg; <span class="hljs-keyword"><span class="hljs-keyword">ANALYSE</span></span> btg; <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> enable_hashagg=<span class="hljs-keyword"><span class="hljs-keyword">off</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> max_parallel_workers= <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> max_parallel_workers_per_gather = <span class="hljs-number"><span class="hljs-number">0</span></span>;</code> </pre> <br><br>  Gruppieren Sie die Ergebnisse: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">VACUUM</span></span> btg; <span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> btg <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> p, v;</code> </pre> <br><br>  PostgreSQL-Plan: <br><br><pre> <code class="pgsql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">------------------------------------------------------ GroupAggregate (cost=204036.84..218981.05 rows=494421 width=73) (actual time=843.999..1194.985 rows=1000000 loops=1) Group Key: p, v -&gt; Sort (cost=204036.84..206536.84 rows=1000000 width=65) (actual time=843.990..946.769 rows=1000000 loops=1) Sort Key: p, v Sort Method: external sort Disk: 73320kB -&gt; Seq Scan on btg (cost=0.00..22346.00 rows=1000000 width=65) (actual time=0.158..151.645 rows=1000000 loops=1) Planning time: 0.317 ms Execution time: 1250.086 ms (8 rows)</span></span></code> </pre> <br><br>  Nun in umgekehrter Reihenfolge: v und erst dann p: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> btg <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> v, p; QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">------------------------------------------------ GroupAggregate (cost=204036.84..218981.05 rows=494421 width=73) (actual time=2552.477..3353.890 rows=1000000 loops=1) Group Key: v, p -&gt; Sort (cost=204036.84..206536.84 rows=1000000 width=65) (actual time=2552.469..3111.516 rows=1000000 loops=1) Sort Key: v, p Sort Method: external merge Disk: 76264kB -&gt; Seq Scan on btg (cost=0.00..22346.00 rows=1000000 width=65) (actual time=0.082..126.578 rows=1000000 loops=1) Planning time: 0.060 ms Execution time: 3411.048 ms (8 rows)</span></span></code> </pre> <br><br>  Es stellt sich heraus, dass der R√ºckw√§rtsgang sp√ºrbar langsamer ist.  Dies liegt daran, dass das erste Feld <code>v</code> mit einer kleinen Wertespreizung analysiert wird.  Sie m√ºssen die restlichen Felder (hier - das Feld p) sehr genau pr√ºfen. <br><br>  Mal sehen, wie dieselbe Abfrage mit einem Patch funktioniert, der die optimale Reihenfolge f√ºr die Verarbeitung von Spalten ausw√§hlt: <br><br><pre> <code class="pgsql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">---------------------------------------------------------------- GroupAggregate (cost=237400.11..252417.09 rows=501698 width=73) (actual time=415.541..703.647 rows=1000000 loops=1) Group Key: p, v -&gt; Sort (cost=237400.11..239900.11 rows=1000000 width=65) (actual time=415.533..507.785 rows=1000000 loops=1) Sort Key: p, v Sort Method: external merge Disk: 73488kB -&gt; Seq Scan on btg (cost=0.00..22346.00 rows=1000000 width=65) (actual time=0.059..139.587 rows=1000000 loops=1) Planning Time: 0.123 ms Execution Time: 742.118 ms (8 rows)</span></span></code> </pre> <br><br>  Und in umgekehrter Reihenfolge: <br><br><pre> <code class="pgsql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">------------------------------------------------------ GroupAggregate (cost=237400.11..252417.09 rows=501698 width=73) (actual time=414.322..714.593 rows=1000000 loops=1) Group Key: p, v -&gt; Sort (cost=237400.11..239900.11 rows=1000000 width=65) (actual time=414.312..517.707 rows=1000000 loops=1) Sort Key: p, v Sort Method: external merge Disk: 76384kB -&gt; Seq Scan on btg (cost=0.00..22346.00 rows=1000000 width=65) (actual time=0.071..129.835 rows=1000000 loops=1) Planning Time: 0.140 ms Execution Time: 753.031 ms (8 rows)</span></span></code> </pre> <br><br>  Der Plan besagt, dass hier und da die Verarbeitungsreihenfolge gleich ist: Sortierschl√ºssel: p, v.  Dementsprechend ist die Zeit ungef√§hr gleich.  Vergleichen Sie nun, was passiert, wenn der Index verwendet wird. <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INDEX</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> btg(p, v); <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> enable_seqscan=<span class="hljs-keyword"><span class="hljs-keyword">off</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> enable_bitmapscan=<span class="hljs-keyword"><span class="hljs-keyword">off</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">VACUUM</span></span> btg; <span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> btg <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> v, p ;</code> </pre> <br><br>  In PostgreSQL: <br><br><pre> <code class="pgsql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">--------------------------------------------------------- GroupAggregate (cost=0.55..74660.04 rows=494408 width=73) (actual time=0.013..391.317 rows=1000000 loops=1) Group Key: p, v -&gt; Index Only Scan using btg_p_v_idx on btg (cost=0.55..62216.16 rows=999974 width=65) (actual time=0.009..120.298 rows=1000000 loops=1) Heap Fetches: 0 Planning time: 0.078 ms Execution time: 442.923 ms (6 rows)</span></span></code> </pre> <br><br>  Und in umgekehrter Reihenfolge: <br><br><pre> <code class="pgsql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">------------------------------------------------------ GroupAggregate (cost=243904.22..258848.04 rows=494408 width=73) (actual time=2558.485..3352.240 rows=1000000 loops=1) Group Key: v, p -&gt; Sort (cost=243904.22..246404.16 rows=999974 width=65) (actual time=2558.478..3110.242 rows=1000000 loops=1) Sort Key: v, p Sort Method: external merge Disk: 76264kB -&gt; Index Only Scan using btg_p_v_idx on btg (cost=0.55..62216.16 rows=999974 width=65) (actual time=0.011..133.563 rows=1000000 loops=1) Heap Fetches: 0 Planning time: 0.093 ms Execution time: 3409.335 ms (9 rows)</span></span></code> </pre> <br><br>  Jetzt in Standard: <br><br><pre> <code class="pgsql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">-------------------------------------------------------------- GroupAggregate (cost=0.55..74196.82 rows=501685 width=73) (actual time=0.150..412.174 rows=1000000 loops=1) Group Key: p, v -&gt; Index Only Scan using btg_p_v_idx on btg (cost=0.55..61680.16 rows=999974 width=65) (actual time=0.134..149.669 rows=1000000 loops=1) Heap Fetches: 0 Planning Time: 0.175 ms Execution Time: 448.635 ms (6 rows)</span></span></code> </pre> <br><br>  Und in umgekehrter Reihenfolge: <br><br><pre> <code class="pgsql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">------------------------------------------------------------- GroupAggregate (cost=0.55..74196.82 rows=501685 width=73) (actual time=0.014..307.258 rows=1000000 loops=1) Group Key: p, v -&gt; Index Only Scan using btg_p_v_idx on btg (cost=0.55..61680.16 rows=999974 width=65) (actual time=0.008..89.204 rows=1000000 loops=1) Heap Fetches: 0 Planning Time: 0.054 ms Execution Time: 337.766 ms (6 rows)</span></span></code> </pre> <br><br>  Die Zeit ist wieder dieselbe, was nat√ºrlich ist: Tats√§chlich sind die Handlungen dieselben. <br><br><h3>  Ersetzen eines Null-Bytes beim Booten </h3><br>  Postgres Pro akzeptiert keine Null-Bytes (0x00) in den Daten, daher m√ºssen diese mit COPY FROM ersetzt werden, da <a href="https://postgrespro.ru/docs/postgrespro/12/runtime-config-compatible">sonst ein Fehler auftritt</a> .  Dies ist das eigentliche Problem, auf das der Kunde beim Importieren von Daten aus einer CSV-Datei gesto√üen ist.  Die L√∂sung besteht darin, Null-Bytes durch das angegebene ASCII-Zeichen zu ersetzen.  Sie muss sich von den Zeichen QUOTE und DELIMITER unterscheiden, die beim Ausf√ºhren von COPY FROM verwendet werden.  Andernfalls ist das Ergebnis m√∂glicherweise unerwartet.  Standardm√§√üig ist der Wert der Variablen nul_byte_replacement_on_import (string) '\ 0', dh es wird keine Ersetzung durchgef√ºhrt. <br><br><h3>  WaitLSN </h3><br>  LSN ist eine <a href="https://postgrespro.ru/docs/postgrespro/12/sql-waitlsn">fortlaufende Nummer im Protokoll</a> , dh ein Zeiger auf eine Position in der WAL (Log Sequence Number).  Der Befehl WAITLSN wartet auf die Wiedergabe der angegebenen LSN.  Wenn die Anwendung sowohl mit dem Master als auch mit dem Replikat zusammenarbeitet, m√ºssen Sie sicherstellen, dass sie von Zeit zu Zeit synchron sind.  WAITLSN ist ein Interprozessmechanismus in PostgrePro, der die Synchronisation w√§hrend der <a href="https://postgrespro.ru/docs/postgrespro/12/runtime-config-replication">synchronen Replikation</a> steuert.  Standardm√§√üig ist die Wartezeit unbegrenzt.  Sie k√∂nnen das Warten abbrechen, indem Sie Strg + C dr√ºcken oder den Postgres-Server stoppen.  Sie k√∂nnen das Zeitlimit auch festlegen, indem Sie den TIMEOUT-Hinweis hinzuf√ºgen, oder den Status der Ziel-LSN √ºberpr√ºfen, ohne mit dem NOWAIT-Hinweis zu warten. <br>  Angenommen, eine Anwendung f√ºhrt eine bestimmte Aktion aus, erh√§lt die LSN-Nummer vom DBMS auf dem Master und m√∂chte nun sicherstellen, dass die Aktionen auf dem Replikat mit dem Master synchronisiert werden, d. H.  Die Anwendung kann sicher sein, dass das, was sie im Assistenten aufgezeichnet hat, bereits im Replikat eingetroffen ist und zum Lesen bereit ist.  Standardm√§√üig ist dies normalerweise nicht garantiert.  Mit WAITLSN k√∂nnen Sie diese Interaktion steuern und einen Schlafmodus von UNENDLICH standardm√§√üig bis TIMEOUT und NOWAIT ausw√§hlen. <br><br><h3>  Erneutes Lesen von Variablen aus der fr√ºheren recovery.conf </h3><br>  Bei einem SIGHUP-Signal liest PostgreSQL die Datei postgresql.conf erneut, nicht jedoch die Datei recovery.conf.  Ein relativ neuer Kernel-Patch, der in Standard und Enterprise 10.4.1 eingef√ºhrt wurde.  erneut lesen und recovery.conf.  In Postgres 12 gibt es jedoch √ºberhaupt keine Datei recovery.conf: Alle Variablen davon werden an postgresql.conf √ºbertragen.  Obwohl die gesamte Datei erneut gelesen wird, wurden die Variablen aus recovery.conf nicht von SIGHUP neu definiert, sondern erforderten einen Neustart von Postgres.  In Standard ist dies nicht erforderlich: Alles wird gelesen und neu definiert. <br><br><h3>  PTRACK-Unterst√ºtzung </h3><br>  PTRACK 2.0 ist ein √ºberarbeiteter PTRACK-Mechanismus f√ºr Standard- und Enterprise-Versionen 11 und fr√ºher.  Auf DBMS-Ebene funktionierte es dank des Kernel-Patches, und jetzt wurde die ptrack-Erweiterung zum <a href="https://postgrespro.ru/docs/postgrespro/12/ptrack">Patch</a> hinzugef√ºgt.  PTRACK 2.0 verfolgt die √Ñnderungen an der Datenseite und bietet eine Schnittstelle zum Abrufen dieser Informationen.  Es kann sowohl zu Diagnosezwecken verwendet werden, um beispielsweise eine Vorstellung davon zu erhalten, wie stark die Instanz im Verh√§ltnis zu einem bestimmten Zeitpunkt "mutiert" ist, als fortlaufende Nummer im Protokoll (LSN) festgelegt ist, als auch um inkrementelle Sicherungen zu erstellen. <br><br>  Der schwierigste und ‚Äûteuerste‚Äú Teil eines inkrementellen Sicherungsvorgangs besteht in der Regel darin, eine Teilmenge der ge√§nderten Seiten von der gesamten Seitenmenge in einem Cluster zu isolieren.  Aufgrund der Tatsache, dass der Server diese Aufgabe √ºbernehmen und schnell Informationen √ºber die ge√§nderten Seiten bereitstellen kann, wird die Zeit f√ºr inkrementelle Sicherungen mit PTRACK erheblich reduziert. <br><br>  PTRACK 2.0 verwendet eine Hash-Tabelle einer bestimmten Gr√∂√üe im gemeinsam genutzten Speicher, die regelm√§√üig mit der Datei ptrack.map synchronisiert wird. <br><br>  Aufgrund einer grundlegenden √Ñnderung des internen Funktionsmechanismus und einer mit √§lteren Versionen nicht kompatiblen Benutzeroberfl√§che ist die ptrack-Erweiterung nur in der 12. Version von PostgresPro Standard und Enterprise verf√ºgbar und wird als Patch und Erweiterung unter PostgreSQL 12 verf√ºgbar sein. <br><br><h3>  Bearbeiten von Befehlen in psql f√ºr Windows </h3><br>  Die erweiterte Unterst√ºtzung f√ºr das Bearbeiten von Eingabebefehlen in psql f√ºr Windows wird mit WinEditLine implementiert.  Jetzt k√∂nnen Sie die Zeichen verschiedener Alphabete gleichzeitig anzeigen (insbesondere wird Kyrillisch normalerweise unter nicht-russischen Windows angezeigt). <br><br><h3>  Einheitliche Paketstruktur </h3><br><br>  Die Struktur der Bin√§rpaketpakete f√ºr alle Linux-Distributionen wurde vereinheitlicht, um die Migration zwischen ihnen zu vereinfachen und die Installation mehrerer verschiedener PostgreSQL-basierter Produkte ohne Konflikte zu erm√∂glichen.  Dies finden Sie in <a href="https://postgrespro.ru/docs/postgrespro/12/installation-bin">Kapitel 16 der</a> Dokumentation. <br><br>  Nun zu den Erweiterungen: <br><br><h3>  dump_stat </h3><br>  Es erschien bereits in 9.5.  Beim √úbertragen oder Wiederherstellen von Daten werden akkumulierte Statistiken normalerweise nicht √ºbertragen.  Wenn Sie es mit dem Befehl ANALYZE wieder zusammenbauen, wird es f√ºr den gesamten Cluster und nicht f√ºr die angegebene Datenbank ausgef√ºhrt.  Dies kann bei gro√üen Datenbanken viel zus√§tzliche Zeit in Anspruch nehmen. <br><br>  Die Erweiterung dump_stat <a href="https://postgrespro.ru/docs/postgrespro/12/dump-stat">bietet Funktionen</a> , mit denen Sie den Inhalt der Tabelle pg_statistic entladen und wiederherstellen k√∂nnen.  Beim Hochladen / Wiederherstellen von Daten k√∂nnen Sie dump_stat verwenden, um vorhandene Statistiken auf einen neuen Server zu √ºbertragen, ohne den Befehl ANALYZE f√ºr den gesamten Cluster ausf√ºhren zu m√ºssen. <br><br>  Die Funktion dump_statistic entl√§dt den Inhalt des Systemkatalogs pg_statistic.  F√ºr jedes Tupel in pg_statistic wird ein INSERT erstellt, mit Ausnahme derjenigen, die Statistiken zu Tabellen in den Schemata information_schema und pg_catalog enthalten. <br><br><h3>  jsquery </h3><br>  Denken Sie daran, dass <a href="https://postgrespro.ru/docs/postgrespro/12/jsquery">dies eine Erweiterung</a> f√ºr die Arbeit mit JSON (B) und nicht mit JS ist.  Es bietet eine Reihe von Funktionen zur Verarbeitung dieser Datentypen.  Dies ist eine spezielle Abfragesprache f√ºr die effiziente Suche mithilfe von Indizes in JSON (B).  Im <a href="https://habr.com/ru/company/postgrespro/blog/448612/">Artikel √ºber den Hub finden</a> Sie einige Beispiele f√ºr jsquery und alternative Methoden f√ºr die Arbeit mit JSON (B), z. B. JSONPath (beide von unserer Firma entwickelt). <br><br><h3>  online_analyze </h3><br>  Diese Erweiterung <a href="https://postgrespro.ru/docs/postgrespro/12/online-analyze">bietet eine</a> Reihe von Funktionen, mit denen Statistiken in den Tabellen, die nach den Operationen INSERT, UPDATE, DELETE oder SELECT INTO angegeben wurden, sofort aktualisiert werden.  Der Autor der Erweiterung ist Fedor Sigaev. <br><br>  Um das Modul online_analyze zu verwenden, m√ºssen Sie die gemeinsam genutzte Bibliothek laden: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">LOAD</span></span> <span class="hljs-string"><span class="hljs-string">'online_analyze'</span></span>;</code> </pre> <br><br>  Statistik-Updates k√∂nnen angepasst werden.  Legen Sie beispielsweise einen Prozentsatz der Tabellengr√∂√üe oder die Mindestanzahl (Schwellenwert) der Zeilen√§nderungen fest, nach denen Statistiken sofort erfasst werden. <br><br><h3>  pg_pathman </h3><br>  Die <a href="https://postgrespro.ru/docs/postgrespro/12/pg-pathman">Erweiterung pg_pathman</a> in Postgres Professional wurde fr√ºher als im PostgreSQL-Kernel erstellt und implementierte einen ziemlich vollst√§ndigen Satz von Funktionen zum Erstellen von Partitionen.  Daher k√∂nnen viele Operationen mit Abschnitten sowohl mit dem einen als auch mit dem anderen Mechanismus durchgef√ºhrt werden.  Es ist nur ratsam, die durch deklarative Partitionierung und pg_pathman erstellten Abschnitte nicht zu mischen. <br><br>  Viele pg_pathman-Operationen sind jedoch immer noch schneller und einige Funktionen fehlen in PostgreSQL.  Zum Beispiel das automatische Erstellen (Schneiden) von Abschnitten.  In PostgreSQL m√ºssen Sie die Grenzen der einzelnen Abschnitte festlegen.  Wenn wir Daten eingeben, von denen nicht im Voraus bekannt ist, wie viele Abschnitte gestreut werden k√∂nnen und sollen, ist es praktisch, das Intervall einfach festzulegen und die Software die Abschnitte selbst schneiden zu lassen - so viel wie erforderlich.  pg_pathman wei√ü wie, PostgreSQL nicht.  Ab PG 11 gibt es jedoch einen Standardabschnitt (Standard), in dem Sie alle Datens√§tze sichern k√∂nnen, die nicht in Abschnitte mit festgelegten Grenzen fallen. <br><br>  Mit den Verantwortlichen der PostgreSQL-Community besteht eine grunds√§tzliche Vereinbarung, dass in Zukunft die besten und einzigartigsten Funktionen von pg_pathman in den Hauptzweig fallen werden.  Bis dahin kann pg_pathman den Administratoren von Anwendungs-DBs und Anwendungsprogrammierern das Leben erleichtern. <br><br>  Erstellen Sie eine Erweiterung: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXTENSION</span></span> pg_pathman;</code> </pre> <br><br>  Mit pg_pathman k√∂nnen Sie gro√üe Tabellen in Abschnitte unterteilen und eine praktische API bereitstellen - eine Reihe von Funktionen zum Erstellen und Arbeiten mit Abschnitten.  Zum Beispiel mit der Funktion <br><br><pre> <code class="pgsql hljs">create_range_partitions(relation <span class="hljs-type"><span class="hljs-type">REGCLASS</span></span>, expression <span class="hljs-type"><span class="hljs-type">TEXT</span></span>, start_value <span class="hljs-type"><span class="hljs-type">ANYELEMENT</span></span>, p_interval <span class="hljs-type"><span class="hljs-type">INTERVAL</span></span>, p_count <span class="hljs-type"><span class="hljs-type">INTEGER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DEFAULT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>, partition_data <span class="hljs-type"><span class="hljs-type">BOOLEAN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DEFAULT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TRUE</span></span>);</code> </pre> <br>  wir k√∂nnen fragen <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_range_partitions(<span class="hljs-string"><span class="hljs-string">'log'</span></span>, <span class="hljs-string"><span class="hljs-string">'dt'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>::<span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-string"><span class="hljs-string">'1 month'</span></span>::<span class="hljs-type"><span class="hljs-type">interval</span></span>);</code> </pre> <br><br>  Danach f√ºgen wir Abschnitte hinzu: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> add_range_partition(<span class="hljs-string"><span class="hljs-string">'log'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>, <span class="hljs-string"><span class="hljs-string">'2017-01-01'</span></span>::<span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-string"><span class="hljs-string">'log_archive'</span></span>, <span class="hljs-string"><span class="hljs-string">'ts0'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> add_range_partition(<span class="hljs-string"><span class="hljs-string">'log'</span></span>, <span class="hljs-string"><span class="hljs-string">'2017-01-01'</span></span>::<span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-string"><span class="hljs-string">'2017-02-01'</span></span>::<span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-string"><span class="hljs-string">'log_1'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> add_range_partition(<span class="hljs-string"><span class="hljs-string">'log'</span></span>, <span class="hljs-string"><span class="hljs-string">'2017-02-01'</span></span>::<span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-string"><span class="hljs-string">'2017-03-01'</span></span>::<span class="hljs-type"><span class="hljs-type">date</span></span><span class="hljs-string"><span class="hljs-string">', log_2'</span></span>);</code> </pre> <br><br>  Das Archivprotokoll wird im Tabellenbereich ts0 erstellt, der Rest ist standardm√§√üig.  Sie k√∂nnen jedoch keine expliziten Abschnitte angeben, sondern dieser DBMS-Operation vertrauen, indem Sie das Intervall festlegen und Abschnitte in einem Schritt erstellen: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_range_partitions(<span class="hljs-string"><span class="hljs-string">'log'</span></span>, <span class="hljs-string"><span class="hljs-string">'dt'</span></span>, <span class="hljs-string"><span class="hljs-string">'2017-01-01'</span></span>::<span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-string"><span class="hljs-string">'1 month'</span></span>::<span class="hljs-type"><span class="hljs-type">interval</span></span>);</code> </pre> <br><br>  Auf einem einfachen Tisch sieht es so aus: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> pg_pathmania(id <span class="hljs-type"><span class="hljs-type">serial</span></span>, val <span class="hljs-type"><span class="hljs-type">float</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> pg_pathmania(val) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> random() * <span class="hljs-number"><span class="hljs-number">1000</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_range_partitions(<span class="hljs-string"><span class="hljs-string">'pg_pathmania'</span></span>, <span class="hljs-string"><span class="hljs-string">'id'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>); test_parti=# \d+ pg_pathmania <span class="hljs-keyword"><span class="hljs-keyword">Table</span></span> "public.pg_pathmania" <span class="hljs-keyword"><span class="hljs-keyword">Column</span></span> | <span class="hljs-keyword"><span class="hljs-keyword">Type</span></span> | <span class="hljs-keyword"><span class="hljs-keyword">Collation</span></span> | Nullable | <span class="hljs-keyword"><span class="hljs-keyword">Default</span></span> | <span class="hljs-keyword"><span class="hljs-keyword">Storage</span></span> | S tats target | Description <span class="hljs-comment"><span class="hljs-comment">--------+------------------+-----------+----------+-----------------------+---------+------+------ id | integer | | not null | nextval('pg_pathmania_id_seq'::regclass) | plain | | val | double precision | | | | plain | | Child tables: pg_pathmania_1, pg_pathmania_10, pg_pathmania_11, pg_pathmania_12, pg_pathmania_13, pg_pathmania_14, pg_pathmania_15, pg_pathmania_16, pg_pathmania_17, pg_pathmania_18, pg_pathmania_19, pg_pathmania_2, pg_pathmania_20, pg_pathmania_21, pg_pathmania_3, pg_pathmania_4, pg_pathmania_5, pg_pathmania_6, pg_pathmania_7, pg_pathmania_8, pg_pathmania_9</span></span></code> </pre> <br><br>  In PostgreSQL m√ºssten wir jeden Abschnitt mit unserem eigenen Team erstellen.  In solchen F√§llen schreiben sie nat√ºrlich ein Skript, das den erforderlichen DDL-Code automatisch generiert.  Sie m√ºssen keine Skripte in pg_pathman schreiben, alles ist bereits vorhanden.  Das ist aber nicht das interessanteste.  Wir f√ºgen einen Datensatz ein, der nicht nur anhand der ID in einen der vorhandenen Abschnitte, sondern auch nicht in den n√§chsten Abschnitt f√§llt: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> pg_pathmania(id, val) <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">2000</span></span>, <span class="hljs-number"><span class="hljs-number">277.835794724524</span></span>);</code> </pre> <br><br>  √úberpr√ºfen Sie erneut den Inhalt der Tabelle mit \ d + pg_pathmania: <br><br><pre> <code class="pgsql hljs">Child <span class="hljs-keyword"><span class="hljs-keyword">tables</span></span>: pg_pathmania_1, pg_pathmania_10, ... pg_pathmania_39, pg_pathmania_4, pg_pathmania_40, pg_pathmania_41,</code> </pre> <br><br>  Folgendes ist passiert: pg_pathman hat festgestellt, dass der Datensatz mit id = 2000 nicht in die bereits erstellten Abschnitte f√§llt. Er hat berechnet, wie viele davon erstellt werden m√ºssen, wobei er das Intervall RANGE kennt, mit dem die Tabelle zuvor partitioniert wurde, und hat den Abschnitt erstellt, in den der neue Datensatz f√§llt. alle Abschnitte zwischen der oberen Grenze der alten Abschnitte und der unteren Grenze des neuen Abschnitts.  Dies ist sehr praktisch und in F√§llen, in denen die Werte des Aufteilungsfelds der aktualisierten Daten schlecht vorhergesagt werden, ist dies ein schwerwiegender Vorteil von pg_pathman. <br><br><h3>  pg_query_state </h3><br>  Mit dieser von uns entwickelten Erweiterung k√∂nnen wir <a href="https://postgrespro.ru/docs/postgrespro/12/pg-query-state">den</a> aktuellen Status der Anfragen im Serving-Prozess ermitteln.  Es existiert seit Version 9.5 und ist auf die zahlreichen Anfragen von Kundenadministratoren zur√ºckzuf√ºhren. <br><br>  Tatsache ist, dass Sie mit EXPLAIN ANALYZE Ausf√ºhrungsstatistiken anzeigen k√∂nnen, die von jedem Knoten des Planbaums erfasst wurden. Diese Statistiken werden jedoch erst nach Abschluss der Abfrage erfasst.  Aber im Leben gibt es leider Situationen, in denen Sie sich ansehen m√ºssen, was die Anforderung noch nicht abgeschlossen hat und m√∂glicherweise nicht zu Ende geht.  Mit pg_query_state k√∂nnen Sie die aktuellen Statistiken einer Abfrage anzeigen, die in einem externen Wartungsprozess ausgef√ºhrt wird.  In diesem Fall ist das Format der resultierenden Ausgabe fast identisch mit der Ausgabe des √ºblichen EXPLAIN ANALYZE-Befehls. <br><br>  Dienstprogramme: <br><br><h3>  pgBouncer </h3><br>  <a href="http://www.pgbouncer.org/">Dies ist</a> ein so <a href="https://postgrespro.ru/docs/postgrespro/12/pgbouncer">beliebter Verbindungs-Puller,</a> dass es seltsam w√§re, hier dar√ºber zu sprechen.  Es ist nur ein Teil von Standard und muss im Fall von Vanilla PostgreSQL separat installiert werden. <br><br><h3>  pg_probackup </h3><br>  <a href="https://postgrespro.ru/docs/postgrespro/12/app-pgprobackup">pg_probackup</a> ist eine unserer beliebtesten Entwicklungen.  Hierbei handelt es sich um einen Sicherungs- und Wiederherstellungsmanager, der haupts√§chlich von Anastasia Lubennikova, Grigory Smolkin und der Benutzergemeinschaft entwickelt und aktualisiert wird. <br><br>  Wettbewerbsvorteile von pg_probackup: inkrementelle Sicherung mit Blockgranularit√§t (8 KB), drei inkrementelle Sicherungsmodi (PAGE, DELTA, PTRACK), On-Demand-√úberpr√ºfung der Sicherungsintegrit√§t, PostgreSQL-Cluster√ºberpr√ºfung, Sicherungskomprimierung, teilweise Wiederherstellung usw. <br><br>  Der PTRACK-Inkrementalkopiermodus, der sich auf <a href="https://postgrespro.ru/docs/postgrespro/12/ptrack">die gleichnamige Erweiterung des</a> √ºberarbeiteten Mechanismus - PTRACK 2.0 - st√ºtzt, ist jetzt noch schneller und eindeutig der schnellste und billigste pg_probackup-Modus. <br><br><h3>  pg_repack </h3><br>  <a href="https://postgrespro.ru/docs/postgrespro/12/app-pgrepack">pg_repack ist ein</a> beliebtes Dienstprogramm, dessen Funktionsweise VACUUM FULL oder <a href="https://postgrespro.ru/docs/postgrespro/12/sql-cluster">CLUSTER</a> √§hnelt.  Es packt nicht nur Tabellen neu, beseitigt L√ºcken, sondern kann auch die physische Reihenfolge von Clustered-Indizes wiederherstellen.  Im Gegensatz zu CLUSTER und VACUUM FULL werden diese Vorg√§nge von unterwegs ausgef√ºhrt, ohne dass exklusive Tabellensperren erforderlich sind, und im Allgemeinen wird effizient gearbeitet.  Es ist nicht in der Vanille-Version enthalten. <br><br><h3>  pg_variables </h3><br>  √úber diese Erweiterung auf einem habr gibt es einen interessanten <a href="https://habr.com/ru/company/postgrespro/blog/302200/">Artikel</a> unseres Mitarbeiters Ivan Frolkov.  Der Grund f√ºr die Erweiterung ist, dass das Arbeiten mit Zwischenergebnissen manchmal unbequem und teuer ist.  Der Artikel untersucht Alternativen.  Am h√§ufigsten sind tempor√§re Tabellen. <br><br>  Als tempor√§res Data Warehouse ist die Erweiterung "pg_variables" viel produktiver als tempor√§re Tabellen (pgbench-Tests sind im Artikel enthalten) und praktischer: Der Datensatz wird durch ein Paar "Paket - Variable" definiert, das als Parameter √ºbergeben, von einer Funktion zur√ºckgegeben usw. werden kann. Es gibt set / get-Funktionen zum Arbeiten mit Variablen.  So k√∂nnen Sie beispielsweise viele Variablen speichern (package ist der Name des Pakets und der Ausdruck nach dem Dezimalpunkt sind die Variablen in diesem Paket: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pgv_set_int(<span class="hljs-string"><span class="hljs-string">'package'</span></span>,<span class="hljs-string"><span class="hljs-string">'#'</span></span>||n,n), n <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1000000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> gs(n);</code> </pre> <br><br>  Variablen haben eine interessante Eigenschaft: kein Fehler oder Vorteil, sondern eine Eigenschaft: Die von den Erweiterungsmitteln gespeicherten Daten liegen au√üerhalb von Transaktionen vor - sie werden sowohl beim Reparieren einer Transaktion als auch beim Rollback gespeichert;  Selbst wenn ein separater Befehl ausgef√ºhrt wird, k√∂nnen dar√ºber hinaus Teildaten erhalten werden: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pgv_insert(<span class="hljs-string"><span class="hljs-string">'package'</span></span>, <span class="hljs-string"><span class="hljs-string">'errs'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">row</span></span>(n)) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> gs(n) <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-number"><span class="hljs-number">1.0</span></span>/(n<span class="hljs-number"><span class="hljs-number">-3</span></span>)&lt;&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>; ERROR: there <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a <span class="hljs-type"><span class="hljs-type">record</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> the variable "errs" <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> same key test_parti=# <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pgv_select(<span class="hljs-string"><span class="hljs-string">'package'</span></span>,<span class="hljs-string"><span class="hljs-string">'errs'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> r(i <span class="hljs-type"><span class="hljs-type">int</span></span>); i <span class="hljs-comment"><span class="hljs-comment">--- 1 2 (2 rows)</span></span></code> </pre> <br><br>  Dies ist zum einen nicht sehr komfortabel - zum einen muss daf√ºr gesorgt werden, dass falsch eingegebene Daten gel√∂scht werden, zum anderen kann es sehr n√ºtzlich sein, zum Beispiel Daten auch bei einem Transaktions-Rollback zu speichern.  Die <a href="https://github.com/postgrespro/pg_variables">Dokumentation</a> enth√§lt Details. <br><br>  Abschlie√üend noch ein paar Erweiterungen: <br><br><h3>  sr_plan, plantuner </h3><br>  <b>sr_plan</b> <a href="https://postgrespro.ru/docs/postgrespro/12/sr-plan">speichert</a> Abfragepl√§ne <a href="https://postgrespro.ru/docs/postgrespro/12/sr-plan">und stellt sie wieder her</a> .  Schlie√üen Sie es so ein: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> sr_plan.write_mode = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>;</code> </pre> <br><br>  Danach werden die Pl√§ne f√ºr alle nachfolgenden Abfragen in der Tabelle sr_plans gespeichert, bis diese Variable auf false gesetzt wird.  Die Pl√§ne f√ºr alle Anfragen, einschlie√ülich wiederholter Anfragen, werden gespeichert. <br><br>  <b>plantuner</b> <a href="https://postgrespro.ru/docs/postgrespro/12/plantuner">unterst√ºtzt</a> Hinweise, mit denen der Scheduler bestimmte Indizes beim Ausf√ºhren einer Abfrage verbinden oder trennen kann.  Es gibt nur zwei GUC-Variablen: enable_index / desable_index: <br><br><pre> <code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> plantuner.disable_index=<span class="hljs-string"><span class="hljs-string">'id_idx2'</span></span>;</code> </pre> <br><br><h3>  Erweiterungen f√ºr die Volltextsuche: shared_ispell, pg_tsparser </h3><br>  Die shared_ispell-Erweiterung, mit der Sie <a href="https://postgrespro.ru/docs/postgrespro/12/hunspell-dict">W√∂rterb√ºcher</a> in den gemeinsamen Speicher stellen k√∂nnen, ist in Standard und nicht in PostgreSQL.  Unser Hunspell-Diktat-Set enth√§lt W√∂rterb√ºcher f√ºr Sprachen: <br><br><ul><li>  hunspell_en_us, </li><li>  hunspell_fr, </li><li>  hunspell_nl_nl, </li><li>  hunspell_ru_ru </li></ul><br><br>  Die <b>Erweiterung pg_tsparser</b> ist <a href="https://postgrespro.ru/docs/postgrespro/12/pg-tsparser">ein alternativer</a> Textsuchanalysator.  Diese Erweiterung √§ndert die Standardstrategie zum Parsen von Text f√ºr W√∂rter, die Unterstriche sowie durch Unterstriche getrennte Zahlen und Buchstaben enthalten.  Zus√§tzlich zu den einzelnen Teilen des Wortes, die standardm√§√üig zur√ºckgegeben werden, gibt pg_tsparser auch das gesamte Wort zur√ºck.  Dies ist sehr wichtig f√ºr technische Dokumentationen oder Artikel wie diesen, in denen sich der Programmcode befindet und in denen W√∂rter wie "pg_tsparser", "pg_probackup", "jsonb_build_object" vorkommen.  Dieser Parser nimmt diese W√∂rter nicht nur als eine Reihe von Komponenten, sondern auch als ein einzelnes Token wahr und verbessert dadurch die Qualit√§t der Suche. <br><br><h3>  Erweiterungen f√ºr 1C </h3><br><ul><li>  <b><a href="https://postgrespro.ru/docs/postgrespro/12/mchar">mchar</a></b> ist ein optionaler Datentyp f√ºr die Kompatibilit√§t mit Microsoft SQL Server. </li><li>  <b><a href="https://postgrespro.ru/docs/postgrespro/12/fulleq">fulleq</a></b> - Bietet einen zus√§tzlichen Gleichheitsoperator f√ºr die Kompatibilit√§t mit Microsoft SQL Server. </li><li> <b><a href="https://postgrespro.ru/docs/postgrespro/12/fasttrun">fasttrun</a></b> ‚Äî  -     ,     pg_class. </li></ul><br><br>      ,    PostgresPro Standard  PostgreSQL.   ,     , , , <a href="https://postgrespro.ru/docs/postgrespro/12/index">  </a> . <br><br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479618/">https://habr.com/ru/post/de479618/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479590/index.html">Top 10 App-Entwicklungsunternehmen im Jahr 2020</a></li>
<li><a href="../de479592/index.html">Wie erreichen Sie Ihre Ziele?</a></li>
<li><a href="../de479598/index.html">Katze und Hund f√ºttern den Roboter</a></li>
<li><a href="../de479600/index.html">Ein weiteres DSL zur Validierung</a></li>
<li><a href="../de479602/index.html">Was ist das vollst√§ndige Genom und warum wird es ben√∂tigt?</a></li>
<li><a href="../de479620/index.html">Umgekehrte Logik</a></li>
<li><a href="../de479622/index.html">So funktioniert der Prototyp anonymer Transaktionen in der Waves-Blockchain</a></li>
<li><a href="../de479624/index.html">Postgres-Profi-Gendar Oleg Bartunov informiert Faride Roslovets √ºber PostgreSQL und das Gesch√§ft in Russland</a></li>
<li><a href="../de479626/index.html">Resonator mit einer Wendung, die Physiker nicht kennen</a></li>
<li><a href="../de479630/index.html">K√§mpfe um Aufmerksamkeit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
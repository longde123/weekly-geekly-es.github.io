<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∞üèº ‚õΩÔ∏è üõë Weiterentwicklung des Code-Bereitstellungsansatzes in Reddit üöú üòæ ‚ò£Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir im Wirex Blockchain-Zahlungsservice- Team sind mit der Erfahrung vertraut, dass die vorhandene technologische L√∂sung st√§ndig weiterentwickelt und ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Weiterentwicklung des Code-Bereitstellungsansatzes in Reddit</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/wirex/blog/404577/"><img src="https://habrastorage.org/web/ff7/6e9/159/ff76e9159228455b8f91663d289c8e2f.png" alt="Bild"><br><br>  <i>Wir im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wirex</a> Blockchain-Zahlungsservice- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Team</a> sind mit der Erfahrung vertraut, dass die vorhandene technologische L√∂sung st√§ndig weiterentwickelt und verbessert werden muss.</i>  <i>Der Autor des folgenden Materials spricht √ºber die Geschichte der Entwicklung der Codebereitstellung der ber√ºhmten Social-News-Plattform Reddit.</i> <br><br><blockquote>  "Es ist wichtig, der Richtung Ihrer Entwicklung zu folgen, um sie rechtzeitig in eine gute Richtung senden zu k√∂nnen." </blockquote><br>  Das Reddit-Team stellt st√§ndig Code bereit.  Alle Mitglieder des Entwicklungsteams schreiben regelm√§√üig Code, der vom Autor selbst √ºberpr√ºft und von au√üen getestet wird, damit er dann zur "Produktion" gehen kann.  Jede Woche f√ºhren wir mindestens 200 ‚ÄûBereitstellungen‚Äú durch, von denen jede normalerweise weniger als 10 Minuten dauert. <br><br>  Das System, das all dies bietet, hat sich im Laufe der Jahre weiterentwickelt.  Mal sehen, was sich die ganze Zeit daran ge√§ndert hat und was unver√§ndert geblieben ist. <br><br><h3>  Beginn der Geschichte: stabile und wiederkehrende Bereitstellungen (2007-2010) </h3><br>  Das gesamte System, das wir heute haben, ist aus einem Samen gewachsen - einem Perl-Skript namens Push.  Es wurde vor langer Zeit geschrieben, zu sehr unterschiedlichen Zeiten f√ºr Reddit.  Unser gesamtes technisches Team war zu dieser Zeit so klein, dass es leise <a href="">in einen kleinen ‚ÄûBesprechungsraum‚Äú passte</a> .  Wir haben AWS damals nicht verwendet.  Die Site arbeitete auf einer begrenzten Anzahl von Servern, und jede zus√§tzliche Kapazit√§t musste manuell hinzugef√ºgt werden.  Alles funktionierte auf einer gro√üen, monolithischen Python-Anwendung namens r2. <br><a name="habracut"></a><br>  Eines ist im Laufe der Jahre unver√§ndert geblieben.  Anforderungen wurden im Load Balancer klassifiziert und auf die "Pools" verteilt, die mehr oder weniger identische Anwendungsserver enthielten.  Beispielsweise werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Themen-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kommentarlistenseiten</a> von verschiedenen Serverpools verarbeitet.  Tats√§chlich kann jeder r2-Prozess jede Art von Anforderung verarbeiten. Durch die Aufteilung in Pools k√∂nnen Sie jedoch jeden von ihnen vor pl√∂tzlichen Verkehrsspr√ºngen in benachbarten Pools sch√ºtzen.  Im Falle eines Verkehrswachstums bedroht ein Ausfall nicht das gesamte System, sondern die einzelnen Pools. <br><br><img src="https://habrastorage.org/web/63d/7b1/8e7/63d7b18e768d4b15a6310ecf6f0e15d5.png" alt="Bild"><br><br>  Die Liste der Zielserver wurde manuell in den Push-Tool-Code geschrieben, und der Bereitstellungsprozess arbeitete mit einem monolithischen System.  Das Tool durchlief die Liste der Server, war √ºber SSH angemeldet, f√ºhrte eine der vordefinierten Befehlssequenzen aus, mit denen die aktuelle Kopie des Codes mit git aktualisiert wurde, und startete alle Anwendungsprozesse neu.  Das Wesentliche des Prozesses (der Code ist f√ºr ein allgemeines Verst√§ndnis stark vereinfacht): <br><br><pre><code class="hljs mel">#            <span class="hljs-string"><span class="hljs-string">`make -C /home/reddit/reddit static`</span></span> <span class="hljs-string"><span class="hljs-string">`rsync /home/reddit/reddit/static public:/var/www/`</span></span> #    app-        #    ,   foreach $h (@hostlist) { <span class="hljs-string"><span class="hljs-string">`git push $h:/home/reddit/reddit master`</span></span> <span class="hljs-string"><span class="hljs-string">`ssh $h make -C /home/reddit/reddit`</span></span> <span class="hljs-string"><span class="hljs-string">`ssh $h /bin/restart-reddit.sh`</span></span> }</code> </pre> <br>  Die Bereitstellung erfolgte nacheinander, ein Server nach dem anderen.  Bei aller Einfachheit hatte das Programm ein wichtiges Plus: Es ist dem ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kanarischen Einsatz</a> ‚Äú sehr √§hnlich.  Durch die Bereitstellung des Codes auf mehreren Servern und das Erkennen von Fehlern haben Sie sofort festgestellt, dass Fehler aufgetreten sind. Sie k√∂nnen den Prozess unterbrechen (Strg-C) und einen Rollback durchf√ºhren, bevor Probleme mit allen Anforderungen gleichzeitig auftreten.  Die einfache Bereitstellung machte es einfach und ohne schwerwiegende Konsequenzen, Dinge in der Produktion zu √ºberpr√ºfen und zur√ºckzusetzen, wenn sie nicht funktionierten.  Dar√ºber hinaus war es praktisch zu bestimmen, welche bestimmte Bereitstellung Fehler verursachte, wo genau und was zur√ºckgesetzt werden muss. <br><br>  Ein solcher Mechanismus hat gute Arbeit geleistet, um Stabilit√§t und Kontrolle w√§hrend des Einsatzes zu gew√§hrleisten.  Das Tool hat ziemlich schnell funktioniert.  Die Dinge liefen gut. <br><br><h3>  Unser Regiment ist angekommen (2011) </h3><br>  Dann stellten wir mehr Leute ein, jetzt gab es sechs Entwickler, und unser neuer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûBesprechungsraum‚Äú wurde ger√§umiger</a> .  Wir stellten fest, dass der Code-Bereitstellungsprozess jetzt mehr Koordination erfordert, insbesondere wenn Kollegen von zu Hause aus arbeiten.  Das Push-Dienstprogramm wurde aktualisiert: Jetzt wurde der Beginn und das Ende von Bereitstellungen mithilfe des IRC-Chatbots angek√ºndigt, der sich einfach im IRC befand und Ereignisse ank√ºndigte.  Die Prozesse, die w√§hrend der Bereitstellung ausgef√ºhrt wurden, wurden fast nicht ge√§ndert, aber jetzt hat das System alles f√ºr den Entwickler getan und alle anderen √ºber die vorgenommenen √Ñnderungen informiert. <br><br>  Von diesem Moment an begann die Verwendung von Chat im Bereitstellungsworkflow.  Die Diskussion √ºber die Verwaltung der Bereitstellung aus Chats war zu dieser Zeit sehr beliebt. Da wir jedoch IRC-Server von Drittanbietern verwendeten, konnten wir dem Chat bei der Verwaltung der Produktionsumgebung nicht hundertprozentig vertrauen, und daher blieb der Prozess auf der Ebene eines einseitigen Informationsflusses. <br><br>  Mit dem wachsenden Datenverkehr auf der Website wuchs auch die Infrastruktur, die diese unterst√ºtzte.  Von Zeit zu Zeit mussten wir eine neue Gruppe von Anwendungsservern starten und in Betrieb nehmen.  Der Prozess war noch nicht automatisiert.  Insbesondere musste die Hostliste in Push noch manuell aktualisiert werden. <br><br>  Die Leistung der Pools wurde normalerweise durch Hinzuf√ºgen mehrerer Server gleichzeitig erh√∂ht.  Infolgedessen gelang es Push, nacheinander durch die Liste zu laufen, √Ñnderungen auf eine ganze Gruppe von Servern im selben Pool zu √ºbertragen, ohne die anderen zu beeinflussen, dh es gab keine Diversifizierung nach Pools. <br><br><img src="https://habrastorage.org/web/ccd/063/580/ccd0635803d647b7b0161762c2aa5ff7.png" alt="Bild"><br><br>  UWSGI wurde zur Steuerung von Arbeitsprozessen verwendet. Als wir der Anwendung einen Neustartbefehl erteilten, wurden alle vorhandenen Prozesse gleichzeitig beendet und durch neue ersetzt.  Es dauerte einige Zeit, bis neue Prozesse f√ºr die Bearbeitung von Anforderungen vorbereitet waren.  Im Falle eines unbeabsichtigten Neustarts einer Gruppe von Servern im selben Pool hat die Kombination dieser beiden Umst√§nde die F√§higkeit dieses Pools, Anforderungen zu bedienen, ernsthaft beeintr√§chtigt.  Daher ist die Geschwindigkeit der sicheren Bereitstellung von Code auf allen Servern begrenzt.  Mit der Anzahl der Server stieg auch die Dauer des gesamten Vorgangs. <br><br><h3>  Bereitstellung von Recycling-Instrumenten (2012) </h3><br>  Wir haben das Bereitstellungstool gr√ºndlich √ºberarbeitet.  Und obwohl sein Name trotz einer vollst√§ndigen √Ñnderung derselbe blieb (Push), wurde er diesmal in Python geschrieben.  Die neue Version hat einige wesentliche Verbesserungen erfahren. <br><br>  Zun√§chst nahm er die Liste der Hosts von DNS und nicht von der Sequenz, die im Code fest codiert war.  Dadurch konnte nur die Liste aktualisiert werden, ohne dass der Push-Code aktualisiert werden musste.  Die Anf√§nge eines Service Discovery Systems sind entstanden. <br><br>  Um das Problem der aufeinanderfolgenden Neustarts zu l√∂sen, haben wir die Liste der Hosts vor der Bereitstellung gemischt.  Das Mischen reduzierte die Risiken und erm√∂glichte es, den Prozess zu beschleunigen. <br><br><img src="https://habrastorage.org/web/b13/1ec/1ee/b131ec1eec994fa0bc9900bd9d8f7766.PNG" alt="Bild"><br><br>  In der Originalversion wurde die Liste jedes Mal nach dem Zufallsprinzip gemischt. Dies machte es jedoch schwierig, schnell einen Rollback durchzuf√ºhren, da die Liste der ersten Servergruppe jedes Mal anders war.  Daher haben wir das Mischen korrigiert: Es wurde nun eine bestimmte Reihenfolge generiert, die w√§hrend der wiederholten Bereitstellung nach dem Rollback verwendet werden konnte. <br><br>  Eine weitere kleine, aber wichtige √Ñnderung war die st√§ndige Bereitstellung einer festen Version des Codes.  In der vorherigen Version des Tools wurde der Master-Zweig auf dem Zielhost immer aktualisiert. Was passiert jedoch, wenn sich der Master direkt w√§hrend der Bereitstellung √§ndert, weil jemand den Code versehentlich gestartet hat?  Durch die Bereitstellung einer bestimmten Git-Revision anstelle des Aufrufs nach Zweigstellennamen konnte sichergestellt werden, dass auf jedem Produktionsserver dieselbe Codeversion verwendet wurde. <br><br>  Und schlie√ülich unterschied das neue Tool seinen Code (es arbeitete haupts√§chlich mit einer Liste von Hosts und griff √ºber SSH darauf zu) und die auf den Servern ausgef√ºhrten Befehle.  Es hing immer noch sehr stark von den Anforderungen von r2 ab, hatte aber so etwas wie einen API-Prototyp.  Dies erm√∂glichte es r2, seine eigenen Bereitstellungsschritte zu befolgen, was das Rollen von √Ñnderungen vereinfachte und den Fluss freisetzte.  Das folgende Beispiel zeigt Befehle, die auf einem separaten Server ausgef√ºhrt werden.  Der Code ist wiederum nicht der genaue Code, aber insgesamt beschreibt diese Sequenz den r2-Workflow gut: <br><br><pre> <code class="hljs pgsql">sudo /opt/reddit/deploy.py <span class="hljs-keyword"><span class="hljs-keyword">fetch</span></span> reddit sudo /opt/reddit/deploy.py deploy reddit f3bbbd66a6 sudo /opt/reddit/deploy.py <span class="hljs-keyword"><span class="hljs-keyword">fetch</span></span>-names sudo /opt/reddit/deploy.py <span class="hljs-keyword"><span class="hljs-keyword">restart</span></span> <span class="hljs-keyword"><span class="hljs-keyword">all</span></span></code> </pre> <br>  Besonders erw√§hnenswert sind Abrufnamen: Diese Anweisung gilt nur f√ºr r2. <br><br><h3>  Autoscaling (2013) </h3><br>  Dann haben wir uns endlich entschlossen, zu einer Cloud mit automatischer Skalierung zu wechseln (ein Thema f√ºr einen ganzen separaten Beitrag).  Auf diese Weise konnten wir in den Momenten, in denen die Website nicht mit Datenverkehr belastet war, eine ganze Menge Geld sparen und automatisch die Kapazit√§t erh√∂hen, um mit einem starken Anstieg der Anforderungen fertig zu werden. <br><br>  Fr√ºhere Verbesserungen, bei denen die Hostliste automatisch aus DNS geladen wurde, haben diesen √úbergang zur Selbstverst√§ndlichkeit gemacht.  Die Liste der Hosts wurde h√§ufiger als zuvor ge√§ndert, aus Sicht des Bereitstellungstools spielte dies jedoch keine Rolle.  Die √Ñnderung, die urspr√ºnglich als Qualit√§tsverbesserung eingef√ºhrt wurde, ist zu einer der Schl√ºsselkomponenten f√ºr die automatische Skalierung geworden. <br><br>  Die automatische Skalierung hat jedoch zu einigen interessanten Grenzf√§llen gef√ºhrt.  Starts mussten kontrolliert werden.  Was passiert, wenn der Server direkt w√§hrend der Bereitstellung gestartet wird?  Wir mussten sicherstellen, dass jeder neue Server, der ausgef√ºhrt wurde, die Verf√ºgbarkeit von neuem Code √ºberpr√ºfte und ihn nahm, falls es einen gab.  Wir konnten nicht vergessen, dass die Server zum Zeitpunkt der Bereitstellung offline gingen.  Das Tool musste intelligenter werden und lernen, festzustellen, ob der Server im Rahmen des Vorgangs offline geschaltet wurde und nicht aufgrund eines Fehlers, der w√§hrend der Bereitstellung aufgetreten ist.  Im letzteren Fall musste er alle an dem Problem beteiligten Kollegen lautstark warnen. <br><br>  Gleichzeitig haben wir √ºbrigens aus verschiedenen Gr√ºnden von uWSGI zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gunicorn gewechselt</a> .  Aus Sicht des Themas dieses Beitrags f√ºhrte ein solcher √úbergang jedoch zu keinen wesentlichen √Ñnderungen. <br><br>  Also hat es eine Weile funktioniert. <br><br><h3>  Zu viele Server (2014) </h3><br>  Im Laufe der Zeit wuchs die Anzahl der Server, die f√ºr die Wartung des Spitzenverkehrs ben√∂tigt werden.  Dies f√ºhrte dazu, dass Bereitstellungen immer mehr Zeit ben√∂tigten.  Im schlimmsten Fall dauerte eine normale Bereitstellung etwa eine Stunde - ein schlechtes Ergebnis. <br><br>  Wir haben das Tool neu geschrieben, damit es die parallele Arbeit mit Hosts unterst√ºtzen kann.  Die neue Version hei√üt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nudelholz</a> .  Die alte Version ben√∂tigte viel Zeit, um SSH-Verbindungen zu initialisieren und auf den Abschluss aller Befehle zu warten. Durch die Parallelisierung innerhalb angemessener Grenzen konnten wir die Bereitstellung beschleunigen.  Die Bereitstellungszeit verringerte sich erneut auf f√ºnf Minuten. <br><br><img src="https://habrastorage.org/web/efb/7ba/c3d/efb7bac3df5a4905897b462dea14bf62.PNG" alt="Bild"><br><br>  Um die Auswirkungen des gleichzeitigen Neustarts mehrerer Server zu verringern, wurde die Mischkomponente des Tools intelligenter.  Anstatt die Liste blind zu mischen, sortierte er die Serverpools so, dass Hosts von einem Pool <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">so weit wie m√∂glich</a> voneinander entfernt waren. <br><br>  Die wichtigste √Ñnderung im neuen Tool war, dass die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">API zwischen dem Bereitstellungstool und den Tools auf jedem Server</a> viel klarer definiert und von den Anforderungen von r2 getrennt wurde.  Urspr√ºnglich geschah dies aus dem Wunsch heraus, den Code Open Source-orientierter zu gestalten, aber bald war dieser Ansatz auf andere Weise sehr n√ºtzlich.  Das Folgende ist eine Beispielbereitstellung mit der Auswahl von remote gestarteten API-Befehlen: <br><br><img src="https://habrastorage.org/web/a8b/2d4/750/a8b2d4750f65444998587581f1d1132f.png" alt="Bild"><br><br><h3>  Zu viele Leute (2015) </h3><br>  Pl√∂tzlich kam ein Moment, in dem, wie sich herausstellte, bereits viele Leute an r2 arbeiteten.  Es war cool und bedeutete gleichzeitig, dass es noch mehr Bereitstellungen geben w√ºrde.  Die Einhaltung der Regel eines Einsatzes zu einem Zeitpunkt wurde immer schwieriger.  Die Entwickler mussten sich auf das Verfahren zur Ausgabe des Codes einigen.  Um die Situation zu optimieren, haben wir dem Chatbot ein weiteres Element hinzugef√ºgt, das die Bereitstellungswarteschlange koordiniert.  Ingenieure haben eine Bereitstellungsreserve angefordert und diese entweder erhalten oder ihren Code in die Warteschlange gestellt.  Dies trug zur Rationalisierung der Bereitstellungen bei, und diejenigen, die sie abschlie√üen wollten, konnten ruhig warten, bis sie an der Reihe waren. <br><br>  Eine weitere wichtige Erg√§nzung im Zuge des Teamwachstums war die Verfolgung von Bereitstellungen an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einem Ort</a> .  Wir haben das Bereitstellungstool ge√§ndert, um Metriken an Graphite zu senden.  Dies machte es einfach, die Korrelation zwischen Bereitstellungen und Metrik√§nderungen zu verfolgen. <br><br><h3>  Viele (zwei) Dienste (auch 2015) </h3><br>  Nur pl√∂tzlich kam der Moment der Ver√∂ffentlichung des zweiten Online-Dienstes.  Es war eine mobile Version der Website mit einem eigenen, v√∂llig anderen Stack, eigenen Servern und dem Build-Prozess.  Dies war der erste echte Test einer API f√ºr ein Split-Deployment-Tool.  Durch die M√∂glichkeit, alle Montagestufen an verschiedenen "Standorten" f√ºr jedes Projekt zu erarbeiten, konnte er der Last standhalten und die Wartung von zwei Diensten innerhalb desselben Systems bew√§ltigen. <br><br><h3>  25 Dienstleistungen (2016) </h3><br>  Im n√§chsten Jahr haben wir die schnelle Erweiterung des Teams miterlebt.  Anstelle von zwei Diensten erschienen zwei Dutzend anstelle von zwei Entwicklungsteams f√ºnfzehn.  Die meisten Dienste wurden entweder auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Baseplate</a> , unserem Backend-Framework, oder auf Clientanwendungen, √§hnlich dem mobilen Web, erstellt.  Die Infrastruktur hinter den Bereitstellungen ist f√ºr alle gleich.  Bald werden viele andere neue Dienste online ver√∂ffentlicht, und all dies ist haupts√§chlich auf die Vielseitigkeit des Nudelholzes zur√ºckzuf√ºhren.  Sie k√∂nnen den Start neuer Dienste mithilfe von Tools vereinfachen, die den Benutzern vertraut sind. <br><br><h3>  Airbag (2017) </h3><br>  Mit zunehmender Anzahl von Servern im Monolithen nahm die Bereitstellungszeit zu.  Wir wollten die Anzahl der parallelen Bereitstellungen erheblich erh√∂hen, dies w√ºrde jedoch zu vielen gleichzeitigen Neustarts der Anwendungsserver f√ºhren.  Solche Dinge f√ºhren nat√ºrlich zu einem R√ºckgang des Durchsatzes und einem Verlust der F√§higkeit, eingehende Anforderungen zu bearbeiten, da die verbleibenden Server √ºberlastet sind. <br><br>  Der Hauptprozess von Gunicorn verwendete dasselbe Modell wie uWSGI und lud alle Arbeiter gleichzeitig neu.  Neue Worker-Prozesse konnten Anforderungen erst bearbeiten, wenn sie vollst√§ndig geladen waren.  Die Startzeit unseres Monolithen lag zwischen 10 und 30 Sekunden.  Dies bedeutete, dass wir in diesem Zeitraum Anfragen √ºberhaupt nicht bearbeiten konnten.  Um einen Ausweg aus dieser Situation zu finden, haben wir den Hauptprozess f√ºr das Gunicorn durch den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Einhorn-</a> Arbeitsmanager von Stripe ersetzt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">und dabei den Gunicorn-HTTP-Stack und den WSGI-Container beibehalten</a> .  W√§hrend des Neustarts erstellt Einhorn einen neuen Worker, wartet, bis er fertig ist, entfernt einen alten Worker und wiederholt den Vorgang, bis das Update abgeschlossen ist.  Dies erzeugt einen Airbag und erm√∂glicht es uns, die Bandbreite w√§hrend der Ausl√∂sung auf einem Niveau zu halten. <br><br>  Das neue Modell verursachte ein weiteres Problem.  Wie bereits erw√§hnt, dauerte das Ersetzen eines Arbeiters durch einen neuen und vollst√§ndig fertigen bis zu 30 Sekunden.  Dies bedeutete, dass ein Fehler im Code nicht sofort angezeigt wurde und auf vielen Servern bereitgestellt werden konnte, bevor er erkannt wurde.  Um dies zu verhindern, haben wir einen Mechanismus zum Blockieren des √úbergangs des Bereitstellungsverfahrens zum neuen Server eingef√ºhrt, der bis zum Neustart aller Arbeitsprozesse wirksam war.  Es wurde einfach umgesetzt - indem der Staat Einhorn abgefragt und auf die Bereitschaft aller neuen Arbeiter gewartet wurde.  Um die Geschwindigkeit auf dem gleichen Niveau zu halten, haben wir die Anzahl der parallel verarbeiteten Server erh√∂ht, was unter den neuen Bedingungen v√∂llig sicher war. <br><br>  Ein solcher Mechanismus erm√∂glicht die gleichzeitige Bereitstellung auf einer viel gr√∂√üeren Anzahl von Computern, und die Bereitstellungszeit, die ungef√§hr 800 Server umfasst, wird auf 7 Minuten reduziert, wobei zus√§tzliche Pausen f√ºr die √úberpr√ºfung auf Fehler ber√ºcksichtigt werden. <br><br><h3>  R√ºckblick </h3><br>  Die hier beschriebene Bereitstellungsinfrastruktur ist ein Produkt, das aus langj√§hrigen konsequenten Verbesserungen und nicht aus einer einmaligen, gezielten Anstrengung entstanden ist.  Die Echos der einmal getroffenen und in den fr√ºhen Phasen von Kompromissen getroffenen Entscheidungen machen sich im gegenw√§rtigen System immer noch bemerkbar, und dies war in allen Phasen immer der Fall.  Ein solcher evolution√§rer Ansatz hat seine Vor- und Nachteile: Er erfordert in jedem Stadium ein Minimum an Aufwand, es besteht jedoch das Risiko, dass er fr√ºher oder sp√§ter zum Stillstand kommt.  Es ist wichtig, der Richtung Ihrer Entwicklung zu folgen, um sie rechtzeitig in eine gute Richtung senden zu k√∂nnen. <br><br><h3>  Die Zukunft </h3><br>  Die Reddit-Infrastruktur sollte f√ºr die kontinuierliche Unterst√ºtzung des Teams bereit sein, wenn es w√§chst und neue Dinge auf den Markt bringt.  Die Wachstumsrate des Unternehmens ist schneller als je zuvor und wir arbeiten an noch interessanteren und umfangreicheren Projekten als alles, was wir zuvor getan haben.  Die Probleme, mit denen wir heute konfrontiert sind, haben zwei Gr√ºnde: Einerseits muss die Autonomie der Entwickler erh√∂ht werden, andererseits muss die Sicherheit der Produktionsinfrastruktur aufrechterhalten und der Airbag verbessert werden, wodurch Entwickler schnell und sicher Bereitstellungen durchf√ºhren k√∂nnen. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/4bd/bf6/597/4bdbf659775744b1bdbb4d8a00a0a980.png" alt="Bild"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de404577/">https://habr.com/ru/post/de404577/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de404567/index.html">Herausgeber Peter. Sommerschlussverkauf</a></li>
<li><a href="../de404569/index.html">Teilchen, Antiteilchen und ihre Vernichtung</a></li>
<li><a href="../de404571/index.html">Soziale Netzwerke - eine neue ernsthafte Quelle f√ºr Cyber-Bedrohungen</a></li>
<li><a href="../de404573/index.html">Das "mathematische Monster" gewinnen: Es geht nicht um Zahlen, sondern darum zu lernen, zu denken</a></li>
<li><a href="../de404575/index.html">Microsofts KI hat den Rekord eines Mannes bei Frau gebrochen. Pac-Man</a></li>
<li><a href="../de404579/index.html">Polybius ICO sammelte in zwei Wochen 20 Millionen US-Dollar</a></li>
<li><a href="../de404583/index.html">Facebook experimentiert mit einem Bot, der verhandeln und l√ºgen kann</a></li>
<li><a href="../de404585/index.html">Da wir im Cottage Village Internet zur Verf√ºgung stellten</a></li>
<li><a href="../de404587/index.html">Fiktion und Fantasie in zweieinhalb Jahren, fast hundert gute B√ºcher</a></li>
<li><a href="../de404589/index.html">Welt der Drohnen: von Handheld-Ger√§ten bis zu Anti-UAVs</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
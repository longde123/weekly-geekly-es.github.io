<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🍳 📰 ⛪️ Hari ketika Dodo berhenti. Skrip asinkron 🍐 👩🏼‍🤝‍👨🏿 💼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo, Habr! Setiap SRE di tim kami pernah bermimpi tidur nyenyak di malam hari. Mimpi menjadi kenyataan. Dalam artikel ini saya akan membicarakan hal ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Hari ketika Dodo berhenti. Skrip asinkron</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dodopizzadev/blog/461081/">  Halo, Habr!  Setiap SRE di tim kami pernah bermimpi tidur nyenyak di malam hari.  Mimpi menjadi kenyataan.  Dalam artikel ini saya akan membicarakan hal ini dan bagaimana kita mencapai kinerja dan stabilitas sistem Dodo IS kita. <br><br><img src="https://habrastorage.org/webt/wk/2o/t6/wk2ot6razkmzgly1s69fdwz5quq.png"><a name="habracut"></a><br><blockquote>  <b>Serangkaian artikel tentang runtuhnya sistem Dodo IS *</b> : <br><br>  1. Hari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ketika Dodo berhenti.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Script sinkron.</a> <br>  2. Hari ketika Dodo berhenti.  Skrip asinkron. <br><br>  * <i>Materi ditulis berdasarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kinerja saya di DotNext 2018 di Moskow</a></i> . </blockquote>  Dalam artikel sebelumnya, kami melihat memblokir masalah kode dalam paradigma Preemptive Multitasking.  Seharusnya itu perlu untuk menulis ulang kode pemblokiran pada async / menunggu.  Jadi kami melakukannya.  Sekarang mari kita bicara tentang masalah apa yang muncul ketika kita melakukan ini. <br><br><h2>  Kami memperkenalkan istilah Concurrency </h2><br>  Sebelum Anda masuk ke async, Anda harus memasukkan istilah Concurrency. <br><blockquote>  Dalam teori antrian, <b>Concurrency</b> adalah jumlah klien yang saat ini ada di dalam sistem.  Konkurensi terkadang dikacaukan dengan Paralelisme, tetapi dalam kenyataannya ini adalah dua hal yang berbeda. </blockquote>  Bagi mereka yang baru mengenal Concurrency untuk pertama kalinya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">saya merekomendasikan video Rob Pike</a> .  Konkurensi adalah ketika kita berurusan dengan banyak hal pada saat yang bersamaan, dan Paralelisme adalah ketika kita melakukan banyak hal pada saat yang bersamaan. <br><br>  Di komputer, tidak banyak hal terjadi secara paralel.  Salah satunya adalah komputasi pada banyak prosesor.  Tingkat paralelisme dibatasi oleh jumlah utas CPU. <br><br>  Faktanya, Threads adalah bagian dari konsep Preemptive Multitasking, salah satu cara untuk memodelkan Concurrency dalam sebuah program ketika kita mengandalkan sistem operasi dalam pertanyaan Concurrency.  Model ini tetap bermanfaat selama kita memahami bahwa kita berurusan secara khusus dengan model Concurrency, dan bukan dengan concurrency. <br><br>  Async / await adalah gula sintaksis untuk State Machine, model Concurrency berguna lainnya yang dapat berjalan dalam lingkungan berulir tunggal.  Intinya, ini adalah Multitasking Kooperatif - model itu sendiri tidak memperhitungkan paralelisme sama sekali.  Dalam kombinasi dengan Multithreading, kami mendapatkan satu model di atas yang lain, dan hidup sangat rumit. <br><br><h2>  Perbandingan kedua model </h2><br><h4>  Cara kerjanya dalam model Preemptive Multitasking </h4><br>  Katakanlah kita memiliki 20 Utas dan 20 permintaan dalam pemrosesan per detik.  Gambar menunjukkan puncak - 200 permintaan dalam sistem secara bersamaan.  Bagaimana ini bisa terjadi: <br><br><ul><li>  permintaan dapat dikelompokkan jika 200 klien mengklik tombol pada saat yang sama; </li><li>  pemulung dapat menghentikan permintaan beberapa puluh milidetik; </li><li>  permintaan dapat ditunda dalam antrian apa pun jika proksi mendukung antrian. </li></ul><br>  Ada banyak alasan mengapa permintaan untuk periode waktu singkat telah terakumulasi dan datang dalam satu bundel.  Bagaimanapun, tidak ada yang mengerikan terjadi, mereka berdiri di antrian Pool Thread dan perlahan-lahan selesai.  Tidak ada lagi puncak, semuanya berjalan, seolah-olah tidak ada yang terjadi. <br><br>  Misalkan algoritma pintar Thread Pool (dan ada elemen pembelajaran mesin di sana) memutuskan bahwa sejauh ini tidak ada alasan untuk menambah jumlah Thread.  Kolam Koneksi di MySql juga 20 karena Thread = 20.  Karenanya, kita hanya perlu 20 koneksi ke SQL. <br><br><img src="https://habrastorage.org/webt/gm/ch/pz/gmchpzxpvegoyljdauranwzgn7k.png"><br><br>  Dalam kasus ini, level Concurrency server dari sudut pandang sistem eksternal = 200. Server telah menerima permintaan ini, tetapi belum menyelesaikannya.  Namun, untuk aplikasi yang berjalan dalam paradigma Multithreading, jumlah permintaan simultan dibatasi oleh ukuran Thread Pool = 20 saat ini. Jadi, kita berurusan dengan derajat Concurrency = 20. <br><br><h4>  Bagaimana semuanya bekerja dalam model async </h4><br><img width="33%" height="33%" src="https://habrastorage.org/webt/dg/yz/pz/dgyzpzj-nl9rawn5ctxdfr3gxgm.png"><br><br>  Mari kita lihat apa yang terjadi dalam aplikasi yang menjalankan async / menunggu dengan beban dan distribusi permintaan yang sama.  Tidak ada antrian sebelum membuat Tugas, dan permintaan segera diproses.  Tentu saja, Utas dari ThreadPool digunakan untuk waktu yang singkat, dan bagian pertama dari permintaan, sebelum menghubungi basis data, dieksekusi segera.  Karena Thread dengan cepat kembali ke Thread Pool, kami tidak perlu banyak Thread untuk diproses.  Dalam diagram ini kita tidak menampilkan Thread Pool sama sekali, itu transparan. <br><br><img src="https://habrastorage.org/webt/bm/6h/to/bm6hto7o6gxnrlg9ruzhfsxfet0.png"><br><br>  Apa artinya ini bagi aplikasi kita?  Gambaran eksternal adalah sama - tingkat Concurrency = 200. Pada saat yang sama, situasi di dalamnya telah berubah.  Sebelumnya, permintaan "ramai" dalam antrian ThreadPool, sekarang derajat Concurrency aplikasi juga 200, karena kami tidak memiliki batasan pada bagian dari TaskScheduler.  Hore!  Kami telah mencapai tujuan async - aplikasi "mengatasi" dengan hampir semua derajat Concurrency! <br><br><h4>  Konsekuensi: degradasi sistem nonlinier </h4><br>  Aplikasi telah menjadi transparan dari sudut pandang Concurrency, jadi sekarang Concurrency diproyeksikan ke database.  Sekarang kita membutuhkan kumpulan koneksi dengan ukuran yang sama = 200. Basis data adalah CPU, memori, jaringan, penyimpanan.  Ini adalah layanan yang sama dengan masalahnya, seperti yang lainnya.  Semakin banyak permintaan yang kami coba jalankan pada saat yang sama, semakin lambat dijalankan. <br><br>  Saat memuat penuh pada database, paling baik, Waktu Respons menurun secara linear: Anda memberi dua kali lebih banyak pertanyaan, itu mulai bekerja dua kali lebih lambat.  Dalam praktiknya, karena persaingan permintaan, overhead akan selalu terjadi, dan mungkin ternyata sistem akan menurun secara non-linear. <br><br><h4>  Mengapa ini terjadi? </h4><br>  Alasan untuk urutan kedua: <br><br><ul><li>  Sekarang database perlu disimpan secara bersamaan dalam memori struktur data untuk melayani lebih banyak permintaan; </li><li>  Sekarang database perlu melayani koleksi yang lebih besar (dan ini secara algoritmik tidak menguntungkan). </li></ul><br>  Alasan urutan pertama: <br><br><ul><li>  pertengkaran, yang sedikit dibahas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di artikel sebelumnya</a> . </li></ul><br>  Pada akhirnya, async berjuang melawan sumber daya yang terbatas dan ... menang!  Basis data gagal dan mulai melambat.  Dari ini, server semakin meningkatkan Concurrency, dan sistem tidak dapat lagi keluar dari situasi ini dengan hormat. <br><br><h2>  Sindrom Kematian Tiba-tiba Server </h2><br>  Terkadang situasi yang menarik terjadi.  Kami memiliki server.  Dia bekerja untuk dirinya sendiri seperti itu, semuanya teratur.  Ada sumber daya yang cukup, bahkan dengan margin.  Lalu kami tiba-tiba mendapat pesan dari klien bahwa server melambat.  Kami melihat grafik dan melihat ada beberapa peningkatan dalam aktivitas pelanggan, tetapi sekarang semuanya normal.  Memikirkan serangan atau kebetulan DOS.  Sekarang semuanya tampak baik-baik saja.  Hanya sekarang server terus bodoh, dan semuanya lebih sulit sampai batas waktu mulai mengalir.  Setelah beberapa waktu, server lain yang menggunakan database yang sama juga mulai membungkuk.  Situasi yang biasa? <br><br><h4>  Mengapa sistem mati? </h4><br>  Anda dapat mencoba menjelaskan ini dengan fakta bahwa pada titik tertentu server menerima jumlah permintaan puncak dan “bangkrut”.  Tetapi kita tahu bahwa bebannya berkurang, dan server setelah itu tidak menjadi lebih baik untuk waktu yang sangat lama, sampai bebannya benar-benar hilang. <br><br>  Pertanyaan retoris: apakah server seharusnya rusak karena beban yang berlebihan?  Apakah mereka melakukan itu? <br><br><h4>  Kami mensimulasikan situasi server crash </h4><br>  Di sini kita tidak akan menganalisis grafik dari sistem produksi nyata.  Pada saat server crash, kita sering tidak bisa mendapatkan jadwal seperti itu.  Server kehabisan sumber daya CPU, dan sebagai hasilnya, ia tidak dapat menulis log, memberikan metrik.  Pada diagram pada saat bencana terjadi, keretakan pada semua grafik sering diamati. <br><br>  SRE harus dapat menghasilkan sistem pemantauan yang kurang rentan terhadap efek ini.  Sistem yang dalam situasi apa pun menyediakan setidaknya beberapa informasi, dan pada saat yang sama, dapat menganalisis sistem post-mortem menggunakan informasi yang terpisah-pisah.  Untuk tujuan pendidikan, kami menggunakan pendekatan yang sedikit berbeda dalam artikel ini. <br><br>  Mari kita coba membuat model yang secara matematis berfungsi seperti server yang sedang dimuat.  Selanjutnya, kita akan mempelajari karakteristik server.  Kami membuang nonlinearitas server nyata dan mensimulasikan situasi di mana deselerasi linier terjadi ketika beban tumbuh di atas nominal.  Dua kali lebih banyak permintaan sesuai kebutuhan - kami melayani dua kali lebih lambat. <br><br>  Pendekatan ini akan memungkinkan: <br><br><ul><li>  pertimbangkan apa yang akan terjadi terbaik; </li><li>  ambil metrik yang akurat. </li></ul><br>  Navigasi Terjadwal: <br><br><ul><li>  biru - jumlah permintaan ke server; </li><li>  hijau - respons server; </li><li>  kuning - batas waktu; </li><li>  abu-abu gelap - permintaan yang berasal dari sumber daya server karena klien tidak menunggu respons waktu habis.  Kadang-kadang klien dapat melaporkan hal ini ke server dengan memutus hubungan, tetapi secara umum, kemewahan seperti itu secara teknis tidak mungkin, misalnya, jika server melakukan pekerjaan yang terikat CPU, tanpa kerja sama dengan klien. </li></ul><br><br><img src="https://habrastorage.org/webt/8d/r8/lr/8dr8lr7gizm-ovozc0laylwadaa.png"><br><br>  Mengapa grafik permintaan klien (berwarna biru pada diagram) ternyata begitu?  Biasanya, jadwal pesanan di restoran pizza kami tumbuh dengan lancar di pagi hari dan menurun di malam hari.  Tapi kami mengamati tiga puncak dengan latar belakang kurva seragam yang biasa.  Bentuk grafik ini tidak dipilih untuk model secara kebetulan, melainkan.  Model ini lahir selama investigasi insiden nyata dengan server pusat kontak pizzeria di Rusia selama Piala Dunia. <br><br><h2>  Kasus "Piala Dunia" </h2><br>  Kami duduk dan menunggu pesanan lagi.  Disiapkan untuk Kejuaraan, sekarang server akan dapat lulus ujian kekuatan. <br><br>  Puncak pertama - penggemar sepakbola menonton kejuaraan, mereka lapar dan membeli pizza.  Selama babak pertama, mereka sibuk dan tidak bisa memesan.  Tetapi orang-orang yang acuh tak acuh terhadap sepak bola bisa, maka pada grafik semuanya berjalan seperti biasa. <br><br>  Dan kemudian babak pertama berakhir, dan puncak kedua datang.  Fans menjadi gugup, lapar dan membuat pesanan tiga kali lebih banyak daripada di puncak pertama.  Pizza dibeli pada tingkat yang mengerikan.  Kemudian babak kedua dimulai, dan sekali lagi tidak ke pizza. <br><br>  Sementara itu, server pusat kontak mulai menekuk perlahan dan melayani permintaan lebih dan lebih lambat.  Komponen sistem, dalam hal ini, server web Pusat Panggilan, tidak stabil. <br><br>  Puncak ketiga akan datang ketika pertandingan selesai.  Kipas dan sistem menunggu penalti. <br><br><h4>  Kami menganalisis alasan kerusakan server </h4><br>  Apa yang terjadi  Server dapat menampung 100 permintaan bersyarat.  Kami memahami bahwa itu dirancang untuk kekuatan ini dan tidak akan tahan lagi.  Sebuah puncak tiba, yang dengan sendirinya tidak begitu besar.  Tetapi area abu-abu Concurrency jauh lebih tinggi. <br><br>  Model ini dirancang sedemikian rupa sehingga Concurrency secara numerik sama dengan jumlah pesanan per detik, sehingga secara visual pada grafik itu harus dari skala yang sama.  Namun, jauh lebih tinggi karena menumpuk. <br><br>  Kami melihat bayangan dari grafik di sini - ini adalah permintaan yang mulai kembali ke klien, dieksekusi (ditunjukkan oleh panah merah pertama).  Skala waktu bersyarat untuk melihat offset waktu.  Puncak kedua sudah merobohkan server kami.  Dia jatuh dan mulai memproses permintaan empat kali lebih sedikit dari biasanya. <br><br><img src="https://habrastorage.org/webt/n1/92/qw/n192qwxtwdrfatt_a-lb8y8eire.png"><br><br>  Pada paruh kedua grafik, jelas bahwa beberapa permintaan masih dieksekusi pada awalnya, tetapi kemudian bintik kuning muncul - permintaan berhenti sepenuhnya. <br><br><img src="https://habrastorage.org/webt/pi/la/nv/pilanvzebdl_vl3k3hno9vwezga.png"><br><br>  Sekali lagi seluruh jadwal.  Dapat dilihat bahwa Concurrency menjadi liar.  Sebuah gunung besar muncul. <br><br><img src="https://habrastorage.org/webt/ci/l6/kb/cil6kblebzhjokmuvzkwolmngvo.png"><br><br>  Biasanya kami menganalisis metrik yang sangat berbeda: seberapa lambat permintaan itu selesai, berapa banyak permintaan per detik.  Kami bahkan tidak melihat Concurrency, kami bahkan tidak memikirkan metrik ini.  Tetapi sia-sia, karena justru kuantitas ini yang terbaik menunjukkan momen kegagalan server. <br><br>  Tapi dari mana datangnya gunung sebesar itu?  Puncak beban terbesar telah lama berlalu! <br><br><h2>  Hukum Kecil </h2><br>  Hukum Little mengatur Concurrency. <br><br>  <i>L (jumlah pelanggan dalam sistem) = λ (kecepatan tinggal mereka) ∗ W (waktu yang mereka habiskan di dalam sistem)</i> <br><br>  Ini rata-rata.  Namun, situasi kita berkembang secara dramatis, rata-rata tidak cocok untuk kita.  Kami akan membedakan persamaan ini, lalu mengintegrasikan.  Untuk melakukan ini, lihat buku John Little, yang menemukan formula ini, dan lihat integral di sana. <br><br><img src="https://habrastorage.org/webt/sx/f5/dz/sxf5dzgwc9l7low8fild5cpsrf0.png"><br><br>  Kami memiliki jumlah entri dalam sistem dan jumlah orang yang meninggalkan sistem.  Permintaan tiba dan pergi ketika semuanya selesai.  Di bawah ini adalah grafik pertumbuhan wilayah yang sesuai dengan pertumbuhan linear Concurrency. <br><br><img src="https://habrastorage.org/webt/ax/rv/du/axrvdu3vyx1iw9afieohv5pe-cs.png"><br><br>  Ada beberapa permintaan hijau.  Inilah yang sebenarnya sedang diimplementasikan.  Yang biru adalah yang datang.  Antara waktu, kami memiliki jumlah permintaan yang biasa, situasinya stabil.  Tapi Concurrency masih terus berkembang.  Server tidak akan lagi mengatasi situasi ini sendiri.  Ini berarti dia akan segera jatuh. <br><br>  Tetapi mengapa konkurensi meningkat?  Kami melihat integral dari konstanta.  Tidak ada yang berubah dalam sistem kami, tetapi integralnya tampak seperti fungsi linier yang hanya tumbuh. <br><br><h2>  Akankah kita bermain? </h2><br>  Penjelasan dengan integral adalah rumit jika Anda tidak ingat matematika.  Di sini saya mengusulkan untuk menghangatkan dan memainkan permainan. <br><br><h4>  Game nomor 1 </h4><br>  <b>Prasyarat</b> : Server menerima permintaan, masing-masing membutuhkan tiga periode pemrosesan pada CPU.  Sumber daya CPU dibagi secara merata antara semua tugas.  Ini mirip dengan bagaimana sumber daya CPU dikonsumsi selama Preemptive Multitasking.  Angka dalam sel berarti jumlah pekerjaan yang tersisa setelah pengukuran ini.  Untuk setiap langkah kondisional, permintaan baru tiba. <br><br>  Bayangkan Anda menerima permintaan.  Hanya 3 unit pekerjaan, pada akhir periode pemrosesan pertama 2 unit tetap. <br><br>  Pada periode kedua, permintaan lain berlapis, sekarang kedua CPU sibuk.  Mereka melakukan satu unit kerja untuk dua pertanyaan pertama.  Tetap menyelesaikan 1 dan 2 unit untuk masing-masing permintaan pertama dan kedua. <br><br>  Sekarang permintaan ketiga telah tiba, dan kesenangan dimulai.  Tampaknya permintaan pertama seharusnya sudah selesai, tetapi dalam periode ini tiga permintaan sudah berbagi sumber daya CPU, sehingga tingkat penyelesaian untuk ketiga permintaan sekarang fraksional pada akhir periode pemrosesan ketiga: <br><br><img src="https://habrastorage.org/webt/k-/tq/mv/k-tqmvjsqabbv0zgwt_vmkfkhy4.png"><br><br>  Lebih jauh lebih menarik!  Permintaan keempat ditambahkan, dan sekarang tingkat Concurrency sudah 4, karena keempat permintaan membutuhkan sumber daya dalam periode ini.  Sementara itu, permintaan pertama pada akhir periode keempat telah selesai, tidak masuk ke periode berikutnya, dan masih ada 0 pekerjaan tersisa untuk CPU. <br><br>  Karena permintaan pertama telah selesai, mari kita simpulkan untuknya: permintaan itu berjalan sepertiga lebih lama dari yang kami harapkan.  Diasumsikan bahwa panjang setiap tugas secara horizontal idealnya = 3, sesuai dengan jumlah pekerjaan.  Kami menandainya dengan oranye, sebagai tanda bahwa kami tidak sepenuhnya puas dengan hasilnya. <br><br><img src="https://habrastorage.org/webt/ap/9n/uy/ap9nuyfqun_gd1ggeidqdlomxuy.png"><br><br>  Permintaan kelima tiba.  Tingkat Concurrency masih 4, tetapi kita melihat bahwa di kolom kelima pekerjaan yang tersisa lebih total.  Ini karena ada lebih banyak pekerjaan yang tersisa di kolom keempat daripada di kolom ketiga. <br><br>  Kami melanjutkan tiga periode lagi.  Menunggu jawaban. <br>  - Server, halo! <br>  - ... <br><br><img src="https://habrastorage.org/webt/tv/2m/8r/tv2m8r8selzumgub75zkvs78deu.png"><br><br>  "Teleponmu sangat penting bagi kami ..." <br><br><img src="https://habrastorage.org/webt/ud/k9/rk/udk9rk7ynqduovmhyymp7shqe0q.png"><br><br>  Nah, akhirnya datang jawaban untuk permintaan kedua.  Waktu respons dua kali lebih lama dari yang diharapkan. <br><br><img src="https://habrastorage.org/webt/tt/7m/iv/tt7mivq-stfincjhlwxm7wqznsq.png"><br><br>  Tingkat Concurrency sudah tiga kali lipat, dan tidak ada yang menandakan bahwa situasinya akan berubah menjadi lebih baik.  Saya tidak menggambar lebih jauh, karena waktu respons terhadap permintaan ketiga tidak lagi sesuai dengan gambar. <br><br><blockquote>  Server kami telah memasuki kondisi yang tidak diinginkan, dari mana ia tidak akan pernah keluar dengan sendirinya.  <b>Game usai</b> </blockquote><br><h2>  Apa yang mencirikan status GameOver di server? </h2><br>  Permintaan diakumulasikan dalam memori tanpa batas.  Cepat atau lambat, ingatan akan berakhir begitu saja.  Selain itu, dengan peningkatan skala, overhead CPU untuk melayani berbagai struktur data meningkat.  Misalnya, kumpulan koneksi sekarang harus melacak timeout untuk lebih banyak koneksi, pengumpul sampah sekarang harus memeriksa ulang lebih banyak objek di heap, dan sebagainya. <br><br>  Menjelajahi semua konsekuensi yang mungkin terjadi dari akumulasi objek aktif bukanlah tujuan dari artikel ini, tetapi bahkan akumulasi sederhana data dalam RAM sudah cukup untuk mengisi server.  Selain itu, kita telah melihat bahwa server klien memproyeksikan masalah Concurrency ke server database, dan server lain yang digunakan sebagai klien. <br><br>  Hal yang paling menarik: sekarang bahkan jika Anda mengirimkan beban yang lebih rendah ke server, itu masih tidak akan pulih.  Semua permintaan akan berakhir dengan batas waktu, dan server akan menggunakan semua sumber daya yang tersedia. <br><br>  Dan apa yang sebenarnya kita harapkan ?!  Bagaimanapun, kami dengan sadar memberi server sejumlah pekerjaan yang tidak bisa ditangani. <br><br>  Ketika berhadapan dengan arsitektur sistem terdistribusi, ada baiknya memikirkan bagaimana orang-orang biasa memecahkan masalah seperti itu.  Ambil contoh, klub malam.  Ini akan berhenti berfungsi jika terlalu banyak orang memasukinya.  Penjaga itu mengatasi masalah itu dengan sederhana: terlihat berapa banyak orang di dalamnya.  Satu kiri - meluncurkan yang lain.  Seorang tamu baru akan datang dan menghargai ukuran antriannya.  Jika garis panjang, dia akan pulang.  Bagaimana jika Anda menerapkan algoritma ini ke server? <br><br><img src="https://habrastorage.org/webt/wg/tn/p3/wgtnp3n6qq57dqzfi-ac9s0rj1u.png"><br><br>  Ayo main lagi. <br><br><h4>  Game nomor 2 </h4><br>  <b>Prasyarat</b> : Sekali lagi kami memiliki dua CPU, tugas yang sama dari 3 unit, tiba di setiap periode, tetapi sekarang kami akan mengatur bouncer, dan tugas akan menjadi pintar - jika mereka melihat bahwa antriannya adalah 2, maka mereka langsung pulang. <br><br><img src="https://habrastorage.org/webt/b4/cs/gt/b4csgtkcmi3hw1qog4fko6aus2o.png"><br><br><img src="https://habrastorage.org/webt/uw/gi/-v/uwgi-vopihzere8fs_c5f5yctfo.png"><br><br>  Permintaan ketiga datang.  Pada periode ini ia berdiri dalam barisan.  Dia memiliki angka 3 di akhir periode.  Tidak ada angka fraksional dalam residu, karena dua CPU melakukan dua tugas, satu untuk suatu periode. <br><br>  Meskipun kami memiliki tiga lapisan permintaan, tingkat Concurrency di dalam sistem = 2. Yang ketiga ada dalam antrian dan tidak masuk hitungan. <br><br><img src="https://habrastorage.org/webt/nm/x4/yw/nmx4ywd6xdqyte5b6vkwgco3hdq.png"><br><br>  Yang keempat datang - gambar yang sama, meskipun lebih banyak pekerjaan telah diakumulasikan. <br><br><img src="https://habrastorage.org/webt/uq/jb/_5/uqjb_5b8whjwjzzetwqwrzjusfy.png"><br>  ... <br>  ... <br><br>  Pada periode keenam, permintaan ketiga selesai dengan lag ketiga, dan tingkat Concurrency sudah = 4. <br><br><img src="https://habrastorage.org/webt/xs/i1/sf/xsi1sf60jniqqbamvlko-bmd_xa.png"><br><br>  Tingkat konkurensi meningkat dua kali lipat.  Dia tidak bisa tumbuh lagi, karena kami telah menetapkan larangan yang jelas tentang ini.  Dengan kecepatan maksimum, hanya dua permintaan pertama yang diselesaikan - mereka yang datang ke klub terlebih dahulu, sementara ada ruang yang cukup untuk semua orang. <br><br>  Permintaan kuning ada di sistem lebih lama, tetapi mereka berdiri dalam antrean dan tidak menunda sumber daya CPU.  Karena itu, mereka yang berada di dalam bersenang-senang.  Ini bisa berlanjut sampai seorang pria datang dan berkata bahwa dia tidak akan mengantri, tetapi dia akan pulang.  Ini adalah permintaan yang gagal: <br><br><img src="https://habrastorage.org/webt/tf/qf/qr/tfqfqrsfqvhxphy3wzrdqf_cpvk.png"><br><br>  Situasi dapat diulang tanpa akhir, sementara waktu eksekusi kueri tetap pada tingkat yang sama - tepat dua kali selama yang kita inginkan. <br><br><img src="https://habrastorage.org/webt/xh/l2/8-/xhl28-uoe_jao9hjppy5zc30in8.png"><br><br>  Kami melihat bahwa pembatasan sederhana pada level Concurrency menghilangkan masalah viabilitas server. <br><br><h4>  Cara Meningkatkan Viabilitas Server Melalui Batas Level Concurrency </h4><br>  Anda dapat menulis sendiri "tukang pukul" paling sederhana.  Di bawah ini adalah kode yang menggunakan semaphore.  Tidak ada batasan untuk panjang garis di luar.    ,    . <br><br><pre><code class="swift hljs">const int <span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span> = <span class="hljs-number"><span class="hljs-number">100</span></span>; <span class="hljs-type"><span class="hljs-type">SemaphoreSlim</span></span> bulkhead = new <span class="hljs-type"><span class="hljs-type">SemaphoreSlim</span></span>(<span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span>, <span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> async <span class="hljs-type"><span class="hljs-type">Task</span></span> <span class="hljs-type"><span class="hljs-type">ProcessRequest</span></span>() { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!await bulkhead.<span class="hljs-type"><span class="hljs-type">WaitAsync</span></span>()) { <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> new <span class="hljs-type"><span class="hljs-type">OperationCanceledException</span></span>(); } <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { await <span class="hljs-type"><span class="hljs-type">ProcessRequestInternal</span></span>(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } finally { bulkhead.<span class="hljs-type"><span class="hljs-type">Release</span></span>(); } }</code> </pre> <br>  Untuk membuat antrian terbatas, Anda perlu dua semafor.  Untuk ini, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perpustakaan Polly</a> , yang direkomendasikan Microsoft, cocok.  Perhatikan pola Sekat.  Diterjemahkan secara harfiah sebagai "sekat" - elemen struktural yang memungkinkan kapal tidak tenggelam.  Sejujurnya, saya pikir istilah bouncer lebih cocok.  Yang penting adalah bahwa pola ini memungkinkan server untuk bertahan dalam situasi tanpa harapan. <br><br>  Pertama, kami memeras segala yang mungkin pada bangku beban dari server sampai kami menentukan berapa banyak permintaan yang dapat ditampungnya.  Misalnya, kami menentukan bahwa itu 100. Kami menempatkan sekat. <br><br>  Selanjutnya, server hanya akan melewatkan jumlah permintaan yang diperlukan, sisanya akan mengantri.  Akan bijaksana untuk memilih nomor yang sedikit lebih kecil sehingga ada margin.  Saya tidak punya rekomendasi siap pakai mengenai hal ini, karena ada ketergantungan yang kuat pada konteks dan situasi khusus. <br><br><ol><li>  Jika perilaku server secara stabil tergantung pada beban dalam hal sumber daya, maka angka ini dapat mendekati batas. </li><li>  Jika medium mengalami fluktuasi beban, jumlah yang lebih konservatif harus dipilih, dengan mempertimbangkan ukuran fluktuasi ini.  Fluktuasi seperti itu dapat terjadi karena berbagai alasan, misalnya, lingkungan kinerja dengan GC ditandai dengan puncak kecil beban pada CPU. </li><li>  Jika server melakukan tugas-tugas berkala sesuai jadwal, ini juga harus dipertimbangkan.  Anda bahkan dapat mengembangkan sekat adaptif yang akan menghitung berapa banyak kueri yang dapat dikirim secara bersamaan tanpa degradasi server (tetapi ini sudah di luar ruang lingkup penelitian ini). </li></ol><br><h2>  Eksperimen Permintaan </h2><br>  Lihatlah post-mortem ini terakhir, kita tidak akan melihatnya lagi. <br><img src="https://habrastorage.org/webt/n1/qn/1i/n1qn1irfrgm-fezifzonark7j94.png"><br>  Semua tumpukan abu-abu ini jelas berkorelasi dengan server crash.  Gray adalah kematian bagi server.  Mari kita potong saja dan lihat apa yang terjadi.  Tampaknya sejumlah permintaan akan pulang, tidak akan dipenuhi.  Tetapi berapa banyak? <br><br><h4>  100 di dalam, 100 di luar </h4><br><img src="https://habrastorage.org/webt/u0/6c/m5/u06cm5odrt-dxltnomhwatmhwze.png"><br>  Ternyata server kami mulai hidup dengan sangat baik dan menyenangkan.  Dia terus-menerus membajak dengan kekuatan maksimum.  Tentu saja, ketika puncak terjadi, itu menendang keluar, tetapi tidak lama. <br><br>  Terinspirasi oleh kesuksesan, kami akan mencoba memastikan bahwa dia tidak terpental sama sekali.  Mari kita coba tambah panjang antrian. <br><br><h4>  100 di dalam, 500 di luar </h4><br><img src="https://habrastorage.org/webt/sk/5i/gi/sk5igi9cfgyjajp8lujawwunace.png"><br><br>  Itu menjadi lebih baik, tetapi ekornya tumbuh.  Ini adalah permintaan yang dieksekusi untuk waktu yang lama kemudian. <br><br><h4>  100 di dalam, 1000 di luar </h4><br>  Karena sesuatu telah menjadi lebih baik, mari kita coba membawanya ke titik absurditas.  Mari kita selesaikan panjang antrian 10 kali lebih banyak dari yang dapat kami layani secara bersamaan: <br><br><img src="https://habrastorage.org/webt/2g/qd/s6/2gqds68piszleawyid_yk_rtdhg.png"><br><br>  Jika kita berbicara tentang metafora klub dan penjaga, situasi ini hampir tidak mungkin - tidak ada yang mau menunggu lebih lama di pintu masuk daripada menghabiskan waktu di klub.  Kami juga tidak akan berpura-pura bahwa ini adalah situasi normal untuk sistem kami. <br><br>  Lebih baik tidak melayani klien sama sekali daripada menyiksanya di situs atau di aplikasi seluler dengan memuat setiap layar selama 30 detik dan merusak reputasi perusahaan.  Lebih baik segera memberi tahu sebagian kecil pelanggan bahwa sekarang kami tidak bisa melayani mereka.  Jika tidak, kami akan melayani semua pelanggan beberapa kali lebih lambat, karena grafik menunjukkan bahwa situasinya bertahan cukup lama. <br><br>  Ada satu risiko lagi - komponen sistem lain mungkin tidak dirancang untuk perilaku server seperti itu, dan, seperti yang sudah kita ketahui, Concurrency diproyeksikan ke klien. <br><br>  Oleh karena itu, kami kembali ke opsi pertama "100 per 100" dan berpikir tentang cara meningkatkan kapasitas kami. <br><br><h4>  Pemenang - 100 di dalam, 100 di luar </h4><br><img src="https://habrastorage.org/webt/z5/cg/pv/z5cgpvn4qs9abj5ifewfelapa6g.png"><br><br>  ¯ \ _ (ツ) _ / ¯ <br><br>  Dengan parameter ini, degradasi terbesar dalam runtime tepat 2 kali lipat dari "nominal".  Pada saat yang sama, itu adalah degradasi 100% dalam waktu eksekusi permintaan. <br><br>  Jika klien Anda sensitif terhadap runtime (dan ini biasanya benar baik dengan klien manusia dan klien server), maka Anda dapat berpikir tentang lebih jauh mengurangi panjang antrian.  Dalam hal ini, kita dapat mengambil beberapa persentase dari Konkurensi internal, dan kita akan tahu pasti bahwa layanan tidak menurun dalam waktu respons lebih dari rata-rata persentase ini. <br><br>  Faktanya, kami tidak mencoba membuat antrian, kami mencoba melindungi diri dari fluktuasi beban.  Di sini, seperti halnya dalam hal menentukan parameter pertama sekat (kuantitas di dalam), hal ini berguna untuk menentukan fluktuasi apa dalam beban yang mungkin disebabkan klien.  Jadi kita akan tahu dalam hal apa, secara kasar, kita akan kehilangan keuntungan dari layanan potensial. <br><br>  Lebih penting lagi untuk menentukan fluktuasi latensi apa yang dapat menahan komponen sistem lain yang berinteraksi dengan server.  Jadi kita akan tahu bahwa kita benar-benar memeras maksimal dari sistem yang ada tanpa bahaya kehilangan layanan sepenuhnya. <br><br><h2>  Diagnosis dan perawatan </h2><br>  Kami memperlakukan Concurrency yang Tidak Terkendali dengan Isolasi Bulkhead. <br>  Metode ini, seperti yang lain yang dibahas dalam seri artikel ini, mudah diterapkan oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perpustakaan Polly</a> . <br><br>  Keuntungan dari metode ini adalah akan sangat sulit untuk mengacaukan komponen individu dari sistem.  Sistem memperoleh perilaku yang sangat dapat diprediksi dalam hal waktu untuk permintaan yang berhasil dan peluang yang jauh lebih tinggi untuk permintaan lengkap yang berhasil. <br><br>  Namun, kami tidak menyelesaikan semua masalah.  Misalnya, masalah daya server tidak mencukupi.  Dalam situasi ini, Anda harus memutuskan untuk "menjatuhkan pemberat" jika terjadi lompatan muatan, yang kami anggap berlebihan. <br><br>  Langkah-langkah lebih lanjut yang tidak dibahas oleh penelitian kami dapat mencakup, misalnya, penskalaan dinamis. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id461081/">https://habr.com/ru/post/id461081/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id461071/index.html">Optimalisasi permintaan basis data pada contoh layanan B2B untuk pembangun</a></li>
<li><a href="../id461073/index.html">Kami menghubungkan peta online ke navigator di smartphone. Bagian 3 - OverpassTurbo</a></li>
<li><a href="../id461075/index.html">Kecerdasan bisnis. Objek IT, komponen, alat</a></li>
<li><a href="../id461077/index.html">Bagaimana pentester dimasak? Pengujian Pintu Masuk untuk Interns Keamanan Digital</a></li>
<li><a href="../id461079/index.html">Kota tanpa kemacetan lalu lintas</a></li>
<li><a href="../id461083/index.html">Menulis perangkat lunak dengan fungsi utilitas klien-server Windows, bagian 02</a></li>
<li><a href="../id461085/index.html">Beralih bahasa di aplikasi Android</a></li>
<li><a href="../id461087/index.html">Menghasilkan ruang bawah tanah dan gua untuk game saya</a></li>
<li><a href="../id461091/index.html">Lampu Camelion LED</a></li>
<li><a href="../id461093/index.html">Berita dari dunia OpenStreetMap No. 469 (07/09/2019 - 07/07/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
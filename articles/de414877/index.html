<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∏üèø ‚ö∞Ô∏è üêΩ Ein ungew√∂hnliches Objektiv f√ºr eine normale Kamera oder wie man aufh√∂rt, √ºber den Fokus nachzudenken ü§∂üèæ üë®üèø‚Äçüíº üëµüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fast zwei Jahrhunderte der Existenz der Kamera h√§tten den Ingenieuren nicht die M√∂glichkeit geben d√ºrfen, ‚Äûetwas anderes‚Äú hinzuzuf√ºgen. Moderne Kamera...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ein ungew√∂hnliches Objektiv f√ºr eine normale Kamera oder wie man aufh√∂rt, √ºber den Fokus nachzudenken</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414877/">  Fast zwei Jahrhunderte der Existenz der Kamera h√§tten den Ingenieuren nicht die M√∂glichkeit geben d√ºrfen, ‚Äûetwas anderes‚Äú hinzuzuf√ºgen.  Moderne Kameras nehmen qualitativ hochwertige Videos auf, laden Fotos in die Cloud hoch und fangen Geo-Tags ein.  Wir k√∂nnen Panoramen und 360 ¬∞ aufnehmen, die Sterne beobachten und die Zeit verlangsamen.  Aber der Fortschritt steht nicht still, sondern eilt in die Zukunft, angeheizt von forschenden K√∂pfen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cb/co/ue/cbcoueypd1fnm9blmcb3ohpqyeu.png" alt="Bildtest"></div><br>  Die Technologie, die heute diskutiert wird, ist nicht neu.  Aber die Art und Weise, wie es implementiert wird, ist definitiv eine √úberlegung wert.  Es wird ein interessantes Lichtfeldobjektiv sein, das mit jeder DSLR-Kamera verwendet werden kann. <br><a name="habracut"></a><br><h2>  Was ist ein Lichtfeld und womit frisst es? </h2><br>  Der Begriff <i>Lichtfeld</i> selbst wurde bereits 1936 vom sowjetischen Physiker Gershun in seiner Arbeit √ºber die radiometrischen Eigenschaften von Licht vorgeschlagen. <br><br>  Ein Lichtfeld ist eine Vektorfunktion, die Licht beschreibt, das in eine beliebige Richtung durch einen Punkt im Raum f√§llt. <img src="https://habrastorage.org/webt/av/tv/ns/avtvnsfa4n-252jrwzy2cntdf5k.png" alt="Bild" align="right">  Ein Lichtstrahl (oder vielmehr seine Richtung) f√ºr einen bestimmten Punkt im Raum kann durch f√ºnf Parameter (die sogenannte 5D-plenoptische Funktion) beschrieben werden: <i>x-</i> , <i>y-</i> , <i>z-</i> Koordinaten und zwei Winkel <i>Œ∏</i> und <i>œï</i> .  Durch Integration der aus verschiedenen Blickwinkeln erhaltenen Feldvektoren erhalten wir den Gesamtbeleuchtungswert.  Mit einer vollst√§ndigen Beschreibung der Lichtstrahlen im Raum k√∂nnen wir beispielsweise genau bestimmen, wie ein Objekt aus jedem Blickwinkel aussieht. <br><br>  Was ist die praktische Anwendung der Theorie des Lichtfeldes?  Eines der interessantesten Gebiete sind Lichtfeldkameras.  Im Gegensatz zu klassischen Kameras, die die Intensit√§t des Lichts an den Punkten eines Objekts aufzeichnen, ber√ºcksichtigt die Kamera des Lichtfelds auch die Richtung der Strahlen, des Ausgangs und dieser Punkte.  Mit anderen Worten, wir erfassen die ‚Äûindividuellen‚Äú Lichtstrahlen, die vom Objekt ausgehen.  Auf diese Weise k√∂nnen Sie die physischen Koordinaten von Objekten im Raum und eine Tiefenkarte abrufen. <br><br><h2>  Wie sind Lichtfeldkameras angeordnet? </h2><br>  Wir wissen bereits, dass eine Kamera dieses Typs nicht nur die Intensit√§t, sondern auch die Richtung der vom Objekt ausgehenden Lichtstrahlen aufzeichnen sollte.  Eine M√∂glichkeit, dies zu implementieren, besteht darin, eine Anordnung von Linsen vor dem optischen Sensor zu verwenden.  Diese Linsen sammeln Lichtstrahlen von einem Objekt in einem bestimmten Teil der Szene und fokussieren sie auf den Sensor. <br><br>  Es ist wichtig zu verstehen, dass in diesem Fall die Hauptlinse der Linse das Bild nicht mehr auf den Sensor fokussiert.  Stattdessen werden die Strahlen auf die Ebene des Linsenarrays projiziert (bei klassischen Kameras befindet sich der Sensor genau in dieser Ebene), das Linsenarray passiert und f√§llt erst dann auf den Sensor, wodurch ein Mosaikbild verschiedener Teile der Szene entsteht. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qf/gl/5i/qfgl5i2miblhvrhz_ge49lqfrnq.png" alt="Bild"></div><br>  Die Abbildung zeigt ein vereinfachtes Diagramm des Betriebs einer solchen Linse.  Dank der ausgekl√ºgelten Organisation des optischen Systems erhalten wir am Ende nicht nur ein, sondern viele Bilder des Objekts, und jedes dieser Bilder erzeugt eine einzigartige Darstellung des Objekts aus seinem einzigartigen Blickwinkel. <br><br>  Dieses Schema weist jedoch eine Reihe von Nachteilen auf, wie beispielsweise die hohen Herstellungskosten, die Komplexit√§t der Kalibrierung, die Apertursteuerung und andere Systemparameter.  Eines der bekanntesten Beispiele f√ºr solche Kameras ist das Produkt von Lytro - die Lytro Illum-Kamera (das Projekt scheint eingefroren zu sein). <br><br><h2>  Kannst du es einfacher machen? </h2><br>  Du kannst.  Das Objektiv, √ºber das ich in diesem Artikel sprechen m√∂chte, enth√§lt keine Reihe von Mikrolinsen.  Stattdessen wird ein System verwendet, bei dem es sich um einen Spiegelkanal mit rechteckigem Querschnitt (Spiegelbox) handelt, bei dem dank Mehrfachreflexion ein sogenanntes kaleidoskopisches Bild entsteht, das vom Kamerasensor auf √ºbliche Weise aufgezeichnet wird. <br><br><img src="https://habrastorage.org/webt/jp/gt/dh/jpgtdhotrubcdjqctkx1ypxtxv8.png" alt="Bild"><br><br>  Ein kleines deutsches Unternehmen entwickelt sich.  Das Objektiv befindet sich im Stadium eines voll funktionsf√§higen Prototyps, und das Prinzip seiner Funktionsweise ist recht einfach. <br><br>  Die vom System erhaltenen Bilder sehen ungef√§hr so ‚Äã‚Äãaus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bc/0z/u9/bc0zu9ojlfgakmjvfyu2ed6j6og.png" alt="Bild"></div><br>  Elemente hier werden gespiegelt.  Ein solches ungew√∂hnliches kaleidoskopisches Bild ist eine Folge der Reflexion von Strahlen im ‚ÄûSpiegelkanal‚Äú. <br><br>  Und so sieht der absolute Unterschied des Paares wiederhergestellter Elemente aus (helle Pixel bedeuten einen gr√∂√üeren Wertunterschied): <br><br><img src="https://habrastorage.org/webt/e1/t5/po/e1t5poethhxhqe9f2i8xmplliys.png" alt="Bild"><br><br>  Mit anderen Worten, wir haben nichts als ein Stereopaar.  Oder besser gesagt, Stereo 9 (3x3 Elemente).  Wenn wir die geometrischen Parameter des Kanals √§ndern, k√∂nnen wir 5x5 und sogar gro√üe Dimensionen erhalten, was jedoch im wirklichen Leben keinen Sinn macht und sogar schadet. <br><br>  Wir haben also eine Reihe von Bildern, die ein kaleidoskopisches Bild bilden.  Was kommt als n√§chstes? <br><br>  Hier endet die warme analoge optische Hardware und die kalte digitale Software beginnt. <br><br><h2>  Kalibrierung </h2><br>  Unabh√§ngig von der Anwendung m√ºssen die Bilder wiederhergestellt werden (Sie m√ºssen das gesamte optische System kalibrieren und die erhaltenen Kalibrierungsdaten auf die Bilder anwenden).  Der Prozess ist ziemlich langwierig, aber wichtig, da die verschiedenen Elemente des kaleidoskopischen Bildes unbedingt miteinander ‚Äûkoordiniert‚Äú werden m√ºssen (selbst unbedeutende / mehrere Pixel / Abweichungen der Elemente k√∂nnen das Ergebnis und den Eindruck stark beeintr√§chtigen).  Es gibt viele Arbeiten zum Thema Kalibrierung, daher macht es keinen Sinn, Details preiszugeben.  Sie m√ºssen sich nur daran erinnern, dass die Kalibrierung f√ºr jede Stereoanwendung sehr wichtig ist. <br><br><h2>  Tiefenkarte </h2><br>  Nachdem wir ‚Äûgerade‚Äú Bilder erhalten haben, k√∂nnen wir eine Tiefenkarte erstellen. <br>  Dies ist vielleicht der wichtigste und schwierigste Teil der Pipeline.  Die Qualit√§t der endg√ºltigen Anwendung h√§ngt von der Qualit√§t der Tiefenkarte ab.  Und die Qualit√§t der Tiefenkarte h√§ngt wiederum von der Qualit√§t der Kalibrierung, dem ausgew√§hlten Algorithmus und der "Komplexit√§t" der Szene ab. <br><br>  Unabh√§ngig vom Algorithmus ist die Aufgabe jedoch immer dieselbe - die entsprechenden Punkte der linken und rechten Bilder (und in unserem Fall + 7 weitere Bilder) zu finden und den Abstand (Disparit√§t) zwischen ihnen zu berechnen.  Der Abstandswert ist der Kehrwert des Tiefenwerts f√ºr ein bestimmtes Pixel. <br><br>  Warum 9 Bilder verwenden, wenn Sie mit zwei auskommen k√∂nnen?  Wenn wir mehr Bilder verwenden, haben wir offensichtlich mehr Informationen √ºber die Szene und k√∂nnen einige Probleme bestehender Algorithmen zur Sch√§tzung der Tiefenkarte teilweise l√∂sen. <br><br>  Zu den klassischen Problemen solcher Algorithmen geh√∂ren: <br><br><ul><li>  Eint√∂nige, einfarbige Oberfl√§chen ohne Textur - der Algorithmus hat beim Auffinden von √úbereinstimmungen einfach nichts zu ‚Äûfangen‚Äú </li><li>  √úberlappende Objekte (sichtbar von einer Ecke und unsichtbar von einer anderen) </li><li>  Schatten und Reflexionen auf verspiegelten oder gl√§nzenden Oberfl√§chen </li><li>  Regelm√§√üige Strukturen wie Zellen und Streifen stellen Probleme dar, da nicht immer klar ist, welche Zelle von Bild A der Zelle von Bild B entspricht. </li><li>  Rahmen von Bildern - ein Problem √§hnlich dem Problem √ºberlappender Objekte.  An den Bildr√§ndern gehen Informationen aus jedem Blickwinkel unweigerlich verloren. </li></ul><br>  Es gibt viele hochwertige und nicht sehr Algorithmen zum Erstellen einer Tiefenkarte.  Die vielversprechendsten Entwicklungen liegen nun im Bereich hybrider Ans√§tze mit klassischen Methoden und verschiedenen Techniken des maschinellen Lernens (CNN, DNN).  Wie immer ist die Wahl des Algorithmus ein Kompromiss zwischen Geschwindigkeit und Qualit√§t.  Gl√ºcklicherweise k√∂nnen wir es uns in der Fotografie leisten, von der Echtzeit zur√ºckzutreten und eine bessere Tiefenkarte zu erhalten. <br><br>  In unserem Beispiel sieht die Tiefenkarte ungef√§hr so ‚Äã‚Äãaus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/a5/p2/lka5p2k7vkqazvlzads_pqai9y4.png" alt="Bild"></div><br><br><h2>  Post Fokus </h2><br>  Wir haben eine Karte der Tiefen, was machen wir jetzt damit?  Informationen √ºber die Entfernung von Objekten sind oft n√ºtzlich.  Eine beliebte Anwendung ist Post Focus. <br><br>  Unscharf zu werden ist eines der Probleme von Fotografen.  Haben Sie bemerkt, dass im Originalbild die gesamte Szene scharfgestellt war?  So sieht die Nachfokussierung basierend auf einer Tiefenkarte aus: <br><br><img src="https://habrastorage.org/webt/5q/qy/dp/5qqydpw85mv-p_b0hzock0cqi20.png" alt="Bild"><br><br>  Es sollte beachtet werden, dass wir mit diesem Ansatz tats√§chlich die physikalischen Eigenschaften des optischen Systems beseitigen.  Dies erm√∂glicht es beispielsweise, ein Bild mit mehreren Tricks algorithmisch zu erstellen.  Oder √§ndern Sie programmgesteuert die Tiefe eines scharf dargestellten Raums (Sch√§rfentiefe). <br><br><h2>  Andere Anwendungen </h2><br>  Nachfokussierung ist die Hauptanwendung, aber immer noch nicht die einzige.  Im Allgemeinen kann dieses Objektiv als Array virtueller Kameras (9 St√ºck) betrachtet werden.  Dementsprechend gilt es f√ºr alle Anwendungen, die Sie sich f√ºr eine Reihe von Kameras vorstellen k√∂nnen, zum Beispiel: <br><br><ul><li>  Polarisationsfilter - Jedes der 9 Bildelemente verf√ºgt √ºber ein eigenes Polarisationsfilter mit einer bestimmten Richtung.  Auf diese Weise k√∂nnen Sie 9 Bilder mit unterschiedlichen Polarisationen auf einmal erhalten und sogar eine Videoserie mit einer sanften √Ñnderung der Polarisationsrichtung erstellen </li><li>  HDR (High-Dynamic-Range) - das gleiche Prinzip: 9 verschiedene Filter + Algorithmus f√ºr die optimale "Kombination" der Helligkeit </li><li>  Perspektivenwechsel </li><li>  Tiefenbasierte Bearbeitung - Erm√∂glicht das Anwenden verschiedener Filter auf verschiedene Tiefen.  Stellen Sie beispielsweise den Hintergrund in Schwarzwei√ü ein und markieren Sie den Vordergrund. </li><li>  Segmentierung - Auswahl von Objekten, die sich in einer bestimmten Entfernung befinden </li><li>  Entfernungsmessung - ein Lineal f√ºr Bilder.  Es funktioniert besonders gut f√ºr ‚Äûflache‚Äú Szenen, f√ºr die Disparit√§t leichter zu berechnen ist. </li><li>  Anwendungen f√ºr die Industrie - verschiedene M√∂glichkeiten zur Bewertung der Produktionsqualit√§t und -√ºberwachung </li></ul><br><h2>  Fazit </h2><br>  Die Frage nach den endg√ºltigen Kosten dieses Objektivs ist noch offen, einige physikalische Parameter wurden jedoch bereits ermittelt.  Es ist bekannt, dass die L√§nge 20 cm und die Masse 800 g nicht √ºberschreiten sollte.  Es wird angegeben, dass dieses Ger√§t haupts√§chlich mit Sony-, Canon- und Nikon-Kameras kompatibel sein wird. <br><br>  Au√üerhalb des Artikels blieben so wichtige Themen wie die praktische Verwendung von Standardkameras mit Suchern, die Wiederherstellung der Aufl√∂sung (Superaufl√∂sung), Verarbeitungsalgorithmen und die Integration in Grafikeditoren.  Ich werde das n√§chste Mal dar√ºber sprechen. <br><br>  Danke f√ºr die Aufmerksamkeit! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414877/">https://habr.com/ru/post/de414877/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414867/index.html">ThinkingHome.Migrator - versionierte Migration des Datenbankschemas auf der .NET Core-Plattform</a></li>
<li><a href="../de414869/index.html">Verschwindende Rahmenbedingungen</a></li>
<li><a href="../de414871/index.html">Der Staubsturm auf dem Mars erreichte das planetare Ausma√ü, sogar die Neugier war betroffen</a></li>
<li><a href="../de414873/index.html">IDisposable - dass deine Mutter nicht √ºber die Freigabe von Ressourcen gesprochen hat. Teil 1</a></li>
<li><a href="../de414875/index.html">Kubernetes Containerd-Integration ersetzt Docker f√ºr die Produktion</a></li>
<li><a href="../de414879/index.html">Warum 2 Extruder in einem 3D-Drucker?</a></li>
<li><a href="../de414881/index.html">Ein bisschen Backstage VK</a></li>
<li><a href="../de414883/index.html">Erinnerungen klangen neu: BBC hat das Soundarchiv des RemArc-Projekts aktualisiert</a></li>
<li><a href="../de414885/index.html">Wir besch√§ftigen uns mit Fehlern und ‚ÄûKr√ºcken‚Äú im einheitlichen staatlichen Register der juristischen Personen - dem staatlichen Register der juristischen Personen</a></li>
<li><a href="../de414887/index.html">Erstellen eines Katzenhakens in Unity. Teil 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
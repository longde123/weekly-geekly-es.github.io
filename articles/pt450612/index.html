<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòß üîñ üôçüèø Intro Newton Protocol: o que pode caber em 4 kilobytes ü§úüèº ‚ò¢Ô∏è ‚ò†Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recentemente, competi na cena demo de Revis√£o 2019 na categoria de introdu√ß√£o para PC 4k, e minha introdu√ß√£o ganhou o primeiro lugar. Eu fiz codifica√ß...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Intro Newton Protocol: o que pode caber em 4 kilobytes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450612/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bfa/bba/a35/bfabbaa350d27446b3b058ce41e73228.png" alt="imagem"></div><br>  Recentemente, competi na cena demo de Revis√£o 2019 na categoria de introdu√ß√£o para PC 4k, e minha introdu√ß√£o ganhou o primeiro lugar.  Eu fiz codifica√ß√£o e gr√°ficos, e dixan comp√¥s m√∫sicas.  A regra b√°sica da competi√ß√£o √© criar um arquivo ou site execut√°vel com apenas 4096 bytes de tamanho.  Isso significa que tudo precisa ser gerado usando matem√°tica e algoritmos;  de nenhuma outra maneira posso espremer imagens, v√≠deo e √°udio em uma quantidade t√£o pequena de mem√≥ria.  Neste artigo, falarei sobre o pipeline de renderiza√ß√£o da minha introdu√ß√£o de Newton.  Abaixo voc√™ pode ver o resultado final, ou <a href="">clique aqui</a> para ver como ficou ao vivo na Revis√£o, ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">acesse o pouet</a> para comentar e baixar a introdu√ß√£o que participou da competi√ß√£o.  Voc√™ pode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ler</a> sobre o trabalho e as corre√ß√µes dos concorrentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/iIIu7kPCN-8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  A t√©cnica dos campos de dist√¢ncia da marcha Ray √© muito popular na disciplina de introdu√ß√£o em 4k, pois permite especificar formas complexas em apenas algumas linhas de c√≥digo.  No entanto, a desvantagem dessa abordagem √© a velocidade de execu√ß√£o.  Para renderizar a cena, voc√™ precisa encontrar o ponto de interse√ß√£o dos raios com a cena, primeiro determinar o que v√™, por exemplo, um raio da c√¢mera e, em seguida, os raios subsequentes do objeto para as fontes de luz para calcular a ilumina√ß√£o.  Ao trabalhar com marchas com raios, essas interse√ß√µes n√£o podem ser encontradas em uma √∫nica etapa, voc√™ precisa dar v√°rias pequenas etapas ao longo da viga e avaliar todos os objetos em cada ponto.  Por outro lado, ao usar o tra√ßado de raios, voc√™ pode encontrar a interse√ß√£o exata marcando cada objeto apenas uma vez, mas o conjunto de formas que podem ser usadas √© muito limitado: voc√™ precisa ter uma f√≥rmula para cada tipo para calcular a interse√ß√£o com o raio. <br><br>  Nesta introdu√ß√£o, eu queria simular uma ilumina√ß√£o muito precisa.  Como era necess√°rio refletir milh√µes de raios na cena, o tra√ßado de raios parecia uma escolha l√≥gica para alcan√ßar esse efeito.  Limitei-me a uma √∫nica figura - uma esfera, porque a interse√ß√£o de um raio e uma esfera √© calculada de maneira bastante simples.  At√© as paredes da introdu√ß√£o s√£o na verdade esferas muito grandes.  Al√©m disso, simplificou a simula√ß√£o da f√≠sica;  bastava levar em conta apenas conflitos entre as esferas. <br><br>  Para ilustrar a quantidade de c√≥digo que cabe em 4096 bytes, abaixo apresentei o c√≥digo fonte completo da introdu√ß√£o conclu√≠da.  Todas as partes, exceto o HTML no final, s√£o codificadas como uma imagem PNG para compact√°-las para um tamanho menor.  Sem essa compacta√ß√£o, o c√≥digo levaria quase 8900 bytes.  A parte chamada Synth √© uma vers√£o simplificada do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SoundBox</a> .  Para empacotar o c√≥digo nesse formato minimizado, usei o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Google Closure Compiler</a> e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Shader Minifier</a> .  No final, quase tudo √© compactado em PNG usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">JsExe</a> .  O pipeline de compila√ß√£o completo pode ser visto no c√≥digo-fonte da minha introdu√ß√£o pr√©via de 4k <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Core Critical</a> , porque corresponde completamente ao apresentado aqui. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e5b/274/690/e5b27469046c9c34bfb14fc2fbe33fa5.png"></div><br>  <i>M√∫sica e sintetizador s√£o totalmente implementados em Javascript.</i>  <i>A parte no WebGL √© dividida em duas partes (destacada em verde no c√≥digo);</i>  <i>ela configura o pipeline de renderiza√ß√£o.</i>  <i>Os elementos de f√≠sica e tra√ßador de raios s√£o sombreadores GLSL.</i>  <i>O restante do c√≥digo √© codificado em uma imagem PNG e o HTML √© adicionado ao final da imagem resultante inalterada.</i>  <i>O navegador ignora os dados da imagem e executa apenas o c√≥digo HTML, que por sua vez decodifica PNG em javascript e o executa.</i> <br><br><h3>  Pipeline de renderiza√ß√£o </h3><br>  A imagem abaixo mostra o pipeline de renderiza√ß√£o.  Consiste em duas partes.  A primeira parte do pipeline √© um simulador de f√≠sica.  A cena de introdu√ß√£o cont√©m 50 esferas colidindo umas com as outras dentro da sala.  A sala em si √© composta por seis esferas, algumas das quais menores que outras para criar paredes mais curvas.  Duas fontes verticais de ilumina√ß√£o nos cantos tamb√©m s√£o esferas, ou seja, um total de 58 esferas na cena.  A segunda parte do pipeline √© o tra√ßador de raios, que renderiza a cena.  O diagrama abaixo mostra a renderiza√ß√£o de um quadro no tempo t.  A simula√ß√£o f√≠sica pega o quadro anterior (t-1) e simula o estado atual.  O tra√ßador de raios toma as posi√ß√µes atuais e as do quadro anterior (para o canal de velocidade) e renderiza a cena.  O p√≥s-processamento combina os 5 quadros anteriores e o quadro atual para reduzir a distor√ß√£o e o ru√≠do e, em seguida, cria um resultado final. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f6a/848/ac0/f6a848ac09343ca15abfd03393a7ceeb.png"></div><br>  <i>Renderizando um quadro no momento t.</i> <br><br>  A parte f√≠sica √© bastante simples, na Internet voc√™ encontra muitos tutoriais sobre como criar simula√ß√µes primitivas para esferas.  Posi√ß√£o, raio, velocidade e massa s√£o armazenados em duas texturas com resolu√ß√£o de 1 x 58. Usei a funcionalidade Webgl 2, que permite renderizar v√°rios destinos de renderiza√ß√£o, para que os dados de duas texturas sejam gravados simultaneamente.  A mesma funcionalidade √© usada pelo ray tracer para criar tr√™s texturas.  O Webgl n√£o fornece acesso √†s APIs de rastreamento de raios NVidia RTX ou DirectX Raytracing (DXR), portanto, tudo √© feito do zero. <br><br><h3>  Tra√ßador de raios </h3><br>  O rastreamento de raios em si √© uma t√©cnica bastante primitiva.  N√≥s liberamos um raio na cena, ele √© refletido 4 vezes e, se entrar na fonte de luz, a cor das reflex√µes se acumula;  caso contr√°rio, ficamos pretos.  Em 4096 bytes (que inclui m√∫sica, sintetizador, f√≠sica e renderiza√ß√£o), n√£o h√° espa√ßo para a cria√ß√£o de estruturas complexas de rastreamento de raios em acelera√ß√£o.  Portanto, usamos o m√©todo de pesquisa aproximada, ou seja, verificamos todas as 57 esferas (a parede frontal √© exclu√≠da) para cada raio, sem fazer nenhuma otimiza√ß√£o para excluir parte das esferas.  Isso significa que, para fornecer 60 quadros por segundo em resolu√ß√£o 1080p, voc√™ pode emitir apenas 2-6 raios ou amostras por pixel.  Est√° perto o suficiente para criar uma ilumina√ß√£o suave. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b23/2ce/72d/b232ce72d49f57a69b96d402ec0bb148.png"></div><br>  <i>1 amostra por pixel.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e52/77d/19e/e5277d19e5a7b897b8dd9046eaae6f26.png"></div><br>  <i>6 amostras por pixel.</i> <br><br>  Como lidar com isso?  Inicialmente, investiguei o algoritmo de rastreamento de raios, mas ele j√° estava simplificado ao ponto.  Consegui aumentar levemente o desempenho eliminando os casos em que o raio come√ßa dentro da esfera, porque esses casos s√£o aplic√°veis ‚Äã‚Äãapenas na presen√ßa de efeitos de transpar√™ncia e apenas objetos opacos estavam presentes em nossa cena.  Depois disso, combinei cada condi√ß√£o if em uma instru√ß√£o separada para evitar ramifica√ß√µes desnecess√°rias: apesar dos c√°lculos "redundantes", essa abordagem ainda √© mais r√°pida do que v√°rias instru√ß√µes condicionais.  Voc√™ tamb√©m pode melhorar o padr√£o de amostragem: em vez de emitir raios aleatoriamente, podemos distribu√≠-los pela cena em um padr√£o mais uniforme.  Infelizmente, isso n√£o ajudou e levou a artefatos ondulados em todos os algoritmos que tentei.  No entanto, essa abordagem criou bons resultados para imagens est√°ticas.  Como resultado, voltei a usar uma distribui√ß√£o completamente aleat√≥ria. <br><br>  Os pixels vizinhos devem ter ilumina√ß√£o muito semelhante. Por que n√£o us√°-los no c√°lculo da ilumina√ß√£o de um √∫nico pixel?  N√£o queremos desfocar texturas, apenas ilumina√ß√£o, por isso precisamos renderiz√°-las em canais separados.  Al√©m disso, n√£o queremos desfocar objetos, portanto, precisamos considerar os identificadores dos objetos para saber quais pixels podem ser desfocados facilmente.  Como temos objetos refletores de luz e precisamos de reflexos claros, n√£o basta descobrir o ID do primeiro objeto com o qual o feixe colide.  Usei um caso especial para materiais refletivos puros para incluir tamb√©m os IDs do primeiro e do segundo objetos vis√≠veis nas reflex√µes no canal identificador do objeto.  Nesse caso, o desfoque pode suavizar a ilumina√ß√£o dos objetos nas reflex√µes, mantendo ao mesmo tempo os limites dos objetos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f69/a24/a6b/f69a24a6b9094903309af27b5606e923.png"></div><br>  <i>Canal de textura, n√£o precisamos desfoc√°-lo.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a4f/c4a/7f6/a4fc4a7f6ec4fa0552542edf7204cb58.png"></div><br>  <i>Aqui no canal vermelho cont√©m o ID do primeiro objeto, em verde - o segundo e em azul - o terceiro.</i>  <i>Na pr√°tica, todos eles s√£o codificados em um √∫nico valor do formato float, no qual a parte inteira armazena os identificadores de objetos, e a parte fracion√°ria indica rugosidade: 332211.RR.</i> <br><br>  Como existem objetos com rugosidade diferente na cena (algumas √°reas s√£o rugosas, a luz √© espalhada em outras, na terceira h√° um reflexo no espelho), guardo a rugosidade para controlar o raio do borr√£o.  Como n√£o h√° pequenos detalhes na cena, usei um n√∫cleo grande de 50 x 50 com os pesos na forma de quadrados inversos para desfocar.  Ele n√£o leva em considera√ß√£o o espa√ßo do mundo (isso pode ser realizado para obter resultados mais precisos), porque em superf√≠cies localizadas em √¢ngulo em algumas dire√ß√µes, corroe uma √°rea maior.  Esse emba√ßamento cria uma imagem bastante suave, mas os artefatos s√£o claramente vis√≠veis, especialmente em movimento. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ca6/553/f9d/ca6553f9d61bc8f7dda51ba41c2cbf28.png"></div><br>  <i>Canal de ilumina√ß√£o com desfoque e artefatos ainda vis√≠veis.</i>  <i>Nesta imagem, pontos emba√ßados na parede traseira s√£o vis√≠veis, causados ‚Äã‚Äãpor um pequeno erro com os identificadores do segundo objeto refletido (os raios deixam a cena).</i>  <i>Na imagem final, isso n√£o √© muito percept√≠vel, porque reflex√µes claras s√£o obtidas do canal de textura.</i>  <i>As fontes de ilumina√ß√£o tamb√©m ficam emba√ßadas, mas eu gostei desse efeito e o deixei.</i>  <i>Se desejado, isso pode ser evitado alterando os identificadores de objetos, dependendo do material.</i> <br><br>  Quando objetos est√£o em cena e a c√¢mera que filma a cena se move lentamente, a ilumina√ß√£o em cada quadro deve permanecer constante.  Portanto, podemos executar o desfoque n√£o apenas nas coordenadas XY da tela;  n√≥s podemos desfocar no tempo.  Se assumirmos que a ilumina√ß√£o n√£o muda muito em 100 ms, podemos calcul√°-la em m√©dia para 6 quadros.  Mas durante essa janela de tempo, os objetos e a c√¢mera ainda ir√£o se distanciar; portanto, um simples c√°lculo da m√©dia de 6 quadros criar√° uma imagem muito emba√ßada.  No entanto, sabemos onde estavam todos os objetos e a c√¢mera no mapa anterior, para que possamos calcular os vetores de velocidade no espa√ßo da tela.  Isso √© chamado de reproje√ß√£o tempor√°ria.  Se eu tiver um pixel no tempo t, posso calcular a velocidade desse pixel e calcular onde estava no tempo t-1, e depois calcular onde o pixel no tempo t-1 est√° no tempo t-2 e assim por diante. 5 quadros de volta.  Ao contr√°rio do desfoque no espa√ßo da tela, usei o mesmo peso para cada quadro, ou seja,  apenas calculou a m√©dia da cor entre todos os quadros para um "desfoque" tempor√°rio. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1fc/a4c/e42/1fca4ce4250f372223862a34472add21.png"></div><br>  <i>Um canal de velocidade de pixel que informa onde o pixel estava no √∫ltimo quadro com base no movimento do objeto e da c√¢mera.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/011/bb5/1f6/011bb51f60e3b3066c87ee4a1d46d403.png"></div><br>  <i>Para evitar o desfoque conjunto de objetos, usaremos novamente o canal de identificadores de objetos.</i>  <i>Nesse caso, consideramos apenas o primeiro objeto com o qual o feixe colidiu.</i>  <i>Isso fornece anti-aliasing dentro do objeto, ou seja,</i>  <i>em reflex√µes.</i> <br><br>  Obviamente, o pixel pode n√£o ter sido vis√≠vel no quadro anterior;  pode estar oculto por outro objeto ou estar fora do campo de vis√£o da c√¢mera.  Nesses casos, n√£o podemos usar as informa√ß√µes anteriores.  Essa verifica√ß√£o √© realizada separadamente para cada quadro, portanto, obtemos de 1 a 6 amostras ou quadros por pixel e usamos os poss√≠veis.  A figura abaixo mostra que para objetos lentos isso n√£o √© um problema muito s√©rio. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c5b/c89/8fc/c5bc898fc8ac6ff9b5a0c8685312604f.png"></div><br>  <i>Quando os objetos se movem e abrem novas partes da cena, n√£o temos 6 quadros de informa√ß√µes para calcul√°-lo como m√©dia para essas partes.</i>  <i>Esta imagem mostra √°reas que possuem 6 quadros (branco), bem como aquelas que n√£o os possuem (tons gradualmente escurecendo).</i>  <i>A apar√™ncia dos contornos √© causada pela randomiza√ß√£o dos locais de amostragem do pixel em cada quadro e pelo fato de pegarmos o identificador do objeto da primeira amostra.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/570/c4c/b4a/570c4cb4a84f008a497678b0b735930e.png"></div><br>  <i>A ilumina√ß√£o borrada tem uma m√©dia de seis quadros.</i>  <i>Os artefatos s√£o quase invis√≠veis e o resultado √© est√°vel ao longo do tempo, porque em cada quadro apenas um quadro em cada seis mudan√ßas em que a ilumina√ß√£o √© levada em considera√ß√£o.</i> <br><br>  Combinando tudo isso, obtemos uma imagem finalizada.  A ilumina√ß√£o √© desfocada para os pixels vizinhos, enquanto as texturas e os reflexos permanecem claros.  Em m√©dia, tudo isso √© calculado entre seis quadros para criar uma imagem ainda mais suave e mais est√°vel ao longo do tempo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bfa/bba/a35/bfabbaa350d27446b3b058ce41e73228.png"></div><br>  <i>A imagem finalizada.</i> <br><br>  Os artefatos de amortecimento ainda s√£o percept√≠veis, porque calculei a m√©dia de v√°rias amostras por pixel, embora eu tenha escolhido o canal do identificador de objeto e a velocidade para a primeira interse√ß√£o.  Voc√™ pode tentar corrigir isso e suavizar as reflex√µes descartando as amostras se elas n√£o coincidirem com a primeira, ou pelo menos se a primeira colis√£o n√£o coincidir em ordem.  Na pr√°tica, os tra√ßos s√£o quase invis√≠veis, ent√£o n√£o me preocupei em elimin√°-los.  Os limites dos objetos tamb√©m s√£o distorcidos, porque os canais de velocidade e identificadores de objetos n√£o podem ser suavizados.  Eu estava considerando a possibilidade de renderizar a imagem inteira em 2160p, com uma redu√ß√£o adicional na escala para 1080p, mas minha NVidia GTX 980ti n√£o √© capaz de processar essas resolu√ß√µes a 60fps, ent√£o decidi abandonar essa id√©ia. <br><br>  Em geral, estou muito satisfeito com o resultado da introdu√ß√£o.  Consegui juntar tudo o que tinha em mente e, apesar de pequenos bugs, o resultado final foi de alta qualidade.  No futuro, voc√™ pode tentar corrigir bugs e melhorar o anti-aliasing.  Tamb√©m vale a pena experimentar recursos como transpar√™ncia, desfoque de movimento, v√°rias formas e transforma√ß√µes de objetos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ba9/f56/e02/ba9f56e02c13d046f73e888540a0d75e.png"></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt450612/">https://habr.com/ru/post/pt450612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt450602/index.html">‚ÄúComo constru√≠mos IaaS‚Äù: materiais 1cloud</a></li>
<li><a href="../pt450604/index.html">Selecionando bilh√µes de n√∫meros simples mais rapidamente que a Wikipedia</a></li>
<li><a href="../pt450606/index.html">Um dia na vida de um modelo de restaurante</a></li>
<li><a href="../pt450608/index.html">Fodendo entre n√≥s</a></li>
<li><a href="../pt450610/index.html">Termoac√∫stica. Gerando eletricidade a partir do som usando um alto-falante</a></li>
<li><a href="../pt450614/index.html">Abril 2019 Joomla Digest</a></li>
<li><a href="../pt450618/index.html">Por que, de acordo com as estat√≠sticas do Yandex e StackOverfow C #, os programadores s√£o os mais baratos?</a></li>
<li><a href="../pt450620/index.html">Enigma de um neutrino de Supernova 1987A</a></li>
<li><a href="../pt450624/index.html">Sauda√ß√£o de Hayabusa-2</a></li>
<li><a href="../pt450626/index.html">Corrigir padr√£o de design - Singleton em PHP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
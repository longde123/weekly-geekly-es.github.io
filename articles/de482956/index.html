<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üññüèº üê® üåõ √úberpr√ºfung von WCS 5.2 - WebRTC Server f√ºr Webcast- und Webcam-Entwickler ü§æüèª üë© üîù</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Alice ist eine erfahrene Full-Stack-Entwicklerin, die in der Lage ist, in einer Woche ein SAAS-Projektframework auf ihrem Lieblingsframework mit PHP z...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√úberpr√ºfung von WCS 5.2 - WebRTC Server f√ºr Webcast- und Webcam-Entwickler</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flashphoner/blog/482956/"><img src="https://habrastorage.org/webt/za/go/wo/zagowolkguxr8_bdsbwjmkvyd0a.jpeg"><br><br><p>  Alice ist eine erfahrene Full-Stack-Entwicklerin, die in der Lage ist, in einer Woche ein SAAS-Projektframework auf ihrem Lieblingsframework mit PHP zu schreiben.  Bez√ºglich des Frontends bevorzugt sie Vue.js. </p><br><p>  Ein Kunde kontaktiert Sie per Telegramm und bittet Sie, eine Website zu entwickeln, auf der sich Arbeitgeber und Arbeitnehmer treffen, um ein pers√∂nliches Interview zu f√ºhren.  Pers√∂nlich bedeutet Face-to-Face, ein direkter Videokontakt in Echtzeit mit Video und Sprache.  "Warum nicht Skype benutzen?", M√∂gen einige fragen.  Zuf√§llig versuchen seri√∂se Projekte - und jedes Startup versteht sich zweifellos als seri√∂ses Projekt - aus verschiedenen Gr√ºnden, einen internen Kommunikationsdienst anzubieten, darunter: </p><a name="habracut"></a><br><p>  1) Sie m√∂chten ihre Benutzer nicht an Kommunikationspartner von Drittanbietern (Skype, Hangouts usw.) verleihen und sie im Dienst behalten. </p><br><p>  2) Sie m√∂chten ihre Kommunikation √ºberwachen, z. B. Anrufverlauf und Interviewergebnisse. </p><br><p>  3) Anrufe aufzeichnen (nat√ºrlich beide Parteien √ºber die Aufzeichnung benachrichtigen). </p><br><p> 4) Sie m√∂chten nicht auf Richtlinien und Aktualisierungen von Diensten Dritter angewiesen sein.  Jeder kennt diese Geschichte: Skype wurde aktualisiert und alles geht in Rauch auf ... </p><br><p>  Es scheint eine leichte Aufgabe zu sein.  WebRTC taucht auf, wenn Sie √ºber das Thema googeln, und es scheint, als k√∂nnten Sie eine Peer-to-Peer-Verbindung zwischen zwei Browsern einrichten, aber es gibt noch einige Fragen: </p><br><p>  1) Woher bekomme ich STUN / TURN Server? </p><br><p>  2) K√∂nnen wir ohne sie auskommen? </p><br><p>  3) Wie zeichnet man einen Peer-to-Peer-WebRTC-Anruf auf? </p><br><p>  4) Was passiert, wenn wir dem Anruf einen Dritten hinzuf√ºgen m√ºssen, z. B. einen Personalleiter oder einen anderen Spezialisten des Arbeitgebers? </p><br><p>  Es stellt sich heraus, dass WebRTC und Peer-to-Peer allein nicht ausreichen, und es ist nicht klar, was mit all dem zu tun ist, um die erforderlichen Videofunktionen des Dienstes zu starten. </p><br><h2>  Artikelinhalt </h2><br><div class="spoiler">  <b class="spoiler_title">Inhalt</b> <div class="spoiler_text"><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Server und API</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Eingehende Streams</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">WebRTC</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">RTMP</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Rtsp</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Vod</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">SIP / RTP</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Ausgehende Streams</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">WebRTC</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">RTMP</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Rtsp</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">MSE</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Hls</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Ein- und ausgehend</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Eingehende Stream-Manipulation</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Aufzeichnung eingehender Streams</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Einen Schnappschuss machen</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Hinzuf√ºgen eines Streams zum Mixer</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Stream-Transcodierung</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Hinzuf√ºgen eines Wasserzeichens</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Hinzuf√ºgen eines FPS-Filters</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Bilddrehung um 90, 180, 270 Grad</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Verwaltung eingehender Streams</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Stream-Relaying</a> <br><ul><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">WebRTC</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">RTMP</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">SIP / RTP</a> </li></ul><br></li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Verbinden von Servern mit einem CDN-Netzwerk zur Inhaltsverarbeitung</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Um es zusammenzufassen</a> </li><li>  <a href="https://habr.com/ru/company/flashphoner/blog/482956/">Links</a> </li></ul><br></div></div><br><h2><a name="serverapi"></a>  Server und API </h2><br><p>  Um diese L√ºcken zu schlie√üen, werden Serverl√∂sungen und eine Peer-Server-Peer-Architektur verwendet.  Web Call Server 5.2 (im Folgenden: WCS) ist eine der Serverl√∂sungen.  Es ist eine Entwicklungsplattform, mit der Sie dem Projekt solche Videofunktionen hinzuf√ºgen k√∂nnen, ohne sich um STUN / TURN und die Stabilit√§t von Peer-to-Peer-Verbindungen sorgen zu m√ºssen. </p><br><p>  Auf der h√∂chsten Ebene ist WCS ein JavaScript-API + -Serverteil.  Die API wird f√ºr die Entwicklung mit regul√§rem JavaScript auf der Browserseite verwendet, und der Server verarbeitet den Videoverkehr und fungiert als Stateful Proxy f√ºr den Medienverkehr. </p><br><p><img src="https://habrastorage.org/webt/7a/w0/qv/7aw0qvwyfc9tak6ij9ycdr1sju4.png"></p><br><p>  Neben der JavaScript-API gibt es auch das Android SDK und das iOS SDK, die f√ºr die Entwicklung nativer mobiler Anwendungen f√ºr iOS bzw. Android erforderlich sind. </p><br><p>  Das Ver√∂ffentlichen eines Streams auf dem Server (Streaming von einer Webcam zum Server) sieht beispielsweise folgenderma√üen aus: </p><br><p>  Web SDK </p><br><pre><code class="plaintext hljs">session.createStream({name:‚Äùstream123‚Äù}).publish();</code> </pre> <br><p>  Android SDK </p><br><pre> <code class="plaintext hljs">publishStream = session.createStream(streamOptions) publishStream.publish();</code> </pre><br><p>  iOS SDK </p><br><pre> <code class="plaintext hljs">FPWCSApi2Stream *stream = [session createStream:options error:&amp;error]; if(![stream publish:&amp;error]) { //published without errors }</code> </pre><br><p>  Auf diese Weise k√∂nnen wir nicht nur eine Webanwendung, sondern auch umfassende Funktionen f√ºr Google Play und den App Store mit Unterst√ºtzung f√ºr Video-Streaming implementieren.  Wenn wir dem Bild auf oberster Ebene ein mobiles SDK hinzuf√ºgen, erhalten wir Folgendes: </p><br><p><img src="https://habrastorage.org/webt/tf/z-/ya/tfz-yax_izaf-eyitcvd57y82h0.png"></p><br><p></p><br><h2><a name="Incomingstreams"></a>  Eingehende Streams </h2><br><p>  Der Streaming-Server (WCS) beginnt mit eingehenden Streams.  Um etwas zu verbreiten, m√ºssen wir es haben.  Um Videostreams an die Zuschauer zu verteilen, m√ºssen diese Streams auf den Server gelangen, den Arbeitsspeicher durchlaufen und √ºber die Netzwerkkarte beendet werden.  Daher ist die erste Frage, die wir stellen m√ºssen, wenn wir uns mit dem Medienserver vertraut machen, welche Protokolle und Formate dieser verwendet, um Datenstr√∂me zu akzeptieren.  Im Fall von WCS sind dies die folgenden Technologien: WebRTC, RTMP, RTSP, VOD, SIP / RTP. </p><br><p><img src="https://habrastorage.org/webt/du/2r/pc/du2rpcr6ihdkicklwlyusrodjog.png"></p><br><p>  Jedes der Protokolle kann von verschiedenen Clients verwendet werden.  Beispielsweise kann nicht nur der Stream vom Browser √ºber WebRTC eingegeben werden, sondern auch von einem anderen Server.  In der folgenden Tabelle sind die m√∂glichen Quellen f√ºr eingehenden Datenverkehr aufgef√ºhrt. </p><br><div class="scrollable-table"><table><tbody><tr><td>  <strong>WebRTC</strong> </td><td>  <strong>RTMP</strong> </td><td>  <strong>Rtsp</strong> </td><td>  <strong>Vod</strong> </td><td>  <strong>SIP / RTP</strong> </td></tr><tr><td><ul><li>  Web SDK <br><ul><li>  Kamera + Mikrofon </li><li>  Leinwand </li><li>  Bildschirmfreigabe </li></ul><br></li><li>  Android SDK </li><li>  iOS SDK </li><li>  WCS <br><ul><li>  schieben </li><li>  ziehen </li></ul><br></li><li>  Cdn </li></ul><br></td><td><ul><li>  RTMP-Encoder <br><ul><li>  ffmpeg </li><li>  Obs </li><li>  Wirecast </li></ul><br></li><li>  Adobe Encoder </li><li>  WCS <br><ul><li>  schieben </li><li>  ziehen </li></ul><br></li><li>  Flash Player </li></ul><br></td><td><ul><li>  IP-Kamera </li><li>  RTSP-Server </li></ul><br></td><td><ul><li>  Dateisystem </li><li>  AWS S3 </li></ul><br></td><td><ul><li>  SIP-Endpunkt </li><li>  SIP-Konferenzen </li></ul><br></td></tr></tbody></table></div><br><br><p>  Wenn wir die Quellen des eingehenden Verkehrs durchgehen, k√∂nnen wir Folgendes hinzuf√ºgen: <br></p><br><h3> <strong><a name="inWebRTC"></a></strong>  <strong>Eingehendes WebRTC</strong> </h3><br><p>  Mit dem Web SDK k√∂nnen Sie nicht nur Kamera und Mikrofon erfassen, sondern auch die Funktionen der Browser-API nutzen, um √ºber die Bildschirmfreigabe auf den Bildschirm zuzugreifen.  Dar√ºber hinaus k√∂nnen wir ein beliebiges Canvas-Element erfassen, auf das f√ºr die anschlie√üende √úbertragung nur Canvas-Streaming gezeichnet wird: </p><br><p>  Aufgrund der Besonderheiten des Mobiltelefons k√∂nnen Android SDK und iOS SDK unterwegs zwischen der vorderen und hinteren Kamera des Ger√§ts wechseln.  Dies erm√∂glicht es uns, die Quelle w√§hrend des Streamings zu wechseln, ohne den Stream anhalten zu m√ºssen. </p><br><p>  Der eingehende WebRTC-Stream kann auch von einem anderen WCS-Server mithilfe der Push-, Pull- und CDN-Methoden abgerufen werden, die sp√§ter erl√§utert werden. </p><br><p><img src="https://habrastorage.org/webt/zn/rw/5i/znrw5ikkd8vcjuexwarfzeqkhg4.jpeg"></p><br><p></p><br><h3> <strong><a name="inRTMP"></a></strong>  <strong>Eingehende rtmp</strong> </h3><br><p>  Das RTMP-Protokoll wird h√§ufig in den bevorzugten OBS der Streamer sowie in anderen Encodern verwendet: Wirecast, Adobe Media Encoder, ffmpeg usw.  Mit einem dieser Encoder k√∂nnen wir den Stream erfassen und an den Server senden. </p><br><p>  Mithilfe der Push- und Pull-Methoden k√∂nnen wir auch einen RTMP-Stream von einem anderen Medienserver oder WCS-Server abrufen.  Im Fall von Push ist der Initiator der Remote-Server.  Im Fall von pull wenden wir uns an den lokalen Server, um den Stream vom Remote-Server abzurufen. </p><br><p><img src="https://habrastorage.org/webt/3o/8x/f8/3o8xf84v5rx2apw_09n_lm2cjoe.jpeg"></p><br><p></p><br><h3> <strong><a name="inRTSP"></a></strong>  <strong>Eingehende rtsp</strong> </h3><br><p>  RTSP-Datenverkehrsquellen sind normalerweise IP-Kameras oder Medienserver von Drittanbietern, die das RTSP-Protokoll unterst√ºtzen.  Obwohl der Initiator beim Herstellen einer RTSP-Verbindung WCS ist, wird der Audio- und Videodatenverkehr von der IP-Kamera zum WCS-Server geleitet.  Daher betrachten wir den Stream von der Kamera als eingehend. </p><br><p><img src="https://habrastorage.org/webt/ch/pj/qi/chpjqiof2ipgoqzmwx0zzkewrgm.jpeg"></p><br><p></p><br><h3> <strong><a name="inVOD"></a></strong>  <strong>Eingehender Vod</strong> </h3><br><p>  Auf den ersten Blick scheint die VOD-Funktion (Video On Demand) ausschlie√ülich mit ausgehenden Streams und der Wiedergabe von Dateien durch Browser verbunden zu sein.  In unserem Fall ist dies jedoch nicht ganz richtig.  WCS sendet eine mp4-Datei vom Dateisystem an localhost.  Infolgedessen wird ein eingehender Stream erstellt, als stamme er aus einer Quelle eines Drittanbieters.  Wenn wir einen Viewer auf eine mp4-Datei beschr√§nken, erhalten wir den klassischen VOD, bei dem der Viewer den Stream erh√§lt und ihn von Anfang an wiedergibt.  Wenn wir einen Betrachter nicht auf eine mp4-Datei beschr√§nken, erhalten wir VOD LIVE - eine Variante von VOD, bei der der Betrachter dieselbe Datei wie einen Stream abspielen kann und eine Verbindung zu dem Wiedergabepunkt herstellt, an dem sich alle anderen aktuell befinden (vor der Wiedergabe). aufgezeichneten Fernsehsendungsmodus). </p><br><p><img src="https://habrastorage.org/webt/cn/ot/tv/cnottvwwytktaxh9vnbjexlxlaq.jpeg"></p><br><p></p><br><h3> <strong><a name="inSIP-RTP"></a></strong>  <strong>Eingehendes SIP / RTP</strong> </h3><br><p>  Um eingehenden RTP-Verkehr innerhalb einer SIP-Sitzung zu empfangen, m√ºssen wir einen Anruf mit einem SIP-Gateway eines Drittanbieters einrichten.  Wenn die Verbindung erfolgreich hergestellt wurde, wird der Audio- und / oder Videodatenverkehr vom SIP-Gateway geleitet, der auf der WCS-Seite in den eingehenden Datenstrom eingeschlossen wird. </p><br><p><img src="https://habrastorage.org/webt/-r/km/io/-rkmio-9lhqlfjioblwkanzuxiq.jpeg"></p><br><p></p><br><h2><a name="Outgoingstreams"></a>  Ausgehende Streams </h2><br><p>  Nach dem Empfang des Streams auf dem Server k√∂nnen wir den empfangenen Stream auf Anfrage an einen oder mehrere Viewer replizieren.  Der Viewer fordert einen Stream vom Player oder einem anderen Ger√§t an.  Solche Streams werden als ausgehende Streams oder "Viewer-Streams" bezeichnet, da Sitzungen mit solchen Streams immer auf der Seite des Viewers / Players initiiert werden.  Die Wiedergabetechnologien umfassen die folgenden Protokolle / Formate: WebRTC, RTMP, RTSP, MSE und HLS. </p><br><br><div class="scrollable-table"><table><thead><tr><th>  WebRTC </th><th>  RTMP </th><th>  Rtsp </th><th>  MSE </th><th>  Hls </th></tr></thead><tbody><tr><td><ul><li>  Web SDK </li><li>  Android SDK </li><li>  iOS SDK </li><li>  WC <br><ul><li>  ziehen </li><li>  Cdn </li></ul><br></li></ul><br></td><td><ul><li>  Flash Player </li><li>  RTMP-Player </li></ul><br></td><td><ul><li>  RTSP-Player <br><ul><li>  VLC </li><li>  WCS </li><li>  usw </li></ul><br></li></ul><br></td><td><ul><li>  Web SDK </li></ul><br></td><td><ul><li>  HLS-Spieler <br><ul><li>  hls.js </li><li>  einheimische Safari </li></ul><br></li></ul><br></td></tr></tbody></table></div><br><h3> <strong><a name="outWebRTC"></a></strong>  <strong>Ausgehendes WebRTC</strong> </h3><br><p>  In diesem Fall fungieren das Web SDK, Android SDK und iOS SDK als API f√ºr den Player.  Ein Beispiel f√ºr das Abspielen eines WebRTC-Streams sieht folgenderma√üen aus: </p><br><p>  Web SDK </p><br><pre> <code class="plaintext hljs">session.createStream({name:‚Äùstream123‚Äù}).play();</code> </pre><br><p>  Android SDK </p><br><pre> <code class="plaintext hljs">playStream = session.createStream(streamOptions); playStream.play();</code> </pre><br><p>  iOS SDK </p><br><pre> <code class="plaintext hljs">FPWCSApi2Stream *stream = [session createStream:options error:nil]; if(![stream play:&amp;error]) { //published without errors }</code> </pre> <br><p>  Dies ist der Ver√∂ffentlichungs-API sehr √§hnlich, mit dem einzigen Unterschied, dass stream.play () anstelle von stream.publish () zum Abspielen aufgerufen wird. </p><br><p>  Ein WCS-Server eines Drittanbieters kann der Player sein, der angewiesen wird, den Stream mithilfe der Pull-Methode √ºber WebRTC von einem anderen Server abzurufen oder den Stream im CDN abzurufen. </p><br><p></p><br><h3> <strong><a name="outRTMP"></a></strong>  <strong>Ausgehende rtmp</strong> </h3><br><p><img src="https://habrastorage.org/webt/in/zq/nb/inzqnbejvsout_d4n5iiej4gozi.png"></p><br><p>  Hier wird es haupts√§chlich RTMP-Player geben - sowohl den bekannten Flash Player als auch Desktop- und Mobilanwendungen, die das RTMP-Protokoll verwenden und einen RTMP-Stream empfangen und wiedergeben.  Trotz der Tatsache, dass Flash den Browser verlassen hat, wurde das f√ºr Video√ºbertragungen weit verbreitete RTMP-Protokoll beibehalten, und die fehlende native Unterst√ºtzung in Browsern verhindert nicht die Verwendung dieses recht erfolgreichen Protokolls in anderen Clientanwendungen.  Es ist bekannt, dass RTMP in VR-Playern f√ºr mobile Anwendungen auf Android und iOS weit verbreitet ist. </p><br><p></p><br><h3> <strong><a name="outRTSP"></a></strong>  <strong>Ausgehende rtsp</strong> </h3><br><p><img src="https://habrastorage.org/webt/ly/xu/r9/lyxur9b3gfzwsubfmrb3afmkfh0.png"></p><br><p>  Der WCS-Server kann als RTSP-Server fungieren und den empfangenen Stream √ºber RTSP als regul√§re IP-Kamera verteilen.  In diesem Fall muss der Player eine RTSP-Verbindung zum Server herstellen und den Stream zur Wiedergabe abrufen, als w√§re es eine IP-Kamera. </p><br><p></p><br><h3> <strong><a name="outMSE"></a></strong>  <strong>Ausgehende mse</strong> </h3><br><p><img src="https://habrastorage.org/webt/lt/wh/wz/ltwhwz7b8urhlg4m5ay-blpg-d8.jpeg"></p><br><p>  In diesem Fall fordert der Player mithilfe des Websocket-Protokolls einen Stream vom Server an.  Der Server verteilt Audio- und Videodaten √ºber Web-Sockets.  Die Daten erreichen den Browser und werden in Bl√∂cke konvertiert, die der Browser dank der standardm√§√üig unterst√ºtzten nativen MSE-Erweiterung wiedergeben kann.  Der Player arbeitet letztendlich auf der Basis des HTML5-Videoelements. </p><br><p></p><br><h3> <strong><a name="outHLS"></a></strong>  <strong>Ausgehende hls</strong> </h3><br><p><img src="https://habrastorage.org/webt/if/5l/5f/if5l5fdsrgbgaekle2edci9gyws.jpeg"></p><br><p>  Hier fungiert WCS als HLS-Server oder Webserver, der HLS (HTTP Live Streaming) unterst√ºtzt.  Sobald der eingehende Stream auf dem Server angezeigt wird, wird eine .m3u8 HLS-Wiedergabeliste generiert, die dem Player als Antwort auf eine HTTP-Anforderung √ºbergeben wird.  Die Wiedergabeliste beschreibt, welche Videosegmente der Player herunterladen und anzeigen soll.  Der Player l√§dt Videosegmente herunter und spielt sie auf der Browserseite, auf dem Mobilger√§t, auf dem Desktop, in der Apple TV-Set-Top-Box und √ºberall dort ab, wo HLS-Unterst√ºtzung in Anspruch genommen wird. </p><br><p></p><br><h2><a name="IncomingOutgoing"></a>  Ein- und ausgehend </h2><br><p>  Insgesamt haben wir 5 Arten von eingehenden und ausgehenden Streams.  Sie sind in der Tabelle aufgef√ºhrt: </p><br><br><div class="scrollable-table"><table><thead><tr><th>  <strong>Posteingang</strong> </th><th>  <strong>Ausgehend</strong> </th></tr></thead><tbody><tr><td>  WebRTC </td><td>  WebRTC </td></tr><tr><td>  RTMP </td><td>  RTMP </td></tr><tr><td>  Rtsp </td><td>  Rtsp </td></tr><tr><td>  Vod </td><td>  MSE </td></tr><tr><td>  SIP / RTP </td><td>  Hls </td></tr></tbody></table></div><br><p>  Das hei√üt, wir k√∂nnen die Streams auf den Server hochladen, eine Verbindung zu ihnen herstellen und sie mit geeigneten Playern abspielen.  Verwenden Sie das Web SDK, um einen WebRTC-Stream abzuspielen.  Verwenden Sie einen HLS-Player usw., um einen WebRTC-Stream als HLS abzuspielen.  Ein Stream kann von vielen Zuschauern gespielt werden.  Eins-zu-viele-Sendungen funktionieren. </p><br><p>  Beschreiben wir nun, welche Aktionen mit Streams ausgef√ºhrt werden k√∂nnen. </p><br><p></p><br><h2><a name="manipulatingincoming"></a>  Eingehende Stream-Manipulation </h2><br><p>  Ausgehende Streams mit Zuschauern sind nicht einfach zu manipulieren.  Wenn der Viewer eine Sitzung mit dem Server aufgebaut hat und bereits einen Stream abruft, k√∂nnen keine √Ñnderungen daran vorgenommen werden, ohne die Sitzung zu unterbrechen.  Aus diesem Grund finden alle Manipulationen und √Ñnderungen an eingehenden Streams zu dem Zeitpunkt statt, an dem die Replikation noch nicht erfolgt ist.  Der Stream, der ge√§ndert wurde, wird dann an alle verbundenen Viewer verteilt. </p><br><p>  Stream-Optionen umfassen: </p><br><p>  - Aufnahme </p><br><p>  - einen Schnappschuss machen </p><br><p>  - Hinzuf√ºgen eines Streams zum Mixer </p><br><p>  - Stream-Transcodierung </p><br><p>  - Hinzuf√ºgen eines Wasserzeichens </p><br><p>  - Hinzuf√ºgen eines FPS-Filters </p><br><p>  - Bilddrehung um 90, 180, 270 Grad </p><br><p></p><br><h3> <strong><a name="recording"></a></strong>  <strong>Aufzeichnung eingehender Streams</strong> </h3><br><p><img src="https://habrastorage.org/webt/m_/je/j8/m_jej8-gdyvh2e2urt4s75ltsse.jpeg"></p><br><p>  Vielleicht die verst√§ndlichste und am h√§ufigsten anzutreffende Funktion.  In der Tat m√ºssen in vielen F√§llen Streams aufgezeichnet werden: Webinare, Englischunterricht, Konsultationen usw. <br><img src="https://habrastorage.org/webt/kz/t0/_r/kzt0_rj0y1mvgb4rnob5ix4_bnk.jpeg"><br>  Die Aufzeichnung kann entweder mit dem Web SDK oder der REST-API mit einer speziellen Anforderung gestartet werden: </p><br><pre> <code class="plaintext hljs">/stream/startRecording {}</code> </pre> <br><p>  Das Ergebnis wird als mp4-Datei im Dateisystem gespeichert. </p><br><p></p><br><h3> <strong><a name="snapshot"></a></strong>  <strong>Einen Schnappschuss machen</strong> </h3><br><p><img src="https://habrastorage.org/webt/cg/g6/yh/cgg6yhu_d8lj4tl6tecphzvgsce.jpeg"></p><br><p>  Ebenso h√§ufig ist es, Bilder des aktuellen Streams aufzunehmen, um Symbole auf der Site anzuzeigen.  Zum Beispiel haben wir 50 Streams in einem Video√ºberwachungssystem, von denen jeder eine IP-Kamera als Quelle hat.  Das Anzeigen aller 50 Threads auf einer Seite ist nicht nur problematisch f√ºr Browser-Ressourcen, sondern auch sinnlos.  Im Fall von 30 FPS betr√§gt die Gesamt-FPS des sich √§ndernden Bildes 1500, und das menschliche Auge akzeptiert eine solche Anzeigefrequenz einfach nicht.  Als L√∂sung k√∂nnen wir automatisches Slicing oder Snapshot-Erstellung nach Bedarf konfigurieren.  In diesem Fall k√∂nnen Bilder mit einer beliebigen Frequenz auf der Site angezeigt werden, z. B. 1 Bild in 10 Sekunden.  Snapshots k√∂nnen √ºber die REST-API aus dem SDK entfernt oder automatisch aufgeteilt werden. </p><br><p><img src="https://habrastorage.org/webt/b9/c5/hf/b9c5hfkspnmifm7wfw96aatldl8.jpeg"></p><br><p>  Der WCS-Server unterst√ºtzt die REST-Methode zum Empfangen von Snapshots: </p><br><pre> <code class="plaintext hljs">/stream/snapshot</code> </pre> <br><p></p><br><p><img src="https://habrastorage.org/webt/5c/8z/v-/5c8zv-0i7uglnd6t5eyldejyzt0.jpeg"></p><br><p></p><br><h3> <strong><a name="mixer"></a></strong>  <strong>Hinzuf√ºgen eines Streams zum Mixer</strong> </h3><br><p><img src="https://habrastorage.org/webt/o3/mx/bj/o3mxbjmxo3evugpsr5td7wko1pc.jpeg"></p><br><p>  Ein Bild aus zwei oder mehr Quellen kann zu einem Bild kombiniert werden, um es den Betrachtern anzuzeigen.  Dieser Vorgang wird als Mischen bezeichnet.  Grundlegende Beispiele: 1) Video√ºberwachung von mehreren Kameras auf dem Bildschirm in einem Bild.  2) Videokonferenz, bei der jeder Benutzer einen Stream empf√§ngt, in den der Rest eingemischt ist, um Ressourcen zu sparen.  Der Mischer wird √ºber die REST-API gesteuert und verf√ºgt √ºber einen MCU-Betriebsmodus zum Erstellen von Videokonferenzen. </p><br><p>  REST-Befehl zum Hinzuf√ºgen eines Streams zum Mixer: </p><br><pre> <code class="plaintext hljs">/mixer/startup</code> </pre> <br><p></p><br><h3> <strong><a name="transcoding"></a></strong>  <strong>Stream-Transcodierung</strong> </h3><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d19/7de/e1b/d197dee1b288f44501461f2893f19af6.jpg" alt="transcoding_WebRTC_Android_iOS_SDK_API_WCS_browser_RTMP_RTSP_VOD_SIP_RTP" width="924" height="553"></p><br><p>  Streams m√ºssen manchmal komprimiert werden, um sie an bestimmte Gruppen von Clientger√§ten nach Aufl√∂sung und Bitrate anzupassen.  Hierf√ºr wird die Transcodierung verwendet.  Die Transkodierung kann auf der Web-SDK-Seite, √ºber die REST-API oder automatisch √ºber einen speziellen Transkodierungsknoten im CDN aktiviert werden.  Beispielsweise kann ein Video mit einer Aufl√∂sung von 1280 x 720 auf 640 x 360 transkodiert werden, um es aus einer geografischen Region mit traditionell geringer Bandbreite an Kunden zu verteilen.  Wo sind deine Satelliten, Elon Musk? </p><br><p><img src="https://habrastorage.org/webt/yn/t2/5g/ynt25g1_9phfzcqtptzb0e0u3gq.jpeg"></p><br><p>  Verwendete REST-Methode: </p><br><pre> <code class="plaintext hljs">/transcoder/startup</code> </pre> <br><p></p><br><h3> <strong><a name="watermark"></a></strong>  <strong>Hinzuf√ºgen eines Wasserzeichens</strong> </h3><br><p><img src="https://habrastorage.org/webt/l_/7q/-t/l_7q-td_lifwkr5aw3mn-btem1o.png"></p><br><p>  Es ist bekannt, dass Inhalte gestohlen und in WebRip umgewandelt werden k√∂nnen, unabh√§ngig vom Schutz des Players.  Wenn Ihr Inhalt wertvoll ist, k√∂nnen Sie ein Wasserzeichen oder Logo einbetten, was die weitere Verwendung und √∂ffentliche Anzeige erheblich erschwert.  Um ein Wasserzeichen hinzuzuf√ºgen, laden Sie einfach ein PNG-Bild hoch und es wird durch Transcodierung in den Videostream eingef√ºgt.  Daher m√ºssen Sie auf der Serverseite einige CPU-Kerne vorbereiten, falls Sie dem Stream dennoch ein Wasserzeichen hinzuf√ºgen m√∂chten.  Um das Wasserzeichen nicht durch Umcodierung auf dem Server zu erstellen, ist es besser, es direkt auf dem Encoder / Streamer hinzuzuf√ºgen, was h√§ufig eine solche M√∂glichkeit bietet. </p><br><p></p><br><h3> <strong><a name="fpsfilter"></a></strong>  <strong>Hinzuf√ºgen eines FPS-Filters</strong> </h3><br><p><img src="https://habrastorage.org/webt/27/oi/bk/27oibkbef1jtrjulbcdcpomi_ts.png"></p><br><p>  In einigen F√§llen ist es erforderlich, dass der Stream eine gerade FPS (Frames pro Sekunde) aufweist.  Dies kann n√ºtzlich sein, wenn wir den Stream zu einer Drittanbieter-Ressource wie Youtube oder Facebook streamen oder ihn mit einem empfindlichen HLS-Player abspielen.  Das Filtern erfordert auch eine Transcodierung. Stellen Sie daher sicher, dass Sie die Leistung Ihres Servers richtig einsch√§tzen und 2 Kerne pro Stream vorbereiten, wenn ein solcher Vorgang geplant ist. </p><br><p></p><br><h3> <strong><a name="rotate"></a></strong>  <strong>Bilddrehung um 90, 180, 270 Grad</strong> </h3><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fe/997/147/8fe997147f962e8d2f2d3405c5415f6e.png" alt="rotation_WebRTC_Android_iOS_SDK_API_WCS_browser_RTMP_RTSP_VOD_SIP_RTP" width="628" height="189"></p><br><p>  Mobile Ger√§te k√∂nnen die Aufl√∂sung des ver√∂ffentlichten Streams in Abh√§ngigkeit vom Drehwinkel √§ndern.  Sie haben beispielsweise mit dem Streaming begonnen, das iPhone horizontal gehalten und es dann gedreht.  Gem√§√ü der WebRTC-Spezifikation sollte der Streamer-Browser des Mobilger√§ts (in diesem Fall iOS Safari) dem Server die Rotation signalisieren.  Der Server muss dieses Ereignis wiederum an alle Abonnenten senden.  Andernfalls w√§re es so: Der Streamer legt das Telefon auf die Seite, sieht die Kamera jedoch immer noch vertikal, w√§hrend der Betrachter ein gedrehtes Bild sieht.  Um mit Rotationen auf der SDK-Seite zu arbeiten, ist die entsprechende cvoExtension-Erweiterung enthalten. </p><br><p></p><br><h3> <strong><a name="manage"></a></strong>  <strong>Verwaltung eingehender Streams</strong> </h3><br><p>  Automatisch - Die Konfiguration wird normalerweise in den Einstellungen serverseitig festgelegt. </p><br><div class="scrollable-table"><table><thead><tr><th>  Flow-Aktion </th><th>  Web, iOS, Android SDK </th><th>  REST-API </th><th>  Automatisch </th><th>  Cdn </th></tr></thead><tbody><tr><td>  Aufnehmen </td><td>  + </td><td>  + </td><td><br></td><td><br></td></tr><tr><td>  Snapshot-Entfernung </td><td>  + </td><td>  + </td><td>  + </td><td><br></td></tr><tr><td>  Zum Mixer hinzuf√ºgen </td><td>  + </td><td>  + </td><td><br></td><td><br></td></tr><tr><td>  Stream-Transcodierung </td><td>  + </td><td>  + </td><td><br></td><td>  + </td></tr><tr><td>  Wasser hinzuf√ºgen <br>  unterschreiben </td><td><br></td><td><br></td><td>  + </td><td><br></td></tr><tr><td>  Hinzuf√ºgen eines FPS-Filters </td><td><br></td><td><br></td><td>  + </td><td><br></td></tr><tr><td>  Drehe das Bild um 90, <br>  180, 270 Grad </td><td>  + </td><td><br></td><td><br></td><td><br></td></tr></tbody></table></div><br><p></p><br><h2><a name="Streamrelay"></a>  Stream-Relaying </h2><br><p>  Relaying ist auch eine Option zum Manipulieren von Streams, die auf den Server gelangen.  Es besteht darin, den Stream auf einen Server eines Drittanbieters zu zwingen.  Relaying ist gleichbedeutend mit Neuver√∂ffentlichung, Push, Injection. </p><br><p>  Die Weiterleitung kann mit einem der folgenden Protokolle implementiert werden: WebRTC, RTMP, SIP / RTP.  Die Tabelle zeigt die Richtung, in die der Stream weitergeleitet werden kann. </p><br><br><div class="scrollable-table"><table><thead><tr><th>  WebRTC </th><th>  RTMP </th><th>  SIP / RTP </th></tr></thead><tbody><tr><td>  WCS </td><td>  RTMP-Server-WCS </td><td>  SIP-Server </td></tr></tbody></table></div><br><br><h3> <strong><a name="repubWebRTC"></a></strong>  <strong>WebRTC-Weiterleitung</strong> </h3><br><p><img src="https://habrastorage.org/webt/d9/yf/cc/d9yfccsjz8zqvx3jo-3gas2nuu8.jpeg"></p><br><p>  Ein Stream kann an einen anderen WCS-Server weitergeleitet werden, wenn es aus irgendeinem Grund erforderlich ist, den Stream auf einem anderen Server verf√ºgbar zu machen.  Die Weitergabe erfolgt √ºber die REST-API √ºber die Methode / push.  Nach Erhalt einer solchen REST-Anforderung stellt WCS eine Verbindung zum angegebenen Server her und ver√∂ffentlicht einen Server-Server-Stream an diesen.  Danach steht der Stream f√ºr die Wiedergabe auf einem anderen Computer zur Verf√ºgung. </p><br><pre> <code class="plaintext hljs">/pull/push</code> </pre> <br><p>  - Verwendete REST-Methode </p><br><p></p><br><h3> <strong><a name="rebubRTMP"></a></strong>  <strong>RTMP-Relaying</strong> </h3><br><p><img src="https://habrastorage.org/webt/y-/hv/tn/y-hvtne9e-vtgry-2or6nhmqzte.jpeg"></p><br><p>  Wie bei der WebRTC-Weiterleitung ist auch eine RTMP-Weiterleitung an einen anderen Server m√∂glich.  Der Unterschied besteht nur im Relaisprotokoll.  RTMP-Relaying wird auch √ºber / push ausgef√ºhrt und erm√∂glicht die √úbertragung des Streams an RTMP-Server von Drittanbietern sowie an Dienste, die RTMP-Ingest unterst√ºtzen: Youtube, Facebook-Streaming usw.  Somit kann der WebRTC-Stream an RTMP weitergeleitet werden.  Wir k√∂nnen ebenso gut jeden anderen Stream, der in den Server gelangt, zum Beispiel RTSP oder VOD, an RTMP weiterleiten. </p><br><p>  Der Videostream wird mithilfe von REST-Aufrufen an einen anderen RTMP-Server weitergeleitet. </p><br><pre> <code class="plaintext hljs">/push/startup</code> </pre> <br><p>  - REST-Aufruf verwendet </p><br><p></p><br><h3> <strong><a name="repubSIP-RTP"></a></strong>  <strong>SIP / RTP-Relaying</strong> </h3><br><p><img src="https://habrastorage.org/webt/sl/tt/hj/sltthjlgwbvryka0vgpqel0hcx8.jpeg"><br></p><p>  Es wird selten Funktion verwendet.  Am h√§ufigsten wird es in Unternehmen eingesetzt.  Zum Beispiel, wenn wir einen SIP-Anruf mit einem externen SIP-Konferenzserver herstellen und den Audio- oder Videostream auf diesen Anruf umleiten m√ºssen, damit das Konferenzpublikum eine Art Videoinhalt sieht: ‚ÄûBitte sehen Sie sich dieses Video an‚Äú oder ‚ÄûKollegen‚Äú Sehen wir uns jetzt einen IP-Kamerastream von der Baustelle an. ‚Äú  Wir m√ºssen ber√ºcksichtigen, dass in diesem Fall die Konferenz selbst existiert und auf einem externen VKS-Server mit SIP-Unterst√ºtzung verwaltet wird (k√ºrzlich haben wir die L√∂sung von Polycom DMA getestet), w√§hrend wir nur den vorhandenen Stream verbinden und weiterleiten dieser Server.  Die REST-API-Funktion hei√üt / inject und dient nur f√ºr diesen Fall. </p><br><p>  REST-API-Befehl: </p><br><pre> <code class="plaintext hljs">/call/inject_stream/startup</code> </pre> <br><p></p><br><h2><a name="CDN"></a>  Verbinden von Servern mit einem CDN-Netzwerk zur Inhaltsverarbeitung </h2><br><p>  Normalerweise verf√ºgt ein Server √ºber eine begrenzte Menge an Ressourcen.  Daher ist f√ºr gro√üe Online-Sendungen, bei denen das Publikum Tausende und Zehntausende z√§hlt, eine Skalierung erforderlich.  Mehrere WCS-Server k√∂nnen zu einem CDN-Netzwerk f√ºr die Bereitstellung von Inhalten zusammengefasst werden.  Intern arbeitet CDN √ºber WebRTC, um die Latenz w√§hrend des Streamings gering zu halten. </p><br><p><img src="https://habrastorage.org/webt/99/sx/gd/99sxgd8frahbmd2trrxsfltfmeg.jpeg"></p><br><p>  Der Server kann in einer der folgenden Rollen konfiguriert werden: Origin, Edge oder Transcoder.  Origin-Server empfangen Datenverkehr und verteilen ihn an die Edgeserver, die f√ºr die √úbermittlung des Streams an die Betrachter verantwortlich sind.  Wenn es erforderlich ist, einen Stream in mehreren Aufl√∂sungen vorzubereiten, werden Transcoder-Knoten in das Schema aufgenommen, die die ressourcenintensive Aufgabe des Transcodierens von Streams √ºbernehmen. </p><br><p></p><br><h2><a name="summarize"></a>  Um es zusammenzufassen </h2><br><p>  WCS 5.2 ist ein Server f√ºr die Entwicklung von Anwendungen mit Audio- und Video-Echtzeitunterst√ºtzung f√ºr Browser und Mobilger√§te.  F√ºr die Entwicklung stehen vier APIs zur Verf√ºgung: Web-SDK, iOS-SDK, Android-SDK und REST-API.  Wir k√∂nnen Videostreams mithilfe von f√ºnf Protokollen auf dem Server ver√∂ffentlichen (Feed): WebRTC, RTMP, RTSP, VOD, SIP / RTP.  Vom Server aus k√∂nnen wir Streams mit Playern unter Verwendung von f√ºnf Protokollen abspielen: WebRTC, RTMP, RTSP, MSE, HLS.  Streams k√∂nnen gesteuert werden und Vorg√§nge wie Aufzeichnen, Aufteilen von Schnappsch√ºssen, Mischen, Transcodieren, Hinzuf√ºgen eines Wasserzeichens, Filtern von FPS und √úbertragen von Videodrehs auf Mobilger√§ten durchlaufen.  Streams k√∂nnen √ºber WebRTC- und RTMP-Protokolle an andere Server weitergeleitet und zu SIP-Konferenzen umgeleitet werden.  Server k√∂nnen zu einem Content Delivery-Netzwerk zusammengefasst und f√ºr die Verarbeitung einer beliebigen Anzahl von Videostreams skaliert werden. </p><br><h3>  <strong>Was Alice wissen muss, um mit dem Server zu arbeiten</strong> </h3><br><p>  Der Entwickler muss Linux beherrschen.  Die folgenden Befehle in der Befehlszeile sollten keine Verwirrung stiften: </p><br><pre> <code class="plaintext hljs">tar -xvzf wcs5.2.tar.gz</code> </pre> <br><pre> <code class="plaintext hljs">cd wcs5.2</code> </pre> <br><pre> <code class="plaintext hljs">./install.sh</code> </pre> <br><pre> <code class="plaintext hljs">tail -f flashphoner.log</code> </pre> <br><pre> <code class="plaintext hljs">ps aux | grep WebCallServer</code> </pre> <br><pre> <code class="plaintext hljs">top</code> </pre> <br><p>  Man muss auch Vanilla JavaScript kennen, wenn es um Webentwicklung geht. </p><br><pre> <code class="plaintext hljs">//publishing the stream session.createStream({name:'mystream'}).publish(); //playing the stream session.createStream({name:'mystream'}).play();</code> </pre><br><p>  Die M√∂glichkeit, mit dem Back-End zu arbeiten, kann sich ebenfalls als n√ºtzlich erweisen. </p><br><p><img src="https://habrastorage.org/webt/3l/0a/9s/3l0a9shqbhfy4yjheu30ocammzg.jpeg"></p><br><p>  WCS kann nicht nur Steuerbefehle √ºber die REST-API empfangen, sondern auch Hooks senden, d. H. Benachrichtigungen √ºber Ereignisse, die auf der REST-API auftreten.  Wenn Sie beispielsweise versuchen, eine Verbindung √ºber einen Browser oder eine mobile Anwendung herzustellen, l√∂st WCS den Hook / connect aus, und wenn Sie versuchen, einen Stream abzuspielen, l√∂st es den Hook playStream aus.  Daher muss der Entwickler ein wenig in die Fu√üstapfen des Back-Enders treten, der in der Lage ist, sowohl einen einfachen REST-Client als auch einen kleinen REST-Server f√ºr die Verarbeitung von Hooks zu erstellen. </p><br><p>  REST-API-Beispiel </p><br><pre> <code class="plaintext hljs">/rest-api/stream/find_all</code> </pre> <br><p>  - Beispiel einer REST-API zum Auflisten von Streams auf dem Server </p><br><p>  Beispiel f√ºr einen REST-Hook </p><br><pre> <code class="plaintext hljs">https://myback-end.com/hook/connect</code> </pre> <br><p>  - REST Hook / Connect-Verarbeitung auf der Backend-Seite. </p><br><p>  Linux, JavaScript, REST-Client / Server - drei Elemente, die ausreichen, um einen Produktionsdienst auf der WCS-Plattform zu entwickeln, der mit Videostreams arbeitet. </p><br><p>  F√ºr die Entwicklung mobiler Anwendungen sind Kenntnisse in Java und Objective-C f√ºr Android bzw. iOS erforderlich. </p><br><h3>  <strong>Installation und Start</strong> </h3><br><p>  Es gibt drei M√∂glichkeiten, WCS heute schnell zu starten: </p><br><p>  1) Installieren Sie Ubuntu 16.x LTS oder Ubuntu 18.x LTS usw.  auf Ihrem Centos7.  oder sich von einem <a href="https://docs.flashphoner.com/display/WCS52EN/Quick%2Bdeployment%2Band%2Btesting%2Bof%2Bthe%2Bserver">Artikel aus der Dokumentation</a> leiten lassen. </p><br><p>  oder </p><br><p>  2) Holen Sie sich ein <a href="https://flashphoner.com/amazon-ec2-support-in-web-call-server">fertiges Image auf Amazon EC2</a> . </p><br><p>  oder </p><br><p>  3) Holen Sie sich ein <a href="https://flashphoner.com/web-call-server-on-digital-ocean-marketplace">fertiges Server-Image auf Digital Ocean</a> . </p><br><p>  Starten Sie eine spannende Projektentwicklung mit Streaming-Videofunktionen. </p><br><p>  Der √úbersichtsartikel erwies sich als ziemlich gro√ü.  Vielen Dank f√ºr die Geduld, es zu lesen. </p><br><p>  Viel Spa√ü beim Streamen! </p><br><p></p><br><h2><a name="Links"></a>  Links </h2><br><p>  <a href="https://flashphoner.com/">WCS 5.2</a> - WebRTC Server </p><br><h3>  Installation und Start </h3><br><p>  <a href="https://docs.flashphoner.com/display/WCS52EN/Quick%2Bdeployment%2Band%2Btesting%2Bof%2Bthe%2Bserver">Installation und Start von WCS</a> <br>  <a href="https://flashphoner.com/amazon-ec2-support-in-web-call-server">Starten Sie ein fertiges Image auf Amazon EC2</a> <br>  <a href="https://flashphoner.com/web-call-server-on-digital-ocean-marketplace">Starten Sie das vorgefertigte Image des Servers auf DigitalOcean</a> </p><br><h3>  SDK </h3><br><p>  <a href="https://docs.flashphoner.com/display/WCS52EN/Web%2BSDK">Dokumentations-Web-SDK</a> <br>  <a href="https://docs.flashphoner.com/display/WCS52EN/Android%2BSDK">Dokumentation Android SDK</a> <br>  <a href="https://docs.flashphoner.com/display/WCS52EN/iOS%2BSDK">Dokumentation iOS SDK</a> </p><br><h3>  F√§lle </h3><br><p>  <a href="https://docs.flashphoner.com/display/WCS52EN/Stream%2Bcapturing%2Band%2Bpublishing%2Bto%2Bthe%2Bserver">Eingehende Streams</a> <br>  <a href="https://docs.flashphoner.com/display/WCS52EN/Playing%2Ba%2Bvideo%2Bstream%2Bfrom%2Bthe%2Bserver">Ausgehende Streams</a> <br>  <a href="https://docs.flashphoner.com/display/WCS52EN/Captured%2Bstream%2Bmanagement">Verwaltung von Streams</a> <br>  <a href="https://docs.flashphoner.com/display/WCS52EN/Republishing%2Ba%2Bvideo%2Bstream">Stream-Relaying</a> <br>  <a href="">CDN f√ºr WebRTC-Streaming mit niedriger Latenz</a> </p><br><h3>  Dokumentation </h3><br><p>  <a href="https://docs.flashphoner.com/display/WCS52EN/Web%2BCall%2BServer%2B5.2%2B-%2BEN">Dokumentation Web Call Server 5.2</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482956/">https://habr.com/ru/post/de482956/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482942/index.html">Mythen und Legenden des alten Fediversums</a></li>
<li><a href="../de482944/index.html">Mehrkomponenten-F√∂rderspender</a></li>
<li><a href="../de482946/index.html">1–° DSS und Sch√§tzung der Projektlaufzeiten und -kosten nach der COCOMO II-Methode</a></li>
<li><a href="../de482948/index.html">"Eins, zwei, drei - verbrenne den Weihnachtsbaum!" Oder mein erster Blick auf den CANNY 3 winzigen Controller</a></li>
<li><a href="../de482950/index.html">Java: Dinge, die einem erfahrenen Entwickler neugierig erscheinen m√∂gen</a></li>
<li><a href="../de482958/index.html">"Wachstumsregeln: Vom Junior zum CTO", Auszug aus einem Webinar von Fedor Borshchev</a></li>
<li><a href="../de482960/index.html">WCS 5.2 √úbersicht - WebRTC Server f√ºr Webentwickler von Online-Broadcasts und Video-Chats</a></li>
<li><a href="../de482968/index.html">Quarkus - Ein neuer Blick auf Cloud Native Java</a></li>
<li><a href="../de482970/index.html">Hack The Box - Walkthrough Craft. Wir st√∂bern in Git, nutzen Schwachstellen in der API aus, besch√§ftigen uns mit Vault</a></li>
<li><a href="../de482974/index.html">Psychologische Unterst√ºtzung mit Virtual Reality</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
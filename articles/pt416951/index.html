<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙄 👂🏻 🏍️ Clusters Kubernetes no serviço VPC 🧓🏼 👋🏻 🦌</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Adicionamos a capacidade de iniciar convenientemente o Kubernetes no serviço Virtual Private Cloud no modo de teste beta inicial. 


 Essa funcionalid...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Clusters Kubernetes no serviço VPC</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/416951/"><img src="https://habrastorage.org/webt/bc/b6/cy/bcb6cykv49fwewsnhfr-7ny-0uc.png"><br><p><br>  Adicionamos a capacidade de iniciar convenientemente o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">Kubernetes</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">serviço Virtual Private Cloud</a> no modo de teste beta inicial. </p><br><p>  Essa funcionalidade será útil para usuários que precisam de gerenciamento conveniente de um grande número de aplicativos em execução como contêineres.  O Kubernetes oferece ferramentas para dimensionamento, autocorreção e balanceamento de carga para contêineres executados dentro de um cluster. </p><br><p>  Como o <strong>serviço de nuvem privada virtual</strong> é baseado no OpenStack, usamos um de seus componentes - o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">OpenStack Magnum</a> .  Permite criar rapidamente clusters Kubernetes privados com o número desejado de nós. </p><br><p>  Atualmente, qualquer usuário do nosso serviço pode criar vários clusters independentes em seu projeto.  Como nós de cluster, serão usadas máquinas virtuais, cuja configuração pode ser selecionada e alterada. </p><br><p>  Neste artigo, falaremos sobre os principais objetos do cluster Kubernetes e usaremos os exemplos para analisar o processo de criação de um cluster usando o OpenStack Magnum. </p><a name="habracut"></a><br><h2>  Criar e gerenciar um cluster Kubernetes </h2><br><p>  Atualmente, a criação de um cluster Kubernetes é possível apenas por meio de utilitários do console ou da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">API OpenStack</a> nas zonas de disponibilidade <strong>ru-1a</strong> e <strong>ru-1b</strong> (São Petersburgo). </p><br><p>  Para começar, você precisará de: </p><br><ul><li>  Crie um novo ou use um projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">VPC</a> existente; </li><li>  Crie um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">usuário com uma chave SSH</a> ; </li><li>  Adicione um usuário ao projeto criado na página de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">gerenciamento de</a> projetos; </li><li>  Vá para o projeto e obtenha o arquivo de acesso na guia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">Acesso</a> ; </li><li>  Instale o cliente do console <strong>openstack com a biblioteca python-magnumclient</strong> ; </li><li>  Instale o cliente do console <strong>kubectl</strong> . </li></ul><br><p>  Para instalar o cliente do console <strong>openstack</strong> , <strong>você</strong> pode usar as instruções <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">no link</a> ; no entanto, lembre-se de que, para esse cliente, você também precisará instalar a biblioteca <strong>python-magnumclient</strong> para suportar a criação de clusters Kubernetes. </p><br><p>  O conjunto completo de comandos para instalar um cliente openstack com o plug-in necessário para sistemas operacionais da família Ubuntu / Debian: </p><br><pre><code class="bash hljs">$ sudo apt update $ sudo apt -y install curl python-pip python-dev python3-dev git libxml2-dev libxslt1-dev python-openssl python3-openssl python-pyasn1 libffi-dev libssl-dev build-essential $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  O conjunto completo de comandos para instalar um cliente openstack com o plug-in necessário para sistemas operacionais da família Fedora / CentOS: </p><br><pre> <code class="bash hljs">$ sudo yum -y install python-pip gcc libffi-devel python-devel libxslt-devel openssl-devel git libffi-devel $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  Para gerenciar objetos Kubernetes, você precisa do cliente do console <strong>kubectl</strong> .  Os métodos de instalação para vários sistemas operacionais são descritos na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">documentação oficial</a> . </p><br><p>  Para criar um cluster, você precisará criar ou usar os existentes: </p><br><ul><li>  <strong>Modelo de</strong> cluster; </li><li>  Um conjunto de parâmetros para a CPU e RAM de máquinas virtuais ( <strong>sabor</strong> ). </li></ul><br><p>  Você pode criar um modelo de cluster e criar um sabor próprio ou usar modelos públicos pré-criados. </p><br><p>  Você também precisará determinar a zona de disponibilidade, o tipo de discos para o cluster e o número de nós.  Vale considerar que ainda não suportamos a possibilidade de criar um cluster em várias zonas.  Você pode escolher qualquer tipo de unidade de rede (rápida, universal ou básica). <br>  Você pode aprender mais sobre os tipos de unidades em nossa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener noreferrer">base de conhecimento</a> . </p><br><p>  O número de nós pode ser diferente para funções <strong>mestre</strong> e <strong>subordinado</strong> .  Nos nós que executam a função principal, os elementos de controle do cluster serão ativados - <strong>controller-manager</strong> , <strong>scheduler</strong> , <strong>api</strong> .  Nos outros nós, os serviços <strong>kubelet</strong> , <strong>kube-proxy</strong> e todos os contêineres de aplicativos serão lançados.  Você pode aprender mais sobre os componentes que são executados nos nós do cluster na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">documentação oficial</a> . </p><br><p>  Para acessar nós via SSH, você precisará usar a chave SSH criada anteriormente.  Os comandos de amostra usarão uma chave chamada <strong>ssh-test</strong> . </p><br><p>  Usaremos o modelo e o sabor do cluster público, o tipo de disco rápido e a zona de disponibilidade do <strong>ru-1b</strong> . <br>  Em nosso cluster, 2 nós principais e 3 nós minion serão inicializados inicialmente. </p><br><p>  Para verificar esses parâmetros, usamos os comandos openstackclient e o arquivo de acesso baixado ( <strong>rc.sh</strong> ): </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#          . $ source rc.sh #  ,         $ openstack flavor show BL1.2-4096 -c ram -c vcpus +-------+-------+ | Field | Value | +-------+-------+ | ram | 4096 | | vcpus | 2 | +-------+-------+ #       ru-1b $ openstack volume type show fast.ru-1b -c name +-------+------------+ | Field | Value | +-------+------------+ | name | fast.ru-1b | +-------+------------+ #    Kubernetes $ openstack coe cluster template list -c name +---------------------------------------+ | name | +---------------------------------------+ | kubernetes-nofloatingips-ru-1b-v1.9.3 | | kubernetes-nofloatingips-ru-1b-v1.9.6 | | kubernetes-nofloatingips-ru-1b-v1.9.9 | | kubernetes-floatingips-ru-1b-v1.9.3 | | kubernetes-floatingips-ru-1b-v1.9.6 | | kubernetes-floatingips-ru-1b-v1.9.9 | | kubernetes-nofloatingips-ru-1a-v1.9.3 | | kubernetes-nofloatingips-ru-1a-v1.9.6 | | kubernetes-nofloatingips-ru-1a-v1.9.9 | | kubernetes-floatingips-ru-1a-v1.9.3 | | kubernetes-floatingips-ru-1a-v1.9.6 | | kubernetes-floatingips-ru-1a-v1.9.9 | +---------------------------------------+</span></span></code> </pre> <br><p>  Por exemplo, escolheremos o segundo modelo de cluster; endereços flutuantes publicamente acessíveis para cada um dos nós não serão criados a partir dele.  Nós não precisaremos deles. </p><br><pre> <code class="plaintext hljs">#   Kubernetes   test-cluster #   keypair   ,   $ openstack coe cluster create \ --cluster-template kubernetes-nofloatingips-ru-1b-v1.9.9 \ --master-count 2 \ --node-count 3 \ --keypair ssh-test \ --master-flavor BL1.2-4096 \ --flavor BL1.2-4096 \ test-cluster</code> </pre> <br><p>  <em>Observe que nós escolhemos a mesma configuração para nós diferentes (parâmetros de sabor principal e sabor), você pode escolher diferentes conjuntos de configurações, dependendo dos requisitos do cluster.</em>  <em>Sua mudança é possível após a sua criação.</em> </p><br><p>  Também vale a pena considerar que, ao criar um cluster com vários nós principais, um balanceador de carga será criado automaticamente para acessar a API do Kubernetes. </p><br><p>  Após alguns minutos, um cluster Kubernetes aparecerá no seu projeto.  No painel de controle do projeto, você verá novas máquinas virtuais, discos e objetos de rede. </p><br><p>  Você pode verificar o status do seu cluster através do openstackclient: </p><br><pre> <code class="bash hljs">openstack coe cluster list -c name -c status +--------------+--------------------+ | name | status | +--------------+--------------------+ | <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster | CREATE_IN_PROGRESS | +--------------+--------------------+</code> </pre> <br><p>  Depois que o cluster entra no estado CREATE_COMPLETE, você pode gerenciar seus objetos através do utilitário kubectl baixando o arquivo de configuração usando os seguintes comandos: </p><br><pre> <code class="bash hljs">$ mkdir -p ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster $ openstack coe cluster config <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster --dir ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster</code> </pre> <br><p>  Depois disso, você pode trabalhar com o cluster usando o utilitário kubectl: </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KUBECONFIG=~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster/config $ kubectl get pods --all-namespaces -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase NAME STATUS coredns-785dcf9c58-6gnfp Running heapster-6846cdc674-rm4k6 Running kube-dns-autoscaler-6b94f7bbf8-x5clt Running kubernetes-dashboard-747575c864-wlg6p Running monitoring-grafana-84b4596dd7-zf5rx Running monitoring-influxdb-c8486fc95-bqqb6 Running node-exporter-test-cluster-robvp4cvwpt7-minion-0 Running</code> </pre> <br><p>  Se necessário, você pode aumentar ou diminuir o número de nós minion no cluster por meio do openstackclient passando o novo valor node_count: </p><br><pre> <code class="bash hljs">$ openstack coe cluster update <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster replace node_count=4</code> </pre> <br><h2>  Principais objetos de cluster do Kubernetes </h2><br><h3>  Pods </h3><br><p>  Embora o Kubernetes gerencie um conjunto de contêineres, a entidade subjacente que o Kubernetes gerencia não é um contêiner, mas um <strong>Pod</strong> . </p><br><p>  Pod é um conjunto de namespaces do kernel do Linux e configurações de pilha de rede que permitem montar um conjunto de contêineres em uma única entidade. <br>  Na maioria das vezes, um contêiner com o aplicativo é iniciado dentro de um Pod separado. <br>  Se necessário, você pode executar vários contêineres dentro de um Pod, isso pode ser útil quando você precisar fornecer acesso de um contêiner para outro por meio da interface de rede localhost ou, por algum outro motivo, executar vários contêineres no mesmo host. <br>  Todos os contêineres em execução no mesmo Pod terão um nome de host, endereço IP, tabela de roteamento e discos. </p><br><p>  É importante notar que, ao dimensionar o número de instâncias do seu aplicativo no Kubernetes, é necessário aumentar o número de Pods, e não o número de contêineres em um Pod específico. <br>  Mais detalhes na documentação oficial dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">pods</a> . </p><br><p>  Por exemplo, vamos criar o Pod mais simples com o Nginx usando a descrição no formato yaml: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-basic.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Para criar um Pod, podemos usar o utilitário <strong>kubectl</strong> . <br>  Adicionamos todos os exemplos apresentados no artigo ao nosso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">grupo Github</a> , para que você não possa criar arquivos no seu computador, mas use o URL do arquivo do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">repositório</a> público: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-basic.yaml</code> </pre> <br><p>  Após a criação, podemos solicitar informações completas sobre o status do Pod usando o comando kubectl description: </p><br><pre> <code class="bash hljs">$ kubectl describe pod nginx Name: nginx Namespace: default Node: <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0/10.0.0.5 Start Time: Sun, 17 Jun 2018 12:29:03 +0000 Labels: &lt;none&gt; Annotations: &lt;none&gt; Status: Running IP: 10.100.88.9 Containers: nginx: Container ID: docker://6ca6383b66686c05c61c1f690737110e0f8994eda393f44a7ebfbbf2b2026267 Image: library/nginx:1.14-alpine Image ID: docker-pullable://docker.io/nginx@sha256:944b79ca7dbe456ce72e73e70816c1990e39967c8f010349a388c00b77ec519c Port: 80/TCP Host Port: 0/TCP State: Running Started: Sun, 17 Jun 2018 12:29:16 +0000 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-rp5ls (ro) Conditions: Type Status Initialized True Ready True PodScheduled True Volumes: default-token-rp5ls: Type: Secret (a volume populated by a Secret) SecretName: default-token-rp5ls Optional: <span class="hljs-literal"><span class="hljs-literal">false</span></span> QoS Class: BestEffort Node-Selectors: &lt;none&gt; Tolerations: &lt;none&gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 52s default-scheduler Successfully assigned nginx to <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Normal SuccessfulMountVolume 51s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 MountVolume.SetUp succeeded <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> volume <span class="hljs-string"><span class="hljs-string">"default-token-rp5ls"</span></span> Normal Pulling 50s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 pulling image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Pulled 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Successfully pulled image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Created 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Created container Normal Started 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Started container</code> </pre> <br><p>  Como você pode ver, o Pod foi iniciado em um nó chamado test-cluster-nd5c5y6lsfxb-minion-0 e recebeu um endereço IP interno de 10.100.88.9. </p><br><p>  Na seção Eventos, você pode ver os principais eventos de inicialização - selecionando um nó para iniciar e fazer o download da imagem. </p><br><p>  Podemos entrar no Pod e verificar o status dos processos dentro do contêiner: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh ps aux PID USER TIME COMMAND 1 root 0:00 nginx: master process nginx -g daemon off; 7 nginx 0:00 nginx: worker process 20 root 0:00 sh 24 root 0:00 ps aux <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Deve-se ter em mente que o endereço IP 10.100.88.9 não estará disponível para outros aplicativos dentro e fora do cluster Kubernetes; o acesso ao Nginx em execução será possível apenas dentro do próprio Pod: </p><br><pre> <code class="bash hljs">$ ping -c 1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes --- 10.100.88.9 ping statistics --- 1 packets transmitted, 0 packets received, 100% packet loss $ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> nginx -- ping -c1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes 64 bytes from 10.100.88.9: seq=0 ttl=64 time=0.075 ms --- 10.100.88.9 ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 0.075/0.075/0.075 ms</code> </pre> <br><p>  Além do fato de o endereço IP especificado estar acessível apenas no contêiner, ele também não é permanente.  Isso significa que, se este Pod for recriado, ele poderá obter um endereço IP diferente. </p><br><p>  Para resolver esses problemas, você pode usar um objeto chamado Serviço. </p><br><h3>  Serviços </h3><br><p>  O serviço permite atribuir endereços IP permanentes para os Pods, fornecer acesso a partir de redes externas e equilibrar solicitações entre os Pods. <br>  Você pode aprender mais sobre o serviço na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">documentação oficial</a> . </p><br><p>  Por exemplo, precisamos remover o Pod em execução: </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  Adicione à descrição do Pod um rótulo (Label), necessário para o Serviço: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-labeled.yaml apiVersion: v1 kind: Pod metadata: name: nginx labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Também precisaremos de uma descrição do Serviço: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-nodeport.yaml apiVersion: v1 kind: Service metadata: name: nginx-nodeport labels: app: webservice spec: type: NodePort ports: - port: 80 nodePort: 30001 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  Crie Pod e Serviço: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-labeled.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-nodeport.yaml</code> </pre> <br><p>  Como o Serviço criado é do tipo NodePort, a porta 30001 indicada por nós em todas as interfaces de rede será aberta em todos os nós do cluster. <br>  Isso significa que, se adicionarmos um endereço IP externo a qualquer nó, podemos acessar o Pod em execução com o Nginx a partir de uma rede externa. </p><br><p>  Para não usar os endereços externos dos nós do cluster para acessar o Serviço, podemos usar o tipo LoadBalancer em vez de NodePort. <br>  Vamos precisar de uma nova descrição do serviço: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-loadbalancer.yaml apiVersion: v1 kind: Service metadata: name: nginx-loadbalancer labels: app: webservice spec: type: LoadBalancer ports: - port: 80 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  Exclua o serviço atual e aplique a nova descrição: </p><br><pre> <code class="bash hljs">$ kubectl delete service nginx-service $ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-loadbalancer.yaml</code> </pre> <br><p>  Depois de iniciar o serviço, o Nginx estará disponível na porta TCP 80 a partir de uma rede externa e não será necessário atribuir e usar endereços externos para os nós do cluster.  O serviço do tipo LoadBalancer alocará automaticamente um novo endereço externo para o seu projeto VPC e começará a usá-lo. </p><br><p>  Você pode obter informações sobre o endereço externo destacado usando o kubectl: </p><br><pre> <code class="bash hljs">$ kubectl get service nginx-service -o=custom-columns=IP:status.loadBalancer.ingress[0].ip IP xxx.xxx.xxx.xxx</code> </pre> <br><p>  Nos nossos exemplos, apenas um Pod foi lançado com o Nginx.  Para dimensionar o aplicativo para mais pods, podemos usar a implantação. </p><br><h3>  Implantações </h3><br><p>  A implantação é a essência do cluster Kubernetes, que permite dimensionar os Pods e atualizar ou reverter convenientemente as versões para um grande número de Pods. <br>  Em vez de Implantação, você também pode usar o objeto ReplicaSet, mas não o tocaremos em nossos exemplos. <br>  Você pode aprender mais sobre implantação na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">documentação oficial</a> . </p><br><p>  Novamente, precisamos remover o Pod (não precisamos remover o Serviço): </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  Adicione a seguinte descrição de implantação: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.14.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Crie a implantação especificada: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.14.yaml</code> </pre> <br><p>  Escolhemos 10 para o parâmetro replicas, para que 10 Pods com o aplicativo Nginx sejam criados em nosso cluster: </p><br><pre> <code class="bash hljs">$ kubectl get pods --selector app=webservice NAME READY STATUS RESTARTS AGE nginx-deployment-54bfdc4489-42rrb 1/1 Running 0 4m nginx-deployment-54bfdc4489-5lvtc 1/1 Running 0 4m nginx-deployment-54bfdc4489-g7rk2 1/1 Running 0 4m nginx-deployment-54bfdc4489-h5rxp 1/1 Running 0 4m nginx-deployment-54bfdc4489-l9l2d 1/1 Running 0 4m nginx-deployment-54bfdc4489-pjpvg 1/1 Running 0 4m nginx-deployment-54bfdc4489-q8dnp 1/1 Running 0 4m nginx-deployment-54bfdc4489-s4wzf 1/1 Running 0 4m nginx-deployment-54bfdc4489-tfxf9 1/1 Running 0 4m nginx-deployment-54bfdc4489-xjzb5 1/1 Running 0 4m</code> </pre> <br><p>  Você pode acessar o aplicativo em execução na rede externa usando o Serviço criado na seção anterior.  O serviço equilibrará automaticamente as solicitações da rede externa entre 10 instâncias do Nginx. </p><br><p>  Se necessário, podemos atualizar a versão do Nginx.  Atualize a descrição de Implantação, alterando a versão da imagem de 1,14-alpino para 1,15-alpino: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.15.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.15-alpine # &lt;-- changed ports: - containerPort: 80</span></span></code> </pre> <br><p>  Para iniciar o processo de atualização dos Pods, usamos o comando kubectl.  Preste atenção ao argumento --record, é útil para a conveniente reversão subsequente da versão do Nginx: </p><br><pre> <code class="bash hljs">$ kubectl apply -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml \ --record</code> </pre> <br><p>  Você pode monitorar o andamento da atualização usando o seguinte comando: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 4 out of 10 new replicas have been updated...</code> </pre> <br><p>  O Kubernetes aguardará 10 segundos após uma atualização bem-sucedida de um Pod, pois especificamos o valor 10 para o parâmetro minReadySeconds na descrição da Implantação. </p><br><p>  Após a conclusão da atualização, todos os Pods for Deployment entrarão em um estado ativo: </p><br><pre> <code class="bash hljs">$ kubectl get deployment --selector app=webservice NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 10 10 10 10 23m</code> </pre> <br><p>  Podemos reverter a versão do aplicativo se algo der errado.  Para fazer isso, precisamos selecionar a revisão de implantação desejada: </p><br><pre> <code class="bash hljs">$ kubectl rollout <span class="hljs-built_in"><span class="hljs-built_in">history</span></span> deployment nginx-deployment deployments <span class="hljs-string"><span class="hljs-string">"nginx-deployment"</span></span> REVISION CHANGE-CAUSE 1 &lt;none&gt; 2 kubectl apply --filename=https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml --record=<span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br><p>  Existem 2 revisões na saída do comando - a primeira é a criação inicial do Deployment, a segunda é uma atualização.  Como usamos o argumento --record ao atualizar, vemos o comando que criou a segunda revisão do Deployment. </p><br><p>  Para reverter a versão, use o seguinte comando: </p><br><pre> <code class="bash hljs">$ kubectl rollout undo deployment nginx-deployment --to-revision=1</code> </pre> <br><p>  Da mesma forma com a atualização, podemos monitorar a reversão da versão usando o comando: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 6 out of 10 new replicas have been updated…</code> </pre> <br><p>  Em todos os nossos exemplos, usamos contêineres sem um armazenamento de dados persistente.  Na próxima seção, vamos corrigi-lo. </p><br><h2>  Armazenamento de dados </h2><br><p>  Por padrão, todos os dados dos contêineres em execução nos Pods são efêmeros e serão perdidos quando os Pods falham. </p><br><p>  Você pode usar o objeto PersistentVolumeClaim para executar Pods com um data warehouse persistente. </p><br><p>  Criar um objeto desse tipo em um cluster é muito simples - basta adicionar sua descrição, semelhante à maneira como criamos Pod, Serviço ou Implantação nas seções anteriores. </p><br><p>  Mais informações podem ser encontradas na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">documentação oficial</a> . </p><br><p>  Descrição de exemplo de PersistentVolumeClaim criando um disco de 10 GB: </p><br><pre> <code class="bash hljs">apiVersion: v1 kind: PersistentVolumeClaim metadata: name: my-pv-claim spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi</code> </pre> <br><p>  Podemos conectá-lo como um disco ao nosso Pod atualizando a descrição do Pod com o Nginx criado anteriormente: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-with-volume.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80 volumeMounts: - mountPath: "/var/www/html" name: data volumes: - name: data persistentVolumeClaim: claimName: my-pv-claim</span></span></code> </pre> <br><p>  No entanto, para que o disco seja criado, você precisará especificar as propriedades do disco criado na forma de StorageClass.  No serviço "Nuvem privada virtual", você pode usar unidades de rede de tipos rápido, universal e básico como armazenamento permanente de dados do Kubernetes Pod. </p><br><p>  Por exemplo, para criar um StorageClass que permita o uso de discos rápidos na zona de disponibilidade do ru-1b, você precisa da seguinte descrição: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># fast.ru-1b.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: fast.ru-1b annotations: storageclass.beta.kubernetes.io/is-default-class: "true" provisioner: kubernetes.io/cinder parameters: type: fast.ru-1b availability: ru-1b</span></span></code> </pre> <br><p>  Antes de criar os objetos especificados, exclua a Implantação criada anteriormente: </p><br><pre> <code class="bash hljs">$ kubectl delete deployment nginx-deployment</code> </pre> <br><p>  Primeiro, vamos criar uma StorageClass, para que ela se torne a classe padrão, e o PersistentVolumeClaim criado posteriormente a usará: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/storageclasses/fast.ru-1b.yaml</code> </pre> <br><p>  Crie PersistentVolumeClaim e Pod: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/persistentvolumeclaims/my-pv-claim.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-with-volume.yaml</code> </pre> <br><p>  Depois disso, um disco será criado automaticamente em seu projeto, que será conectado a um dos nós subordinados do cluster.  Quando cai, o disco muda automaticamente para outro nó. </p><br><p>  Podemos ver o disco dentro do contêiner com o Nginx: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh mount | grep <span class="hljs-string"><span class="hljs-string">"/var/www/html"</span></span> /dev/sdc on /var/www/html <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> ext4 (rw,seclabel,relatime,data=ordered) <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Você pode conectar a unidade ao Deployment.  Um exemplo correspondente pode ser encontrado na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">documentação oficial</a> . </p><br><h2>  Painel de Controle Kubernetes </h2><br><p>  Você pode usar o painel interno do próprio Kubernetes para exibir o status dos objetos de cluster e seu gerenciamento. </p><br><p>  Para acessar todos os recursos do painel, você precisará criar uma conta com a função de administrador em seu cluster. </p><br><p>  Para fazer isso, precisamos de uma descrição da conta: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># admin-user.yaml apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  E descrição da função: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cluster-admin.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  Crie os objetos especificados: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/accounts/admin-user.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/clusterrolebindings/cluster-admin.yaml</code> </pre> <br><p>  Em seguida, você precisará descobrir o valor do token gerado para esta conta. <br>  Para fazer isso, localize o objeto Secreto correspondente no cluster: </p><br><pre> <code class="bash hljs">$ kubectl get secret --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"admin-user-token"</span></span> admin-user-token-bkfhb kubernetes.io/service-account-token 3 22m</code> </pre> <br><p>  E observe o valor do token do Segredo encontrado com o nome admin-user-token-bkfhb: </p><br><pre> <code class="bash hljs">$ kubectl describe secret admin-user-token-bkfhb --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"token:"</span></span> token: XXXXXX...</code> </pre> <br><p>  Em resposta, você receberá o valor do token, salve-o, será útil para nós no futuro. <br>  Para detalhes de controle de acesso para objetos Kubernetes, consulte a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">documentação oficial</a> . </p><br><p>  Caso você tenha criado um cluster a partir de um modelo público, o Pod e o Serviço já existem nele para garantir a operação do painel: </p><br><pre> <code class="bash hljs">$ kubectl get svc kubernetes-dashboard --namespace=kube-system 206ms Tue Jun 19 14:35:19 2018 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard ClusterIP 10.254.122.245 &lt;none&gt; 443/TCP 2d $ kubectl get pod --namespace=kube-system --selector k8s-app=kubernetes-dashboard 119ms Tue Jun 19 14:36:48 2018 NAME READY STATUS RESTARTS AGE kubernetes-dashboard-747575c864-jpxvt 1/1 Running 0 2d</code> </pre> <br><p>  Como o Serviço é do tipo ClusterIP, ele estará disponível apenas no próprio cluster. <br>  Você pode acessar o painel do seu computador em funcionamento com o arquivo de configuração do cluster usando o comando kubectl: </p><br><pre> <code class="bash hljs">$ kubectl proxy Starting to serve on 127.0.0.1:8001</code> </pre> <br><p>  Teste o proxy abrindo o endereço especificado no navegador: </p><br><img src="https://habrastorage.org/webt/lc/zm/k1/lczmk1ud4tjatfu3lthvkrcu66e.png"><br><p>  Se você encontrar uma resposta semelhante à captura de tela, poderá ir para a tela do painel de controle usando o seguinte endereço: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</code> </pre> <br><p>  Passando por isso, você deve ver a tela de login no painel: </p><br><img src="https://habrastorage.org/webt/60/fj/p5/60fjp5-2xjyn_p5mz-jh_ozwzxe.png"><br><p>  Você precisará especificar o token recebido anteriormente.  Após o login, você pode usar o painel de controle: </p><br><img src="https://habrastorage.org/webt/38/ry/dr/38rydrraxndpo0hyqhnm-k1nb_k.png"><br><p>  Você pode descobrir todos os recursos do painel de controle na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener noreferrer">documentação oficial</a> . </p><br><h2>  Monitorando objetos Kubernetes </h2><br><p>  Se você usar o modelo de cluster público, executará automaticamente os componentes para coletar e exibir métricas - Prometheus e Grafana. </p><br><p>  Da mesma forma que no painel de controle, o ClusterIP é instalado como o tipo de Serviço; o acesso a ele é possível apenas dentro do cluster ou através do proxy kubectl.  Você pode acessar o Grafana no seu computador de trabalho no seguinte endereço: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana:80</code> </pre> <br><img src="https://habrastorage.org/webt/p3/7e/go/p37egoksdoz8bvp8tsq2fgpsuru.png"><br><h2>  Conclusão </h2><br><p>  Neste artigo, examinamos os objetos Kubernetes mais usados ​​e analisamos exemplos de como iniciar e gerenciar um cluster usando o OpenStack Magnum. </p><br><p>  Num futuro próximo, será possível usar as versões mais recentes do Kubernetes, e o gerenciamento de cluster estará disponível <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no painel de controle</a> . </p><br><p>  Ficaremos contentes se você usar nosso serviço no modo de teste e fornecer feedback. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt416951/">https://habr.com/ru/post/pt416951/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt416941/index.html">Teoria da felicidade. Introdução à Merfologia</a></li>
<li><a href="../pt416943/index.html">Materiais úteis para projetar interfaces de voz</a></li>
<li><a href="../pt416945/index.html">Como fizemos o BelAZ. Parte 1 - Ferro</a></li>
<li><a href="../pt416947/index.html">Jogue o jogo antes das Olimpíadas: eSports se torna oficial</a></li>
<li><a href="../pt416949/index.html">A atualização em larga escala do Sr. Steven para instalar uma rede de caça quatro vezes maior foi concluída</a></li>
<li><a href="../pt416953/index.html">Crie um sombreador de água de desenho animado para a web. Parte 1</a></li>
<li><a href="../pt416955/index.html">Pequenos truques com Elasticsearch</a></li>
<li><a href="../pt416957/index.html">Qual máquina a laser comprar? Revisão confiável da máquina a laser Raylogic 11G</a></li>
<li><a href="../pt416959/index.html">Apple apresenta novo recurso anti-roubo para iOS</a></li>
<li><a href="../pt416961/index.html">Resolução automática de conflitos usando transformações operacionais</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
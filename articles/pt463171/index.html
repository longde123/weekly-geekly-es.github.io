<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üàØÔ∏è üÜî üë®üèΩ‚Äçü§ù‚Äçüë®üèº Redes neurais e aprendizado profundo: um tutorial on-line, cap√≠tulo 6, parte 1: aprendizado profundo ü§û ‚è∏Ô∏è ‚úä</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Conte√∫do 

- Cap√≠tulo 1: usando redes neurais para reconhecer n√∫meros manuscritos 
- Cap√≠tulo 2: como o algoritmo de retropropaga√ß√£o funciona 
- Cap√≠t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes neurais e aprendizado profundo: um tutorial on-line, cap√≠tulo 6, parte 1: aprendizado profundo</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/463171/"><div class="spoiler">  <b class="spoiler_title">Conte√∫do</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 1: usando redes neurais para reconhecer n√∫meros manuscritos</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 2: como o algoritmo de retropropaga√ß√£o funciona</a> </li><li>  Cap√≠tulo 3: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 1: aprimorando o m√©todo de treinamento de redes neurais</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 2: Por que a regulariza√ß√£o ajuda a reduzir a reciclagem?</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 3: como escolher hiperpar√¢metros de redes neurais?</a> <br></li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 4: prova visual de que as redes neurais s√£o capazes de computar qualquer fun√ß√£o</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 5: por que as redes neurais profundas s√£o t√£o dif√≠ceis de treinar?</a> </li><li>  Cap√≠tulo 6: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 1: Aprendizado Profundo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 2: progresso recente no reconhecimento de imagens</a> </li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Posf√°cio: existe um algoritmo simples para criar intelig√™ncia?</a> </li></ul></div></div><br>  No √∫ltimo cap√≠tulo, aprendemos que as redes neurais profundas (GNSs) s√£o muitas vezes mais dif√≠ceis de treinar do que as rasas.  E isso √© ruim, porque temos todos os motivos para acreditar que, se pud√©ssemos treinar o STS, eles seriam muito melhores nas tarefas.  Mas, embora as not√≠cias do cap√≠tulo anterior sejam decepcionantes, elas n√£o nos impedir√£o.  Neste cap√≠tulo, desenvolveremos t√©cnicas que podemos usar para treinar redes profundas e coloc√°-las em pr√°tica.  Tamb√©m examinaremos a situa√ß√£o de maneira mais ampla, nos familiarizaremos brevemente com o recente progresso no uso do GNS para reconhecimento de imagem, fala e outras aplica√ß√µes.  E tamb√©m considere superficialmente o futuro que as redes neurais e a IA podem esperar. <br><br>  Este ser√° um longo cap√≠tulo, ent√£o vamos examinar um pouco o √≠ndice.  Suas se√ß√µes n√£o est√£o fortemente interconectadas; portanto, se voc√™ tiver alguns conceitos b√°sicos sobre redes neurais, poder√° come√ßar pela se√ß√£o que mais lhe interessa. <br><br>  A parte principal do cap√≠tulo √© uma introdu√ß√£o a um dos tipos mais populares de redes profundas: redes profundas de convolu√ß√£o (GSS).  Trabalharemos com um exemplo detalhado do uso de uma rede de convolu√ß√£o, com um c√≥digo e outras coisas, para resolver o problema de classifica√ß√£o de d√≠gitos manuscritos do conjunto de dados MNIST: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/839/d0b/543/839d0b54370af70f06b3f097897de457.png"><br><a name="habracut"></a><br>  Come√ßamos nossa revis√£o de redes convolucionais com redes rasas, que usamos para resolver esse problema no in√≠cio do livro.  Em v√°rias etapas, criaremos redes cada vez mais poderosas.  Ao longo do caminho, conheceremos muitas tecnologias poderosas: convolu√ß√µes, pooling, uso de GPUs para aumentar seriamente a quantidade de treinamento em compara√ß√£o com o que fizemos com redes rasas, expans√£o algor√≠tmica dos dados de treinamento (para reduzir o overfitting), usando a tecnologia de abandono (tamb√©m para reduzir a reciclagem), usando conjuntos de redes e outros.  Como resultado, chegaremos a um sistema cujas habilidades est√£o quase no n√≠vel humano.  Das 10.000 imagens de verifica√ß√£o MNIST - que o sistema n√£o viu durante o treinamento - ele poder√° reconhecer corretamente o 9967. E aqui est√£o algumas dessas imagens que n√£o foram reconhecidas corretamente.  No canto superior direito, est√£o as op√ß√µes corretas;  o que o nosso programa mostrou est√° indicado no canto inferior direito. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b6e/2d7/69a/b6e2d769a802b1ae5f249932789f2dff.png"><br><br>  Muitos deles s√£o dif√≠ceis de classificar para os seres humanos.  Pegue, por exemplo, o terceiro d√≠gito na linha superior.  Parece-me mais como "9" do que a vers√£o oficial de "8".  Nossa rede tamb√©m decidiu que era "9".  Pelo menos, esses erros podem ser totalmente compreendidos e talvez at√© aprovados.  Conclu√≠mos nossa discuss√£o sobre reconhecimento de imagem com uma vis√£o geral do tremendo progresso recentemente alcan√ßado pela rede neural (em particular, convolucionais). <br><br>  O restante do cap√≠tulo √© dedicado a uma discuss√£o sobre aprendizado profundo, de um ponto de vista mais amplo e menos detalhado.  Consideraremos brevemente outros modelos de NS, em particular, NSs recorrentes e unidades de mem√≥ria de curto prazo de longo prazo, e como esses modelos podem ser usados ‚Äã‚Äãpara resolver problemas no reconhecimento de fala, processamento de linguagem natural e outros.  Discutiremos o futuro do NS e da defesa civil, desde id√©ias como interfaces de usu√°rio orientadas por inten√ß√£o at√© o papel do aprendizado profundo na IA. <br><br>  Este cap√≠tulo √© baseado no material dos cap√≠tulos anteriores do livro, usando e integrando id√©ias como retropropaga√ß√£o, regulariza√ß√£o, softmax e assim por diante.  No entanto, para ler este cap√≠tulo, n√£o √© necess√°rio elaborar o material de todos os cap√≠tulos anteriores.  No entanto, n√£o custa ler o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 1</a> e aprender sobre o b√°sico da Assembl√©ia Nacional.  Quando uso os conceitos dos cap√≠tulos 2 a 5, darei os links necess√°rios para o material, conforme necess√°rio. <br><br>  Vale a pena notar que este cap√≠tulo n√£o.  Este n√£o √© um material de treinamento nas bibliotecas mais recentes e legais para trabalhar com o NS.  N√£o vamos treinar STS com dezenas de camadas para resolver problemas a partir da vanguarda da pesquisa.  Vamos tentar entender alguns dos princ√≠pios b√°sicos subjacentes ao GNS e aplic√°-los ao contexto simples e f√°cil de entender das tarefas do MNIST.  Em outras palavras, este cap√≠tulo n√£o o levar√° √† vanguarda da regi√£o.  O desejo deste e dos cap√≠tulos anteriores √© concentrar-se no b√°sico e preparar voc√™ para entender uma ampla gama de obras contempor√¢neas. <br><br><h2>  Introdu√ß√£o √†s redes neurais convolucionais </h2><br>  Nos cap√≠tulos anteriores, ensinamos √†s nossas redes neurais que √© muito bom reconhecer imagens de n√∫meros manuscritos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/839/d0b/543/839d0b54370af70f06b3f097897de457.png"><br><br>  Fizemos isso usando redes nas quais as camadas vizinhas estavam completamente conectadas umas √†s outras.  Ou seja, cada neur√¥nio da rede foi associado a cada neur√¥nio da camada vizinha: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/248/73a/b05/24873ab052991e684b9ff0650c11a1c4.png"><br><br>  Em particular, codificamos a intensidade de cada pixel na imagem como um valor para o neur√¥nio correspondente da camada de entrada.  Para imagens com tamanho de 28x28 pixels, isso significa que a rede ter√° 784 (= 28 √ó 28) neur√¥nios recebidos.  Em seguida, treinamos os pesos e as compensa√ß√µes da rede para que a sa√≠da (houvesse essa esperan√ßa) identificasse corretamente a imagem recebida: '0', '1', '2', ..., '8' ou '9'. <br><br>  Nossas redes iniciais funcionam muito bem: alcan√ßamos uma precis√£o de classifica√ß√£o acima de 98% usando dados de treinamento e teste dos d√≠gitos manuscritos do MNIST.  Mas se voc√™ avaliar essa situa√ß√£o agora, parece estranho usar uma rede com camadas totalmente conectadas para classificar imagens.  O fato √© que essa rede n√£o leva em conta a estrutura espacial das imagens.  Por exemplo, aplica-se exatamente a pixels localizados longe um do outro, bem como a pixels vizinhos.  Sup√µe-se que conclus√µes sobre tais conceitos de estrutura espacial devam ser feitas com base no estudo de dados de treinamento.  Mas e se, em vez de iniciar a estrutura de rede do zero, usaremos uma arquitetura tentando tirar proveito da estrutura espacial?  Nesta se√ß√£o, descrevo redes neurais convolucionais (SNA).  Eles usam uma arquitetura especial, especialmente adequada para classificar imagens.  Com o uso dessa arquitetura, os SNAs aprendem mais rapidamente.  E isso nos ajuda a treinar redes mais profundas e em camadas que fazem um bom trabalho na classifica√ß√£o de imagens.  Hoje, SNA profundo ou alguma variante semelhante √© usada na maioria dos casos de reconhecimento de imagem. <br><br>  As origens do SNA remontam √† d√©cada de 1970.  Mas o trabalho inicial, que iniciou sua distribui√ß√£o moderna, foi o trabalho de 1998, " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gradient Learning for Recognizing Documents</a> ".  Lekun fez uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">observa√ß√£o</a> interessante sobre a terminologia usada no SNA: ‚ÄúA conex√£o de modelos como redes convolucionais com neurobiologia √© muito superficial.  Portanto, eu os chamo de redes convolucionais, n√£o redes neurais convolucionais, e, portanto, chamamos seus elementos de n√≥s, n√£o neur√¥nios ".  Mas, apesar disso, o SNA usa muitas id√©ias do mundo NS que j√° estudamos: propaga√ß√£o de retorno, descida gradiente, regulariza√ß√£o, fun√ß√µes de ativa√ß√£o n√£o linear, etc.  Portanto, seguiremos o acordo geralmente aceito e os consideraremos como uma esp√©cie de NA.  Vou cham√°-los de redes e redes neurais, e seus n√≥s - neur√¥nios e elementos. <br><br>  O SNA usa tr√™s id√©ias b√°sicas: campos receptivos locais, pesos totais e pool.  Vamos dar uma olhada nessas id√©ias, por sua vez. <br><br><h3>  Campos receptivos locais </h3><br>  Nas camadas de rede totalmente conectadas, as camadas de entrada s√£o indicadas por linhas verticais de neur√¥nios.  No SNA, √© mais conveniente representar a camada de entrada na forma de um quadrado de neur√¥nios com uma dimens√£o de 28x28, cujos valores correspondem √†s intensidades de pixel da imagem 28x28: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/da3/848/9d0/da38489d04325743131546e76f99396d.png"><br><br>  Como sempre, associamos os pixels recebidos a uma camada de neur√¥nios ocultos.  No entanto, n√£o associaremos todos os pixels a todos os neur√¥nios ocultos.  Organizamos as comunica√ß√µes em pequenas √°reas localizadas da imagem recebida. <br><br>  Mais precisamente, cada neur√¥nio da primeira camada oculta ser√° associado a uma pequena por√ß√£o dos neur√¥nios recebidos, por exemplo, uma regi√£o 5x5 correspondente a 25 pixels recebidos.  Portanto, para alguns neur√¥nios ocultos, a conex√£o pode ser assim: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cf9/71d/5dc/cf971d5dc7106f1c56832c8416d7847a.png"><br><br>  Essa parte da imagem recebida √© chamada de campo receptivo local para esse neur√¥nio oculto.  Essa √© uma pequena janela observando os pixels recebidos.  Cada v√≠nculo aprende seu peso.  Al√©m disso, um neur√¥nio oculto estuda o deslocamento geral.  Podemos assumir que esse neur√¥nio em particular est√° aprendendo a analisar seu campo receptivo local espec√≠fico. <br><br>  Em seguida, movemos o campo receptivo local pela imagem recebida.  Cada campo receptivo local possui seu pr√≥prio neur√¥nio oculto na primeira camada oculta.  Para uma ilustra√ß√£o mais espec√≠fica, comece com o campo receptivo local no canto superior esquerdo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c41/5cd/64d/c415cd64dfc93b81b89395ae360026c1.png"><br><br>  Mova o campo receptivo local um pixel para a direita (um neur√¥nio) para associ√°-lo ao segundo neur√¥nio oculto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db1/285/a7a/db1285a7a7009e0210e97253061054f3.png"><br><br>  Ent√£o, constru√≠mos a primeira camada oculta.  Observe que, se nossa imagem recebida for 28x28 e o campo receptivo local for 5x5, haver√° 24x24 neur√¥nios na camada oculta.  Isso ocorre porque s√≥ podemos mover o campo receptivo local por 23 neur√¥nios para a direita (ou para baixo) e, em seguida, encontraremos o lado direito (ou inferior) da imagem recebida. <br><br>  Neste exemplo, os campos receptivos locais movem um pixel de cada vez.  Mas, √†s vezes, um tamanho de etapa diferente √© usado.  Por exemplo, podemos mudar o campo receptivo local 2 pixels para o lado e, neste caso, podemos falar sobre o tamanho da etapa 2. Neste cap√≠tulo, usaremos principalmente a etapa 1, mas voc√™ deve saber que, √†s vezes, s√£o realizadas experi√™ncias com etapas de tamanho diferente. .  Voc√™ pode experimentar o tamanho da etapa, como em outros hiperpar√¢metros.  Voc√™ tamb√©m pode alterar o tamanho do campo receptivo local, mas geralmente acontece que um tamanho maior do campo receptivo local funciona melhor em imagens significativamente maiores que 28x28 pixels. <br><br><h3>  Pesos totais e compensa√ß√µes </h3><br>  Mencionei que cada neur√¥nio oculto tem um deslocamento e pesos 5x5 associados ao seu campo receptivo local.  Mas n√£o mencionei que usaremos os mesmos pesos e deslocamentos para todos os neur√¥nios ocultos 24x24.  Em outras palavras, para um neur√¥nio oculto j, k, a sa√≠da ser√° igual a: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mtext>&amp;#xA0;</mtext><mi>l</mi><mi>e</mi><mi>f</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>+</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>l</mi><mo>=</mo><mn>0</mn></mrow><mn>4</mn></msubsup><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mn>4</mn></msubsup><msub><mi>w</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msub><msub><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi><mo>+</mo><mi>l</mi><mo>,</mo><mi>k</mi><mo>+</mo><mi>m</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>r</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>a</mi><mi>g</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>125</mn></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="58.874ex" height="3.021ex" viewBox="0 -883.9 25348.3 1300.8" role="img" focusable="false" style="vertical-align: -0.969ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6C" x="3203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-65" x="3502" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-66" x="3968" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-74" x="4519" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-28" x="4880" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-62" x="5270" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-2B" x="5921" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-73" x="7172" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-75" x="7641" y="0"></use><g transform="translate(8214,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-34" x="1242" y="488"></use><g transform="translate(878,-328)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-3D" x="298" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-30" x="1077" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-73" x="10558" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-75" x="11027" y="0"></use><g transform="translate(11600,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-34" x="1242" y="488"></use><g transform="translate(878,-308)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-3D" x="878" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-30" x="1657" y="0"></use></g></g><g transform="translate(14104,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-77" x="0" y="0"></use><g transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-2C" x="298" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6D" x="577" y="0"></use></g></g><g transform="translate(15950,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-61" x="0" y="0"></use><g transform="translate(529,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6A" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-2B" x="412" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6C" x="1191" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-2C" x="1489" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6B" x="1768" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-2B" x="2289" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-6D" x="3068" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-72" x="19620" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-69" x="20071" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-67" x="20417" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-68" x="20897" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-74" x="21474" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-29" x="21835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-74" x="22475" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-61" x="22836" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMATHI-67" x="23366" y="0"></use><g transform="translate(23846,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-32" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhiG-hvgDyo9MyWQZ0hICevQxPVDnw#MJMAIN-35" x="1001" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eu</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a</font></font></mi><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eu</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(</font></font></mo><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b</font></font></mi><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></mo><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vc</font></font></mi><msubsup><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eu</font></font></mi><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">=</font></font></mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0 0</font></font></mn></mrow><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4</font></font></mn></msubsup><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vc</font></font></mi><msubsup><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">=</font></font></mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0 0</font></font></mn></mrow><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4</font></font></mn></msubsup><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eu</font></font></mi><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,</font></font></mo><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi></mrow></msub><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></mi><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></mo><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eu</font></font></mi><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,</font></font></mo><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></mi><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></mo><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi></mrow></msub><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eu</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></mo><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">125</font></font></mn></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> \ sigma \ left (b + \ sum_ {l = 0} ^ 4 \ sum_ {m = 0} ^ 4 w_ {l, m} a_ {j + l, k + m} \ right) \ tag {125} </script></p><br><br>  Aqui œÉ √© a fun√ß√£o de ativa√ß√£o, possivelmente um sigm√≥ide dos cap√≠tulos anteriores.  b √© o valor total do deslocamento.  w <sub>l, m</sub> - conjunto de pesos totais 5x5.  E, finalmente, a <sub>x, y</sub> indica a ativa√ß√£o da entrada na posi√ß√£o x, y. <br><br>  Isso significa que todos os neur√¥nios da primeira camada oculta detectam o mesmo sinal, apenas localizados em diferentes partes da imagem.  Um sinal detectado por um neur√¥nio oculto √© uma certa sequ√™ncia de entrada que leva √† ativa√ß√£o de um neur√¥nio: talvez a borda da imagem ou alguma forma.  Para entender por que isso faz sentido, suponha que nossos pesos e deslocamentos sejam tais que um neur√¥nio oculto possa reconhecer, digamos, uma face vertical em um campo receptivo local espec√≠fico.  √â prov√°vel que essa capacidade seja √∫til em qualquer outro local da imagem.  Portanto, √© √∫til usar o mesmo detector de recursos em toda a √°rea da imagem.  Mais abstratamente, o SNA est√° bem adaptado √† invari√¢ncia translacional das imagens: mova a imagem, por exemplo, do gato, um pouco para o lado, e continuar√° sendo a imagem do gato.  √â verdade que as imagens do problema de classifica√ß√£o de d√≠gitos MNIST s√£o todas centralizadas e normalizadas em tamanho.  Portanto, o MNIST tem menos invari√¢ncia de tradu√ß√£o que as imagens aleat√≥rias.  Ainda assim, recursos como rostos e √¢ngulos provavelmente ser√£o √∫teis em toda a superf√≠cie da imagem recebida. <br><br>  Por esse motivo, √†s vezes nos referimos ao mapeamento de uma camada de entrada e de uma camada oculta como um mapa de recursos.  Pesos que definem o mapa de caracter√≠sticas, chamamos pesos totais.  E o vi√©s que define o mapa de recursos √© o vi√©s geral.  Costuma-se dizer que o peso total e o deslocamento determinam um n√∫cleo ou filtro.  Mas, na literatura, as pessoas √†s vezes usam esses termos por uma raz√£o um pouco diferente e, portanto, n√£o vou aprofundar na terminologia;  melhor, vamos ver alguns exemplos espec√≠ficos. <br><br>  A estrutura de rede descrita por mim √© capaz de reconhecer apenas um atributo localizado de uma esp√©cie.  Para reconhecer imagens, precisamos de mais mapas de recursos.  Portanto, a camada convolucional acabada consiste em v√°rios mapas de recursos diferentes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f84/5df/a57/f845dfa572668e27590c5bd1c057f849.png"><br><br>  O exemplo mostra 3 mapas de recursos.  Cada cart√£o √© determinado por um conjunto de pesos totais de 5x5 e um deslocamento comum.  Como resultado, essa rede pode reconhecer tr√™s tipos diferentes de sinais e cada sinal pode ser encontrado em qualquer parte da imagem. <br><br>  Eu desenhei tr√™s cartas de atributos por simplicidade.  Na pr√°tica, o SNA pode usar mais (possivelmente muito mais) mapas de recursos.  Um dos primeiros SNSs, LeNet-5, usava 6 cart√µes de fun√ß√µes, cada um dos quais associado a um campo receptivo 5x5, para reconhecer os d√≠gitos MNIST.  Portanto, o exemplo acima √© muito semelhante ao LeNet-5.  Nos exemplos que iremos desenvolver independentemente, usaremos camadas convolucionais contendo 20 e 40 cart√µes de recursos.  Vamos dar uma r√°pida olhada nos sinais que examinaremos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fad/a16/6b7/fada166b767b58edbff262944ee6488b.png"><br><br>  Essas 20 imagens correspondem a 20 mapas de atributos diferentes (filtros ou kernels).  Cada cart√£o √© representado por uma imagem 5x5 correspondente a pesos 5x5 do campo receptivo local.  Pixels brancos significam peso baixo (geralmente mais negativo), e o mapa de recursos reage menos aos pixels correspondentes.  Pixels mais escuros significam mais peso, e o mapa de recursos reage mais aos pixels correspondentes.  Grosso modo, essas imagens mostram aqueles sinais aos quais a camada convolucional responde. <br><br>  Que conclus√µes podem ser tiradas desses mapas de atributos?  As estruturas espaciais aqui, obviamente, n√£o apareceram de maneira aleat√≥ria - muitos sinais mostram √°reas claras de luz e escurid√£o.  Isso sugere que nossa rede est√° realmente aprendendo algo relacionado a estruturas espaciais.  No entanto, al√©m disso, √© bastante dif√≠cil entender quais s√£o esses sinais.  Obviamente, n√£o estudamos, digamos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filtros Gabor</a> , que foram usados ‚Äã‚Äãem muitas abordagens tradicionais para reconhecimento de padr√µes.  De fato, muito trabalho est√° sendo feito agora para melhor entender exatamente quais sinais s√£o estudados pelo SNA.  Se voc√™ estiver interessado, recomendo come√ßar em <a href="">2013</a> . <br><br>  A grande vantagem de pesos e compensa√ß√µes gerais √© que isso reduz drasticamente o n√∫mero de par√¢metros dispon√≠veis para o SNA.  Para cada mapa de recursos, precisamos de 5 √ó 5 = 25 pesos totais e um deslocamento comum.  Portanto, s√£o necess√°rios 26 par√¢metros para cada mapa de recursos.  Se tivermos 20 mapas de caracter√≠sticas, no total, teremos 20 √ó 26 = 520 par√¢metros que definem a camada de convolu√ß√£o.  Para compara√ß√£o, suponha que tenhamos uma primeira camada totalmente conectada com 28 √ó 28 = 784 neur√¥nios recebidos e relativamente modestos 30 neur√¥nios ocultos - usamos esse esquema em muitos exemplos anteriores.  Acontece 784 √ó 30 pesos, mais 30 compensa√ß√µes, um total de 23.550 par√¢metros.  Em outras palavras, uma camada totalmente conectada ter√° mais de 40 vezes mais par√¢metros que uma camada convolucional. <br><br>  Obviamente, n√£o podemos comparar diretamente o n√∫mero de par√¢metros, pois esses dois modelos diferem radicalmente.  Mas, intuitivamente, parece que o uso da invari√¢ncia translacional convolucional reduz o n√∫mero de par√¢metros necess√°rios para obter efici√™ncia compar√°vel √† de um modelo totalmente conectado.  E isso, por sua vez, acelerar√° o treinamento do modelo convolucional e, finalmente, nos ajudar√° a criar redes mais profundas usando camadas convolucionais. <br><br>  A prop√≥sito, o nome ‚Äúconvolucional‚Äù vem da opera√ß√£o na equa√ß√£o (125), que √†s vezes √© chamada de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">convolu√ß√£o</a> .  Mais precisamente, √†s vezes as pessoas escrevem essa equa√ß√£o como <sup>1</sup> = œÉ (b + w ‚àó a <sup>0</sup> ), em que <sup>1</sup> indica um conjunto de ativa√ß√µes de sa√≠da de uma placa de recurso, um <sup>0</sup> - um conjunto de ativa√ß√µes de entrada e * √© chamado de opera√ß√£o de convolu√ß√£o.  N√£o vamos nos aprofundar na matem√°tica das convolu√ß√µes, portanto voc√™ n√£o precisa se preocupar particularmente com essa conex√£o.  Mas vale a pena saber de onde veio o nome. <br><br><h3>  Camadas de pool </h3><br>  Al√©m das camadas convolucionais descritas no SNA, tamb√©m existem camadas de pool.  Eles geralmente s√£o usados ‚Äã‚Äãimediatamente ap√≥s convolucionais.  Eles est√£o empenhados em simplificar as informa√ß√µes da sa√≠da da camada convolucional. <br><br>  Aqui eu uso a frase ‚Äúmapa de caracter√≠sticas‚Äù n√£o no significado da fun√ß√£o calculada pela camada convolucional, mas para indicar a ativa√ß√£o da sa√≠da dos neur√¥nios da camada oculta.  Esse uso gratuito de termos √© frequentemente encontrado na literatura de pesquisa. <br><br>  A camada de pool aceita a sa√≠da de cada mapa de recursos da camada de convolu√ß√£o e prepara um mapa de recursos compactados.  Por exemplo, cada elemento da camada de pool pode resumir uma se√ß√£o de, digamos, 2x2 neur√¥nios da camada anterior.  Estudo de caso: Um procedimento comum de agrupamento √© conhecido como agrupamento m√°ximo.  No pool m√°ximo, o elemento de pool simplesmente fornece a ativa√ß√£o m√°xima a partir da se√ß√£o 2x2, conforme mostrado no diagrama: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dd0/f6b/86c/dd0f6b86c374504de4ae58056a0f7008.png"><br><br>  Como a sa√≠da dos neur√¥nios da camada convolucional fornece valores 24x24, ap√≥s puxar, obtemos 12x12 neur√¥nios. <br><br>  Como mencionado acima, uma camada convolucional geralmente implica algo mais do que um √∫nico mapa de caracter√≠sticas.  Aplicamos o pool m√°ximo a cada mapa de recursos individualmente.  Portanto, se tivermos tr√™s mapas de recursos, as camadas combinadas de convolu√ß√£o e m√°ximo pool ficar√£o assim: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a95/68f/8d1/a9568f8d10dd7dced2f682fe259aed48.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A extra√ß√£o m√°xima pode ser imaginada como uma maneira da rede de perguntar se existe um determinado sinal em qualquer lugar da imagem. E ent√£o ela descarta informa√ß√µes sobre sua localiza√ß√£o exata. √â intuitivamente claro que, quando um sinal √© encontrado, sua localiza√ß√£o exata n√£o √© mais t√£o importante quanto sua localiza√ß√£o aproximada em rela√ß√£o a outros sinais. A vantagem √© que o n√∫mero de recursos obtidos usando o pool √© muito menor, e isso ajuda a reduzir o n√∫mero de par√¢metros necess√°rios nas pr√≥ximas camadas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O pool m√°ximo n√£o √© a √∫nica tecnologia de pool. </font><font style="vertical-align: inherit;">Outra abordagem comum √© conhecida como pooling L2. </font><font style="vertical-align: inherit;">Nele, em vez de obter a ativa√ß√£o m√°xima da regi√£o dos neur√¥nios 2x2, pegamos a raiz quadrada da soma dos quadrados da ativa√ß√£o da regi√£o 2x2. </font><font style="vertical-align: inherit;">Os detalhes das abordagens diferem, mas intuitivamente √© semelhante ao pool m√°ximo: o pool L2 √© uma maneira de compactar informa√ß√µes de uma camada convolucional. </font><font style="vertical-align: inherit;">Na pr√°tica, ambas as tecnologias s√£o frequentemente usadas. </font><font style="vertical-align: inherit;">√Äs vezes, as pessoas usam outros tipos de pool. </font><font style="vertical-align: inherit;">Se voc√™ est√° tentando otimizar a qualidade da rede, pode usar os dados de suporte para comparar v√°rias abordagens diferentes para puxar e escolher a melhor. </font><font style="vertical-align: inherit;">Mas n√£o vamos nos preocupar com uma otimiza√ß√£o t√£o detalhada.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Resumindo </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora podemos reunir todas as informa√ß√µes e obter um SNA completo. √â semelhante √† arquitetura que analisamos recentemente, no entanto, possui uma camada adicional de 10 neur√¥nios de sa√≠da correspondentes a 10 valores poss√≠veis dos d√≠gitos MNIST ('0', '1', '2', ..): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2d/ba1/8ee/b2dba18ee40b3f642fb9f4e9cbda772b.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A rede come√ßa com os neur√¥nios de entrada 28x28 usados para codificar a intensidade de pixel da imagem MNIST. Depois disso, surge uma camada convolucional usando os campos receptivos locais 5x5 e 3 mapas de caracter√≠sticas. O resultado √© uma camada de neur√¥nios de tra√ßos ocultos 3x24x24. O pr√≥ximo passo √© uma camada m√°xima de pool aplicada a √°reas 2x2 em cada um dos tr√™s mapas de recursos. O resultado √© uma camada de neur√¥nios de tra√ßos ocultos 3x12x12.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A √∫ltima camada de conex√µes na rede est√° totalmente conectada. Ou seja, ele conecta cada neur√¥nio da camada de pool m√°ximo a cada um dos 10 neur√¥nios de sa√≠da. Usamos uma arquitetura totalmente conectada anteriormente. Observe que no diagrama acima usei uma √∫nica seta para simplificar, n√£o mostrando todos os links. Voc√™ pode facilmente imaginar todos eles. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Essa arquitetura convolucional √© muito diferente da que usamos anteriormente. No entanto, o quadro geral √© semelhante: uma rede que consiste em muitos elementos simples, cujo comportamento √© determinado por pesos e compensa√ß√µes. O objetivo permanece o mesmo: use dados de treinamento para treinar a rede em pesos e compensa√ß√µes, para que a rede classifique bem os n√∫meros recebidos.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em particular, como nos cap√≠tulos anteriores, treinaremos nossa rede usando descida de gradiente estoc√°stico e propaga√ß√£o de retorno. O procedimento √© quase o mesmo de antes. No entanto, precisamos fazer algumas altera√ß√µes no procedimento de retropropaga√ß√£o. O fato √© que nossos derivados para propaga√ß√£o reversa foram projetados para uma rede com camadas totalmente conectadas. Felizmente, alterar derivadas para camadas convolucionais e de pool m√°ximo √© bastante simples. Se voc√™ quiser entender os detalhes, convido voc√™ a tentar resolver o seguinte problema. Avisarei que levar√° muito tempo, a menos que voc√™ tenha entendido completamente as perguntas iniciais da diferencia√ß√£o da retropropaga√ß√£o.</font></font><br><br><h3>  Desafio </h3><br><ul><li>     .            (BP1)-(BP4). ,     ,  -     ,     .      ? </li></ul><br><h2>      </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Discutimos as id√©ias por tr√°s do SNA. Vamos ver como eles funcionam na pr√°tica, implementando alguns SNAs e aplicando-os ao problema de classifica√ß√£o de d√≠gitos do MNIST. Usaremos o programa network3.py, uma vers√£o aprimorada dos programas network.py e network2.py criados nos cap√≠tulos anteriores. O programa network3.py usa id√©ias da documenta√ß√£o da biblioteca </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Theano</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (em particular, a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">implementa√ß√£o </font></font></a><font style="vertical-align: inherit;"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">LeNet-5</font></a><font style="vertical-align: inherit;"> ), da </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">implementa√ß√£o da exce√ß√£o</font></a><font style="vertical-align: inherit;"> de Misha Denil e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chris Olah</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . O c√≥digo do programa est√° dispon√≠vel no GitHub. Na pr√≥xima se√ß√£o, estudaremos o c√≥digo do programa network3.py e nesta se√ß√£o o usaremos como uma biblioteca para criar o SNA.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Os programas network.py e network2.py foram escritos em python usando a biblioteca de matrizes Numpy. Eles trabalharam com base nos primeiros princ√≠pios e alcan√ßaram os detalhes mais detalhados de propaga√ß√£o das costas, descida do gradiente estoc√°stico, etc. Mas agora, quando entendermos esses detalhes, para network3.py, usaremos a biblioteca de aprendizado de m√°quina Theano (consulte o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trabalho cient√≠fico</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> com sua descri√ß√£o). Theano tamb√©m √© a base das bibliotecas populares para NS </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pylearn2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keras</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , al√©m de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caffe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Torch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O uso do Theano facilita a implementa√ß√£o da retropropaga√ß√£o no SNA, uma vez que conta automaticamente todos os cart√µes. O Theano tamb√©m √© visivelmente mais r√°pido que o nosso c√≥digo anterior (que foi escrito para facilitar o entendimento, e n√£o para trabalhos de alta velocidade), portanto, √© razo√°vel us√°-lo para treinar redes mais complexas. Em particular, um dos grandes recursos do Theano √© executar o c√≥digo na CPU e na GPU, se dispon√≠vel. A execu√ß√£o em uma GPU fornece um aumento significativo na velocidade e ajuda a treinar redes mais complexas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para trabalhar em paralelo com o livro, voc√™ precisa instalar o Theano no seu sistema. Para fazer isso, siga as instru√ß√µes na </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p√°gina inicial do projeto</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. No momento da reda√ß√£o e lan√ßamento dos exemplos, o Theano 0.7 estava dispon√≠vel. Fiz algumas experi√™ncias no Mac OS X Yosemite sem uma GPU. Alguns no Ubuntu 14.04 com uma GPU NVIDIA. E alguns est√£o l√°, e ali. Para iniciar o network3.py, defina o sinalizador GPU no c√≥digo como Verdadeiro ou Falso. Al√©m disso, as </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seguintes instru√ß√µes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> podem ajud√°-lo a executar o Theano na sua GPU </font><font style="vertical-align: inherit;">. Tamb√©m √© f√°cil encontrar materiais de treinamento online. Se voc√™ n√£o possui sua pr√≥pria GPU, pode procurar o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Amazon Web Services EC2 G2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Mas mesmo com uma GPU, nosso c√≥digo n√£o funcionar√° muito rapidamente. Muitos experimentos v√£o de alguns minutos a v√°rias horas. Os mais complexos em uma √∫nica CPU ser√£o executados por v√°rios dias. Como nos cap√≠tulos anteriores, recomendo iniciar o experimento e continuar lendo, verificando periodicamente seu funcionamento. Sem usar uma GPU, recomendo que voc√™ reduza o n√∫mero de eras de treinamento para as experi√™ncias mais complexas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para obter resultados b√°sicos para compara√ß√£o, vamos come√ßar com uma arquitetura superficial com uma camada oculta contendo 100 neur√¥nios ocultos. Estudaremos 60 eras, usaremos a velocidade de aprendizado Œ∑ = 0,1, o tamanho do mini-pacote ser√° 10 e estudaremos sem regulariza√ß√£o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nesta se√ß√£o, defino um n√∫mero espec√≠fico de eras de treinamento. </font><font style="vertical-align: inherit;">Fa√ßo isso para maior clareza no processo de aprendizagem. </font><font style="vertical-align: inherit;">Na pr√°tica, √© √∫til usar paradas precoces, rastrear a precis√£o do conjunto de confirma√ß√£o e interromper o treinamento quando estivermos convencidos de que a precis√£o da confirma√ß√£o n√£o est√° mais melhorando:</font></font><br><br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> network3 &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> network3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Network &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> network3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer &gt;&gt;&gt; training_data, validation_data, test_data = network3.load_data_shared() &gt;&gt;&gt; mini_batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> &gt;&gt;&gt; net = Network([ FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">784</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.1</span></span>, validation_data, test_data)</code> </pre> <br>  A melhor precis√£o de classifica√ß√£o foi de 97,80%.  Essa √© a precis√£o da classifica√ß√£o test_data, estimada a partir da era do treinamento, na qual obtivemos a melhor precis√£o da classifica√ß√£o para dados em validation_data.  O uso de dados de valida√ß√£o para tomar uma decis√£o sobre a avalia√ß√£o da precis√£o ajuda a evitar a reciclagem.  Ent√£o vamos fazer isso.  Seus resultados podem variar um pouco, pois os pesos e compensa√ß√µes da rede s√£o inicializados aleatoriamente. <br><br>  A precis√£o de 97,80% √© bem pr√≥xima da precis√£o de 98,04% obtida no Cap√≠tulo 3, usando arquitetura de rede semelhante e hiperpar√¢metros de treinamento.  Em particular, ambos os exemplos usam redes rasas com uma camada oculta contendo 100 neur√¥nios ocultos.  Ambas as redes aprendem 60 eras com um tamanho de minipacote de 10 e uma taxa de aprendizado de Œ∑ = 0,1. <br><br>  No entanto, havia duas diferen√ßas na rede anterior.  Primeiro, realizamos a regulariza√ß√£o para ajudar a reduzir o impacto da reciclagem.  Regularizar a rede atual melhora a precis√£o, mas n√£o muito, por isso n√£o vamos pensar nisso por enquanto.  Em segundo lugar, embora a √∫ltima camada da rede inicial usasse ativa√ß√µes sigm√≥ides e a fun√ß√£o de custo de entropia cruzada, a rede atual usa a √∫ltima camada com softmax e a probabilidade logar√≠tmica funciona como uma fun√ß√£o de custo.  Conforme descrito no cap√≠tulo 3, essa n√£o √© uma mudan√ßa importante.  N√£o mudei de um para o outro por algum motivo profundo - principalmente porque o softmax e a fun√ß√£o de probabilidade logar√≠tmica s√£o mais frequentemente usados ‚Äã‚Äãnas redes modernas para classificar imagens. <br><br>  Podemos melhorar os resultados usando uma arquitetura de rede mais profunda? <br><br>  Vamos come√ßar inserindo uma camada convolucional, no in√≠cio da rede.  Usaremos o campo receptivo local 5x5, uma etapa de 1 e 20 cart√µes de recursos.  Tamb√©m inseriremos uma camada m√°xima de pool combinando recursos usando janelas de pool 2x2.  Portanto, a arquitetura geral da rede ser√° semelhante √† que discutimos na se√ß√£o anterior, mas com uma camada adicional totalmente conectada: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ca/178/8d2/7ca1788d2206313b37a6f8896086b582.png"><br><br>  Nessa arquitetura, as camadas de convolu√ß√£o e pool s√£o treinadas na estrutura espacial local contida na imagem de treinamento recebida, e a √∫ltima camada totalmente conectada √© treinada em um n√≠vel mais abstrato, integrando informa√ß√µes globais de toda a imagem.  Este √© um esquema comumente usado no SNA. <br><br>  Vamos treinar essa rede e ver como ela se comporta. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">20</span></span>*<span class="hljs-number"><span class="hljs-number">12</span></span>*<span class="hljs-number"><span class="hljs-number">12</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.1</span></span>, validation_data, test_data)</code> </pre> <br>  Temos uma precis√£o de 98,78%, que √© significativamente maior do que qualquer um dos resultados anteriores.  Reduzimos o erro em mais de um ter√ßo - um excelente resultado. <br><br>  Ao descrever a estrutura da rede, considerei as camadas convolucionais e de pool como uma √∫nica camada.  Considere-os como camadas separadas ou como uma √∫nica camada - uma quest√£o de prefer√™ncia.  O network3.py considera uma camada, uma vez que o c√≥digo √© mais compacto.  No entanto, √© f√°cil modificar o network3.py para que as camadas possam ser definidas individualmente. <br><br><h3>  Exerc√≠cio </h3><br><ul><li>  Que precis√£o de classifica√ß√£o obteremos se abaixarmos a camada totalmente conectada e usarmos apenas a camada de convolu√ß√£o / pool e a camada softmax?  A inclus√£o de uma camada totalmente conectada ajuda? </li></ul><br>  Podemos melhorar o resultado em 98,78%? <br><br>  Vamos tentar inserir a segunda camada de convolu√ß√£o / pool.  Vamos inseri-lo entre a convolu√ß√£o / pool existente e as camadas ocultas totalmente conectadas.  Novamente usamos o campo receptivo 5x5 local e o pool em se√ß√µes 2x2.  Vamos ver o que acontece quando treinamos uma rede com aproximadamente os mesmos hiperpar√¢metros de antes: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.1</span></span>, validation_data, test_data)</code> </pre> <br>  E, novamente, temos uma melhoria: agora temos uma precis√£o de 99,06%! <br><br>  No momento, duas quest√µes naturais surgem.  Primeiro: o que significa usar a segunda camada de convolu√ß√£o / pool?  Voc√™ pode assumir que, na segunda camada de convolu√ß√£o / pool, as imagens ‚Äú12x12‚Äù chegam √† entrada, cujos ‚Äúpixels‚Äù representam a presen√ßa (ou aus√™ncia) de certos recursos localizados na imagem original.  Ou seja, podemos assumir que uma determinada vers√£o da imagem original chega √† entrada dessa camada.  Esta ser√° uma vers√£o mais abstrata e concisa, mas ainda possui estrutura espacial suficiente, portanto, faz sentido usar uma segunda camada de convolu√ß√£o / extra√ß√£o para process√°-la. <br><br>  Um ponto de vista agrad√°vel, mas levanta uma segunda quest√£o.  Na sa√≠da da camada anterior, s√£o obtidos 20 KPs ‚Äã‚Äãseparados, portanto, grupos de 20x12x12 de dados de entrada chegam √† segunda camada de convolu√ß√£o / pool.  Acontece que temos, por assim dizer, 20 imagens separadas inclu√≠das na camada de convolu√ß√£o / pool, e nenhuma imagem, como foi o caso da primeira camada de convolu√ß√£o / pool.  Ent√£o, como os neur√¥nios da segunda camada de convolu√ß√£o / pool precisam responder a muitas dessas imagens recebidas?  De fato, simplesmente permitimos que cada neur√¥nio dessa camada seja treinado com base em todos os 20x5x5 que entram no seu campo receptivo local.  Em uma linguagem menos formal, os detectores de recursos na segunda camada de convolu√ß√£o / pool ter√£o acesso a todos os recursos da primeira camada, mas apenas dentro de seus campos receptivos locais espec√≠ficos. <br><br>  A prop√≥sito, esse problema teria surgido na primeira camada, se as imagens fossem coloridas.  Nesse caso, ter√≠amos 3 atributos de entrada para cada pixel correspondente aos canais vermelho, verde e azul da imagem original.  E ent√£o tamb√©m damos aos detectores de sinais acesso a todas as informa√ß√µes de cores, mas apenas dentro da estrutura de seu campo receptivo local. <br><br><h3>  Desafio </h3><br><ul><li>  Utilizando a fun√ß√£o de ativa√ß√£o na forma de tangente hiperb√≥lica.  No in√≠cio deste livro, mencionei evid√™ncias v√°rias vezes de que a fun√ß√£o tanh, uma tangente hiperb√≥lica, poderia ser mais adequada para ser uma fun√ß√£o de ativa√ß√£o do que um sigm√≥ide.  N√£o fizemos nada com isso, pois tivemos um bom progresso com o sigm√≥ide.  Mas vamos tentar alguns experimentos com o tanh como uma fun√ß√£o de ativa√ß√£o.  Tente treinar uma rede ativada por tang com camadas convolucionais e totalmente conectadas (voc√™ pode passar o activation_fn = tanh como um par√¢metro para as classes ConvPoolLayer e FullyConnectedLayer).  Comece com os mesmos hiperpar√¢metros da rede sigm√≥ide, mas treine a rede de 20 eras, n√£o 60. Como a rede se comporta?  O que acontecer√° se continuarmos at√© a era 60?  Tente construir um gr√°fico da precis√£o da confirma√ß√£o do trabalho por √©pocas para tangente e sigm√≥ide, at√© a era 60.  Se seus resultados forem semelhantes aos meus, voc√™ descobrir√° que a rede baseada em tangente aprende um pouco mais r√°pido, mas a precis√£o resultante de ambas as redes √© a mesma.  Voc√™ pode explicar por que isso acontece?  √â poss√≠vel alcan√ßar a mesma velocidade de aprendizado com um sigm√≥ide - por exemplo, alterando a velocidade de aprendizado ou escalando (lembre-se de que œÉ (z) = (1 + tanh (z / 2)) / 2)?  Experimente cinco ou seis hiperpar√¢metros ou arquiteturas de rede diferentes, procure onde a tangente pode estar √† frente do sigm√≥ide.  Noto que esta tarefa est√° aberta.  Pessoalmente, n√£o encontrei vantagens s√©rias ao mudar para a tangente, embora n√£o tenha realizado experimentos abrangentes, e talvez voc√™ os encontre.  De qualquer forma, em breve encontraremos uma vantagem em mudar para uma fun√ß√£o de ativa√ß√£o linear corrigida, para que n√£o nos aprofundemos mais na quest√£o da tangente hiperb√≥lica. </li></ul><br><h3>  Usando elementos lineares endireitados </h3><br>  A rede que desenvolvemos no momento √© uma das op√ß√µes de rede usadas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">frut√≠fero trabalho de 1998</a> , no qual a tarefa do MNIST, uma rede chamada LeNet-5, foi apresentada pela primeira vez.  Essa √© uma boa base para novas experi√™ncias, para melhorar a compreens√£o do problema e da intui√ß√£o.  Em particular, existem muitas maneiras pelas quais podemos mudar nossa rede em busca de maneiras de melhorar os resultados. <br><br>  Primeiro, vamos mudar nossos neur√¥nios para que, em vez de usar a fun√ß√£o de ativa√ß√£o sigm√≥ide, possamos usar elementos lineares endireitados (ReLU).  Ou seja, usaremos a fun√ß√£o de ativa√ß√£o da forma f (z) ‚â° max (0, z).  Treinaremos uma rede de 60 √©pocas, com uma velocidade de Œ∑ = 0,03.  Tamb√©m achei um pouco mais conveniente usar a regulariza√ß√£o L2 com o par√¢metro de regulariza√ß√£o Œª = 0.1: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> network3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ReLU &gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data, lmbda=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)</code> </pre> <br>  Eu tenho uma precis√£o de classifica√ß√£o de 99,23%.  Uma melhora modesta em rela√ß√£o aos resultados sigm√≥ides (99,06%).  No entanto, em todas as minhas experi√™ncias, descobri que as redes baseadas em ReLU estavam √† frente das redes baseadas na fun√ß√£o de ativa√ß√£o sigm√≥ide com const√¢ncia invej√°vel.  Aparentemente, existem vantagens reais ao mudar para o ReLU para resolver esse problema. <br><br>  O que torna a ativa√ß√£o da ReLU melhor do que a tangente sigm√≥ide ou hiperb√≥lica?  No momento, n√£o entendemos isso particularmente.  Costuma-se dizer que a fun√ß√£o max (0, z) n√£o satura em geral z, diferentemente dos neur√¥nios sigm√≥ides, e isso ajuda os neur√¥nios ReLU a continuar aprendendo.  N√£o discuto, mas essa justificativa n√£o pode ser considerada abrangente, √© apenas algum tipo de observa√ß√£o (lembro que discutimos a satura√ß√£o no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cap√≠tulo 2</a> ). <br><br>  O ReLU come√ßou a ser usado ativamente nos √∫ltimos anos.  Eles foram adotados por raz√µes emp√≠ricas: algumas pessoas tentaram a ReLU, geralmente simplesmente baseadas em pressentimentos ou argumentos heur√≠sticos.  Eles obtiveram bons resultados e a pr√°tica se espalhou.  Em um mundo ideal, ter√≠amos uma teoria nos dizendo quais aplicativos quais fun√ß√µes de ativa√ß√£o s√£o melhores para quais aplicativos.  Mas, por enquanto, ainda temos um longo caminho a percorrer para essa situa√ß√£o.  N√£o ficarei surpreso se mais melhorias na opera√ß√£o das redes puderem ser obtidas escolhendo algumas fun√ß√µes de ativa√ß√£o ainda mais adequadas.  Tamb√©m espero que uma boa teoria das fun√ß√µes de ativa√ß√£o seja desenvolvida nas pr√≥ximas d√©cadas.  Hoje, por√©m, temos que confiar em regras pr√°ticas e experi√™ncia pouco estudadas. <br><br><h3>  Expans√£o dos dados de treinamento </h3><br>  Outra maneira que pode nos ajudar a melhorar nossos resultados √© expandir algoritmos os dados do treinamento.  A maneira mais f√°cil de expandir os dados de treinamento √© mudar cada imagem de treinamento em um pixel, para cima, para baixo, direita ou esquerda.  Isso pode ser feito executando o programa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">expand_mnist.py</a> . <br><br><pre> <code class="bash hljs">$ python expand_mnist.py</code> </pre> <br>  O lan√ßamento do programa transforma 50.000 imagens de treinamento do MNIST em um conjunto expandido de 250.000 imagens de treinamento.  Em seguida, podemos usar essas imagens de treinamento para treinar a rede.  Usaremos a mesma rede de antes com o ReLU.  Nas minhas primeiras experi√™ncias, reduzi o n√∫mero de eras de treinamento - fazia sentido, porque possu√≠mos 5 vezes mais dados de treinamento.  No entanto, a expans√£o do conjunto de dados reduziu significativamente o efeito da reciclagem.  Portanto, depois de realizar v√°rias experi√™ncias, retornei ao n√∫mero de eras 60. De qualquer forma, vamos treinar: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>expanded_training_data, _, _ = network3.load_data_shared( <span class="hljs-string"><span class="hljs-string">"../data/mnist_expanded.pkl.gz"</span></span>) &gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(expanded_training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data, lmbda=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)</code> </pre> <br>  Usando dados avan√ßados de treinamento, obtive uma precis√£o de 99,37%.  Essa mudan√ßa quase trivial fornece uma melhoria significativa na precis√£o da classifica√ß√£o.  E, como discutimos anteriormente, a extens√£o de dados algor√≠tmicos pode ser mais desenvolvida.  Apenas para lembr√°-lo: em 2003, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Simard, Steinkraus e Platt</a> melhoraram a precis√£o de sua rede para 99,6%.  Sua rede era semelhante √† nossa, eles usavam duas camadas de convolu√ß√£o / pool, seguidas por uma camada totalmente conectada com 100 neur√¥nios.  Os detalhes de sua arquitetura variaram - eles n√£o tiveram a oportunidade de tirar proveito do ReLU, por exemplo - no entanto, a chave para melhorar a qualidade do trabalho foi a expans√£o dos dados de treinamento.  Eles conseguiram isso girando, transferindo e distorcendo imagens de treinamento MNIST.  Eles tamb√©m desenvolveram o processo de ‚Äúdistor√ß√£o el√°stica‚Äù, emulando as vibra√ß√µes aleat√≥rias dos m√∫sculos do bra√ßo enquanto escreviam.  Ao combinar todos esses processos, eles aumentaram significativamente o volume efetivo de sua base de dados de treinamento e, devido a isso, alcan√ßaram uma precis√£o de 99,6%. <br><br><h3>  Desafio </h3><br><ul><li>  A id√©ia de camadas convolucionais √© trabalhar independentemente da localiza√ß√£o na imagem.  Por√©m, pode parecer estranho que nossa rede seja melhor treinada quando simplesmente mudamos as imagens de entrada.  Voc√™ pode explicar por que isso √© realmente bastante razo√°vel? </li></ul><br><br><h3>  Adicionando uma camada adicional totalmente conectada </h3><br>  √â poss√≠vel melhorar a situa√ß√£o?  Uma possibilidade √© usar exatamente o mesmo procedimento, mas ao mesmo tempo aumentar o tamanho da camada totalmente conectada.  Eu executei o programa com 300 e 1000 neur√¥nios e obtive resultados em 99,46% e 99,43%, respectivamente.  Isso √© interessante, mas n√£o particularmente convincente que o resultado anterior (99,37%). <br><br>  Que tal adicionar uma camada extra totalmente conectada?  Vamos tentar adicionar uma camada totalmente conectada adicional para que tenhamos duas camadas ocultas totalmente conectadas de 100 neur√¥nios: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(expanded_training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data, lmbda=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)</code> </pre> <br>  Assim, alcancei precis√£o de verifica√ß√£o de 99,43%.  A rede expandida novamente n√£o melhorou muito o desempenho.  Depois de realizar experi√™ncias semelhantes com camadas totalmente conectadas de 300 e 100 neur√¥nios, obtive uma precis√£o de 99,48% e 99,47%.  Inspirador, mas n√£o como uma vit√≥ria real. <br><br>  O que est√° havendo?  √â poss√≠vel que camadas estendidas ou adicionais totalmente conectadas n√£o ajudem na solu√ß√£o do problema MNIST?  Ou nossa rede pode alcan√ßar melhor, mas estamos desenvolvendo-a na dire√ß√£o errada?  Talvez pud√©ssemos, por exemplo, usar uma regulariza√ß√£o mais r√≠gida para reduzir a reciclagem.  Uma possibilidade √© a t√©cnica de abandono mencionada no cap√≠tulo 3. Lembre-se de que a id√©ia b√°sica de exclus√£o √© remover aleatoriamente ativa√ß√µes individuais ao treinar a rede.  Como resultado, o modelo se torna mais resistente √† perda de evid√™ncias individuais e, portanto, √© menos prov√°vel que ele se baseie em alguns pequenos recursos n√£o padronizados dos dados de treinamento.  Vamos tentar aplicar a exce√ß√£o √† √∫ltima camada totalmente conectada: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer( n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">1000</span></span>, activation_fn=ReLU, p_dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>), FullyConnectedLayer( n_in=<span class="hljs-number"><span class="hljs-number">1000</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">1000</span></span>, activation_fn=ReLU, p_dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">1000</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>, p_dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(expanded_training_data, <span class="hljs-number"><span class="hljs-number">40</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data)</code> </pre> <br>  Usando essa abordagem, alcan√ßamos uma precis√£o de 99,60%, muito melhor do que as anteriores, especialmente nossa avalia√ß√£o b√°sica - uma rede com 100 neur√¥nios ocultos, que fornece uma precis√£o de 99,37%. <br><br>  Duas mudan√ßas s√£o dignas de nota aqui. <br><br>  Primeiro, reduzi o n√∫mero de eras de treinamento para 40: a exce√ß√£o reduz a reciclagem e aprendemos mais r√°pido. <br><br>  Em segundo lugar, as camadas ocultas totalmente conectadas cont√™m 1000 neur√¥nios, e n√£o 100, como antes.  Obviamente, a exce√ß√£o elimina muitos neur√¥nios durante o treinamento, por isso devemos esperar algum tipo de expans√£o.  De fato, conduzi experimentos com 300 e 1000 neur√¥nios e recebi uma confirma√ß√£o um pouco melhor no caso de 1000 neur√¥nios. <br><br><h3>  Usando o Network Ensemble </h3><br>  Uma maneira f√°cil de melhorar a efici√™ncia √© criar v√°rias redes neurais e faz√™-las votar em uma classifica√ß√£o melhor.  Suponha, por exemplo, que treinamos 5 NS diferentes usando a receita acima, e cada um deles tenha atingido uma precis√£o pr√≥xima a 99,6%.  Embora todas as redes mostrem precis√£o semelhante, elas podem ter erros diferentes devido a diferentes inicializa√ß√£o aleat√≥ria.  √â razo√°vel supor que, se 5 NA votarem, sua classifica√ß√£o geral ser√° melhor que a de qualquer rede separadamente. <br><br>  Parece bom demais para ser verdade, mas montar esses conjuntos √© um truque comum para a Assembl√©ia Nacional e outras t√©cnicas de MO.  E, na verdade, melhora a efici√™ncia: obtemos uma precis√£o de 99,67%.  Em outras palavras, nosso conjunto de rede classifica corretamente todas as 10.000 imagens de verifica√ß√£o, com exce√ß√£o de 33. <br><br>  Os erros restantes s√£o mostrados abaixo.  O r√≥tulo no canto superior direito √© a classifica√ß√£o correta de acordo com os dados do MNIST, e no canto inferior direito √© o r√≥tulo recebido pelo conjunto da rede: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b6e/2d7/69a/b6e2d769a802b1ae5f249932789f2dff.png"><br><br>  Vale a pena insistir nas imagens.  Os dois primeiros d√≠gitos, 6 e 5, s√£o os erros reais do nosso grupo.  No entanto, eles podem ser entendidos, tal erro pode ser cometido pelo homem.  Esse 6 √© realmente muito parecido com 0 e 5 √© muito parecido com 3. A terceira foto, supostamente 8, realmente se parece mais com 9. Estou do lado do conjunto de redes: acho que ele fez o trabalho melhor do que a pessoa que escreveu essa figura.  Por outro lado, a quarta imagem, 6, √© realmente incorretamente classificada por redes. <br><br>  E assim por diante  Na maioria dos casos, a solu√ß√£o de rede parece plaus√≠vel e, em alguns casos, eles classificam melhor o n√∫mero do que a pessoa que o escreveu.  No geral, nossas redes demonstram efici√™ncia excepcional, especialmente se lembrarmos que elas classificaram corretamente 9967 imagens, que n√£o apresentamos aqui.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nesse contexto, v√°rios erros √≥bvios podem ser entendidos. </font><font style="vertical-align: inherit;">Mesmo uma pessoa cautelosa √†s vezes se engana. </font><font style="vertical-align: inherit;">Portanto, posso esperar um resultado melhor apenas de uma pessoa extremamente precisa e met√≥dica. </font><font style="vertical-align: inherit;">Nossa rede est√° se aproximando do desempenho humano.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Por que aplicamos a exce√ß√£o apenas a camadas totalmente conectadas </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se voc√™ observar atentamente o c√≥digo acima, ver√° que aplicamos a exce√ß√£o apenas √†s camadas de rede totalmente conectadas, mas n√£o √†s convolucionais. </font><font style="vertical-align: inherit;">Em princ√≠pio, um procedimento semelhante pode ser aplicado √†s camadas convolucionais. </font><font style="vertical-align: inherit;">Mas n√£o h√° necessidade disso: as camadas convolucionais t√™m uma resist√™ncia interna significativa √† reciclagem. </font><font style="vertical-align: inherit;">Isso ocorre porque o peso total faz com que os filtros convolucionais aprendam em todo o cen√°rio de uma s√≥ vez. </font><font style="vertical-align: inherit;">Como resultado, eles s√£o menos propensos a trope√ßar em algumas distor√ß√µes locais nos dados de treinamento. </font><font style="vertical-align: inherit;">Portanto, n√£o h√° necessidade espec√≠fica de aplicar outros regularizadores a eles, como exce√ß√µes.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Seguindo em frente </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voc√™ pode melhorar ainda mais a efici√™ncia da solu√ß√£o do problema MNIST. Rodrigo Benenson montou um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tablet informativo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mostrando o progresso ao longo dos anos e links para o trabalho. Muitos dos trabalhos usam o GSS da mesma maneira que n√≥s os usamos. Se voc√™ vasculhar seu trabalho, encontrar√° muitas t√©cnicas interessantes e poder√° implementar algumas delas. Nesse caso, seria aconselh√°vel iniciar sua implementa√ß√£o com uma rede simples que possa ser treinada rapidamente, e isso ajudar√° voc√™ a come√ßar rapidamente a entender o que est√° acontecendo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Na maioria das vezes, n√£o tentarei revisar trabalhos recentes. Mas n√£o posso resistir a uma exce√ß√£o. √â sobre um </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trabalho em 2010</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Eu gosto da sua simplicidade nela. A rede √© multicamada e usa apenas camadas totalmente conectadas (sem convolu√ß√µes). Na rede de maior sucesso, existem camadas ocultas contendo 2500, 2000, 1500, 1000 e 500 neur√¥nios, respectivamente. Eles usaram id√©ias semelhantes para expandir os dados de treinamento. Mas, al√©m disso, eles aplicaram v√°rios outros truques, incluindo a falta de camadas convolucionais: era a rede baunilha mais simples que, com a devida paci√™ncia e a disponibilidade de recursos computacionais adequados, poderia ter sido ensinada na d√©cada de 1980 (se o conjunto MNIST existisse). Eles alcan√ßaram uma precis√£o de classifica√ß√£o de 99,65%, o que coincide aproximadamente com a nossa. O principal em seu trabalho √© o uso de uma rede muito grande e profunda, e o uso de GPUs para acelerar o aprendizado. Isso lhes permitiu aprender muitas eras. Eles tamb√©m aproveitaram a longa dura√ß√£o dos intervalos de treinamento,e reduziu gradualmente a velocidade de aprendizado de 10</font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-3</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> a 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-6</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Tentar alcan√ßar resultados semelhantes com uma arquitetura como a deles √© um exerc√≠cio interessante.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Por que aprendemos? </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No cap√≠tulo anterior, vimos obst√°culos fundamentais para a aprendizagem de SN multicamada profunda. </font><font style="vertical-align: inherit;">Em particular, vimos que o gradiente se torna muito inst√°vel: ao passar da camada de sa√≠da para as anteriores, o gradiente pode desaparecer (o problema do gradiente que desaparece) ou crescimento explosivo (o problema do crescimento explosivo do gradiente). </font><font style="vertical-align: inherit;">Como o gradiente √© o sinal que usamos no treinamento, isso causa problemas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como conseguimos evit√°-los?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A resposta, naturalmente, √© esta: n√£o fomos capazes de evit√°-los. Em vez disso, fizemos algumas coisas que nos permitiram continuar trabalhando, apesar disso. Em particular: (1) o uso de camadas convolucionais reduz bastante o n√∫mero de par√¢metros contidos nelas, facilitando bastante o problema de aprendizagem; (2) o uso de t√©cnicas de regulariza√ß√£o mais eficientes (camadas de exclus√£o e convolucionais); (3) usando ReLU em vez de neur√¥nios sigm√≥ides para acelerar o aprendizado - empiricamente at√© 3-5 vezes; (4) o uso da GPU e a capacidade de aprender com o tempo. Em particular, em experimentos recentes, estudamos 40 eras usando um conjunto de dados 5 vezes maior que os dados de treinamento padr√£o do MNIST. No in√≠cio do livro, estudamos principalmente 30 eras usando dados de treinamento padr√£o. A combina√ß√£o dos fatores (3) e (4) produz esse efeito,como se estud√°ssemos 30 vezes mais que antes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voc√™ provavelmente diz: "Isso √© tudo?" Isso √© o suficiente para treinar redes neurais profundas? E por que motivo o barulho pegou fogo? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obviamente, usamos outras id√©ias: conjuntos de dados grandes o suficiente (para ajudar a evitar a reciclagem); fun√ß√£o de custo correta (para evitar lentid√£o na aprendizagem); boa inicializa√ß√£o de pesos (tamb√©m para evitar lentid√£o na aprendizagem devido √† satura√ß√£o de neur√¥nios); extens√£o algor√≠tmica do conjunto de dados de treinamento. Discutimos essas e outras id√©ias nos cap√≠tulos anteriores e, geralmente, tivemos a oportunidade de reutiliz√°-las com pequenas notas neste cap√≠tulo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De todas as indica√ß√µes, este √© um conjunto bastante simples de id√©ias. Simples, no entanto, capaz de muito quando usado em um complexo. Descobriu-se que come√ßar com o aprendizado profundo era bastante f√°cil!</font></font><br><br><h3>       ? </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se considerarmos as camadas de convolu√ß√£o / pool como uma s√≥, em nossa arquitetura final existem quatro camadas ocultas. Essa rede merece um t√≠tulo profundo? Naturalmente, quatro camadas ocultas s√£o muito mais do que em redes rasas que estudamos anteriormente. A maioria das redes possui uma camada oculta, √†s vezes 2. Por outro lado, as redes avan√ßadas modernas √†s vezes t√™m dezenas de camadas ocultas. √Äs vezes, conheci pessoas que pensavam que quanto mais profunda a rede, melhor e que se voc√™ n√£o usar um n√∫mero suficientemente grande de camadas ocultas, isso significa que voc√™ n√£o est√° realmente aprendendo profundamente. Acho que n√£o, principalmente porque essa abordagem transforma a defini√ß√£o de aprendizado profundo em um procedimento que depende de resultados moment√¢neos. Uma verdadeira inova√ß√£o nessa √°rea foi a id√©ia da praticidade de ir al√©m das redes com uma ou duas camadas ocultas,prevalecente em meados dos anos 2000. Essa foi uma verdadeira inova√ß√£o, abrindo um campo de pesquisa com modelos mais expressivos. Bem, um n√∫mero espec√≠fico de camadas n√£o √© de interesse fundamental. O uso de redes profundas √© uma ferramenta para atingir outros objetivos, como melhorar a precis√£o da classifica√ß√£o.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Quest√£o processual </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nesta se√ß√£o, alternamos suavemente de redes rasas com uma camada oculta para redes de convolu√ß√£o de v√°rias camadas. </font><font style="vertical-align: inherit;">Tudo parecia t√£o f√°cil! </font><font style="vertical-align: inherit;">Fizemos uma mudan√ßa e conseguimos uma melhoria. </font><font style="vertical-align: inherit;">Se voc√™ come√ßar a experimentar, garanto que geralmente tudo n√£o vai t√£o bem. </font><font style="vertical-align: inherit;">Apresentei uma hist√≥ria penteada, omitindo muitas experi√™ncias, incluindo as que n√£o tiveram √™xito. </font><font style="vertical-align: inherit;">Espero que essa hist√≥ria penteada o ajude a entender melhor as id√©ias b√°sicas. </font><font style="vertical-align: inherit;">Mas ele corre o risco de transmitir uma impress√£o incompleta. </font><font style="vertical-align: inherit;">Conseguir uma boa rede de trabalho exige muita tentativa e erro, entremeados de frustra√ß√£o. </font><font style="vertical-align: inherit;">Na pr√°tica, voc√™ pode esperar um grande n√∫mero de experimentos. </font><font style="vertical-align: inherit;">Para acelerar o processo, as informa√ß√µes no cap√≠tulo 3 sobre a sele√ß√£o de hiperpar√¢metros de rede, bem como a literatura adicional mencionada, podem ajud√°-lo.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> C√≥digo para nossas redes de convolu√ß√£o </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tudo bem, agora vamos olhar o c√≥digo do nosso programa network3.py. Estruturalmente, √© semelhante ao network2.py, que desenvolvemos no cap√≠tulo 3, mas os detalhes s√£o diferentes devido ao uso da biblioteca Theano. Vamos come√ßar com a classe FullyConnectedLayer, semelhante √†s camadas que estudamos anteriormente.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FullyConnectedLayer</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(object)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, n_in, n_out, activation_fn=sigmoid, p_dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.n_in = n_in self.n_out = n_out self.activation_fn = activation_fn self.p_dropout = p_dropout <span class="hljs-comment"><span class="hljs-comment"># Initialize weights and biases self.w = theano.shared( np.asarray( np.random.normal( loc=0.0, scale=np.sqrt(1.0/n_out), size=(n_in, n_out)), dtype=theano.config.floatX), name='w', borrow=True) self.b = theano.shared( np.asarray(np.random.normal(loc=0.0, scale=1.0, size=(n_out,)), dtype=theano.config.floatX), name='b', borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape((mini_batch_size, self.n_in)) self.output = self.activation_fn( (1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b) self.y_out = T.argmax(self.output, axis=1) self.inpt_dropout = dropout_layer( inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout) self.output_dropout = self.activation_fn( T.dot(self.inpt_dropout, self.w) + self.b) def accuracy(self, y): "Return the accuracy for the mini-batch." return T.mean(T.eq(y, self.y_out))</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A maior parte do m√©todo __init__ fala por si, mas algumas notas podem ajudar a esclarecer o c√≥digo. Como sempre, inicializamos aleatoriamente pesos e compensa√ß√µes usando valores aleat√≥rios normais com desvios padr√£o adequados. Essas linhas parecem um pouco incompreens√≠veis. No entanto, a maior parte do c√≥digo estranho est√° carregando pesos e compensa√ß√µes para o que a biblioteca Theano chama de vari√°veis ‚Äã‚Äãcompartilhadas. Isso garante que as vari√°veis ‚Äã‚Äãpossam ser processadas na GPU, se dispon√≠vel. N√£o vamos nos aprofundar nesta quest√£o - se estiver interessado, leia a documenta√ß√£o para Theano. Observe tamb√©m que essa inicializa√ß√£o de pesos e deslocamentos √© para a fun√ß√£o de ativa√ß√£o sigm√≥ide. Idealmente, para fun√ß√µes como tangente hiperb√≥lica e ReLU, inicializar√≠amos pesos e compensa√ß√µes de maneira diferente. Esse problema √© discutido em tarefas futuras.O m√©todo __init__ termina com a instru√ß√£o self.params = [self.w, self.b]. Essa √© uma maneira conveniente de reunir todos os par√¢metros de aprendizado associados a uma camada. O Network.SGD posteriormente usa os atributos params para descobrir quais vari√°veis ‚Äã‚Äãna inst√¢ncia da classe Network podem ser treinadas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O m√©todo set_inpt √© usado para passar a entrada para uma camada e calcular a sa√≠da correspondente. Escrevo inpt em vez de input, porque input √© uma fun√ß√£o python interna e, se voc√™ jogar com eles, isso pode levar a um comportamento imprevis√≠vel do programa e a dif√≠cil diagn√≥stico de erros. De fato, passamos informa√ß√µes de duas maneiras: atrav√©s de self.inpt e self.inpt_dropout. Isso √© feito, pois podemos usar exce√ß√£o durante o treinamento. E ent√£o precisaremos remover parte dos neur√¥nios self.p_dropout. √â isso que a fun√ß√£o dropout_layer na pen√∫ltima linha do m√©todo set_inpt faz. Portanto, self.inpt_dropout e self.output_dropout s√£o usados ‚Äã‚Äãdurante o treinamento, e self.inpt e self.output s√£o usados ‚Äã‚Äãpara todos os outros prop√≥sitos, por exemplo, avaliar a precis√£o dos dados de valida√ß√£o e teste.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As defini√ß√µes de classe para ConvPoolLayer e SoftmaxLayer s√£o semelhantes a FullyConnectedLayer. T√£o parecido que nem cito o c√≥digo. Se voc√™ estiver interessado, o c√≥digo completo do programa pode ser estudado mais adiante neste cap√≠tulo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vale mencionar alguns detalhes diferentes. Obviamente, no ConvPoolLayer e SoftmaxLayer, calculamos as ativa√ß√µes de sa√≠da de uma maneira que se adapte ao tipo de camada. Felizmente, o Theano √© f√°cil de executar, possui opera√ß√µes integradas para calcular a convolu√ß√£o, o pool m√°ximo e a fun√ß√£o softmax.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√â menos √≥bvio como inicializar pesos e compensa√ß√µes na camada softmax - n√£o discutimos isso. Mencionamos que, para as camadas de peso sigmoidal, √© necess√°rio inicializar distribui√ß√µes aleat√≥rias normais adequadamente parametrizadas. Mas esse argumento heur√≠stico se aplicava aos neur√¥nios sigm√≥ides (e, com pequenas corre√ß√µes, aos neur√¥nios tangentes). No entanto, n√£o h√° raz√£o espec√≠fica para esse argumento se aplicar √†s camadas softmax. Portanto, n√£o h√° raz√£o para a priori aplicar essa inicializa√ß√£o novamente. Em vez disso, inicializo todos os pesos e compensa√ß√µes para 0. A op√ß√£o √© espont√¢nea, mas funciona muito bem na pr√°tica. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ent√£o, estudamos todas as classes de camadas. E a classe Rede? Vamos come√ßar explorando o m√©todo __init__:</font></font><br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Network</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(object)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, layers, mini_batch_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""   layers,   ,   mini_batch_size          """</span></span> self.layers = layers self.mini_batch_size = mini_batch_size self.params = [param <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.layers <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> param <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> layer.params] self.x = T.matrix(<span class="hljs-string"><span class="hljs-string">"x"</span></span>) self.y = T.ivector(<span class="hljs-string"><span class="hljs-string">"y"</span></span>) init_layer = self.layers[<span class="hljs-number"><span class="hljs-number">0</span></span>] init_layer.set_inpt(self.x, self.x, self.mini_batch_size) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> xrange(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(self.layers)): prev_layer, layer = self.layers[j<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.layers[j] layer.set_inpt( prev_layer.output, prev_layer.output_dropout, self.mini_batch_size) self.output = self.layers[<span class="hljs-number"><span class="hljs-number">-1</span></span>].output self.output_dropout = self.layers[<span class="hljs-number"><span class="hljs-number">-1</span></span>].output_dropout</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A maior parte do c√≥digo fala por si. A linha self.params = [param for layer in ...] coleta todos os par√¢metros de cada camada em uma √∫nica lista. Como sugerido anteriormente, o m√©todo Network.SGD usa self.params para descobrir com quais par√¢metros a rede pode aprender. As linhas self.x = T.matrix ("x") e self.y = T.ivector ("y") definem as vari√°veis ‚Äã‚Äãsimb√≥licas Theano x e y. Eles representar√£o a entrada e a sa√≠da desejada da rede. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este n√£o √© um tutorial sobre como usar o Theano, por isso n√£o vou explicar o significado das vari√°veis ‚Äã‚Äãsimb√≥licas (consulte a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">documenta√ß√£o</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e tamb√©m um dos </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tutoriais</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Grosso modo, eles denotam vari√°veis ‚Äã‚Äãmatem√°ticas, n√£o espec√≠ficas. Com eles, voc√™ pode realizar muitas opera√ß√µes comuns: adicionar, subtrair, multiplicar, aplicar fun√ß√µes e assim por diante. O Theano oferece muitas possibilidades para manipular essas vari√°veis ‚Äã‚Äãsimb√≥licas, convolver, puxar no m√°ximo e assim por diante. No entanto, o principal √© a possibilidade de r√°pida diferencia√ß√£o simb√≥lica usando uma forma muito geral do algoritmo de retropropaga√ß√£o. Isso √© extremamente √∫til para aplicar descida de gradiente estoc√°stico a uma ampla variedade de arquiteturas de rede. Em particular, as seguintes linhas de c√≥digo definem a sa√≠da simb√≥lica da rede. Come√ßamos atribuindo a entrada √† primeira camada:</font></font><br><br><pre> <code class="python hljs"> init_layer.set_inpt(self.x, self.x, self.mini_batch_size)</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Os dados de entrada s√£o transmitidos um minipacote de cada vez, ent√£o seu tamanho √© indicado l√°. Passamos a entrada do self.x duas vezes: o fato √© que podemos usar a rede de duas maneiras diferentes (com ou sem exce√ß√£o). O loop for propaga a vari√°vel simb√≥lica self.x atrav√©s das camadas de rede. Isso nos permite definir os atributos finais output e output_dropout, que representam simbolicamente a sa√≠da da rede. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tendo lidado com a inicializa√ß√£o da rede, vamos analisar seu treinamento atrav√©s do m√©todo SGD. O c√≥digo parece longo, mas sua estrutura √© bastante simples. As explica√ß√µes seguem o c√≥digo:</font></font><br><br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">SGD</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    -    ."""</span></span> training_x, training_y = training_data validation_x, validation_y = validation_data test_x, test_y = test_data <span class="hljs-comment"><span class="hljs-comment">#   -  ,    num_training_batches = size(training_data)/mini_batch_size num_validation_batches = size(validation_data)/mini_batch_size num_test_batches = size(test_data)/mini_batch_size #    ,     l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers]) cost = self.layers[-1].cost(self)+\ 0.5*lmbda*l2_norm_squared/num_training_batches grads = T.grad(cost, self.params) updates = [(param, param-eta*grad) for param, grad in zip(self.params, grads)] #     -    #      -. i = T.lscalar() # mini-batch index train_mb = theano.function( [i], cost, updates=updates, givens={ self.x: training_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: training_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) validate_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: validation_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: validation_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) test_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: test_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) self.test_mb_predictions = theano.function( [i], self.layers[-1].y_out, givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) #    best_validation_accuracy = 0.0 for epoch in xrange(epochs): for minibatch_index in xrange(num_training_batches): iteration = num_training_batches*epoch+minibatch_index if iteration print("Training mini-batch number {0}".format(iteration)) cost_ij = train_mb(minibatch_index) if (iteration+1) validation_accuracy = np.mean( [validate_mb_accuracy(j) for j in xrange(num_validation_batches)]) print("Epoch {0}: validation accuracy {1:.2 epoch, validation_accuracy)) if validation_accuracy &gt;= best_validation_accuracy: print("This is the best validation accuracy to date.") best_validation_accuracy = validation_accuracy best_iteration = iteration if test_data: test_accuracy = np.mean( [test_mb_accuracy(j) for j in xrange(num_test_batches)]) print('The corresponding test accuracy is {0:.2 test_accuracy)) print("Finished training network.") print("Best validation accuracy of {0:.2 best_validation_accuracy, best_iteration)) print("Corresponding test accuracy of {0:.2</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As primeiras linhas s√£o claras, separam os conjuntos de dados nos componentes xey, e calculam o n√∫mero de mini-pacotes usados ‚Äã‚Äãem cada conjunto de dados. As linhas a seguir s√£o mais interessantes e demonstram por que √© t√£o interessante trabalhar com a biblioteca Theano. Vou cit√°-los aqui:</font></font><br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    ,     l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers]) cost = self.layers[-1].cost(self)+\ 0.5*lmbda*l2_norm_squared/num_training_batches grads = T.grad(cost, self.params) updates = [(param, param-eta*grad) for param, grad in zip(self.params, grads)]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nestas linhas, definimos simbolicamente a fun√ß√£o de custo regularizado com base na fun√ß√£o de verossimilhan√ßa logar√≠tmica, calculamos as derivadas correspondentes na fun√ß√£o gradiente e tamb√©m as atualiza√ß√µes de par√¢metros correspondentes. Theano nos permite fazer tudo isso em apenas algumas linhas. A √∫nica coisa oculta √© que o c√°lculo do custo envolve a invoca√ß√£o do m√©todo de custo para a camada de sa√≠da; esse c√≥digo est√° localizado em outro lugar no network3.py. Mas √© curto e simples. Com a defini√ß√£o de tudo isso, tudo est√° pronto para definir a fun√ß√£o train_mb, a fun√ß√£o simb√≥lica do Theano que usa atualiza√ß√µes para atualizar os par√¢metros de rede pelo √≠ndice de mini pacotes. Da mesma forma, as fun√ß√µes validate_mb_accuracy e test_mb_accuracy calculam a precis√£o da rede em qualquer minipacote de dados de valida√ß√£o ou verifica√ß√£o. M√©dia sobre essas fun√ß√µes,podemos calcular a precis√£o de todos os conjuntos de dados de valida√ß√£o e verifica√ß√£o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O restante do m√©todo SGD fala por si - simplesmente passamos pelas √©pocas sucessivamente, treinando a rede repetidamente em mini-pacotes de dados de treinamento e calculamos a precis√£o da confirma√ß√£o e verifica√ß√£o. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora entendemos as partes mais importantes do ano network3.py. </font><font style="vertical-align: inherit;">Vamos brevemente passar por todo o programa. </font><font style="vertical-align: inherit;">N√£o √© necess√°rio estudar tudo em detalhes, mas voc√™ pode ir al√©m e talvez mergulhar em algumas passagens especialmente apreciadas. </font><font style="vertical-align: inherit;">Mas, √© claro, a melhor maneira de entender o programa √© alter√°-lo, adicionar algo novo, refatorar as partes que, na sua opini√£o, podem ser aprimoradas. </font><font style="vertical-align: inherit;">Ap√≥s o c√≥digo, apresento v√°rias tarefas que cont√™m v√°rias sugest√µes iniciais sobre o que pode ser feito aqui. </font><font style="vertical-align: inherit;">Aqui est√° o c√≥digo.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">"""network3.py ~~~~~~~~~~~~~~     Theano      .     (, , -, softmax)    (,  , ReLU;   ).    CPU     ,  network.py  network2.py. ,    ,      GPU,    .     Theano,       network.py  network2.py.  ,       .  , API   network2.py.       ,  ,     .   ,     ,    .      Theano   (http://deeplearning.net/tutorial/lenet.html ),       (https://github.com/mdenil/dropout )      (http://colah.github.io ).   Theano 0.6  0.7,       . """</span></span> <span class="hljs-comment"><span class="hljs-comment">####  #  import cPickle import gzip #  import numpy as np import theano import theano.tensor as T from theano.tensor.nnet import conv from theano.tensor.nnet import softmax from theano.tensor import shared_randomstreams from theano.tensor.signal import downsample #    def linear(z): return z def ReLU(z): return T.maximum(0.0, z) from theano.tensor.nnet import sigmoid from theano.tensor import tanh ####  GPU = True if GPU: print "Trying to run under a GPU. If this is not desired, then modify "+\ "network3.py\nto set the GPU flag to False." try: theano.config.device = 'gpu' except: pass # it's already set theano.config.floatX = 'float32' else: print "Running with a CPU. If this is not desired, then the modify "+\ "network3.py to set\nthe GPU flag to True." ####   MNIST def load_data_shared(filename="../data/mnist.pkl.gz"): f = gzip.open(filename, 'rb') training_data, validation_data, test_data = cPickle.load(f) f.close() def shared(data): """    .   Theano    GPU,   . """ shared_x = theano.shared( np.asarray(data[0], dtype=theano.config.floatX), borrow=True) shared_y = theano.shared( np.asarray(data[1], dtype=theano.config.floatX), borrow=True) return shared_x, T.cast(shared_y, "int32") return [shared(training_data), shared(validation_data), shared(test_data)] ####        class Network(object): def __init__(self, layers, mini_batch_size): """   layers,   ,   mini_batch_size         . """ self.layers = layers self.mini_batch_size = mini_batch_size self.params = [param for layer in self.layers for param in layer.params] self.x = T.matrix("x") self.y = T.ivector("y") init_layer = self.layers[0] init_layer.set_inpt(self.x, self.x, self.mini_batch_size) for j in xrange(1, len(self.layers)): prev_layer, layer = self.layers[j-1], self.layers[j] layer.set_inpt( prev_layer.output, prev_layer.output_dropout, self.mini_batch_size) self.output = self.layers[-1].output self.output_dropout = self.layers[-1].output_dropout def SGD(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda=0.0): """    -    .""" training_x, training_y = training_data validation_x, validation_y = validation_data test_x, test_y = test_data #   -  ,    num_training_batches = size(training_data)/mini_batch_size num_validation_batches = size(validation_data)/mini_batch_size num_test_batches = size(test_data)/mini_batch_size #    ,     l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers]) cost = self.layers[-1].cost(self)+\ 0.5*lmbda*l2_norm_squared/num_training_batches grads = T.grad(cost, self.params) updates = [(param, param-eta*grad) for param, grad in zip(self.params, grads)] #     -    #      -. i = T.lscalar() # mini-batch index train_mb = theano.function( [i], cost, updates=updates, givens={ self.x: training_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: training_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) validate_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: validation_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: validation_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) test_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: test_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) self.test_mb_predictions = theano.function( [i], self.layers[-1].y_out, givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) #    best_validation_accuracy = 0.0 for epoch in xrange(epochs): for minibatch_index in xrange(num_training_batches): iteration = num_training_batches*epoch+minibatch_index if iteration % 1000 == 0: print("Training mini-batch number {0}".format(iteration)) cost_ij = train_mb(minibatch_index) if (iteration+1) % num_training_batches == 0: validation_accuracy = np.mean( [validate_mb_accuracy(j) for j in xrange(num_validation_batches)]) print("Epoch {0}: validation accuracy {1:.2%}".format( epoch, validation_accuracy)) if validation_accuracy &gt;= best_validation_accuracy: print("This is the best validation accuracy to date.") best_validation_accuracy = validation_accuracy best_iteration = iteration if test_data: test_accuracy = np.mean( [test_mb_accuracy(j) for j in xrange(num_test_batches)]) print('The corresponding test accuracy is {0:.2%}'.format( test_accuracy)) print("Finished training network.") print("Best validation accuracy of {0:.2%} obtained at iteration {1}".format( best_validation_accuracy, best_iteration)) print("Corresponding test accuracy of {0:.2%}".format(test_accuracy)) ####    class ConvPoolLayer(object): """     - .        ,         ,    ,   . """ def __init__(self, filter_shape, image_shape, poolsize=(2, 2), activation_fn=sigmoid): """`filter_shape` -   4,   ,    ,     . `image_shape` -   4,   -,    ,    . `poolsize` -   2,    y  x. """ self.filter_shape = filter_shape self.image_shape = image_shape self.poolsize = poolsize self.activation_fn=activation_fn # initialize weights and biases n_out = (filter_shape[0]*np.prod(filter_shape[2:])/np.prod(poolsize)) self.w = theano.shared( np.asarray( np.random.normal(loc=0, scale=np.sqrt(1.0/n_out), size=filter_shape), dtype=theano.config.floatX), borrow=True) self.b = theano.shared( np.asarray( np.random.normal(loc=0, scale=1.0, size=(filter_shape[0],)), dtype=theano.config.floatX), borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape(self.image_shape) conv_out = conv.conv2d( input=self.inpt, filters=self.w, filter_shape=self.filter_shape, image_shape=self.image_shape) pooled_out = downsample.max_pool_2d( input=conv_out, ds=self.poolsize, ignore_border=True) self.output = self.activation_fn( pooled_out + self.b.dimshuffle('x', 0, 'x', 'x')) self.output_dropout = self.output # no dropout in the convolutional layers class FullyConnectedLayer(object): def __init__(self, n_in, n_out, activation_fn=sigmoid, p_dropout=0.0): self.n_in = n_in self.n_out = n_out self.activation_fn = activation_fn self.p_dropout = p_dropout # Initialize weights and biases self.w = theano.shared( np.asarray( np.random.normal( loc=0.0, scale=np.sqrt(1.0/n_out), size=(n_in, n_out)), dtype=theano.config.floatX), name='w', borrow=True) self.b = theano.shared( np.asarray(np.random.normal(loc=0.0, scale=1.0, size=(n_out,)), dtype=theano.config.floatX), name='b', borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape((mini_batch_size, self.n_in)) self.output = self.activation_fn( (1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b) self.y_out = T.argmax(self.output, axis=1) self.inpt_dropout = dropout_layer( inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout) self.output_dropout = self.activation_fn( T.dot(self.inpt_dropout, self.w) + self.b) def accuracy(self, y): "Return the accuracy for the mini-batch." return T.mean(T.eq(y, self.y_out)) class SoftmaxLayer(object): def __init__(self, n_in, n_out, p_dropout=0.0): self.n_in = n_in self.n_out = n_out self.p_dropout = p_dropout #     self.w = theano.shared( np.zeros((n_in, n_out), dtype=theano.config.floatX), name='w', borrow=True) self.b = theano.shared( np.zeros((n_out,), dtype=theano.config.floatX), name='b', borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape((mini_batch_size, self.n_in)) self.output = softmax((1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b) self.y_out = T.argmax(self.output, axis=1) self.inpt_dropout = dropout_layer( inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout) self.output_dropout = softmax(T.dot(self.inpt_dropout, self.w) + self.b) def cost(self, net): "   ." return -T.mean(T.log(self.output_dropout)[T.arange(net.y.shape[0]), net.y]) def accuracy(self, y): "  -." return T.mean(T.eq(y, self.y_out)) ####  def size(data): "    `data`." return data[0].get_value(borrow=True).shape[0] def dropout_layer(layer, p_dropout): srng = shared_randomstreams.RandomStreams( np.random.RandomState(0).randint(999999)) mask = srng.binomial(n=1, p=1-p_dropout, size=layer.shape) return layer*T.cast(mask, theano.config.floatX)</span></span></code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> As tarefas </font></font></h3><br><ul><li>     SGD       .            ,  .  network3.py ,      . </li><li>   Network ,       . </li><li>  SGD ,       Œ∑      (   , , ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> ). </li><li>              ,   .  network3.py,      . ,         ,      .    . </li><li>      . </li><li>    ‚Äì     .    ,    ,  ,   ?  . </li><li>    ReLU    ,     ( -) .       .  ,    ReLU ( ). ,        c&gt;0     c <sup>L‚àí1</sup> ,  L ‚Äì  .  ,     softmax?         ReLU?       ? ,    ,       .        ,   ReLU. </li><li>         .     ,      ReLU?         ,        ? :  ¬´¬ª   .        ‚Äì       ,   - -  . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt463171/">https://habr.com/ru/post/pt463171/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt463157/index.html">Servidor de Streaming de V√≠deo ESP32-CAM Conectando Monitores I2C e SPI</a></li>
<li><a href="../pt463159/index.html">Sobre seguran√ßa, n√∫meros, e-mails e um pouco sobre publicidade</a></li>
<li><a href="../pt463165/index.html">Telegrama revoga DPI e bloqueios - TLS falso</a></li>
<li><a href="../pt463167/index.html">Materiais necess√°rios para iniciar o desenvolvimento de um projeto de treinamento em VR</a></li>
<li><a href="../pt463169/index.html">Aparelho auditivo de c√≥digo aberto - como funciona</a></li>
<li><a href="../pt463175/index.html">Visualiza√ß√£o de depend√™ncias e heran√ßa entre modelos de aprendizado de m√°quina</a></li>
<li><a href="../pt463177/index.html">Cr√©dito do Service Desk em Casa. E o que tem dentro? ...</a></li>
<li><a href="../pt463179/index.html">Big Data Big Billing: Sobre o BigData em Telecom</a></li>
<li><a href="../pt463181/index.html">Figma - uma solu√ß√£o simples para um designer, uma solu√ß√£o dif√≠cil para um designer de layout</a></li>
<li><a href="../pt463183/index.html">Treinamento Cisco 200-125 CCNA v3.0. Dia 13. Configurar VLAN</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïØÔ∏è üë©üèø‚Äçüé§ üôç Automatische Skalierung und Ressourcenverwaltung in Kubernetes (√úberpr√ºfung und Videobericht) üëèüèΩ üçõ üë®üèª‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Am 27. April wurde auf der Strike-2019- Konferenz im Rahmen der DevOps-Sektion ein Bericht zum Thema ‚ÄûAutomatische Skalierung und Ressourcenverwaltung...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Automatische Skalierung und Ressourcenverwaltung in Kubernetes (√úberpr√ºfung und Videobericht)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/459326/">  Am 27. April wurde auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Strike-2019-</a> Konferenz im Rahmen der DevOps-Sektion ein Bericht zum Thema ‚ÄûAutomatische Skalierung und Ressourcenverwaltung in Kubernetes‚Äú erstellt.  Es wird erl√§utert, wie K8s verwendet werden, um eine hohe Verf√ºgbarkeit von Anwendungen und deren maximale Leistung sicherzustellen. <br><br><img src="https://habrastorage.org/webt/ol/sv/vf/olsvvfwmfrorzavctm_ipdufuxo.jpeg"><br><br>  Aus Tradition freuen wir uns, ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>Video mit einem Bericht</b></a> (44 Minuten, viel informativer als der Artikel) und dem Hauptdruck in Textform zu pr√§sentieren.  Lass uns gehen! <a name="habracut"></a><br><br>  Wir werden das Thema des Berichts anhand der W√∂rter analysieren und am Ende beginnen. <br><br><h2>  Kubernetes </h2><br>  Lassen Sie uns Docker-Container auf dem Host haben.  Warum?  Um Wiederholbarkeit und Isolation zu gew√§hrleisten, was wiederum eine einfache und gute Bereitstellung erm√∂glicht, CI / CD.  Wir haben viele solcher Maschinen mit Containern. <br><br>  Was gibt Kubernetes in diesem Fall? <br><br><ol><li>  Wir h√∂ren auf, an diese Maschinen zu denken, und beginnen mit der ‚ÄûCloud‚Äú zu arbeiten, einer <b>Gruppe von Containern</b> oder Pods (Gruppen von Containern). </li><li>  Dar√ºber hinaus denken wir nicht einmal an einzelne Pods, sondern verwalten gr√∂√üere Gruppen.  Mit solchen <b>√ºbergeordneten Grundelementen</b> k√∂nnen wir sagen, dass es eine Vorlage zum Starten einer bestimmten Arbeitslast gibt, jedoch die erforderliche Anzahl von Instanzen f√ºr deren Start.  Wenn wir die Vorlage anschlie√üend √§ndern, √§ndern sich auch alle Instanzen. </li><li>  Mithilfe der <b>deklarativen API</b> beschreiben wir das von Kubernetes erstellte ‚ÄûWeltger√§t‚Äú (in YAML) <b>,</b> anstatt eine Folge bestimmter Befehle auszuf√ºhren.  Und noch einmal: Wenn sich die Beschreibung √§ndert, √§ndert sich auch die tats√§chliche Anzeige. </li></ol><br><h2>  Ressourcenmanagement </h2><br><h3>  CPU </h3><br>  Lassen Sie uns nginx, php-fpm und mysql auf dem Server ausf√ºhren.  Diese Dienste werden sogar noch mehr laufende Prozesse haben, f√ºr die jeweils Rechenressourcen erforderlich sind: <br><br><img src="https://habrastorage.org/webt/yu/v6/t8/yuv6t8a5q6txbhi25fe5mwv8f4k.png"><br>  <i>(Die Zahlen auf der Folie sind "Papageien", das abstrakte Bed√ºrfnis jedes Prozesses nach Rechenleistung)</i> <br><br>  Um die Arbeit damit zu vereinfachen, ist es logisch, Prozesse zu Gruppen zusammenzufassen (z. B. alle Nginx-Prozesse zu einer ‚ÄûNginx‚Äú -Gruppe).  Eine einfache und offensichtliche M√∂glichkeit, dies zu tun, besteht darin, jede Gruppe in einen Container zu legen: <br><br><img src="https://habrastorage.org/webt/yu/en/fr/yuenfrw6vzvexx1xrkvy3dfgw3o.png"><br><br>  Um fortzufahren, m√ºssen Sie sich merken, was ein Container ist (unter Linux).  Ihr Erscheinungsbild wurde durch drei wichtige Funktionen im Kernel erm√∂glicht, die seit langem implementiert sind: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Funktionen</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Namespaces</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cgroups</a> .  Andere Technologien (einschlie√ülich praktischer "Shells" wie Docker) trugen zur Weiterentwicklung bei: <br><br><img src="https://habrastorage.org/webt/f-/nf/ua/f-nfuaos1_9xdwyblt2em4yp-gs.png"><br><br>  Im Kontext des Berichts sind wir nur an <b>cgroups</b> interessiert, da Kontrollgruppen Teil der Funktionalit√§t von Containern (Docker usw.) sind, die das Ressourcenmanagement implementieren.  Die Prozesse, die, wie wir wollten, in Gruppen zusammengefasst sind, sind die Kontrollgruppen. <br><br>  Kehren wir zu den CPU-Anforderungen f√ºr diese Prozesse und jetzt f√ºr die Prozessgruppen zur√ºck: <br><br><img src="https://habrastorage.org/webt/_s/cl/7v/_scl7v6nsak1ieo-dipaz9sgb_a.png"><br>  <i>(Ich wiederhole, dass alle Zahlen ein abstrakter Ausdruck der Ressourcenanforderungen sind.)</i> <br><br>  Gleichzeitig verf√ºgt die CPU selbst √ºber eine bestimmte endg√ºltige Ressource <i>(im Beispiel 1000)</i> , die m√∂glicherweise nicht f√ºr alle ausreicht (die Summe der Anforderungen aller Gruppen betr√§gt 150 + 850 + 460 = 1460).  Was wird in diesem Fall passieren? <br><br>  Der Kernel beginnt, Ressourcen zu verteilen und tut dies ‚Äûehrlich‚Äú, indem er jeder Gruppe die gleiche Menge an Ressourcen zur Verf√ºgung stellt.  Im ersten Fall gibt es jedoch mehr als n√∂tig (333&gt; 150), sodass der √úberschuss (333-150 = 183) in der Reserve verbleibt, die ebenfalls gleichm√§√üig auf zwei andere Container verteilt ist: <br><br><img src="https://habrastorage.org/webt/nm/qv/te/nmqvteopou65lsc_ku2b0-qmbco.gif"><br><br>  Als Ergebnis: Der erste Container hatte genug Ressourcen, der zweite - war nicht genug, der dritte - war nicht genug.  Dies ist das Ergebnis des <b>"ehrlichen" Schedulers in Linux</b> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CFS</a> .  Seine Arbeit kann reguliert werden, indem jedem Beh√§lter ein <b>Gewicht</b> zugewiesen wird.  Zum Beispiel so: <br><br><img src="https://habrastorage.org/webt/z1/c_/_b/z1c__bumb8hy1k5zdrkcwo_aak0.gif"><br><br>  Schauen wir uns den Fall eines Ressourcenmangels im zweiten Container (php-fpm) an.  Alle Containerressourcen werden gleichm√§√üig auf die Prozesse verteilt.  Infolgedessen funktioniert der Master-Prozess gut, und alle Mitarbeiter werden langsamer, da sie weniger als die H√§lfte des ben√∂tigten Bedarfs erhalten haben: <br><br><img src="https://habrastorage.org/webt/9z/wi/d2/9zwid2g1znmdoslkl9bf9cogrnq.gif"><br><br>  So funktioniert der CFS-Scheduler.  Die Gewichte, die wir den Containern zuweisen, werden in Zukunft als <b>Anfragen bezeichnet</b> .  Warum so - siehe unten. <br><br>  Schauen wir uns die ganze Situation von der anderen Seite an.  Wie Sie wissen, f√ºhren alle Wege nach Rom und im Falle eines Computers zur CPU.  Eine CPU, viele Aufgaben - Sie brauchen eine Ampel.  Der einfachste Weg, Ressourcen zu verwalten, ist die Ampel: Sie geben einem Prozess eine feste Zugriffszeit auf die CPU, dann dem n√§chsten usw. <br><br><img src="https://habrastorage.org/webt/vf/af/qe/vfafqespiii6mnts87i4amfdyku.gif"><br><br>  Dieser Ansatz wird als <i>harte Begrenzung bezeichnet</i> .  Denken Sie daran, nur als <b>Grenzen</b> .  Wenn Sie jedoch Grenzwerte auf alle Container verteilen, tritt ein Problem auf: MySQL fuhr die Stra√üe entlang und irgendwann endete sein Bedarf an einer CPU, aber alle anderen Prozesse mussten warten, w√§hrend die CPU im <b>Leerlauf war</b> . <br><br><img src="https://habrastorage.org/webt/7o/1m/ps/7o1mps5khnoqkfywizrusxtug1q.png"><br><br>  Kehren wir zum Linux-Kernel und seiner Interaktion mit der CPU zur√ºck - das Gesamtbild sieht wie folgt aus: <br><br><img src="https://habrastorage.org/webt/m7/xz/x8/m7xzx8brcdgbihu8qchb63rwjwc.png"><br><br>  Cgroup verf√ºgt √ºber zwei Einstellungen. Dies sind zwei einfache ‚ÄûWendungen‚Äú, mit denen Sie Folgendes bestimmen k√∂nnen: <br><br><ol><li>  Gewicht f√ºr den Container (Anfrage) ist <b>Aktien</b> ; </li><li>  Ein Prozentsatz der gesamten CPU-Zeit f√ºr die Bearbeitung von Containeraufgaben (Limits) ist das <b>Kontingent</b> . </li></ol><br><h3>  Wie messe ich die CPU? </h3><br>  Es gibt verschiedene M√∂glichkeiten: <br><br><ol><li>  Was <i>Papageien sind</i> , wei√ü niemand - jedes Mal, wenn Sie zustimmen m√ºssen. </li><li>  <i>Das Interesse ist</i> klarer, aber relativ: 50% eines Servers mit 4 Kernen und 20 Kernen sind v√∂llig verschiedene Dinge. </li><li>  Sie k√∂nnen die bereits erw√§hnten <i>Gewichte verwenden</i> , die Linux kennt, aber sie sind auch relativ. </li><li>  Die am besten geeignete Option besteht darin, die Rechenressourcen in <i>Sekunden</i> zu messen.  Das hei√üt,  in Sekunden Prozessorzeit im Verh√§ltnis zu Sekunden Echtzeit: Sie gaben 1 Sekunde Prozessorzeit in 1 realen Sekunde aus - dies ist ein ganzer CPU-Kern. </li></ol><br>  Um es noch einfacher zu sagen, begannen sie direkt in den <i>Kernen</i> zu messen, dh die CPU-Zeit relativ zur realen.  Da Linux eher Gewichte als Prozessorzeit / -kerne versteht, war ein √úbersetzungsmechanismus von einem zum anderen erforderlich. <br><br>  Stellen Sie sich ein einfaches Beispiel mit einem Server mit 3 CPU-Kernen vor, bei dem drei Pods Gewichte (500, 1000 und 1500) ausw√§hlen, die leicht in die entsprechenden Teile der ihnen zugewiesenen Kerne (0,5, 1 und 1,5) konvertiert werden k√∂nnen. <br><br><img src="https://habrastorage.org/webt/mz/vl/1x/mzvl1xmzbtvlwgsqtf1-_n_rhns.png"><br><br>  Wenn Sie einen zweiten Server mit doppelt so vielen Kernen (6) verwenden und dort dieselben Pods platzieren, kann die Verteilung der Kerne einfach durch einfaches Multiplizieren mit 2 (1, 2 bzw. 3) berechnet werden.  Der wichtige Punkt tritt jedoch auf, wenn der vierte Pod auf diesem Server angezeigt wird, dessen Gewicht der Einfachheit halber 3000 betr√§gt. Dadurch werden einige CPU-Ressourcen (die H√§lfte der Kerne) weggenommen, und der Rest der Pods gibt sie wieder (H√§lfte): <br><br><img src="https://habrastorage.org/webt/p3/1t/nd/p31tndrejrchgwgbnpk53q5qnig.gif"><br><br><h3>  Kubernetes und CPU-Ressourcen </h3><br>  In Kubernetes werden CPU-Ressourcen normalerweise in <b>Millikernen</b> gemessen, d.h.  Als Grundgewicht werden 0,001 Kerne verwendet.  <i>(Dasselbe gilt in der Linux / cgroups-Terminologie als CPU-Freigabe, genauer gesagt 1000 CPU = 1024 CPU-Freigaben.)</i> K8s stellt sicher, dass nicht mehr Pods auf dem Server platziert werden, als CPU-Ressourcen f√ºr die Summe der Gewichte vorhanden sind alle H√ºlsen. <br><br>  Wie l√§uft das  Wenn ein Server zu einem Kubernetes-Cluster hinzugef√ºgt wird, wird gemeldet, wie viele CPU-Kerne f√ºr ihn verf√ºgbar sind.  Beim Erstellen eines neuen Pods wei√ü der Kubernetes-Scheduler, wie viele Kerne dieser Pod ben√∂tigt.  Somit wird der Pod auf dem Server definiert, auf dem gen√ºgend Kerne vorhanden sind. <br><br>  Was passiert, wenn <b>keine</b> Anforderung angegeben wird (d. H. Der Pod bestimmt nicht die Anzahl der ben√∂tigten Kernel)?  Mal sehen, wie Kubernetes im Allgemeinen Ressourcen z√§hlt. <br><br>  Der Pod kann sowohl Anforderungen (CFS-Scheduler) als auch Grenzwerte angeben (erinnern Sie sich an die Ampel?): <br><br><ul><li>  Wenn sie gleich sind, wird die garantierte QoS-Klasse dem Pod zugewiesen.  Eine solche Menge an Kerneln, die ihm immer zur Verf√ºgung stehen, ist garantiert. </li><li>  Wenn die Anforderung unter dem Grenzwert liegt, kann die QoS-Klasse <b>geplatzt werden</b> .  Das hei√üt,  Wir erwarten, dass Pod beispielsweise immer 1 Kern verwendet, aber dieser Wert ist keine Einschr√§nkung daf√ºr: <i>Manchmal</i> kann Pod mehr verwenden (wenn daf√ºr freie Ressourcen auf dem Server vorhanden sind). </li><li>  Es gibt auch die QoS-Klasse mit dem <b>besten Aufwand</b> - diejenigen Pods, f√ºr die keine Anforderung angegeben ist, geh√∂ren dazu.  Ressourcen werden ihnen zuletzt gegeben. </li></ul><br><h3>  Die Erinnerung </h3><br>  √Ñhnlich verh√§lt es sich mit dem Ged√§chtnis, aber ein wenig anders - schlie√ülich ist die Art dieser Ressourcen anders.  Im Allgemeinen lautet die Analogie wie folgt: <br><br><img src="https://habrastorage.org/webt/hw/zu/ja/hwzuja_vf0ojiz8uai-hhtn23ys.png"><br><br>  Mal sehen, wie Anfragen im Speicher implementiert werden.  Lassen Sie Pods auf dem Server leben und √§ndern Sie den verbrauchten Speicher, bis einer von ihnen so gro√ü wird, dass der Speicher knapp wird.  In diesem Fall erscheint der OOM-Killer und beendet den gr√∂√üten Prozess: <br><br><img src="https://habrastorage.org/webt/mg/i0/at/mgi0atkc5o5m0xo-crxt3augbnm.gif"><br><br>  Dies passt nicht immer zu uns, daher ist es m√∂glich zu regeln, welche Prozesse f√ºr uns wichtig sind und nicht get√∂tet werden sollten.  Verwenden Sie dazu den Parameter <b>oom_score_adj</b> . <br><br>  Kehren wir zu den CPU-QoS-Klassen zur√ºck und ziehen eine Analogie zu den oom_score_adj-Werten, die die Speicherverbrauchspriorit√§ten f√ºr Pods bestimmen: <br><br><ul><li>  Der niedrigste oom_score_adj-Wert eines Pods ist -998, was bedeutet, dass ein solcher Pod an letzter Stelle get√∂tet werden sollte. Dies ist <b>garantiert</b> . </li><li>  Die h√∂chste - 1000 - ist die <b>beste Anstrengung</b> , solche Schoten werden vor allen anderen get√∂tet. </li><li>  Um den Rest der Werte ( <b>Burstable</b> ) zu berechnen, gibt es eine Formel, deren Essenz darauf <b>hinausl√§uft</b> , dass je mehr Pod Ressourcen angefordert hat, desto geringer ist die Wahrscheinlichkeit, dass sie get√∂tet werden. </li></ul><br><img src="https://habrastorage.org/webt/sc/yo/rm/scyorm9zwn_lltxminknyv-cbhy.png"><br><br>  Die zweite "Drehung" - <b>limit_in_bytes</b> - f√ºr Limits.  Damit ist alles einfacher: Wir weisen einfach die maximale Speichermenge zu, die ausgegeben werden soll, und hier (im Gegensatz zur CPU) steht au√üer Frage, worin sie (Speicher) gemessen wird. <br><br><h3>  Insgesamt </h3><br>  Anforderungen und <code>limits</code> werden f√ºr jeden Pod in Kubernetes festgelegt - sowohl Parameter f√ºr die CPU als auch f√ºr den Speicher: <br><br><ol><li>  Basierend auf Anforderungen funktioniert der Kubernetes-Scheduler, der Pods auf mehrere Server verteilt. </li><li>  Basierend auf allen Parametern wird die QodS-Klasse des Pods bestimmt. </li><li>  Relative Gewichte werden basierend auf CPU-Anforderungen berechnet. </li><li>  Basierend auf CPU-Anforderungen wird ein CFS-Scheduler konfiguriert. </li><li>  Basierend auf Speicheranforderungen wird OOM Killer konfiguriert. </li><li>  Basierend auf den CPU-Grenzwerten wird eine ‚ÄûAmpel‚Äú konfiguriert. </li><li>  Basierend auf Speicherlimits wird ein Limit f√ºr cgroup festgelegt. </li></ol><br><img src="https://habrastorage.org/webt/dr/1i/0_/dr1i0_troiqlcg4q_ki2fytefs0.png"><br><br>  Im Allgemeinen beantwortet dieses Bild alle Fragen, wie der Hauptteil des Ressourcenmanagements in Kubernetes stattfindet. <br><br><h2>  Autoskalierung </h2><br><h3>  K8s Cluster-Autoscaler </h3><br>  Stellen Sie sich vor, der gesamte Cluster ist bereits belegt und es muss ein neuer Pod erstellt werden.  Der Pod kann zwar nicht angezeigt werden, h√§ngt jedoch im Status " <i>Ausstehend</i> ".  Damit es so aussieht, k√∂nnen wir einen neuen Server mit dem Cluster verbinden oder ... Cluster-Autoscaler einsetzen, der dies f√ºr uns erledigt: Bestellen Sie eine virtuelle Maschine beim Cloud-Anbieter (auf API-Anfrage) und verbinden Sie sie mit dem Cluster. Anschlie√üend wird der Pod hinzugef√ºgt . <br><br><img src="https://habrastorage.org/webt/zu/va/dq/zuvadqhlpycxkqaw5q35bmr08_e.gif"><br><br>  Dies ist die automatische Skalierung des Kubernetes-Clusters, die (nach unserer Erfahrung) hervorragend funktioniert.  Wie auch hier gibt es hier einige Nuancen ... <br><br>  W√§hrend wir die Clustergr√∂√üe vergr√∂√üerten, war alles in Ordnung, aber was passiert, wenn der Cluster <b>freigegeben wird</b> ?  Das Problem ist, dass die Migration von Pods (auf freie Hosts) technisch sehr schwierig und ressourcenintensiv ist.  Kubernetes verfolgt einen v√∂llig anderen Ansatz. <br><br>  Stellen Sie sich einen Cluster von 3 Servern vor, auf denen eine Bereitstellung stattfindet.  Er hat 6 Pods: Jetzt sind es 2 f√ºr jeden Server.  Aus irgendeinem Grund wollten wir einen der Server ausschalten.  Verwenden Sie dazu den Befehl <code>kubectl drain</code> , der: <br><br><ul><li>  verbietet das Senden neuer Pods an diesen Server; </li><li>  Entfernen Sie vorhandene Pods auf dem Server. </li></ul><br>  Da Kubernetes die Wartung der Anzahl der Pods (6) √ºberwacht, werden sie einfach auf anderen Knoten neu erstellt, jedoch nicht auf dem nicht verbundenen Knoten, da sie bereits als nicht zug√§nglich f√ºr das Platzieren neuer Pods markiert sind.  Dies ist die grundlegende Mechanik f√ºr Kubernetes. <br><br><img src="https://habrastorage.org/webt/l8/dw/jf/l8dwjfv1yyszva-knkk6p0hls_s.gif"><br><br>  Hier gibt es jedoch eine Nuance.  In einer √§hnlichen Situation f√ºr StatefulSet (anstelle von Deployment) sind die Aktionen unterschiedlich.  Jetzt haben wir bereits eine Stateful-Anwendung - zum Beispiel drei Pods mit MongoDB, von denen einer ein Problem hatte (die Daten wurden besch√§digt oder ein anderer Fehler verhinderte, dass der Pod richtig gestartet wurde).  Und wieder beschlie√üen wir, einen Server zu trennen.  Was wird passieren? <br><br><img src="https://habrastorage.org/webt/a1/dx/ck/a1dxckkad2wpckrygftdzcjbuyq.gif"><br><br>  MongoDB <i>k√∂nnte</i> sterben, weil es ein Quorum ben√∂tigt: F√ºr einen Cluster von drei Installationen m√ºssen mindestens zwei funktionieren.  Dies <i>geschieht jedoch nicht</i> - dank des <b>PodDisruptionBudget</b> .  Dieser Parameter bestimmt die minimal erforderliche Anzahl von Arbeitskapseln.  Wenn Sie wissen, dass einer der Pods mit MongoDB nicht mehr funktioniert, und wenn minAvailable in <code>minAvailable: 2</code> f√ºr MongoDB festgelegt ist, k√∂nnen Sie den Pod mit Kubernetes nicht entfernen. <br><br>  Fazit: Um Pods bei der Freigabe des Clusters korrekt zu verschieben (und tats√§chlich neu zu erstellen), m√ºssen Sie PodDisruptionBudget konfigurieren. <br><br><h3>  Horizontale Skalierung </h3><br>  Betrachten Sie eine andere Situation.  In Kubernetes wird eine Anwendung als Bereitstellung ausgef√ºhrt.  Der Benutzerverkehr kommt zu seinen Pods (zum Beispiel gibt es drei davon), und wir messen einen bestimmten Indikator in ihnen (z. B. CPU-Auslastung).  Wenn die Last zunimmt, korrigieren wir sie im Zeitplan und erh√∂hen die Anzahl der Pods, um Anforderungen zu verteilen. <br><br>  In Kubernetes m√ºssen Sie dies heute nicht mehr manuell tun: Sie k√∂nnen die Anzahl der Pods abh√§ngig von den Werten der gemessenen Lastindikatoren automatisch erh√∂hen / verringern. <br><br><img src="https://habrastorage.org/webt/kj/fm/_t/kjfm_tu0u83c4mthfjayisabme0.gif"><br><br>  Die Hauptfragen hier sind, <b>was genau zu messen ist</b> und <b>wie die</b> erhaltenen Werte <b>zu interpretieren</b> sind (um eine Entscheidung √ºber die √Ñnderung der Anzahl der Pods zu treffen).  Sie k√∂nnen viel messen: <br><br><img src="https://habrastorage.org/webt/h-/tw/a8/h-twa8kqe49av8gwxwxeoadyalc.png"><br><br>  Wie es technisch geht - Metriken sammeln usw.  - Ich habe im Bericht √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberwachung und Kubernetes</a> ausf√ºhrlich gesprochen.  Und der wichtigste Rat f√ºr die Auswahl der optimalen Parameter ist das <b>Experimentieren</b> ! <br><br>  Es gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eine USE-Methode</a> <i>(Utilization Saturation and Errors</i> ), deren Bedeutung wie folgt lautet.  Auf welcher Basis ist es sinnvoll, beispielsweise php-fpm zu skalieren?  Basierend auf der Tatsache, dass die Arbeiter enden, ist es die <i>Nutzung</i> .  Und wenn die Arbeiter vorbei sind und neue Verbindungen nicht akzeptiert werden, ist das <i>S√§ttigung</i> .  Beide Parameter m√ºssen gemessen werden, und abh√§ngig von den Werten sollte eine Skalierung durchgef√ºhrt werden. <br><br><h2>  Anstelle einer Schlussfolgerung </h2><br>  Der Bericht enth√§lt eine Fortsetzung: Informationen zur vertikalen Skalierung und zur Auswahl der richtigen Ressourcen.  Ich werde in zuk√ºnftigen Videos auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unserem YouTube dar√ºber</a> sprechen - abonnieren, um es nicht zu verpassen! <br><br><h2>  Videos und Folien </h2><br>  Video von der Auff√ºhrung (44 Minuten): <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/10ZR-fbyuSY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Pr√§sentation des Berichts: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  PS </h2><br>  Andere Kubernetes-Berichte in unserem Blog: <br><br><ul><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes erweitern und erg√§nzen</a> ‚Äú <i>(Andrey Polov; 8. April 2019 bei Saint HighLoad ++)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datenbanken und Kubernetes</a> " <i>(Dmitry Stolyarov; 8. November 2018 auf HighLoad ++)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Monitoring and Kubernetes</a> " <i>(Dmitry Stolyarov; 28. Mai 2018 bei RootConf)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beste CI / CD-Praktiken mit Kubernetes und GitLab</a> ‚Äú <i>(Dmitry Stolyarov; 7. November 2017 bei HighLoad ++)</i> ; </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unsere Erfahrung mit Kubernetes in kleinen Projekten</a> ‚Äú <i>(Dmitry Stolyarov; 6. Juni 2017 bei RootConf)</i> . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de459326/">https://habr.com/ru/post/de459326/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de459314/index.html">Visualisieren und behandeln Sie Hash Match Join</a></li>
<li><a href="../de459316/index.html">Hydra 2019: kostenlose √úbertragung der ersten Halle und ein wenig dar√ºber, was auf der Konferenz sein wird</a></li>
<li><a href="../de459318/index.html">TypeScript und kurze Sprints. Wie wir das Variationstool f√ºr das Front-End-Interview erstellt haben</a></li>
<li><a href="../de459320/index.html">Kubernetes Operator in Python ohne Frameworks und SDKs</a></li>
<li><a href="../de459322/index.html">Herausgeber Peter. Sommerschlussverkauf</a></li>
<li><a href="../de459328/index.html">Best-in-Class-Preis-Leistungsverh√§ltnis - Mpow A5 (059)</a></li>
<li><a href="../de459330/index.html">Bitrix f√ºr Programmierer und Manager: Liebe und Hass</a></li>
<li><a href="../de459334/index.html">YouTrack 2019.2: ein systemweites Banner, Verbesserungen der Aufgabenlistenseite, neue Suchoptionen und mehr</a></li>
<li><a href="../de459336/index.html">Lebe und lerne. Teil 1. Schul- und Berufsberatung</a></li>
<li><a href="../de459338/index.html">Verwendung des Verifizierers als Mittel zur schnellen Modellierung von RTL-Projekten. Einf√ºhrung in UVM</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
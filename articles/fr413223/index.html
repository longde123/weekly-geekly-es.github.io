<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤼 ➡️ 💛 Dictionnaire Habra. Partie 1 👨🏻‍🏫 🧑🏿‍🤝‍🧑🏿 😔</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mes amis, bonjour. 


 J'ai résolu le problème de la compilation du dictionnaire Habrahabr dans le but de suivre l'émergence de nouveaux langages, cad...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Dictionnaire Habra. Partie 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413223/"><p>  Mes amis, bonjour. </p><br><p>  J'ai résolu le problème de la compilation du dictionnaire Habrahabr dans le but de suivre l'émergence de nouveaux langages, cadres, pratiques de gestion, etc.  Bref, de nouveaux mots. </p><br><p>  Le résultat a été une liste de mots anglais "dans le cas nominatif et au singulier". </p><br><p>  Il l'a fait dans l'environnement Windows 10 x64, a utilisé le langage Python 3 dans l'éditeur Spyder dans Anaconda 5.1.0 et a utilisé une connexion réseau filaire. </p><br><p>  Dans cet article, je reçois un dictionnaire de mots anglais dans un échantillon limité.  Si le sujet s'avère intéressant, je prévois à l'avenir d'obtenir un dictionnaire de mots anglais et russes sur une sélection complète d'articles de Habr.  Avec la langue russe, tout est plus compliqué. </p><br><p>  <strong>Processus d'analyse</strong> </p><br><p>  J'ai pris le disque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'ici</a> .  Voici le code de ma version de l'analyseur. </p><br><p> Pour collecter le dictionnaire Habr, vous devez contourner ses articles et sélectionner le texte des articles à partir d'eux.  Je n'ai pas traité les méta-informations des articles.  Les articles sur Habré ont mon "numéro", comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://habr.com/post/346198/</a> .  L'énumération des articles peut se faire de 0 à 354366, c'était le dernier article au moment du projet. </p><a name="habracut"></a><br><p>  Pour chaque problème, nous essayons d'obtenir une page html et, lorsque cela réussit, nous extrayons le titre et le texte de l'article de la structure html.  Le code de contournement est le suivant: </p><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup dataset = pd.DataFrame() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">350000</span></span>,<span class="hljs-number"><span class="hljs-number">354366</span></span>): r = requests.<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>(<span class="hljs-string"><span class="hljs-string">'https://habrahabr.ru/post/'</span></span> +str(pid) + <span class="hljs-string"><span class="hljs-string">'/'</span></span>) soup = BeautifulSoup(r.text, <span class="hljs-string"><span class="hljs-string">'html5lib'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> soup.find("span", {"class": "post__title-text"}): title = soup.find("span", {"class": "post__title-text"}).text <span class="hljs-type"><span class="hljs-type">text</span></span> = soup.find("div", {"class": "post__text"}).text my_series = pd.Series([pid, title, <span class="hljs-type"><span class="hljs-type">text</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=[<span class="hljs-string"><span class="hljs-string">'id'</span></span>, <span class="hljs-string"><span class="hljs-string">'title'</span></span>, <span class="hljs-string"><span class="hljs-string">'text'</span></span>]) df_new = pd.DataFrame(my_series).transpose() dataset = dataset.append(df_new, ignore_index = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  Empiriquement établi que les articles eux-mêmes sont moins de trois fois le nombre.  Je me suis entraîné sur les numéros 4366 - c'est la charge de mon système en une demi-heure. </p><br><p>  Je n'ai pas fait d'optimisation de la vitesse, bien qu'ils disent que si vous commencez le traitement dans 100 threads, ce sera beaucoup plus rapide. </p><br><p>  J'ai enregistré le résultat sur le disque </p><br><pre> <code class="hljs pgsql">dataset.to_excel(directory+<span class="hljs-string"><span class="hljs-string">'dataset.xlsx'</span></span>, sheet_name=<span class="hljs-string"><span class="hljs-string">'sheet1'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><p>  - afin de ne pas répéter le téléchargement lent depuis Internet.  Le fichier s'est avéré être de 10 mégaoctets. </p><br><p>  Je m'intéressais aux noms anglais des instruments.  Je n'avais pas besoin de termes sous différentes formes, je voulais obtenir immédiatement des formes de mots normales.  Il est clair que les mots les plus courants sont «in», «on» et «by», nous les supprimons.  Pour normaliser le dictionnaire, j'ai utilisé le Stimmer Porter anglais de la bibliothèque ntlk. </p><br><p>  J'ai utilisé la méthode indirecte pour créer une liste de mots du dictionnaire, voir le code commençant par "from sklearn.feature_extraction.text import CountVectorizer".  J'en aurai besoin plus tard. </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk nltk.download(<span class="hljs-string"><span class="hljs-string">'stopwords'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.corpus <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> stopwords <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.stem.porter <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PorterStemmer corpus = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">0</span></span>, len(dataset.<span class="hljs-keyword"><span class="hljs-keyword">index</span></span>)): review = re.sub(<span class="hljs-string"><span class="hljs-string">'[^a-zA-Z]'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, dataset[<span class="hljs-string"><span class="hljs-string">'text'</span></span>][i]) review = review.lower() review = review.split() ps = PorterStemmer() review = [ps.stem(word) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> review <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(stopwords.words(<span class="hljs-string"><span class="hljs-string">'english'</span></span>))] review = <span class="hljs-string"><span class="hljs-string">' '</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(review) corpus.append(review) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CountVectorizer cv = CountVectorizer() X = cv.fit_transform(corpus).toarray() names = cv.get_feature_names() dfnames = pd.DataFrame(names).transpose() dfnames.to_excel(directory+<span class="hljs-string"><span class="hljs-string">'names.xlsx'</span></span>, sheet_name=<span class="hljs-string"><span class="hljs-string">'sheet1'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><p>  L'objet <strong>names</strong> est le dictionnaire que vous recherchez.  Nous l'avons enregistré sur le disque. </p><br><p>  <strong>Aperçu des résultats</strong> </p><br><p>  Il s'est avéré plus de 30 000 morceaux de mots déjà normalisés.  Et ce ne sont que 4366 numéros d'article et mots en anglais uniquement. </p><br><p>  De l'intéressant: </p><br><ol><li><p>  Les auteurs d'articles utilisent beaucoup de «mots» étranges, par exemple: aaaaaaaaaaaa, aaaabbbbccccdddd ou zzzhoditqxfpqbcwr </p><br></li><li>  De l'objet X, nous obtenons le top 10 des mots anglais les plus populaires de notre échantillon: </li></ol><br><p>  <strong>PC Word</strong> <br>  iter 4133 <br>  op 4030 <br>  retour 2866 <br>  ns 2834 <br>  id 2740 <br>  nom 2556 <br>  nouveau 2410 <br>  données 2381 <br>  chaîne 2358 <br>  http 2304 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr413223/">https://habr.com/ru/post/fr413223/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr413213/index.html">Apple WWDC 2018: diffusion de texte</a></li>
<li><a href="../fr413215/index.html">GitHub appartient désormais officiellement à Microsoft</a></li>
<li><a href="../fr413217/index.html">Les voitures électriques sont-elles si respectueuses de l'environnement?</a></li>
<li><a href="../fr413219/index.html">Bienvenue sur le SuperJob QA-Meetup</a></li>
<li><a href="../fr413221/index.html">Les bactéries survivent dans une "salle blanche" pendant l'assemblage du vaisseau spatial, en mangeant des produits de nettoyage</a></li>
<li><a href="../fr413225/index.html">Semaine de la sécurité 20: cyberattaques non triviales</a></li>
<li><a href="../fr413227/index.html">Qu'est-ce que Dieu sous les vêtements</a></li>
<li><a href="../fr413229/index.html">Build Caffe sur Google Colaboratory: carte graphique gratuite dans le cloud</a></li>
<li><a href="../fr413231/index.html">Introduction aux contrats intelligents</a></li>
<li><a href="../fr413233/index.html">Le service uLogin envoie les données des formulaires (courrier, téléphone) à un site tiers et ne dit rien à ce sujet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
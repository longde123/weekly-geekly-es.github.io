<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçü§ù‚Äçüë®üèª ü¶ï üõ§Ô∏è Analyse: OOM auf Kubernetes üë¶üèø üö£üèª ü§±üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Probleme in der Arbeitsumgebung sind immer eine Katastrophe. Es passiert, wenn Sie nach Hause gehen, und der Grund scheint immer dumm. In letzter Zeit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse: OOM auf Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/467823/"><p><img src="https://habrastorage.org/webt/m8/of/zv/m8ofzvtlhfh8mkwo-i04c5ren38.jpeg"></p><br><p>  Probleme in der Arbeitsumgebung sind immer eine Katastrophe.  Es passiert, wenn Sie nach Hause gehen, und der Grund scheint immer dumm.  In letzter Zeit ist auf den Knoten im Kubernetes-Cluster nicht mehr gen√ºgend Speicher vorhanden, obwohl der Knoten ohne sichtbare Unterbrechungen sofort wiederhergestellt wurde.  Heute werden wir √ºber diesen Fall sprechen, dar√ºber, welchen Schaden wir erlitten haben und wie wir ein √§hnliches Problem in Zukunft vermeiden wollen. </p><br><h2 id="sluchay-pervyy">  Fall eins </h2><br><h3 id="subbota-15-iyunya-2019-g-1712">  Samstag, 15. Juni 2019, 17:12 Uhr </h3><a name="habracut"></a><br><p>  Blue Matador (ja, wir √ºberwachen uns selbst!) Erzeugt eine Warnung: ein Ereignis auf einem der Knoten im Kubernetes-Produktionscluster - SystemOOM. </p><br><h3 id="1716">  17:16 </h3><br><p>  Blue Matador generiert eine Warnung: EBS Burst Balance ist auf dem Root-Volume des Knotens niedrig - dem, auf dem das SystemOOM-Ereignis stattgefunden hat.  Obwohl nach einer Benachrichtigung √ºber SystemOOM eine Warnung zum Burst Balance angezeigt wurde, zeigen die tats√§chlichen CloudWatch-Daten, dass das Burst Balance um 17:02 Uhr einen Mindestwert erreicht hat.  Der Grund f√ºr die Verz√∂gerung ist, dass die EBS-Metriken st√§ndig 10 bis 15 Minuten zur√ºckliegen und unser System nicht alle Ereignisse in Echtzeit erfasst. </p><br><p><img src="https://habrastorage.org/webt/xw/gb/u3/xwgbu3jxukrpz_qmakfhvsb5bm4.png"></p><br><h3 id="1718">  17:18 </h3><br><p> Im Moment sah ich eine Warnung und eine Warnung.  Ich <strong>f√ºhre kubectl get pods</strong> schnell aus, <strong>um</strong> zu sehen, welchen Schaden wir erlitten haben, und ich bin √ºberrascht, dass die Pods in der Anwendung genau 0 gestorben sind. Ich <strong>f√ºhre kubectl top knoten durch</strong> , aber diese √úberpr√ºfung zeigt auch, dass der verd√§chtige Knoten ein Speicherproblem hat;  Es stimmt, es hat sich bereits erholt und verwendet ungef√§hr 60% seines Speichers.  Es ist 17 Uhr und das Craft Beer w√§rmt sich bereits auf.  Nachdem ich sichergestellt hatte, dass der Knoten betriebsbereit war und kein einziger Pod besch√§digt war, entschied ich, dass ein Unfall aufgetreten war.  Wenn √ºberhaupt, werde ich es am Montag herausfinden. </p><br><p>  Hier ist unsere Korrespondenz mit der Tankstelle in Slack an diesem Abend: </p><br><p><img src="https://habrastorage.org/webt/ib/fp/f0/ibfpf05vnjd2uaukxr0rwjgcjj0.png"></p><br><h2 id="sluchay-vtoroy">  Fall zwei </h2><br><h3 id="subbota-16-iyunya-2019-g-1802">  Samstag, 16. Juni 2019, 18:02 Uhr </h3><br><p>  Blue Matador generiert eine Warnung: Das Ereignis befindet sich bereits auf einem anderen Knoten, ebenfalls SystemOOM.  Es muss gewesen sein, dass die Tankstelle in diesem Moment nur auf den Bildschirm des Smartphones schaute, weil sie mir schrieb und mich sofort dazu brachte, das Ereignis aufzunehmen. Ich selbst kann den Computer nicht einschalten (ist es Zeit, Windows erneut zu installieren?).  Und wieder scheint alles normal zu sein.  Es wird kein einziger Pod get√∂tet, und der Knoten belegt kaum 70% des Speichers. </p><br><h3 id="1806">  18:06 </h3><br><p>  Blue Matador generiert erneut eine Warnung: EBS Burst Balance.  Das zweite Mal an einem Tag, was bedeutet, dass ich dieses Problem nicht auf den Bremsen l√∂sen kann.  Bei unver√§nderter CloudWatch weicht Burst Balance 2 Stunden oder l√§nger von der Norm ab, bevor das Problem identifiziert wurde. </p><br><h3 id="1811">  18:11 </h3><br><p>  Ich gehe zu Datalog und schaue mir die Daten zum Speicherverbrauch an.  Ich sehe, dass der verd√§chtige Knoten kurz vor dem SystemOOM-Ereignis wirklich viel Speicherplatz beansprucht hat.  Der Weg f√ºhrt zu unseren flie√üend-sumologischen Kapseln. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/ae/s-/k-/aes-k-fwfx5qtsm7ehvhkgnpofe.png"></a> </p><br><p>  Sie k√∂nnen deutlich eine starke Abweichung des Speicherverbrauchs erkennen, ungef√§hr zur gleichen Zeit, zu der SystemOOM-Ereignisse aufgetreten sind.  Mein Fazit: Es waren diese Pods, die den gesamten Speicher beanspruchten, und als SystemOOM passierte, erkannte Kubernetes, dass diese Pods get√∂tet und neu gestartet werden konnten, um den erforderlichen Speicher zur√ºckzugeben, ohne meine anderen Pods zu beeintr√§chtigen.  Gut gemacht, Kubernetes! </p><br><p>  Warum habe ich das am Samstag nicht gesehen, als ich herausgefunden habe, welche Pods neu gestartet wurden?  Tatsache ist, dass ich flie√üend-sumologische Pods in einem separaten Namespace verwende und in Eile einfach nicht daran gedacht habe, mich damit zu befassen. </p><br><blockquote>  Schlussfolgerung 1: Wenn Sie nach neu gestarteten Pods suchen, √ºberpr√ºfen Sie alle Namespaces. </blockquote><p>  Nachdem ich diese Daten erhalten hatte, berechnete ich, dass der Speicher auf anderen Knoten am n√§chsten Tag nicht enden w√ºrde. Ich startete jedoch alle sumologischen Pods neu, sodass sie mit geringem Speicherverbrauch arbeiteten.  Am n√§chsten Morgen habe ich vor, die Arbeit an dem Problem in einen Wochenplan zu integrieren und nicht zu viel Sonntagabend zu laden. </p><br><h3 id="2300">  23:00 </h3><br><p>  Ich sah mir die n√§chste Serie von "Black Mirror" an (√ºbrigens mochte ich Miley) und beschloss, mir anzusehen, wie es dem Cluster ging.  Der Speicherverbrauch ist normal. Sie k√∂nnen also alles so lassen, wie es f√ºr die Nacht ist. </p><br><h2 id="pochinka">  Fix </h2><br><p>  Am Montag habe ich mir Zeit f√ºr dieses Problem genommen.  Es tut nicht weh, jede Nacht mit ihr herum zu jagen.  Was ich im Moment wei√ü: </p><br><ul><li>  Flie√üend-sumologische Beh√§lter verschlang eine Tonne Speicher; </li><li>  Dem SystemOOM-Ereignis geht eine hohe Festplattenaktivit√§t voraus, aber ich wei√ü nicht, welche. </li></ul><br><p>  Zuerst dachte ich, dass fl√ºssig-sumologische Beh√§lter akzeptiert werden, um bei einem pl√∂tzlichen Zufluss von Protokollen Speicher zu fressen.  Nachdem ich Sumologic √ºberpr√ºft hatte, stellte ich jedoch fest, dass die Protokolle stabil verwendet wurden, und zur gleichen Zeit, als es Probleme gab, gab es keine Zunahme dieser Protokolle. </p><br><p>  Ein wenig googeln, fand ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diese Aufgabe auf Github</a> , die vorschl√§gt, einige Ruby-Einstellungen anzupassen - um den Speicherverbrauch zu reduzieren.  Ich habe beschlossen, es auszuprobieren, der Pod-Spezifikation eine Umgebungsvariable hinzuzuf√ºgen und auszuf√ºhren: </p><br><pre><code class="plaintext hljs">env: - name: RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR value: "0.9"</code> </pre> <br><p>  Beim Durchsehen des flie√üend-sumologischen Manifests stellte ich fest, dass ich keine Ressourcenanforderungen und -beschr√§nkungen definiert hatte.  Ich fange an zu vermuten, dass der RUBY_GCP_HEAP-Fix ein Wunder bewirken wird. Daher ist es jetzt sinnvoll, Speicherverbrauchsgrenzen festzulegen.  Selbst wenn ich das Speicherproblem nicht behebe, ist es zumindest m√∂glich, den Verbrauch auf diesen Satz von Pods zu beschr√§nken.  Verwenden von <strong>kubectl top pods |</strong>  <strong>grep fluentd-sumologic</strong> , ich wei√ü bereits, wie viele Ressourcen ich anfordern muss: </p><br><pre> <code class="plaintext hljs">resources: requests: memory: "128Mi" cpu: "100m" limits: memory: "1024Mi" cpu: "250m"</code> </pre> <br><blockquote>  Schlussfolgerung 2: Festlegen von Ressourcenlimits, insbesondere f√ºr Anwendungen von Drittanbietern. </blockquote><br><h2 id="proverka-ispolneniya">  Ausf√ºhrungs√ºberpr√ºfung </h2><br><p>  Nach einigen Tagen best√§tige ich, dass die oben beschriebene Methode funktioniert.  Der Speicherverbrauch war stabil und - keine Probleme mit Komponenten von Kubernetes, EC2 und EBS.  Jetzt ist klar, wie wichtig es ist, Ressourcenanforderungen und -einschr√§nkungen f√ºr alle von mir ausgef√ºhrten Pods zu ermitteln. Folgendes muss getan werden: Wenden Sie eine Kombination aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Standardressourcenlimits und Ressourcenquoten an</a> . </p><br><p>  Das letzte ungel√∂ste R√§tsel ist EBS Burst Balance, das mit dem SystemOOM-Ereignis zusammenfiel.  Ich wei√ü, dass das Betriebssystem bei wenig Speicher den Auslagerungsbereich verwendet, um nicht vollst√§ndig ohne Speicher zu bleiben.  Aber ich wurde gestern nicht geboren und mir ist bewusst, dass Kubernetes nicht einmal auf Servern startet, auf denen die Auslagerungsdatei aktiviert ist.  Um sicherzugehen, bin ich √ºber SSH in meine Knoten geklettert, um zu √ºberpr√ºfen, ob die Auslagerungsdatei aktiviert wurde.  Ich habe sowohl freien Speicher als auch den im Swap-Bereich verwendet.  Die Datei wurde nicht aktiviert. </p><br><p>  Und da das Austauschen nicht funktioniert, habe ich mehr Hinweise darauf, was das Wachstum der E / A-Fl√ºsse verursacht hat, weshalb dem Knoten fast der Speicher ausgegangen ist, nein.  Eigentlich habe ich eine Ahnung: Der flie√üend-sumologische Pod selbst hat zu diesem Zeitpunkt eine Menge Protokollnachrichten geschrieben, m√∂glicherweise sogar eine Protokollnachricht im Zusammenhang mit der Einrichtung von Ruby GC.  Es ist auch m√∂glich, dass es andere Quellen f√ºr Kubernetes oder Journald-Nachrichten gibt, die √ºberm√§√üig produktiv werden, wenn der Speicher knapp wird, und ich habe sie beim Einrichten von flie√üend beseitigt.  Leider habe ich keinen Zugriff mehr auf die Protokolldateien, die unmittelbar vor der Fehlfunktion aufgezeichnet wurden, und kann jetzt nicht tiefer graben. </p><br><blockquote>  Schlussfolgerung 3: W√§hrend es eine Gelegenheit gibt, sollten Sie bei der Analyse der Grundursachen, unabh√§ngig vom Problem, tiefer gehen. </blockquote><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>  Und obwohl ich den Ursachen nicht auf den Grund gegangen bin, bin ich sicher, dass sie nicht ben√∂tigt werden, um die gleichen Fehlfunktionen in Zukunft zu verhindern.  Zeit ist Geld, aber ich war zu lange besch√§ftigt, und danach habe ich auch diesen Beitrag f√ºr Sie geschrieben.  Und da wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blue Matador verwenden</a> , werden solche St√∂rungen sehr detailliert behandelt, sodass ich mir erlaube, etwas auf den Bremsen zu l√∂sen, ohne vom Hauptprojekt abgelenkt zu werden. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de467823/">https://habr.com/ru/post/de467823/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de467811/index.html">Architektur und Programmierung Fairchild Channel F.</a></li>
<li><a href="../de467813/index.html">√úberpr√ºfung der √Ñnderungen in der 17. Ordnung der FSTEC</a></li>
<li><a href="../de467815/index.html">Die Medien l√∂sten eine Panik aus, dass "IP-Adressen in Russland ausgehen". Wie wirklich?</a></li>
<li><a href="../de467817/index.html">Ein wenig √ºber generative Designmuster</a></li>
<li><a href="../de467821/index.html">Vereinfachen und ausschneiden Sie das Notwendige: Interview mit John Romero, dem Sch√∂pfer von Doom</a></li>
<li><a href="../de467825/index.html">Must-Have-Algorithmen f√ºr maschinelles Lernen</a></li>
<li><a href="../de467827/index.html">Wie wir unsere kleine Einheit von Grund auf neu gemacht haben</a></li>
<li><a href="../de467831/index.html">Der dornige Weg zur Programmierung</a></li>
<li><a href="../de467837/index.html">"Schreckliche" Drei-Cent-MCU - ein kurzer √úberblick √ºber Mikrocontroller, die weniger als 0,1 US-Dollar kosten</a></li>
<li><a href="../de467841/index.html">Machen Sie es sich leichter, fertig zu werden: Interview mit John Romero, Entwickler von Doom</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
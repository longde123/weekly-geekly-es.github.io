<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë£ üê∑ üÜñ Kubernetes: por que √© t√£o importante configurar o gerenciamento de recursos do sistema? üë®üèæ‚Äçüåæ ‚öìÔ∏è üà¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como regra, sempre h√° a necessidade de fornecer um conjunto dedicado de recursos a qualquer aplicativo para sua opera√ß√£o correta e est√°vel. Mas e se v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes: por que √© t√£o importante configurar o gerenciamento de recursos do sistema?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nixys/blog/480072/"><p>  Como regra, sempre h√° a necessidade de fornecer um conjunto dedicado de recursos a qualquer aplicativo para sua opera√ß√£o correta e est√°vel.  Mas e se v√°rios aplicativos funcionarem com as mesmas capacidades ao mesmo tempo?  Como fornecer os recursos m√≠nimos necess√°rios para cada um deles?  Como posso limitar o consumo de recursos?  Como distribuir corretamente a carga entre n√≥s?  Como garantir o mecanismo de escala horizontal em caso de aumento de carga na aplica√ß√£o? </p><br><p><img src="https://habrastorage.org/webt/-f/yj/hw/-fyjhwhkhcibnshgzndgd4w4e_c.png"></p><a name="habracut"></a><br><p>  Voc√™ precisa come√ßar com quais tipos b√°sicos de recursos existem no sistema - √© claro, tempo do processador e RAM.  Nos manifestos do k8s, esses tipos de recursos s√£o medidos nas seguintes unidades: </p><br><ul><li>  CPU - nos n√∫cleos </li><li>  RAM - em bytes </li></ul><br><p>  Al√©m disso, para cada recurso, h√° uma oportunidade de definir dois tipos de requisitos - <strong>solicita√ß√µes</strong> e <strong>limites</strong> .  Solicita√ß√µes - descreve os requisitos m√≠nimos para os recursos livres do n√≥ executarem o cont√™iner (e a lareira como um todo), enquanto os limites definem um limite estrito nos recursos dispon√≠veis para o cont√™iner. </p><br><p>  √â importante entender que no manifesto n√£o √© necess√°rio definir explicitamente os dois tipos, e o comportamento ser√° o seguinte: </p><br><ul><li>  Se apenas os limites do recurso forem definidos explicitamente, as solicita√ß√µes para esse recurso ter√£o automaticamente um valor igual a limites (isso pode ser verificado chamando entidades de descri√ß√£o).  I.e.  de fato, a opera√ß√£o do cont√™iner ser√° limitada pela mesma quantidade de recursos necess√°ria para executar. </li><li>  Se apenas solicita√ß√µes forem explicitamente definidas para um recurso, nenhuma restri√ß√£o ser√° definida sobre ele - ou seja,  o cont√™iner √© limitado apenas pelos recursos do pr√≥prio n√≥. </li></ul><br><p>  Tamb√©m √© poss√≠vel configurar o gerenciamento de recursos n√£o apenas no n√≠vel de um cont√™iner espec√≠fico, mas tamb√©m no n√≠vel do namespace, usando as seguintes entidades: </p><br><ul><li>  <strong>LimitRange</strong> - descreve a pol√≠tica de restri√ß√£o no n√≠vel do cont√™iner / lareira em ns e √© necess√°ria para descrever as restri√ß√µes padr√£o no cont√™iner / lareira, al√©m de impedir a cria√ß√£o de cont√™ineres / lareiras obviamente gordas (ou vice-versa), limitar seu n√∫mero e determinar a poss√≠vel diferen√ßa nos valores dentro dos limites e pedidos </li><li>  <strong>ResourceQuotas</strong> - descreva a pol√≠tica de restri√ß√£o em geral para todos os cont√™ineres em ns e √© usada, como regra, para diferenciar recursos entre ambientes (√∫til quando os ambientes n√£o s√£o rigidamente delimitados no n√≠vel dos n√≥s) </li></ul><br><p>  A seguir, exemplos de manifestos em que os limites de recursos s√£o definidos: </p><br><ul><li><p>  No n√≠vel do cont√™iner espec√≠fico: </p><br><pre><code class="plaintext hljs">containers: - name: app-nginx image: nginx resources: requests: memory: 1Gi limits: cpu: 200m</code> </pre> <br><p>  I.e.  nesse caso, para iniciar um cont√™iner com nginx, voc√™ precisar√° pelo menos da presen√ßa de 1G OP e 0,2 CPU livre no n√≥, enquanto o cont√™iner m√°ximo pode consumir 0,2 CPU e todo o OP dispon√≠vel no n√≥. </p><br></li><li><p>  No n√≠vel inteiro ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: ResourceQuota metadata: name: nxs-test spec: hard: requests.cpu: 300m requests.memory: 1Gi limits.cpu: 700m limits.memory: 2Gi</code> </pre> <br><p>  I.e.  a soma de todos os cont√™ineres de solicita√ß√£o nos ns padr√£o n√£o pode exceder 300m para a CPU e 1G para o OP e a soma de todo o limite √© 700m para a CPU e 2G para o OP. </p><br></li><li><p>  Restri√ß√µes padr√£o para cont√™ineres em ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-per-container spec: limits: - type: Container defaultRequest: cpu: 100m memory: 1Gi default: cpu: 1 memory: 2Gi min: cpu: 50m memory: 500Mi max: cpu: 2 memory: 4Gi</code> </pre> <br><p>  I.e.  no espa√ßo de nome padr√£o para todos os cont√™ineres, por padr√£o, a solicita√ß√£o ser√° definida como 100m para a CPU e 1G para o OP, limite - 1 CPU e 2G.  Ao mesmo tempo, tamb√©m foi estabelecida uma restri√ß√£o sobre os poss√≠veis valores em solicita√ß√£o / limite para a CPU (50m &lt;x &lt;2) e RAM (500M &lt;x &lt;4G). </p><br></li><li><p>  Limita√ß√µes no n√≠vel da lareira ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-pod spec: limits: - type: Pod max: cpu: 4 memory: 1Gi</code> </pre> <br><p>  I.e.  para cada lareira nos ns padr√£o, ser√° definido um limite de 4 vCPU e 1G. </p><br></li></ul><br><p>  Agora, gostaria de dizer quais vantagens a instala√ß√£o dessas restri√ß√µes pode nos dar. </p><br><h2 id="mehanizm-balansirovki-nagruzki-mezhdu-nodami">  O mecanismo de balanceamento de carga entre n√≥s </h2><br><p>  Como voc√™ sabe, o componente k8s, como o <strong>agendador</strong> , que funciona de acordo com um determinado algoritmo, √© respons√°vel pela distribui√ß√£o dos lares pelos n√≥s.  Esse algoritmo no processo de escolha do n√≥ ideal para execu√ß√£o passa por dois est√°gios: </p><br><ol><li>  Filtragem </li><li>  Ranking </li></ol><br><p>  I.e.  de acordo com a pol√≠tica descrita, os n√≥s s√£o selecionados inicialmente no qual uma lareira pode ser iniciada com base em um conjunto de <strong>predicados</strong> (incluindo se o n√≥ possui recursos suficientes para executar uma lareira - PodFitsResources) e, em seguida, s√£o concedidos pontos para cada um desses n√≥s, de acordo com as <strong>prioridades</strong> (incluindo, quanto mais recursos livres o n√≥ tiver - mais pontos ele ser√° atribu√≠do - LeastResourceAllocation / LeastRequestedPriority / BalancedResourceAllocation) e ser√° executado no n√≥ com mais pontos (se v√°rios n√≥s atenderem a essa condi√ß√£o ao mesmo tempo, ser√° selecionado um aleat√≥rio). </p><br><p>  Ao mesmo tempo, voc√™ precisa entender que o planejador, ao avaliar os recursos dispon√≠veis do n√≥, se concentra nos dados armazenados no etcd - ou seja,  pela quantidade do recurso solicitado / limite de cada pod em execu√ß√£o neste n√≥, mas n√£o pelo consumo real de recursos.  Esta informa√ß√£o pode ser obtida na sa√≠da do comando <code>kubectl describe node $NODE</code> do <code>kubectl describe node $NODE</code> , por exemplo: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># kubectl describe nodes nxs-k8s-s1 .. Non-terminated Pods: (9 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits AGE --------- ---- ------------ ---------- --------------- ------------- --- ingress-nginx nginx-ingress-controller-754b85bf44-qkt2t 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-flannel-26bl4 150m (0%) 300m (1%) 64M (0%) 500M (1%) 233d kube-system kube-proxy-exporter-cb629 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-proxy-x9fsc 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system nginx-proxy-k8s-worker-s1 25m (0%) 300m (1%) 32M (0%) 512M (1%) 233d nxs-monitoring alertmanager-main-1 100m (0%) 100m (0%) 425Mi (1%) 25Mi (0%) 233d nxs-logging filebeat-lmsmp 100m (0%) 0 (0%) 100Mi (0%) 200Mi (0%) 233d nxs-monitoring node-exporter-v4gdq 112m (0%) 122m (0%) 200Mi (0%) 220Mi (0%) 233d Allocated resources: (Total limits may be over 100 percent, ie, overcommitted.) Resource Requests Limits -------- -------- ------ cpu 487m (3%) 822m (5%) memory 15856217600 (2%) 749976320 (3%) ephemeral-storage 0 (0%) 0 (0%)</span></span></code> </pre> <br><p>  Aqui vemos todos os pods em execu√ß√£o em um n√≥ espec√≠fico, bem como os recursos solicitados por cada um dos pods.  E aqui est√° a apar√™ncia dos logs do planejador ao iniciar o pod cronjob-cron-events-1573793820-xt6q9 (essas informa√ß√µes aparecem no log do planejador ao definir o 10¬∫ n√≠vel de log nos argumentos do comando start --v = 10): </p><br><div class="spoiler">  <b class="spoiler_title">gaivota larga</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">I1115 07:57:21.637791 1 scheduling_queue.go:908] About to try and schedule pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.637804 1 scheduler.go:453] Attempting to schedule pod: nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.638285 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s5 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638300 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s6 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s3 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s4 is allowed, Node is running only 17 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638365 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s12 is allowed, Node is running only 9 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s11 is allowed, Node is running only 11 out of 110 Pods. I1115 07:57:21.638385 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s1 is allowed, Node is running only 19 out of 110 Pods. I1115 07:57:21.638402 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s2 is allowed, Node is running only 21 out of 110 Pods. I1115 07:57:21.638383 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638335 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, Node is running only 18 out of 110 Pods. I1115 07:57:21.638408 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s13 is allowed, Node is running only 8 out of 110 Pods. I1115 07:57:21.638478 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638505 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638577 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638583 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s7 is allowed, Node is running only 25 out of 110 Pods. I1115 07:57:21.638932 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 9 I1115 07:57:21.638946 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 8 I1115 07:57:21.638961 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: BalancedResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 9 I1115 07:57:21.638971 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.638975 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: LeastResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 8 I1115 07:57:21.638990 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.639022 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: TaintTolerationPriority, Score: (10) I1115 07:57:21.639030 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: TaintTolerationPriority, Score: (10) I1115 07:57:21.639034 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: TaintTolerationPriority, Score: (10) I1115 07:57:21.639041 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: NodeAffinityPriority, Score: (0) I1115 07:57:21.639053 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: NodeAffinityPriority, Score: (0) I1115 07:57:21.639059 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: NodeAffinityPriority, Score: (0) I1115 07:57:21.639061 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639063 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639073 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639077 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639085 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639088 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639103 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639109 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639114 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639127 1 generic_scheduler.go:781] Host nxs-k8s-s10 =&gt; Score 100037 I1115 07:57:21.639150 1 generic_scheduler.go:781] Host nxs-k8s-s8 =&gt; Score 100034 I1115 07:57:21.639154 1 generic_scheduler.go:781] Host nxs-k8s-s9 =&gt; Score 100037 I1115 07:57:21.639267 1 scheduler_binder.go:269] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10" I1115 07:57:21.639286 1 scheduler_binder.go:279] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10": all PVCs bound and nothing to do I1115 07:57:21.639333 1 factory.go:733] Attempting to bind cronjob-cron-events-1573793820-xt6q9 to nxs-k8s-s10</code> </pre> </div></div><br><p>  Aqui vemos que, inicialmente, o planejador realiza a filtragem e forma uma lista de 3 n√≥s nos quais √© poss√≠vel executar (nxs-k8s-s8, nxs-k8s-s9, nxs-k8s-s10).  Em seguida, calcula os pontos de acordo com v√°rios par√¢metros (incluindo BalancedResourceAllocation, LeastResourceAllocation) para cada um desses n√≥s, a fim de determinar o n√≥ mais adequado.  No final, ele √© planejado no n√≥ com mais pontos (aqui, dois n√≥s ao mesmo tempo t√™m o mesmo n√∫mero de pontos 100037, portanto, um aleat√≥rio √© selecionado - nxs-k8s-s10). </p><br><p>  <strong>Conclus√£o</strong> : se os pods funcionam no n√≥ para o qual n√£o h√° restri√ß√µes, ent√£o para os k8s (do ponto de vista do consumo de recursos) isso ser√° equivalente a se esses pods estavam completamente ausentes nesse n√≥.  Portanto, se voc√™ possui um pod condicionalmente com um processo voraz (por exemplo, wowza) e n√£o h√° restri√ß√µes para isso, uma situa√ß√£o pode surgir quando, de fato, o usu√°rio consumiu todos os recursos do n√≥, mas para o k8s esse n√≥ √© considerado descarregado e ele receber√° o mesmo n√∫mero de pontos na classifica√ß√£o (ou seja, em pontos com uma avalia√ß√£o dos recursos dispon√≠veis), bem como um n√≥ que n√£o possui campos de trabalho, o que pode levar a uma distribui√ß√£o desigual da carga entre os n√≥s. </p><br><h2 id="vyselenie-poda">  Despejo da lareira </h2><br><p>  Como voc√™ sabe, cada um dos pods recebe uma das tr√™s classes de QoS: </p><br><ol><li>  <strong>garantido</strong> - √© atribu√≠do quando a solicita√ß√£o e o limite s√£o definidos para cada cont√™iner na lareira para mem√≥ria e CPU, e esses valores devem corresponder </li><li>  <strong>estour√°vel</strong> - pelo menos um cont√™iner na lareira tem solicita√ß√£o e limite, enquanto solicita√ß√£o &lt;limite </li><li>  <strong>melhor esfor√ßo</strong> - quando nenhum recipiente na lareira √© limitado em recursos </li></ol><br><p>  Ao mesmo tempo, quando h√° uma escassez de recursos (disco, mem√≥ria) no n√≥, o kubelet come√ßa a classificar e despejar os pods de acordo com um determinado algoritmo que leva em considera√ß√£o a prioridade do pod e sua classe de QoS.  Por exemplo, se estivermos falando sobre RAM, os pontos de classe de QoS ser√£o atribu√≠dos com base no seguinte princ√≠pio: </p><br><ul><li>  <strong>Garantido</strong> : -998 </li><li>  <strong>Melhor esfor√ßo</strong> : 1000 </li><li>  <strong>Burstable</strong> : min (max (2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999) </li></ul><br><p>  I.e.  com a mesma prioridade, o kubelet expelir√° os pods com a melhor classe de esfor√ßo de QoS do n√≥. </p><br><p>  <strong>Conclus√£o</strong> : se voc√™ deseja reduzir a probabilidade de remo√ß√£o do pod necess√°rio do n√≥ em caso de recursos insuficientes, em seguida, juntamente com a prioridade, tamb√©m deve definir a solicita√ß√£o / limite para ele. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-podov-prilozheniya-hpa">  Mecanismo de auto-dimensionamento horizontal (HPA) </h2><br><p>  Quando a tarefa √© aumentar e diminuir automaticamente o n√∫mero de pod, dependendo do uso de recursos (sistema - CPU / RAM ou usu√°rio - rps), uma entidade k8s como <strong>HPA</strong> (Horizontal Pod Autoscaler) pode ajudar em sua solu√ß√£o.  O algoritmo √© o seguinte: </p><br><ol><li>  As leituras atuais do recurso observado (currentMetricValue) s√£o determinadas </li><li>  Os valores desejados para o recurso (desejadoM√©tricoValorado) s√£o determinados, que s√£o configurados para recursos do sistema usando solicita√ß√£o </li><li>  O n√∫mero atual de r√©plicas √© determinado (currentReplicas) </li><li>  A f√≥rmula a seguir calcula o n√∫mero de r√©plicas desejado (r√©plicas desejadas) <br>  allowedReplicas = [currentReplicas * (currentMetricValue / desejadoMetricValue)] </li></ol><br><p>  No entanto, a escala n√£o ocorrer√° quando o coeficiente (currentMetricValue / desejadoMetricValue) estiver pr√≥ximo de 1 (podemos definir o erro permitido, por padr√£o, √© 0,1). </p><br><p>  Considere hpa usando o aplicativo de teste de aplicativo (descrito como Implanta√ß√£o), onde √© necess√°rio alterar o n√∫mero de r√©plicas, dependendo do consumo da CPU: </p><br><ul><li><p>  Manifesto de aplicativo </p><br><pre> <code class="plaintext hljs">kind: Deployment apiVersion: apps/v1beta2 metadata: name: app-test spec: selector: matchLabels: app: app-test replicas: 2 template: metadata: labels: app: app-test spec: containers: - name: nginx image: registry.nixys.ru/generic-images/nginx imagePullPolicy: Always resources: requests: cpu: 60m ports: - name: http containerPort: 80 - name: nginx-exporter image: nginx/nginx-prometheus-exporter resources: requests: cpu: 30m ports: - name: nginx-exporter containerPort: 9113 args: - -nginx.scrape-uri - http://127.0.0.1:80/nginx-status</code> </pre> <br><p>  I.e.  vemos que, com o aplicativo, ele √© iniciado inicialmente em duas inst√¢ncias, cada uma contendo dois cont√™ineres nginx e nginx-exportador, para cada um dos quais s√£o <strong>solicitados pedidos</strong> de CPU. </p><br></li><li><p>  Manifesto HPA </p><br><pre> <code class="plaintext hljs">apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: app-test-hpa spec: maxReplicas: 10 minReplicas: 2 scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment name: app-test metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 30</code> </pre> <br><p>  I.e.  criamos um hpa que monitora o aplicativo de teste de implanta√ß√£o e ajusta o n√∫mero de lares com o aplicativo com base no indicador da CPU (esperamos que o lar consuma 30% por cento da CPU solicitada por ele), enquanto o n√∫mero de r√©plicas est√° entre 2 e 10. </p><br><p>  Agora, consideraremos o mecanismo de opera√ß√£o hpa se aplicarmos uma carga a uma das lareiras: </p><br><pre> <code class="bash hljs"> <span class="hljs-comment"><span class="hljs-comment"># kubectl top pod NAME CPU(cores) MEMORY(bytes) app-test-78559f8f44-pgs58 101m 243Mi app-test-78559f8f44-cj4jz 4m 240Mi</span></span></code> </pre> <br></li></ul><br><p>  Total, temos o seguinte: </p><br><ul><li>  Valor desejado (valorM√©trico desejado) - de acordo com as configura√ß√µes de hpa, temos 30% </li><li>  Valor atual (currentMetricValue) - para c√°lculo, o controlador-gerente calcula o valor m√©dio do consumo de recursos em%, ou seja,  condicionalmente faz o seguinte: <br><ol><li>  Obt√©m os valores absolutos das m√©tricas do cora√ß√£o do servidor de m√©tricas, ou seja,  101m e 4m </li><li>  Calcula o valor absoluto m√©dio, ou seja,  (101m + 4m) / 2 = 53m </li><li>  Obt√©m o valor absoluto para o consumo de recursos desejado (para isso, a solicita√ß√£o de todos os cont√™ineres √© somada) 60m + 30m = 90m </li><li>  Calcula a porcentagem m√©dia de consumo de CPU em rela√ß√£o √† lareira da solicita√ß√£o, ou seja,  53m / 90m * 100% = 59% </li></ol></li></ul><br><p>  Agora temos todo o necess√°rio para determinar se √© necess√°rio alterar o n√∫mero de r√©plicas, para isso calculamos o coeficiente: </p><br><p> <code>ratio = 59% / 30% = 1.96</code> </p> <br><p>  I.e.  o n√∫mero de r√©plicas deve ser aumentado ~ 2 vezes e compor [2 * 1,96] = 4. </p><br><p>  <strong>Conclus√£o:</strong> Como voc√™ pode ver, para que esse mecanismo funcione, um pr√©-requisito √© incluir a disponibilidade de solicita√ß√µes para todos os cont√™ineres na lareira observada. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-nod-cluster-autoscaler">  O mecanismo de dimensionamento autom√°tico horizontal de n√≥s (Cluster Autoscaler) </h2><br><p>  Para neutralizar o impacto negativo no sistema durante explos√µes de carga, a presen√ßa de um hpa ajustado n√£o √© suficiente.  Por exemplo, de acordo com as configura√ß√µes no gerenciador do controlador hpa, decide que o n√∫mero de r√©plicas precisa ser aumentado em 2 vezes, no entanto, n√£o h√° recursos livres nos n√≥s para executar esse n√∫mero de pods (ou seja, o n√≥ n√£o pode fornecer os recursos solicitados para as solicita√ß√µes de pod) e esses pods insira o estado Pendente. </p><br><p>  Nesse caso, se o provedor tiver IaaS / PaaS apropriado (por exemplo, GKE / GCE, AKS, EKS etc.), uma ferramenta como o <strong>Node Autoscaler</strong> pode nos ajudar.  Permite definir o n√∫mero m√°ximo e m√≠nimo de n√≥s no cluster e ajustar automaticamente o n√∫mero atual de n√≥s (acessando a API do provedor de nuvem para solicitar / excluir n√≥s) quando houver falta de recursos no cluster e os pods n√£o puderem ser agendados (eles est√£o no estado Pendente). </p><br><p>  <strong>Conclus√£o:</strong> para poder dimensionar automaticamente os n√≥s, √© necess√°rio especificar solicita√ß√µes nos cont√™ineres da lareira, para que os k8s possam avaliar corretamente a carga dos n√≥s e, consequentemente, informar que n√£o h√° recursos no cluster para iniciar a pr√≥xima lareira. </p><br><hr><br><h2 id="zaklyuchenie">  Conclus√£o </h2><br><p>  Deve-se observar que definir limites de recursos para o cont√™iner n√£o √© um pr√©-requisito para o lan√ßamento bem-sucedido do aplicativo, mas ainda √© melhor fazer isso pelos seguintes motivos: </p><br><ol><li>  Para uma opera√ß√£o mais precisa do planejador em termos de balanceamento de carga entre os n√≥s k8s </li><li>  Para reduzir a probabilidade de um evento de despejo da lareira </li><li>  Para fornos de aplicativos de dimensionamento autom√°tico horizontal (HPA) </li><li>  Para dimensionamento autom√°tico horizontal de n√≥s (escalonamento autom√°tico de cluster) para provedores de nuvem </li></ol><br><h2 id="takzhe-chitayte-drugie-stati-v-nashem-bloge">  Leia tamb√©m outros artigos em nosso blog: </h2><br><ul><li>  <a href="https://habr.com/ru/company/nixys/blog/481992/">Pipeline Tekton - pipelines nativos de Kubernetes</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/473578/">Criando m√≥dulos din√¢micos para o Nginx</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/468779/">Qual foi o resultado da migra√ß√£o do ClickHouse sem autoriza√ß√£o para o ClickHouse com autoriza√ß√£o</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/461723/">Compreendendo o pacote de contexto em Golang</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/437372/">Tr√™s truques simples para reduzir as imagens do docker</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/424717/">Fazendo backup de um grande n√∫mero de projetos da web heterog√™neos</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt480072/">https://habr.com/ru/post/pt480072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt480060/index.html">Classificador P300 simples em dados abertos</a></li>
<li><a href="../pt480062/index.html">10 sistemas de controle. Onde √© mais conveniente se comunicar em tarefas e compartilhar arquivos?</a></li>
<li><a href="../pt480064/index.html">Aprendendo palavras agrupadas tematicamente</a></li>
<li><a href="../pt480068/index.html">[Update] Nosso povo √© espancado, e n√≥s ficaremos em sil√™ncio?</a></li>
<li><a href="../pt480070/index.html">Reativar benef√≠cios: uma b√™n√ß√£o para as empresas?</a></li>
<li><a href="../pt480076/index.html">Multiprocessamento e reconcilia√ß√£o de dados de v√°rias fontes</a></li>
<li><a href="../pt480078/index.html">Novas bibliotecas front-end nos perif√©ricos React</a></li>
<li><a href="../pt480080/index.html">O que voc√™ precisa na anota√ß√£o de aplicativos?</a></li>
<li><a href="../pt480082/index.html">Usando particionamento no MySQL para Zabbix com um grande n√∫mero de objetos de monitoramento</a></li>
<li><a href="../pt480086/index.html">Como cumprir os requisitos do 152-FZ, proteger os dados pessoais de nossos clientes e n√£o pisar em nosso ancinho</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
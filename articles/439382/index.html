<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóùÔ∏è üë®‚Äçüëß üïö Usando Ansible, Terraform, Docker, Consul, Nomad en las nubes (Alexey Vakhov, Uchi.ru) üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë® üë®üèª‚Äç‚öñÔ∏è üë®üèΩ‚Äçüöí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este art√≠culo es una transcripci√≥n del video del informe de Alexei Vakhov de Uchi.ru "Nubes en las nubes" 


 Uchi.ru es una plataforma en l√≠nea para ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Usando Ansible, Terraform, Docker, Consul, Nomad en las nubes (Alexey Vakhov, Uchi.ru)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439382/"><p>  Este art√≠culo es una transcripci√≥n del video del informe de Alexei Vakhov de Uchi.ru "Nubes en las nubes" </p><br><p>  Uchi.ru es una plataforma en l√≠nea para la educaci√≥n escolar, m√°s de 2 millones de estudiantes, las clases interactivas regularmente deciden con nosotros.  Todos nuestros proyectos est√°n alojados completamente en nubes p√∫blicas, el 100% de las aplicaciones funcionan en contenedores, comenzando desde el m√°s peque√±o, para uso interno, y terminando con grandes producciones a 1k + solicitudes por segundo.  Dio la casualidad de que tenemos 15 cl√∫steres de acopladores aislados (¬°no Kubernetes, sic!) En cinco proveedores de la nube.  Mil quinientas aplicaciones de usuario, cuyo n√∫mero crece constantemente. </p><br><p>  Hablar√© sobre cosas muy espec√≠ficas: c√≥mo cambiamos a contenedores, c√≥mo gestionamos la infraestructura, los problemas que encontramos, qu√© funcion√≥ y qu√© no. </p><br><p>  Durante el informe, discutiremos: </p><br><ul><li>  Motivaci√≥n para la selecci√≥n de tecnolog√≠a y caracter√≠sticas comerciales </li><li>  Herramientas: Ansible, Terraform, Docker, Github Flow, Consul, Nomad, Prometheus, Shaman: una interfaz web para Nomad. </li><li>  Uso de la federaci√≥n de cl√∫steres para gestionar la infraestructura distribuida </li><li>  Implementaciones de NoOps, entornos de prueba, circuitos de aplicaci√≥n (los desarrolladores realizan sus propios cambios pr√°cticamente por su cuenta) </li><li>  Historias entretenidas de la pr√°ctica </li></ul><br><iframe width="560" height="315" src="https://www.youtube.com/embed/C7utdhh6UCk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  A qui√©n le importa, por favor, debajo del gato. </p><a name="habracut"></a><br><p>  Me llamo Alexey Vakhov.  Trabajo como director t√©cnico en Uchi.ru.  Nos alojamos en nubes p√∫blicas.  Utilizamos activamente Terraform, Ansible.  Desde entonces, nos hemos cambiado por completo a Docker.  Muy satisfecho  Qu√© contento, qu√© contentos estamos, lo dir√©. </p><br><p><img src="https://habrastorage.org/webt/l3/zh/6x/l3zh6xrikma1bku1ks6vo7hixva.png"></p><br><p>  La empresa Uchi.ru se dedica a la producci√≥n de productos para la educaci√≥n escolar.  Tenemos una plataforma principal en la que los ni√±os resuelven problemas interactivos en diversas materias en Rusia, Brasil y Estados Unidos.  Realizamos olimpiadas, concursos, clubes, campamentos en l√≠nea.  Cada a√±o esta actividad est√° creciendo. </p><br><p><img src="https://habrastorage.org/webt/ms/m8/8h/msm88h-eoc67vkjnokat3ssq_wo.png"></p><br><p>  Desde el punto de vista de la ingenier√≠a, la pila web cl√°sica (Ruby, Python, NodeJS, Nginx, Redis, ELK, PostgreSQL).  La caracter√≠stica principal es que muchas aplicaciones.  Las aplicaciones est√°n alojadas en todo el mundo.  Todos los d√≠as hay lanzamientos en producci√≥n. </p><br><p>  La segunda caracter√≠stica es que nuestros esquemas cambian muy a menudo.  Piden plantear una nueva aplicaci√≥n, detener la anterior, agregar cron para trabajos en segundo plano.  Cada 2 semanas hay una nueva Olimpiada, esta es una nueva aplicaci√≥n.  Todo es necesario para acompa√±ar, monitorear, respaldar.  Por lo tanto, el ambiente es superdin√°mico.  El dinamismo es nuestra principal dificultad. </p><br><p><img src="https://habrastorage.org/webt/gm/dn/vu/gmdnvuag9g19b-bkzqbamcrwdw8.png"></p><br><p>  Nuestra unidad de trabajo es el sitio.  En t√©rminos de proveedores de la nube, este es el Proyecto.  Nuestro sitio es una entidad completamente aislada con una API y una subred privada.  Cuando ingresamos al pa√≠s, buscamos proveedores locales en la nube.  No en todas partes hay Google y Amazon.  A veces sucede que no hay API para el proveedor de la nube.  Exteriormente publicamos VPN y HTTP, HTTPS para equilibradores.  Todos los dem√°s servicios se comunican dentro de la nube. </p><br><p><img src="https://habrastorage.org/webt/vz/b6/w2/vzb6w2yehx_arktffwsjxildnhe.png"></p><br><p>  Para cada sitio hemos creado nuestro propio repositorio Ansible.  El repositorio tiene hosts.yml, libro de jugadas, roles y 3 carpetas secretas, de las que hablar√© m√°s adelante.  Esto es terraformaci√≥n, provisi√≥n, enrutamiento.  Somos fan√°ticos de la estandarizaci√≥n.  Nuestro repositorio siempre debe llamarse el "nombre ansible del sitio".  Estandarizamos cada nombre de archivo, estructura interna.  Esto es muy importante para una mayor automatizaci√≥n. </p><br><p><img src="https://habrastorage.org/webt/v3/a0/kk/v3a0kke8aauqojk4hj5blhgwmt4.png"></p><br><p>  Configuramos Terraform hace un a√±o y medio, por lo que lo usamos.  Terraform sin m√≥dulos, sin estructura de archivo (se utiliza estructura plana).  Estructura del archivo Terraform: 1 servidor - 1 archivo, configuraciones de red y otras configuraciones.  Usando terraform, describimos servidores, unidades, dominios, s3-buckets, redes, etc.  Terraform en el sitio est√° preparando completamente el hierro. </p><br><p><img src="https://habrastorage.org/webt/wq/qz/ly/wqqzly1s4_6brivoh4hkeyvexmu.png"></p><br><p>  Terraform crea el servidor, luego el conjunto rueda estos servidores.  Debido al hecho de que usamos la misma versi√≥n del sistema operativo en todas partes, escribimos todos los roles desde cero.  Los roles relevantes generalmente se publican en Internet para todos los sistemas operativos que no funcionan en ning√∫n lugar.  Todos tomamos roles de Ansible y dejamos solo lo que necesit√°bamos.  Roles Ansibles Estandarizados.  Tenemos 6 libros de jugadas b√°sicos.  Cuando se inicia, Ansible instala una lista est√°ndar de software: OpenVPN, PostgreSQL, Nginx, Docker.  Kubernetes que no usamos. </p><br><p><img src="https://habrastorage.org/webt/fh/x4/i4/fhx4i4ztn5fvmjj6uivdbkdrub8.png"></p><br><p>  Usamos Consul + Nomad.  Estos son programas muy simples.  Ejecute 2 programas escritos en Golang en cada servidor.  El c√≥nsul es responsable del descubrimiento del servicio, la verificaci√≥n del estado y el valor clave para almacenar la configuraci√≥n.  Nomad es responsable de la programaci√≥n, de la implementaci√≥n.  Nomad lanza contenedores, proporciona despliegues, incluida la actualizaci√≥n continua en la comprobaci√≥n de estado, le permite ejecutar contenedores sidecar.  El cl√∫ster es f√°cil de expandir o viceversa para reducir.  Nomad admite cron distribuido. </p><br><p><img src="https://habrastorage.org/webt/dc/ic/sm/dcicsmnhzdduqbnxsdpe6ewkvws.png"></p><br><p>  Despu√©s de ingresar al sitio, Ansible ejecuta el libro de jugadas ubicado en el directorio de suministro.  El libro de jugadas en este directorio es responsable de instalar el software en el cluster docker que usan los administradores.  Instale el software prometheus, grafana y secret shaman. </p><br><p>  Shaman es un tablero web para n√≥madas.  Nomad es de bajo nivel y realmente no quiero dejar entrar a los desarrolladores.  En cham√°n vemos una lista de aplicaciones, les damos a los desarrolladores un bot√≥n de implementaci√≥n para las aplicaciones.  Los desarrolladores pueden cambiar las configuraciones: agregar contenedores, variables de entorno, iniciar servicios. </p><br><p><img src="https://habrastorage.org/webt/cm/jw/ry/cmjwryicd-9dvhlpg--bhfrfe9w.png"></p><br><p>  Y finalmente, el componente final del sitio es el enrutamiento.  El enrutamiento se almacena en el almacenamiento K / V del c√≥nsul, es decir, hay un enlace entre el flujo ascendente, el servicio, la URL, etc.  En cada equilibrador, hay una plantilla de C√≥nsul que genera una configuraci√≥n nginx y hace que se vuelva a cargar.  Una cosa muy confiable, nunca tuvimos un problema con eso.  La caracter√≠stica de este esquema es que el tr√°fico acepta nginx est√°ndar y siempre puede ver qu√© configuraci√≥n se gener√≥ y funciona como con nginx est√°ndar. </p><br><p><img src="https://habrastorage.org/webt/rn/ew/7g/rnew7gm_fe4gcc57clp3f41ob68.png"></p><br><p>  Por lo tanto, cada sitio consta de 5 capas.  Con terraform, personalizamos el hardware.  Ansible llevamos a cabo la configuraci√≥n b√°sica de los servidores, poner el docker-cluster.  La provisi√≥n acumula el software del sistema.  El enrutamiento dirige el tr√°fico dentro del sitio.  Aplicaciones contiene aplicaciones de usuario y aplicaciones de administrador. </p><br><p>  Depuramos estas capas durante mucho tiempo para que fueran lo m√°s id√©nticas posible.  Provisi√≥n, coincidencia de enrutamiento 100% entre sitios.  Por lo tanto, para los desarrolladores, cada sitio es absolutamente igual. </p><br><p>  Si los profesionales de TI cambian de un proyecto a otro, caen en un entorno completamente t√≠pico.  En realidad, no pudimos hacer que la configuraci√≥n de firewall y VPN sea id√©ntica para diferentes proveedores de la nube.  Con una red, todos los proveedores de la nube funcionan de manera diferente.  Terraform es propio en todas partes, porque contiene dise√±os espec√≠ficos para cada proveedor de la nube. </p><br><p><img src="https://habrastorage.org/webt/36/kg/ti/36kgtipfv8rl9lhjevdjhhiwp5m.png"></p><br><p>  Tenemos 14 sitios de producci√≥n.  Surge la pregunta: ¬øc√≥mo gestionarlos?  Creamos el decimoquinto sitio maestro, en el que solo permitimos administradores.  Ella trabaja en un esquema de federaci√≥n. </p><br><p>  La idea fue tomada de prometeo.  Hay un modo en prometheus cuando instalamos prometheus en cada sitio.  Publicamos Prometheus a trav√©s de la autorizaci√≥n de autenticaci√≥n b√°sica HTTPS.  Prometheus master recoge solo las m√©tricas necesarias de prometheus remoto.  Esto permite comparar m√©tricas de aplicaciones en diferentes nubes, encontrar las aplicaciones m√°s descargadas o descargadas.  La notificaci√≥n centralizada (alerta) pasa por el maestro prometheus para administradores.  Los desarrolladores reciben alertas de prometheus local. </p><br><p><img src="https://habrastorage.org/webt/cw/c9/yd/cwc9yd3hpmbhbxvlz0ygacktloa.png"></p><br><p>  El cham√°n est√° configurado de la misma manera.  A trav√©s del sitio principal, los administradores pueden implementar y configurar en cualquier sitio a trav√©s de una √∫nica interfaz.  Resolvemos una clase suficientemente grande de problemas sin salir de este sitio maestro. </p><br><p><img src="https://habrastorage.org/webt/kz/ul/hi/kzulhi1jrz8c3bssubwqzremd6g.png"></p><br><p>  Te dir√© c√≥mo nos cambiamos a Docker.  Este proceso es muy lento.  Cruzamos unos 10 meses.  En el verano de 2017, tuvimos 0 contenedores de producci√≥n.  En abril de 2018, acoplamos y lanzamos nuestra √∫ltima aplicaci√≥n a producci√≥n. </p><br><p><img src="https://habrastorage.org/webt/h5/9t/ib/h59tibngi0uru-f4vehjhnq3e1c.png"></p><br><p>  Somos del mundo del rub√≠ sobre rieles.  Sol√≠a ‚Äã‚Äãhaber 99% de las aplicaciones de Ruby on Rails.  Los rieles se extienden por Capistrano.  T√©cnicamente, Capistrano funciona de la siguiente manera: el desarrollador inicia la implementaci√≥n de la tapa, capistrano va a todos los servidores de aplicaciones a trav√©s de ssh, recoge la √∫ltima versi√≥n del c√≥digo, recopila activos y migra la base de datos.  Capistrano crea un enlace simb√≥lico a la nueva versi√≥n del c√≥digo y env√≠a una se√±al USR2 a la aplicaci√≥n web.  A esta se√±al, el servidor web recoge el nuevo c√≥digo. </p><br><p><img src="https://habrastorage.org/webt/il/us/4e/ilus4ejwfkd6cvjnmjrcln2ugyy.png"></p><br><p>  El √∫ltimo paso en Docker no se hace as√≠.  En la ventana acoplable, debe detener el contenedor anterior, levantar el contenedor nuevo.  Esto plantea la pregunta: ¬øc√≥mo cambiar el tr√°fico?  En el mundo de la nube, el descubrimiento de servicios es responsable de esto. </p><br><p><img src="https://habrastorage.org/webt/k3/il/ig/k3iligqv5uphvlp1l3cvkmbggem.png"></p><br><p>  Por lo tanto, agregamos c√≥nsul a cada sitio.  C√≥nsul fue agregado porque usaron Terraform.  Empaquetamos todas las configuraciones de nginx en una plantilla de c√≥nsul.  Formalmente, lo mismo, pero ya est√°bamos listos para administrar din√°micamente el tr√°fico dentro de los sitios. </p><br><p><img src="https://habrastorage.org/webt/u9/qg/ag/u9qgagdnxiwo4lowkqi7micapqu.png"></p><br><p>  Luego, escribimos un script de ruby ‚Äã‚Äãque recog√≠a una imagen en uno de los servidores, la introduc√≠a en el registro, luego se enviaba por ssh a cada servidor, recog√≠a nuevos y deten√≠a los contenedores antiguos, registr√°ndolos en el c√≥nsul.  Los desarrolladores tambi√©n continuaron ejecutando la implementaci√≥n de cap, pero los servicios ya se estaban ejecutando en Docker. </p><br><p>  Recuerdo que hab√≠a dos versiones del gui√≥n, la segunda result√≥ ser bastante avanzada, hubo una actualizaci√≥n continua, cuando se detuvo un peque√±o n√∫mero de contenedores, se levantaron otros nuevos, el c√≥nsul Helfcheki esper√≥ y sigui√≥ adelante. </p><br><p><img src="https://habrastorage.org/webt/07/fx/gk/07fxgkf2fcvnhs8gpfjfrygalxs.png"></p><br><p>  Luego se dieron cuenta de que este es un m√©todo sin salida.  El gui√≥n aument√≥ a 600 l√≠neas.  El siguiente paso en la eliminaci√≥n manual reemplazamos a Nomad.  Ocultando los detalles del trabajo del desarrollador.  Es decir, todav√≠a llamaron despliegue de tope, pero por dentro ya era una tecnolog√≠a completamente diferente. </p><br><p><img src="https://habrastorage.org/webt/4j/o-/ms/4jo-ms4v5mx1q4cn6sqt6n0jr4a.png"></p><br><p>  Y al final, trasladamos la implementaci√≥n a la interfaz de usuario y eliminamos el acceso al servidor, dejando el bot√≥n de implementaci√≥n verde y la interfaz de control. </p><br><p>  En principio, tal transici√≥n result√≥ ser, por supuesto, larga, pero evitamos el problema que encontr√© varias veces. </p><br><p>  Hay alg√∫n tipo de pila heredada, sistema o algo as√≠.  Khachennaya ya solo en flaps.  Comienza el desarrollo de una nueva versi√≥n.  Despu√©s de un par de meses o un par de a√±os, dependiendo del tama√±o de la empresa, en la nueva versi√≥n se implementa menos de la mitad de la funcionalidad necesaria, y la versi√≥n anterior a√∫n escap√≥.  Y ese nuevo tambi√©n se convirti√≥ en un gran legado.  Y es hora de comenzar una nueva tercera versi√≥n desde cero.  En general, este es un proceso interminable. </p><br><p>  Por lo tanto, siempre movemos toda la pila como un todo.  En peque√±os pasos, torcidos, con muletas, pero enteramente.  No podemos actualizar, por ejemplo, el motor acoplable en un sitio.  Es necesario actualizar en todas partes, si hay un deseo. </p><br><p><img src="https://habrastorage.org/webt/qy/31/jr/qy31jrpbehnyyrcozqaxnj41jk8.png"></p><br><p>  Roll-outs.  Todas las instrucciones de la ventana acoplable despliegan 10 contenedores nginx, o 10 contenedores redis, en la ventana acoplable.  Este es un mal ejemplo, porque las im√°genes ya est√°n ensambladas, las im√°genes son claras.  Empaquetamos nuestras aplicaciones de rieles en Docker.  El tama√±o de las im√°genes de la ventana acoplable era de 2-3 gigabytes.  Saldr√°n no tan r√°pido. </p><br><p><img src="https://habrastorage.org/webt/2q/lx/bf/2qlxbfo5lnhpjfxcjtlljrntgxy.png"></p><br><p>  El segundo problema vino de la web hipster.  Una web hipster siempre es Github Flow.  En 2011, hubo una publicaci√≥n de creaci√≥n de √©poca que Github Flow dirige, por lo que toda la web rueda.  ¬øC√≥mo se ve?  La rama maestra es siempre producci√≥n.  Al agregar una nueva funcionalidad, hacemos una rama.  Cuando fusionamos, revisamos el c√≥digo, ejecutamos pruebas, aumentamos el entorno de preparaci√≥n.  Negocios buscando entorno de puesta en escena.  En el momento X, si todo tiene √©xito, fusionamos la sucursal en master y la lanzamos a producci√≥n. </p><br><p>  En capistrano, esto funcion√≥ bien, porque fue creado para esto.  Docker siempre nos vende una tuber√≠a.  Montado el contenedor.  El contenedor puede ser transferido al desarrollador, probador, transferido a producci√≥n.  Pero en el momento de la fusi√≥n en master, el c√≥digo ya es diferente.  Todas las im√°genes de la ventana acoplable que se recopilaron de la rama de caracter√≠sticas, no se recopilaron del maestro. </p><br><p><img src="https://habrastorage.org/webt/vl/th/8g/vlth8gjbcyby-rpamtltaijqxcy.png"></p><br><p>  Como lo hicimos  Recopilamos la imagen, la colocamos en el registro local de acopladores.  Y despu√©s de eso, hacemos el resto de las operaciones: migraci√≥n, implementaci√≥n en producci√≥n. </p><br><p><img src="https://habrastorage.org/webt/1i/kb/yu/1ikbyuh88pytsfprkkwdi6_6ppq.png"></p><br><p>  Para ensamblar r√°pidamente esta imagen, utilizamos Docker-in-Docker.  En Internet, todos escriben que esto es un antipatr√≥n, se bloquea.  No ten√≠amos nada de eso.  Cu√°ntos ya trabajan con √©l nunca tuvo un problema.  Reenviamos el directorio / var / lib / docker al servidor principal utilizando el volumen Persistente.  Todas las im√°genes intermedias est√°n en el servidor primario.  Ensamblar una nueva imagen se ajusta en unos minutos. </p><br><p><img src="https://habrastorage.org/webt/6q/_g/67/6q_g67tuzx_n078pff6-aisdvdc.png"></p><br><p>  Para cada aplicaci√≥n, creamos un registro local de acopladores internos y nuestro volumen de compilaci√≥n.  Porque Docker guarda todas las capas en el disco y es dif√≠cil de limpiar.  Ahora sabemos la utilizaci√≥n del disco de cada registro local de acopladores.  Sabemos cu√°nto disco requiere.  Puede recibir alertas a trav√©s de Grafana centralizado y limpio.  Mientras nos limpiamos las manos.  Pero lo automatizaremos. </p><br><p><img src="https://habrastorage.org/webt/mf/py/wj/mfpywjgwpsj0tbqb6vvvyzz8_1u.png"></p><br><p>  Otro punto  Imagen de Docker recopilada.  Ahora esta imagen necesita descomponerse en servidores.  Al copiar una imagen de acoplador grande, la red no hace frente.  En la nube tenemos 1 Gbit / s.  Hay un cierre global en la nube.  Ahora estamos implementando una imagen acoplable en 4 servidores de producci√≥n pesada.  En el gr√°fico puede ver que el disco funcion√≥ en 1 paquete de servidores.  Luego se despliega el segundo paquete de servidores.  A continuaci√≥n puede ver la utilizaci√≥n del canal.  Aproximadamente 1 Gbit / s casi tiramos.  Ya no hay mucha aceleraci√≥n all√≠. </p><br><p><img src="https://habrastorage.org/webt/lk/eo/hl/lkeohl4fjm-y97kmp3hyogr3p1a.png"></p><br><p>  Mi producci√≥n favorita es Sud√°frica.  Hay hierro muy caro y lento.  Cuatro veces m√°s caro que en Rusia.  Hay muy mal internet.  Internet de nivel de m√≥dem, pero no con errores.  All√≠ implementamos aplicaciones en 40 minutos, teniendo en cuenta el ajuste de cach√©s, par√°metros de tiempo de espera. </p><br><p><img src="https://habrastorage.org/webt/zl/8x/ig/zl8xig0k9liveeiuzoykh-ctgwm.png"></p><br><p>  El √∫ltimo problema que me preocup√≥ antes de que Docker contactara fue la carga.  De hecho, la carga es la misma que sin un acoplador con hierro id√©ntico.  El √∫nico matiz que encontramos en un solo punto.  Si recolecta registros del motor Docker a trav√©s del controlador fluido incorporado, entonces a una carga de aproximadamente 1000 rps, el b√∫fer fluido interno comienza a ensuciarse y las solicitudes comienzan a disminuir.  Sacamos el registro en contenedores de sidecar.  En n√≥mada, esto se llama log-shipper.  Un peque√±o contenedor cuelga al lado de un gran contenedor de aplicaciones.  La √∫nica tarea es recogerlo y enviarlo a un repositorio centralizado. </p><br><p><img src="https://habrastorage.org/webt/8r/fv/7x/8rfv7xzfamwjrwemisa1laingzy.png"></p><br><p>  Cu√°les fueron los problemas / soluciones / desaf√≠os.  Trat√© de analizar cu√°l era la tarea.  Las caracter√≠sticas de nuestros problemas son: </p><br><ul><li>  muchas aplicaciones independientes </li><li>  cambios continuos en la infraestructura </li><li>  Flujo de Github y grandes im√°genes acoplables </li></ul><br><p><img src="https://habrastorage.org/webt/da/xm/jm/daxmjmflat8cz4a5b-2nmx4pip4.png"></p><br><p>  Nuestras soluciones </p><br><ul><li>  Federaci√≥n de agrupaciones de acopladores.  Desde el punto de vista del manejo es dif√≠cil.  Pero Docker es bueno para implementar la funcionalidad empresarial en la producci√≥n.  Trabajamos con datos personales y tenemos certificaci√≥n en todos los pa√≠ses.  En un sitio aislado, dicha certificaci√≥n es f√°cil de aprobar.  Durante la certificaci√≥n surgen todas las preguntas: d√≥nde est√° alojado, c√≥mo tiene un proveedor en la nube, d√≥nde almacena datos personales, d√≥nde realiza copias de seguridad y qui√©n tiene acceso a los datos.  Cuando todo est√° aislado, es mucho m√°s f√°cil describir el c√≠rculo de sospechosos y monitorear todo esto es mucho m√°s f√°cil. </li><li>  Orquestaci√≥n  Est√° claro que kubernetes.  El esta en todas partes.  Pero quiero decir que Consul + Nomad es una soluci√≥n de producci√≥n completa. </li><li>  Montaje de im√°genes.  Puede crear im√°genes r√°pidamente en Docker-in-Docker. </li><li>  Cuando se usa Docker, tambi√©n es posible una carga de 1000 rps. </li></ul><br><p>  Vector de direcci√≥n de desarrollo </p><br><p>  Ahora uno de los grandes problemas es la desincronizaci√≥n de las versiones de software en los sitios.  Anteriormente, configuramos el servidor a mano.  Luego nos convertimos en ingenieros devops.  Ahora configure el servidor usando ansible.  Ahora tenemos unificaci√≥n total, estandarizaci√≥n.  Introducimos el pensamiento ordinario en la cabeza.  No podemos arreglar PostgreSQL con nuestras manos en el servidor.  Si necesita alg√∫n tipo de ajuste en solo 1 servidor, entonces pensamos c√≥mo difundir esta configuraci√≥n en todas partes.  Si no estandariza, habr√° un zool√≥gico de configuraciones. </p><br><p>  Estoy encantado y muy contento de que salgamos de la caja de forma gratuita una infraestructura de trabajo realmente muy agradable. </p><br><p><img src="https://habrastorage.org/webt/w6/nz/pw/w6nzpwpzt1tsxifw0gksrvoplpg.png"></p><br><p>  Puedes agregarme en facebook.  Si hacemos algo bueno, escribir√© sobre eso. </p><br><p>  Preguntas: </p><br><p>  ¬øCu√°l es la ventaja de la plantilla de c√≥nsul sobre la plantilla de Ansible, por ejemplo, para configurar reglas de firewall y m√°s? </p><br><p>  Respuesta: Ahora tenemos tr√°fico de balanceadores externos que van directamente a los contenedores.  No hay nadie en el medio.  All√≠ se forma una configuraci√≥n que reenv√≠a las direcciones IP y los puertos del cl√∫ster.  Adem√°s, tenemos todas las configuraciones de balance en K / V en Consul.  Tenemos la idea de proporcionar configuraciones de enrutamiento a los desarrolladores a trav√©s de una interfaz segura para que no rompan nada. </p><br><p>  Pregunta: Respecto a la homogeneidad de todos los sitios.  ¬øRealmente no hay solicitudes de empresas o desarrolladores que necesiten implementar algo no est√°ndar en este sitio?  Por ejemplo, tarantool con cassandra. </p><br><p>  Respuesta: Sucede, pero es muy raro.  Esto dibujamos un artefacto interno separado.  Existe tal problema, pero es raro. </p><br><p>  Pregunta: La soluci√≥n al problema de entrega es usar un registro privado de acopladores en cada sitio y desde all√≠ ya es r√°pido obtener im√°genes de acopladores. </p><br><p>  Respuesta: De todos modos, la implementaci√≥n se ejecutar√° en la red, ya que estamos implementando la imagen del acoplador en 15 servidores all√≠ simult√°neamente.  Descansamos contra la red.  Dentro de la red, 1 Gbit / s. </p><br><p>  Pregunta: ¬øHay tantos contenedores acoplables basados ‚Äã‚Äãaproximadamente en la misma pila tecnol√≥gica? </p><br><p>  Respuesta: Ruby, Python, NodeJS. </p><br><p>  Pregunta: ¬øCon qu√© frecuencia prueba o verifica las im√°genes de su ventana acoplable en busca de actualizaciones?  ¬øC√≥mo se resuelven los problemas de actualizaci√≥n, por ejemplo, cuando glibc, openssl debe corregirse en todos los acopladores? </p><br><p>  Respuesta: Si encuentra tal error, vulnerabilidad, entonces nos sentamos por una semana y lo reparamos.  Si necesita implementar, entonces podemos implementar toda la nube (todas las aplicaciones) desde cero a trav√©s de la federaci√≥n.  Podemos hacer clic en todos los botones verdes para el despliegue de aplicaciones y salir a tomar t√©. </p><br><p>  Pregunta: ¬øVas a liberar a tu cham√°n en c√≥digo abierto? </p><br><p>  Respuesta: Aqu√≠ Andrei (se√±ala a la persona de la audiencia) nos promete que tendremos un cham√°n en el oto√±o.  Pero all√≠ debe agregar soporte para kubernetes.  OpenSource siempre deber√≠a ser mejor. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439382/">https://habr.com/ru/post/439382/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439372/index.html">¬øQuieres jugar a un detective? Encuentra el error en una funci√≥n de Midnight Commander</a></li>
<li><a href="../439374/index.html">Para aquellos que quieren jugar al detective: encuentre el error en la funci√≥n de Midnight Commander</a></li>
<li><a href="../439376/index.html">Club de intereses</a></li>
<li><a href="../439378/index.html">Libro (de ser?). Reflexiones sobre la naturaleza de la mente. Parte 1</a></li>
<li><a href="../439380/index.html">C√≥mo cre√© una extensi√≥n para Atom y VS Code: experiencia personal y fuentes</a></li>
<li><a href="../439384/index.html">Modelado de metr√≥polis</a></li>
<li><a href="../439388/index.html">Robots en periodismo, o c√≥mo usar la inteligencia artificial para crear contenido</a></li>
<li><a href="../439390/index.html">Las mejores innovaciones de las redes sociales en 2018</a></li>
<li><a href="../439392/index.html">¬°La temporada de campeonato 2019 est√° abierta! Comienza el SNA Hackathon Ala ML Boot Camp 8</a></li>
<li><a href="../439394/index.html">Como programador, los n√∫cleos del centro de datos escribieron</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì™ üë©‚Äçüç≥ üçÖ Comment comprendre Tensorflow et ne pas mourir, et m√™me enseigner quelque chose sur une voiture üâê üë©üèΩ‚Äçü§ù‚Äçüë©üèº ‚ôíÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, les gardes. La publication d'aujourd'hui portera sur la fa√ßon de ne pas se perdre dans la nature des nombreuses options d'utilisation de Tens...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment comprendre Tensorflow et ne pas mourir, et m√™me enseigner quelque chose sur une voiture</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427449/"><p>  Bonjour, les gardes.  La publication d'aujourd'hui portera sur la fa√ßon de ne pas se perdre dans la nature des nombreuses options d'utilisation de TensorFlow pour l'apprentissage automatique et d'atteindre votre objectif.  L'article est con√ßu pour que le lecteur connaisse les bases des principes de l'apprentissage automatique, mais n'a pas encore essay√© de le faire de ses propres mains.  En cons√©quence, nous obtenons une d√©mo fonctionnelle sur Android, qui reconna√Æt quelque chose avec une pr√©cision assez √©lev√©e.  Mais tout d'abord. </p><br><p><img src="https://habrastorage.org/webt/rs/7r/_f/rs7r_f7v6dywnklpaok4htwntsq.jpeg"></p><a name="habracut"></a><br><p>  Apr√®s avoir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">examin√© les</a> derniers documents, il a √©t√© d√©cid√© de faire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">appel</a> √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tensorflow</a> , qui prend maintenant de l'ampleur, et les articles en anglais et en russe semblent √™tre suffisants pour ne pas creuser dans cela et r√©ussir √† comprendre ce qui est quoi. </p><br><p>  Passer deux semaines, √©tudier des articles et de nombreux ex-√©chantillons au bureau.  site, j'ai r√©alis√© que je ne comprenais rien.  Trop d'informations et d'options sur la fa√ßon dont Tensorflow peut √™tre utilis√©.  Ma t√™te est d√©j√† gonfl√©e de voir √† quel point ils proposent des solutions diff√©rentes et ce que j'en fais, tel qu'appliqu√© √† ma t√¢che. </p><br><p><img src="https://habrastorage.org/webt/bd/2z/jy/bd2zjyct-gx0xbz9nfbwwya5aw8.png"></p><br><p>  J'ai ensuite d√©cid√© de tout essayer, des options les plus simples et les plus pr√™tes √† l'emploi (dans lesquelles je devais enregistrer une d√©pendance dans gradle et ajouter quelques lignes de code) aux plus complexes (dans lesquelles je devrais cr√©er et former nous-m√™mes des mod√®les graphiques et apprendre √† les utiliser dans un mobile application). </p><br><p>  Au final, j'ai d√ª utiliser une version compliqu√©e, qui sera discut√©e plus en d√©tail ci-dessous.  En attendant, j'ai compil√© pour vous une liste d'options plus simples et tout aussi efficaces, chacune s'adaptant √† son objectif. </p><br><h3 id="1--ml-kithttpsfirebasegooglecomdocsml-kit">  1. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ML KIT</a> </h3><br><p><img src="https://habrastorage.org/webt/al/of/8w/alof8wunrnv66f66xwv2rrlbrn0.png"></p><br><p>  La solution la plus simple √† utiliser - quelques lignes de code que vous pouvez utiliser: </p><br><ul><li>  Reconnaissance de texte (texte, caract√®res latins) </li><li>  D√©tection des visages (visages, √©motions) </li><li>  Num√©risation de codes-barres (code-barres, code qr) </li><li>  √âtiquetage d'image (un nombre limit√© de types d'objets dans l'image) </li><li>  Reconnaissance historique (attractions) </li></ul><br><p>  C'est un peu plus compliqu√©. Avec cette solution, vous pouvez √©galement utiliser votre propre mod√®le TensorFlow Lite, mais la conversion √† ce format a pos√© des probl√®mes, donc cet √©l√©ment n'a pas √©t√© essay√©. </p><br><p>  Comme l'√©crivent les cr√©ateurs de cette prog√©niture, la plupart des t√¢ches peuvent √™tre r√©solues √† l'aide de ces d√©veloppements.  Mais si cela ne s'applique pas √† votre t√¢che, vous devrez utiliser des mod√®les personnalis√©s. </p><br><h3 id="2--custom-visionhttpswwwcustomvisionai">  2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vision personnalis√©e</a> </h3><br><p><img src="https://habrastorage.org/webt/p9/c_/2u/p9c_2ujglvyu8mbffhrmoqpzav0.png"></p><br><p>  Un outil tr√®s pratique pour cr√©er et former vos mod√®les personnalis√©s √† l'aide d'images. <br>  Des pros - il existe une version gratuite qui vous permet de garder un projet. <br>  Des inconv√©nients - la version gratuite limite le nombre d'images ¬´entrantes¬ª √† 3 000.  Pour essayer de cr√©er un r√©seau de pr√©cision m√©diocre - cela suffit.  Pour des t√¢ches plus pr√©cises, vous en avez besoin de plus. <br>  Tout ce qui est requis de l'utilisateur est d'ajouter des images avec une marque (par exemple - image1 est "racoon", image2 est "sun"), former et exporter le graphique pour une utilisation future. </p><br><p><img src="https://habrastorage.org/webt/co/lk/nw/colknw0ljunbtzcixxdrde6qwtm.png"></p><br><p>  Caring Microsoft propose m√™me son propre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©chantillon</a> , avec lequel vous pouvez essayer votre graphique re√ßu. <br>  Pour ceux qui sont d√©j√† ¬´dans le sujet¬ª - le graphique est d√©j√† g√©n√©r√© √† l'√©tat Frozen, c'est-√†-dire  vous n'avez pas besoin de faire / convertir quoi que ce soit avec. <br>  Cette solution est bonne lorsque vous avez un grand √©chantillon et (beaucoup d'attention) de diff√©rentes classes en formation.  Parce que  sinon, il y aura de nombreuses fausses d√©finitions dans la pratique.  Par exemple, vous vous √™tes entra√Æn√© sur les ratons laveurs et les soleils, et s'il y a une personne √† l'entr√©e, alors elle peut, avec une probabilit√© √©gale, √™tre d√©finie par un syst√®me comme l'un ou l'autre.  Bien qu'en fait - ni l'un ni l'autre. </p><br><h3 id="3--sozdanie-modeli-vruchnuyu">  3. Cr√©ation manuelle d'un mod√®le </h3><br><p><img src="https://habrastorage.org/webt/m_/ku/r_/m_kur_ks0vdyiqoiw7h5pvbwoey.jpeg"></p><br><p>  Lorsque vous devez affiner vous-m√™me le mod√®le pour la reconnaissance d'image, des manipulations plus complexes avec la s√©lection d'image d'entr√©e entrent en jeu. <br>  Par exemple, nous ne voulons pas avoir de restrictions sur le volume de l'√©chantillon d'entr√©e (comme dans le paragraphe pr√©c√©dent), ou nous voulons former le mod√®le plus pr√©cis√©ment en d√©finissant nous-m√™mes le nombre d'√©poque et d'autres param√®tres d'apprentissage. <br>  Dans cette approche, il existe plusieurs exemples de Tensorflow qui d√©crivent la proc√©dure et le r√©sultat final. <br>  Voici quelques exemples: </p><br><ul><li>  Cool codelab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tensorflow pour les po√®tes</a> . <br></li></ul><br><br><p>  Il donne un exemple de la fa√ßon de cr√©er un classificateur de types de couleurs bas√© sur la base de donn√©es d'images ouverte ImageNet - pr√©parer des images, puis former le mod√®le.  Une petite mention est √©galement faite de la fa√ßon dont vous pouvez travailler avec un outil plut√¥t int√©ressant - TensorBoard.  De ses fonctions les plus simples - il d√©montre clairement la structure de votre mod√®le fini, ainsi que le processus d'apprentissage √† bien des √©gards. </p><br><ul><li><p>  Kodlab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tensorflow for Poets 2</a> - poursuite du travail avec le classificateur de couleurs.  Il montre comment si vous avez les fichiers graphiques et leurs √©tiquettes (qui ont √©t√© obtenus dans le codelab pr√©c√©dent), vous pouvez ex√©cuter l'application sur Android.  Un des points du codelab est la conversion du format graphique "habituel" ".pb" au format Tensorflow lite (qui implique des optimisations de fichier pour r√©duire la taille finale du fichier graphique, car les appareils mobiles en ont besoin). </p><br></li><li><p>  Reconnaissance de l'√©criture manuscrite <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MNIST</a> . <br></p><br><img src="https://habrastorage.org/webt/bz/ah/mx/bzahmxc0xozicgssbkzfqbgi1qw.gif"></li></ul><br><br><p>  Le navet contient le mod√®le d'origine (qui a d√©j√† √©t√© pr√©par√© pour cette t√¢che), des instructions sur la fa√ßon de le former, le convertir et comment ex√©cuter un projet pour Android √† la fin pour v√©rifier comment tout cela fonctionne. </p><br><p>  Sur la base de ces exemples, vous pouvez comprendre comment travailler avec des mod√®les personnalis√©s dans Tensorflow et essayer de cr√©er le v√¥tre ou de prendre l'un des mod√®les pr√©-form√©s qui sont assembl√©s sur un github: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®les de Tensorflow</a> </p><br><p>  Parlant de mod√®les "pr√©-form√©s".  Nuances int√©ressantes lors de leur utilisation: </p><br><ul><li>  Leur structure est d√©j√† pr√©par√©e pour une t√¢che sp√©cifique. </li><li>  Ils sont d√©j√† form√©s √† de grands √©chantillons. <br>  Par cons√©quent, si votre √©chantillon n'est pas suffisamment rempli, vous pouvez prendre un mod√®le pr√©-form√© qui est proche de la port√©e de votre t√¢che.  En utilisant ce mod√®le, en ajoutant vos propres r√®gles de formation, vous obtiendrez un meilleur r√©sultat que vous n'essaieriez de former le mod√®le √† partir de z√©ro. </li></ul><br><h3 id="4--object-detection-api---cozdanie-modeli-vruchnuyu">  4. API de d√©tection d'objets + cr√©ation manuelle de mod√®le </h3><br><p>  Cependant, tous les paragraphes pr√©c√©dents n'ont pas donn√© le r√©sultat souhait√©.  D√®s le d√©but, il √©tait difficile de comprendre ce qui devait √™tre fait et avec quelle approche.  Ensuite, un article sympa sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">API de d√©tection d'objets a</a> √©t√© trouv√©, qui explique comment trouver plusieurs cat√©gories sur une image, ainsi que plusieurs instances de la m√™me cat√©gorie.  Dans le processus de travail sur cet exemple, les articles sources et les didacticiels vid√©o sur la reconnaissance des objets personnalis√©s se sont av√©r√©s plus pratiques (les liens seront √† la fin). </p><br><p>  Mais le travail n'aurait pas pu √™tre achev√© sans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article sur la reconnaissance de Pikachu</a> - car une nuance tr√®s importante y a √©t√© soulign√©e, qui pour une raison quelconque n'est mentionn√©e nulle part dans un guide ou un exemple.  Et sans cela, tout le travail accompli serait vain. </p><br><p>  Alors, maintenant enfin sur ce qui restait √† faire et ce qui s'est pass√© √† la sortie. </p><br><ol><li>  Tout d'abord, la farine de l'installation Tensorflow.  Qui ne peut pas l'installer ou utiliser les scripts standard pour cr√©er, former un mod√®le - soyez patient et google.  Presque tous les probl√®mes ont d√©j√† √©t√© √©crits dans des probl√®mes sur githib ou sur stackoverflow. <br></li></ol><br>  Selon les instructions pour la reconnaissance d'objets, nous devons pr√©parer un √©chantillon d'entr√©e avant de former le mod√®le.  Ces articles d√©crivent en d√©tail comment proc√©der √† l'aide d'un outil pratique - labelImg.  La seule difficult√© ici est de faire un travail tr√®s long et minutieux pour mettre en √©vidence les limites des objets dont nous avons besoin.  Dans ce cas, tampons sur des images de documents. <br><br><img src="https://habrastorage.org/webt/ge/hh/x_/gehhx_5fqfezu1sbh5tvoofss20.png"><br>  L'√©tape suivante, √† l'aide de scripts pr√™ts √† l'emploi, nous exportons les donn√©es de l'√©tape 2 d'abord vers des fichiers csv, puis vers TFRecords - le format de donn√©es d'entr√©e Tensorflow.  Aucune difficult√© ne devrait survenir ici. <br>  Le choix d'un mod√®le pr√©-form√©, sur la base duquel nous allons pr√©-former le graphique, ainsi que la formation elle-m√™me.  C'est l√† que le plus grand nombre d'erreurs inconnues peut se produire, dont la cause est les packages d√©sinstall√©s (ou install√©s de mani√®re incorrecte) n√©cessaires au travail.  Mais vous r√©ussirez, ne d√©sesp√©rez pas, le r√©sultat en vaut la peine. <br><br><img src="https://habrastorage.org/webt/9y/qw/1b/9yqw1boyubfcrrf5jcaylkjjtyo.jpeg"><br>  Exportez le fichier re√ßu apr√®s la formation au format 'pb'.  S√©lectionnez simplement le dernier fichier 'ckpt' et exportez-le. <br>  Ex√©cution d'un exemple de travail sur Android. <br>  T√©l√©chargement de l'√©chantillon de reconnaissance d'objet officiel √† partir du github Tensorflow - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TF Detect</a> .  Ins√©rez-y votre mod√®le et votre fichier avec des √©tiquettes.  Mais.  Rien ne fonctionnera. <br><br><img src="https://habrastorage.org/webt/kj/3k/o4/kj3ko4d3ywoap8ff6oknuwova7c.gif"><br><br><p>  C'est l√† que le plus grand gag dans tout le travail vient de se produire, assez curieusement - eh bien, les √©chantillons Tensorflow ne voulaient en aucun cas fonctionner.  Tout est tomb√©.  Seul le puissant Pikachu avec son article a r√©ussi √† tout faire fonctionner. <br>  La premi√®re ligne du fichier labels.txt doit √™tre l'inscription "???", car  par d√©faut dans l'API Object Detection, les num√©ros d'identification des objets ne commencent pas par 0 comme d'habitude, mais par 1. En raison du fait que la classe null est r√©serv√©e, des questions magiques doivent √™tre indiqu√©es.  C'est-√†-dire  votre fichier de balises ressemblera √† ceci: </p><br><pre><code class="hljs">??? stamp</code> </pre> <br><p>  Et puis - ex√©cutez l'√©chantillon et voyez la reconnaissance des objets et le niveau de confiance avec lequel il a √©t√© re√ßu. </p><br><p><img src="https://habrastorage.org/webt/ly/kr/dm/lykrdma-x9h8epuqsuah3gkr3bk.png"><img src="https://habrastorage.org/webt/ne/lm/7v/nelm7v8rpjiuhzhevlptp0dc-fa.png"><img src="https://habrastorage.org/webt/9t/ci/4r/9tci4rxzhixufdjhb5ecpdof0ik.png"></p><br><p>  Ainsi, le r√©sultat est une application simple qui, lorsque vous survolez l'appareil photo, reconna√Æt les limites du tampon sur le document et les indique avec la pr√©cision de reconnaissance. <br>  Et si l'on exclut le temps pass√© √† chercher la bonne approche et √† essayer de la lancer, alors, dans l'ensemble, le travail s'est av√©r√© assez rapide et vraiment pas compliqu√©.  Vous avez juste besoin de conna√Ætre les nuances avant de commencer √† travailler. </p><br><p>  D√©j√† en tant que section suppl√©mentaire (ici, vous pouvez d√©j√† fermer l'article si vous √™tes fatigu√© des informations), je voudrais √©crire quelques astuces de vie qui ont aid√© √† travailler avec tout cela. </p><br><ul><li><p>  assez souvent, les scripts tensorflow ne fonctionnaient pas car ils √©taient ex√©cut√©s √† partir de mauvais r√©pertoires.  De plus, c'√©tait diff√©rent sur diff√©rents PC: quelqu'un devait s'ex√©cuter √† partir du <code>tensroflowmodels/models/research</code> pour travailler, et quelqu'un <code>tensroflowmodels/models/research/object-detection</code> niveau plus profond √† partir du <code>tensroflowmodels/models/research/object-detection</code> </p><br></li><li><p>  rappelez-vous que pour chaque terminal ouvert, vous devez r√©exporter le chemin √† l'aide de la commande </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">export</span></span> PYTHONPATH=/  /tensroflowmodels/models/research/slim:<span class="hljs-variable"><span class="hljs-variable">$PYTHONPATH</span></span></code> </pre> <br></li><li><p>  si vous n'utilisez pas votre propre graphique et que vous souhaitez en savoir plus (par exemple, " <code>input_node_name</code> ", qui sera requis plus tard), ex√©cutez deux commandes √† partir du dossier racine: </p><br><pre> <code class="hljs powershell">bazel build tensorflow/tools/graph_transforms:summarize_graph bazel<span class="hljs-literal"><span class="hljs-literal">-bin</span></span>/tensorflow/tools/graph_transforms/summarize_graph -<span class="hljs-literal"><span class="hljs-literal">-in_graph</span></span>=<span class="hljs-string"><span class="hljs-string">"/  /frozen_inference_graph.pb"</span></span></code> </pre> <br><p>  o√π " <code>/  /frozen_inference_graph.pb</code> " est le chemin d'acc√®s au graphique que vous souhaitez conna√Ætre </p><br></li><li><p>  Pour afficher des informations sur le graphique, vous pouvez utiliser Tensorboard. </p><br><pre> <code class="hljs powershell">python import_pb_to_tensorboard.py -<span class="hljs-literal"><span class="hljs-literal">-model_dir</span></span>=output/frozen_inference_graph.pb -<span class="hljs-literal"><span class="hljs-literal">-log_dir</span></span>=training</code> </pre> <br><p>  o√π vous devez sp√©cifier le chemin d'acc√®s au graphique ( <code>model_dir</code> ) et le chemin d'acc√®s aux fichiers re√ßus pendant la formation ( <code>log_dir</code> ).  Ensuite, ouvrez simplement localhost dans le navigateur et regardez ce qui vous int√©resse. </p><br></li></ul><br><p>  Et la derni√®re partie - sur l'utilisation des scripts python dans les instructions de l'API Object Detection - une petite feuille de triche ci-dessous avec des commandes et des conseils a √©t√© pr√©par√©e pour vous. </p><br><div class="spoiler">  <b class="spoiler_title">Feuille de triche</b> <div class="spoiler_text"><p>  Exporter de labelimg vers csv (depuis le r√©pertoire object_detection) </p><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">python</span></span> xml_to_csv.py</code> </pre> <br><p>  De plus, toutes les √©tapes √©num√©r√©es ci-dessous doivent √™tre effectu√©es √† partir du m√™me dossier Tensorflow (" <code>tensroflowmodels/models/research/object-detection</code> " ou d'un niveau sup√©rieur - selon la fa√ßon dont vous allez) - c'est tout les images de la s√©lection d'entr√©e, des TFRecords et d'autres fichiers doivent √™tre copi√©s dans ce r√©pertoire avant de commencer le travail. </p><br><p>  Exporter de csv vers tfrecord </p><br><pre> <code class="hljs powershell">python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train.record python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test.record</code> </pre> <br><p>  * N'oubliez pas de changer les lignes 'train' et 'test' dans les chemins du fichier lui-m√™me (generate_tfrecord.py), ainsi que <br>  le nom des classes reconnues dans la fonction <code>class_text_to_int</code> (qui doit √™tre dupliqu√©e dans le fichier <code>pbtxt</code> que vous allez cr√©er avant d'entra√Æner le graphique). </p><br><p>  La formation </p><br><pre> <code class="hljs powershell">python legacy/train.py ‚Äîlogtostderr -<span class="hljs-literal"><span class="hljs-literal">-train_dir</span></span>=training/ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/ssd_mobilenet_v1_coco.config</code> </pre> <br><p>  ** Avant l'entra√Ænement, n'oubliez pas de v√©rifier le fichier " <code>training/object-detection.pbtxt</code> " - il devrait y avoir toutes les classes reconnues et le fichier " <code>training/ssd_mobilenet_v1_coco.config</code> " - l√† vous devez changer le param√®tre " <code>num_classes</code> " au nombre de vos classes. </p><br><p>  Exporter le mod√®le vers pb </p><br><pre> <code class="hljs powershell">python export_inference_graph.py \ -<span class="hljs-literal"><span class="hljs-literal">-input_type</span></span>=image_tensor \ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/pipeline.config \ -<span class="hljs-literal"><span class="hljs-literal">-trained_checkpoint_prefix</span></span>=training/model.ckpt<span class="hljs-literal"><span class="hljs-literal">-110</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-output_directory</span></span>=output</code> </pre> </div></div><br><p>  Merci de votre int√©r√™t pour ce sujet! </p><br><p>  Les r√©f√©rences </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article original sur la reconnaissance d'objets</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Un cycle de vid√©o √† l'article sur la reconnaissance des objets en anglais</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'ensemble des scripts utilis√©s dans l'article d'origine</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr427449/">https://habr.com/ru/post/fr427449/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr427437/index.html">Configuration des serveurs li√©s: serveur sql ms et teradata</a></li>
<li><a href="../fr427439/index.html">Toute la v√©rit√© sur RTOS. Article # 16. Signaux</a></li>
<li><a href="../fr427441/index.html">Convergence avec Kubernetes</a></li>
<li><a href="../fr427443/index.html">Vivisection du succ√®s</a></li>
<li><a href="../fr427447/index.html">PVS-Studio prend en charge la cha√Æne d'outils int√©gr√©e GNU Arm</a></li>
<li><a href="../fr427451/index.html">Connectez les t√¢ches phpStorm √† Bitrix24</a></li>
<li><a href="../fr427453/index.html">Comment j'ai fait la transmission du son sur le Raspberry Pi</a></li>
<li><a href="../fr427457/index.html">La troisi√®me vague d'IA et de syst√®mes pour la s√©curit√© de l'√âtat</a></li>
<li><a href="../fr427459/index.html">Lampes LED Diall du magasin Castorama</a></li>
<li><a href="../fr427461/index.html">La beaut√© des fonctions NON anonymes en JavaScript</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤾🏾 🔷 🔕 Membangun AI yang Aman: Spesifikasi, Keandalan, dan Jaminan 🤶🏽 🌚 👩🏿‍⚖️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Di antara penulis artikel adalah karyawan tim keselamatan kecerdasan buatan (safety team) dari perusahaan DeepMind. 

 Membangun roket itu sulit. Seti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Membangun AI yang Aman: Spesifikasi, Keandalan, dan Jaminan</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/425387/">  <font color="gray">Di antara penulis artikel adalah karyawan tim keselamatan kecerdasan buatan (safety team) dari perusahaan DeepMind.</font> <br><br>  Membangun roket itu sulit.  Setiap komponen membutuhkan studi dan pengujian yang cermat, sementara keselamatan dan keandalan merupakan inti.  Para ilmuwan dan insinyur roket berkumpul untuk merancang semua sistem: mulai dari navigasi hingga kontrol, mesin, dan sasis.  Setelah semua bagian dirakit dan sistem diperiksa, barulah kita dapat menempatkan astronot di papan dengan keyakinan bahwa semuanya akan baik-baik saja. <br><br>  Jika kecerdasan buatan (AI) adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">roket</a> , maka suatu hari kita semua akan mendapatkan tiket.  Dan, seperti roket, keamanan adalah bagian penting dari penciptaan sistem kecerdasan buatan.  Keamanan membutuhkan desain sistem yang cermat dari awal untuk memastikan bahwa berbagai komponen bekerja bersama sebagaimana dimaksud, sementara pada saat yang sama menciptakan semua alat untuk memantau keberhasilan operasi sistem setelah commissioning. <br><br>  Pada tingkat tinggi, riset keamanan di DeepMind berfokus pada perancangan sistem yang andal sembari mendeteksi dan memitigasi risiko jangka pendek dan jangka panjang yang mungkin terjadi.  <b>Keamanan teknis AI</b> adalah bidang yang relatif baru tetapi berkembang pesat, yang isinya bervariasi dari tingkat teoretis yang tinggi hingga penelitian empiris dan spesifik.  Tujuan dari blog ini adalah untuk berkontribusi pada pengembangan lapangan dan mendorong percakapan substantif tentang ide-ide teknis, sehingga mempromosikan pemahaman kolektif kita tentang keamanan AI. <br><a name="habracut"></a><br>  Pada artikel pertama, kita akan membahas tiga bidang keamanan teknis AI: <b>spesifikasi</b> , <b>keandalan,</b> dan <b>jaminan</b> .  Artikel mendatang umumnya akan sesuai dengan batas yang diuraikan di sini.  Meskipun pandangan kami berubah seiring waktu, kami percaya bahwa ketiga bidang ini mencakup spektrum yang cukup luas untuk memberikan kategorisasi yang berguna untuk penelitian saat ini dan masa depan. <br><br><img src="https://habrastorage.org/webt/sv/8c/se/sv8cseuw2rlofm85zszbk6nhv6k.png"><br>  <i><font color="gray">Tiga bidang masalah keamanan AI.</font></i>  <i><font color="gray">Setiap blok mencantumkan beberapa masalah dan pendekatan yang relevan.</font></i>  <i><font color="gray">Ketiga area ini tidak terisolasi, tetapi saling berinteraksi.</font></i>  <i><font color="gray">Secara khusus, masalah keamanan tertentu dapat mencakup beberapa masalah blok.</font></i> <br><br><h1>  Spesifikasi: mendefinisikan tugas sistem </h1><br><h4>  Spesifikasi memastikan bahwa perilaku sistem AI konsisten dengan niat sebenarnya dari operator </h4><br>  Mungkin Anda tahu mitos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Raja Midas</a> dan sentuhan emas.  Dalam salah satu pilihan, dewa Yunani Dionysus berjanji pada Midas hadiah yang ia inginkan, sebagai rasa terima kasih atas kenyataan bahwa raja berusaha sebaik mungkin untuk menunjukkan keramahan dan kemurahan hati kepada teman Dionysus.  Kemudian <b>Midas meminta agar semua yang disentuhnya berubah menjadi emas</b> .  Dia berada di samping dirinya sendiri dengan kegembiraan dari kekuatan baru ini: cabang pohon ek, batu dan mawar di taman - semuanya berubah menjadi emas dari sentuhannya.  Tetapi dia segera menemukan kebodohan keinginannya: bahkan makanan dan minuman berubah menjadi emas di tangannya.  Dalam beberapa versi cerita, bahkan putrinya menjadi korban berkat yang ternyata merupakan kutukan. <br><br>  Kisah ini menggambarkan masalah spesifikasi: bagaimana cara merumuskan keinginan kita dengan benar?  Spesifikasi harus memastikan bahwa sistem AI berusaha untuk bertindak sesuai dengan keinginan sebenarnya dari pencipta, dan tidak menyesuaikan dengan target yang didefinisikan dengan buruk atau bahkan salah.  Tiga jenis spesifikasi secara resmi dibedakan: <br><br><ul><li>  <b>spesifikasi ideal</b> (" <b>keinginan</b> "), sesuai dengan deskripsi hipotetis (tetapi sulit untuk dirumuskan) dari sistem AI ideal, sepenuhnya konsisten dengan keinginan operator manusia; </li><li>  <b>spesifikasi proyek</b> (" <b>cetak biru</b> "), spesifikasi terkait yang <i>sebenarnya</i> kami <i>gunakan</i> untuk membuat sistem AI, misalnya, fungsi remunerasi tertentu, untuk memaksimalkan program pembelajaran penguatan yang diprogram; </li><li>  <b>spesifikasi teridentifikasi</b> (" <b>perilaku</b> "), yang paling menggambarkan <i>perilaku nyata</i> sistem.  Misalnya, fungsi hadiah diidentifikasi sebagai hasil dari rekayasa terbalik setelah mengamati perilaku sistem (pembelajaran penguatan terbalik).  Fungsi dan spesifikasi hadiah ini biasanya berbeda dari yang diprogram oleh operator karena sistem AI bukan pengoptimal yang ideal atau karena konsekuensi tak terduga lainnya dari penggunaan spesifikasi desain. </li></ul><br>  <b>Masalah spesifikasi</b> muncul ketika ada perbedaan antara <b>spesifikasi ideal</b> dan <b>spesifikasi</b> yang <b>diidentifikasi</b> , yaitu, ketika sistem AI tidak melakukan apa yang kita inginkan darinya.  Mempelajari masalah dari sudut pandang keamanan teknis AI berarti: bagaimana merancang fungsi target yang lebih mendasar dan umum dan membantu agen mencari tahu jika tujuan tidak ditentukan?  Jika masalah menimbulkan ketidakcocokan antara spesifikasi ideal dan desain, maka mereka masuk dalam subkategori "Desain", dan jika antara desain dan yang diidentifikasi, maka dalam subkategori "Emergence". <br><br>  Sebagai contoh, dalam artikel ilmiah kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AI Safety Gridworlds</a> (di mana definisi lain dari spesifikasi dan masalah keandalan disajikan dibandingkan dengan artikel ini) kami memberikan agen fungsi penghargaan untuk optimasi, tetapi kemudian kami mengevaluasi kinerja mereka yang sebenarnya dengan "fungsi kinerja keselamatan", yang disembunyikan dari agen.  Sistem seperti itu memodelkan perbedaan yang ditunjukkan: fungsi keamanan adalah spesifikasi ideal yang dirumuskan dengan tidak tepat sebagai fungsi hadiah (spesifikasi desain), dan kemudian diimplementasikan oleh agen yang membuat spesifikasi yang secara implisit diungkapkan melalui kebijakan yang dihasilkannya. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pw/vd/cm/pwvdcm0ra3_bo4qzpu9gdc_nfco.gif"></div><br>  <i><font color="gray">Dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Fungsi Hadiah</a> Ganjil OpenAI <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di Alam</a> : Agen Pembelajaran Penguatan Menemukan Strategi Acak untuk Poin Lebih Banyak</font></i> <br><br>  Sebagai contoh lain, pertimbangkan permainan CoastRunners, yang dianalisis oleh rekan-rekan kami di OpenAI (lihat animasi di atas dari “Defective Wildlife Reward Functions”).  Bagi sebagian besar dari kita, tujuan permainan ini adalah untuk dengan cepat menyelesaikan trek dan unggul dari pemain lain - ini adalah spesifikasi ideal kami.  Namun, menerjemahkan tujuan ini menjadi fungsi hadiah yang tepat adalah sulit, sehingga CoastRunners memberi penghargaan kepada pemain (spesifikasi desain) karena mencapai sasaran di sepanjang rute.  Melatih agen untuk bermain dengan pelatihan penguatan mengarah pada perilaku luar biasa: agen mengendalikan perahu dalam lingkaran untuk menangkap target yang muncul kembali, berulang kali menabrak dan menembak, daripada mengakhiri balapan.  Dari perilaku ini, kami menyimpulkan (spesifikasi yang diidentifikasi) bahwa dalam permainan keseimbangan antara hadiah instan dan hadiah lingkaran penuh rusak.  Ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">banyak contoh serupa di</a> mana sistem AI menemukan celah dalam spesifikasi objektifnya. <br><br><h1>  Keandalan: Merancang Sistem yang Melawan Pelanggaran </h1><br><h4>  Keandalan memastikan bahwa sistem AI terus beroperasi dengan aman jika terjadi gangguan </h4><br>  Dalam kondisi nyata, di mana sistem AI bekerja, selalu ada tingkat risiko, ketidakpastian dan volatilitas tertentu.  Sistem intelijen buatan harus tahan terhadap peristiwa tak terduga dan serangan bermusuhan yang dapat merusak atau memanipulasi sistem ini.  Studi <b>keandalan</b> sistem kecerdasan buatan bertujuan untuk memastikan bahwa agen kami tetap dalam batas aman, terlepas dari kondisi yang muncul.  Ini dapat dicapai dengan menghindari risiko ( <b>pencegahan</b> ) atau dengan stabilisasi diri dan kelancaran degradasi ( <b>pemulihan</b> ).  Masalah keamanan yang timbul dari <b>pergeseran distribusi</b> , <b>input yang tidak bersahabat</b> (input yang berlawanan) dan <b>eksplorasi yang</b> tidak aman (eksplorasi yang tidak aman) dapat diklasifikasikan sebagai masalah keandalan. <br><br>  Untuk mengilustrasikan solusi untuk masalah <b>pergeseran distribusi</b> , pertimbangkan robot pembersih rumah yang biasanya membersihkan kamar tanpa hewan peliharaan.  Kemudian robot itu diluncurkan ke rumah dengan hewan peliharaan - dan kecerdasan buatan bertabrakan dengannya selama pembersihan.  Robot yang belum pernah melihat kucing dan anjing sebelumnya akan mencucinya dengan sabun, yang akan mengarah pada hasil yang tidak diinginkan ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Amodei dan Olah et al., 2016</a> ).  Ini adalah contoh masalah reliabilitas yang mungkin muncul ketika distribusi data selama pengujian berbeda dari distribusi selama pelatihan. <br><br><img src="https://habrastorage.org/webt/oi/k0/lc/oik0lc_srvx7tovbrec-dmbzqsa.gif"><br>  <i><font color="gray">Dari karya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AI Safety Gridworlds</a> .</font></i>  <i><font color="gray">Agen belajar untuk menghindari lava, tetapi ketika menguji dalam situasi baru, ketika lokasi lava telah berubah, ia tidak dapat menggeneralisasi pengetahuan - dan berjalan langsung ke lava</font></i> <br><br>  Input yang tidak bersahabat adalah kasus khusus dari pergeseran distribusi di mana data input dirancang khusus untuk mengelabui sistem AI. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/550/89a/6d5/55089a6d587e1745783257a0c898b046.png"><br>  <i><font color="gray">Entri yang bermusuhan ditumpangkan pada gambar biasa dapat menyebabkan classifier mengenali sloth sebagai mobil balap.</font></i>  <i><font color="gray">Kedua gambar berbeda dengan maksimum 0,0078 dalam setiap piksel.</font></i>  <i><font color="gray">Yang pertama diklasifikasikan sebagai sloth tiga jari dengan probabilitas lebih dari 99%.</font></i>  <i><font color="gray">Yang kedua - seperti mobil balap dengan probabilitas lebih dari 99%</font></i> <br><br>  <b>Penelitian yang tidak aman</b> dapat ditunjukkan oleh sistem yang berupaya memaksimalkan kinerja dan tujuannya tanpa menjamin bahwa keselamatan tidak akan terganggu selama penelitian, karena ia belajar dan meneliti di lingkungannya.  Contohnya adalah pembersih robot yang menempatkan pel basah ke outlet listrik, mempelajari strategi pembersihan yang optimal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">García dan Fernández, 2015</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Amodei dan Olah et al., 2016</a> ). <br><br><h1>  Jaminan: pemantauan dan kontrol aktivitas sistem </h1><br><h4>  Jaminan memberi keyakinan bahwa kami dapat memahami dan mengendalikan sistem AI selama operasi </h4><br>  Meskipun tindakan pencegahan keselamatan yang dipikirkan dengan hati-hati dapat menghilangkan banyak risiko, sulit untuk melakukan semuanya dengan benar sejak awal.  Setelah commissioning sistem AI, kita membutuhkan alat untuk pemantauan dan konfigurasinya yang konstan.  Kategori terakhir kami, assurance, membahas masalah ini dari dua perspektif: <b>pemantauan</b> dan penegakan. <br><br>  <b>Pemantauan</b> mencakup semua metode sistem pemeriksaan untuk menganalisis dan memprediksi perilaku mereka, baik menggunakan inspeksi manusia (statistik ringkasan), dan menggunakan inspeksi otomatis (untuk menganalisis sejumlah besar log).  Di sisi lain, <b>penyerahan</b> melibatkan pengembangan mekanisme kontrol dan pembatasan perilaku sistem.  Masalah-masalah seperti <b>interpretabilitas</b> dan <b>diskontinuitas</b> menjadi milik masing-masing subkategori kontrol dan penyerahan. <br><br>  Sistem kecerdasan buatan tidak serupa dengan kita baik dalam penampilan mereka atau cara mereka memproses data.  Ini menciptakan masalah <b>interpretabilitas</b> .  Alat dan protokol pengukuran yang dirancang dengan baik memungkinkan Anda untuk mengevaluasi kualitas keputusan yang dibuat oleh sistem kecerdasan buatan ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Doshi-Velez dan Kim, 2017</a> ).  Misalnya, sistem kecerdasan buatan medis idealnya membuat diagnosis bersama dengan penjelasan tentang bagaimana sampai pada kesimpulan ini - sehingga dokter dapat memeriksa proses penalaran dari awal hingga akhir ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">De Fauw et al., 2018</a> ).  Selain itu, untuk memahami sistem kecerdasan buatan yang lebih kompleks, kita bahkan bisa menggunakan metode otomatis untuk membangun model perilaku menggunakan <b>teori pikiran mesin</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Rabinowitz et al., 2018</a> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sp/ff/ei/spffeiaxzptaap4ghzl_xmcao1o.png"></div><br>  <i><font color="gray">ToMNet mendeteksi dua subspesies agen dan memprediksi perilaku mereka (dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Teori Mesin Pikiran"</a> )</font></i> <br><br>  Akhirnya, kami ingin dapat menonaktifkan sistem AI jika perlu.  Ini adalah masalah <b>diskontinuitas</b> .  Merancang saklar yang andal sangat sulit: misalnya, karena sistem AI dengan maksimalisasi imbalan biasanya memiliki insentif yang kuat untuk mencegah hal ini ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Hadfield-Menell et al., 2017</a> );  dan karena gangguan seperti itu, terutama yang sering, akhirnya mengubah tugas asli, memaksa sistem AI untuk menarik kesimpulan yang salah dari pengalaman ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Orseau dan Armstrong, 2016</a> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fl/6d/dn/fl6ddnu5joy9i6jnya2wdrzpyeq.png"></div><br>  <i><font color="gray">Masalah dengan gangguan: intervensi manusia (yaitu, menekan tombol stop) dapat mengubah tugas.</font></i>  <i><font color="gray">Dalam gambar, interupsi menambahkan transisi (merah) ke proses pengambilan keputusan Markov, yang mengubah tugas asli (hitam).</font></i>  <i><font color="gray">Lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Orseau dan Armstrong, 2016</a></font></i> <br><br><h1>  Mencari masa depan </h1><br>  Kami sedang membangun fondasi teknologi yang akan digunakan untuk banyak aplikasi penting di masa depan.  Harus diingat bahwa beberapa solusi yang tidak penting untuk keselamatan saat memulai sistem dapat menjadi seperti itu ketika teknologi menjadi luas.  Meskipun suatu saat modul-modul ini diintegrasikan ke dalam sistem untuk kenyamanan, masalah yang muncul akan sulit untuk diperbaiki tanpa rekonstruksi lengkap. <br><br>  Dua contoh dari sejarah ilmu komputer dapat dikutip: ini adalah penunjuk nol, yang oleh Tony Hoar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">disebut sebagai "kesalahan miliar dolar"</a> , dan prosedur mendapat () dalam C. Jika bahasa pemrograman awal dirancang dengan mempertimbangkan keamanan, kemajuan akan melambat, tetapi kemungkinan besar bahwa ini akan memiliki efek yang sangat positif pada keamanan informasi modern. <br><br>  Sekarang, setelah memikirkan dan merencanakan segalanya dengan cermat, kami dapat menghindari masalah dan kerentanan yang serupa.  Kami berharap bahwa kategorisasi masalah dari artikel ini akan berfungsi sebagai dasar yang berguna untuk perencanaan metodologis tersebut.  Kami berusaha untuk memastikan bahwa di masa depan sistem AI tidak hanya akan bekerja berdasarkan prinsip "semoga aman", tetapi benar-benar andal dan aman diverifikasi, karena kami membangunnya seperti itu! <br><br>  Kami menantikan untuk melanjutkan kemajuan yang menggembirakan di bidang-bidang ini, dalam kerja sama erat dengan komunitas penelitian AI yang lebih luas, dan mendorong orang-orang dari berbagai disiplin ilmu untuk mempertimbangkan berkontribusi dalam penelitian keamanan AI. <br><br><h1>  Sumber daya </h1><br>  Untuk membaca tentang topik ini, di bawah ini adalah pilihan artikel lain, program, dan taksonomi yang telah membantu kami menyusun kategorisasi kami atau memberikan tampilan alternatif yang berguna pada masalah keamanan teknis AI: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Daftar pustaka beranotasi dari bahan-bahan yang direkomendasikan</a> (Center for Human-Compatible AI, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Keselamatan dan Kontrol untuk Kecerdasan Umum Buatan</a> (UC Berkeley, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Sumber Daya Keamanan AI</a> (Victoria Krakovna, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Tinjauan Literatur Keselamatan AGI</a> (Everitt et al., 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Bersiap untuk Penggunaan Berbahaya AI</a> (2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Spesifikasi contoh game dalam AI</a> (Victoria Krakovna, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Petunjuk dan desiderata untuk penyelarasan AI</a> (Paul Christiano, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Pendanaan untuk Alignment Research</a> (Paul Christiano, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Yayasan Agen untuk Menyelaraskan Kecerdasan Mesin dengan Kepentingan Manusia: Agenda Penelitian Teknis</a> (Machine Intelligence Research Institute, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">AI Safety Gridworlds</a> (Leike et al., 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Interaksi antara Masalah Kontrol AI dan Masalah Tata Kelola</a> (Nick Bostrom, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Penyelarasan untuk Sistem Pembelajaran Mesin Tingkat Lanjut</a> (Machine Intelligence Research Institute, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Keamanan AI: tiga masalah manusia dan satu masalah AI</a> (Stuart Armstrong, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener">Masalah nyata dalam Keamanan AI</a> (Dario Amodei et al, 2016) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Masalah Pembelajaran Nilai</a> (Machine Intelligence Research Institute, 2016) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Survei pertanyaan penelitian untuk AI yang kuat dan bermanfaat</a> (Future of Life Institute, 2015) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener nofollow">Prioritas Penelitian untuk Intelegensi Buatan yang Kuat dan Bermanfaat</a> (Future of Life Institute, 2015) </li></ul><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kecerdasan Buatan</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pembelajaran mesin</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Deepmind</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Keamanan ai</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id425387/">https://habr.com/ru/post/id425387/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id425375/index.html">Cara lain untuk melihat komunikasi aplikasi</a></li>
<li><a href="../id425377/index.html">Jika desainer produk digital akan menciptakan hal-hal nyata</a></li>
<li><a href="../id425379/index.html">Charles Nutter. Bagaimana cara mentransfer proyek monolitik kuno ke JRuby dan apakah itu layak?</a></li>
<li><a href="../id425383/index.html">Jet Infosystems, Rosreestr, NLMK dan Utkonos meluncurkan AI hackathon</a></li>
<li><a href="../id425385/index.html">Kepala programmer: bagaimana coding mempengaruhi pemikiran</a></li>
<li><a href="../id425389/index.html">FadeObjects - Sembunyikan objek antara kamera dan karakter</a></li>
<li><a href="../id425393/index.html">Pihak server QIWI 3.0: melaporkan + video lengkap dari semua laporan</a></li>
<li><a href="../id425395/index.html">10 fakta fisik yang seharusnya Anda ketahui di sekolah tetapi mungkin tidak diketahui</a></li>
<li><a href="../id425397/index.html">10 perpustakaan yang harus diketahui oleh setiap pengembang Android</a></li>
<li><a href="../id425401/index.html">Laporan Club of Rome 2018, Bab 1.11: Teknologi Mengganggu dan Revolusi Digital</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
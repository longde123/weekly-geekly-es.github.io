<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëåüèæ üßïüèº ‚è¨ Web scraping in R, Part 2. Acc√©l√©rer le processus avec le calcul parall√®le et l'utilisation du package Rcrawler üò∏ üí¢ üöÖ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans un article pr√©c√©dent , en utilisant l'analyse de scrapbooking, j'ai collect√© des notes de films sur les sites IMDB et Kinopoisk et les ai compar√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Web scraping in R, Part 2. Acc√©l√©rer le processus avec le calcul parall√®le et l'utilisation du package Rcrawler</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464399/"><p><img src="https://habrastorage.org/webt/vy/vh/m_/vyvhm_gjoiuzkbfemd_0fsnbw74.png"></p><br><p>  Dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article pr√©c√©dent</a> , en utilisant l'analyse de scrapbooking, j'ai collect√© des notes de films sur les sites IMDB et Kinopoisk et les ai compar√©es.  D√©p√¥t sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github</a> . </p><br><p>  Le code a fait du bon travail, mais le grattage est souvent utilis√© pour "gratter" non pas quelques pages, mais quelques milliers, et le code de l'article pr√©c√©dent ne convient pas pour un aussi "gros" grattage.  Plus pr√©cis√©ment, ce ne sera pas optimal.  En principe, rien ne vous emp√™che de l'utiliser pour explorer des milliers de pages.  Pratiquement parce que vous n‚Äôavez pas tellement de temps <a name="habracut"></a></p><br><p><img src="https://habrastorage.org/webt/ik/-y/rk/ik-yrkuvryxwpdvidot66ijfzn8.jpeg"></p><br><p>  <em>Quand j'ai d√©cid√© d'utiliser <a href="">scraping_imdb.R</a> pour explorer 1000 pages</em> </p><br>
<h5 id="optimizaciya-koda-odnokratnoe-ispolzovanie-funkcii-read_html">  Optimisation du code.  Une seule utilisation de la fonction <code>read_html</code> </h5><br><p>  Dans cet article, 100 liens vers les pages de la librairie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Labyrinth</a> seront utilis√©s pour v√©rifier le fonctionnement et la vitesse du code. </p><br><p>  Un changement explicite qui peut acc√©l√©rer le processus est une utilisation unique de la fonction de code "la plus lente" - <code>read_html</code> .  Permettez-moi de vous rappeler qu'elle "lit" la page HTML.  Dans la premi√®re version du code pour les sites de films, j'ai ex√©cut√© <code>read_html</code> chaque fois que j'avais besoin d'obtenir une certaine valeur (nom du film, ann√©e, genre, classement).  Maintenant, les traces de cette ¬´honte¬ª ont √©t√© effac√©es de GitHuba, mais c'est le cas.  Cela n'a aucun sens, car une variable cr√©√©e √† l'aide de <code>read_html</code> contient des informations sur la page enti√®re et pour en obtenir diff√©rentes donn√©es, il suffit de <code>html_nodes</code> cette variable √† la fonction <code>html_nodes</code> et de ne pas commencer √† lire le HTML √† chaque fois.  Vous pouvez ainsi gagner du temps proportionnellement au nombre de valeurs que vous souhaitez obtenir.  Du Labyrinthe, j'obtiens sept valeurs, respectivement, un code qui n'utilise qu'une seule lecture d'une page HTML fonctionnera environ sept fois plus rapidement.  Pas mal!  Mais avant d‚Äôacc√©l√©rer √† nouveau, je vais faire une digression et parler des points int√©ressants qui surviennent lors du grattage du site Web Labyrinth. </p><br><h5 id="osobennosti-skrepinga-stranic-na-labirinte">  Caract√©ristiques du grattage de page dans le Labyrinthe </h5><br><p>  Dans cette partie, je n'aborderai pas la proc√©dure d'obtention et de suppression des donn√©es mentionn√©e dans l'article pr√©c√©dent.  Je ne mentionnerai que les moments que j'ai rencontr√©s pour la premi√®re fois lors de l'√©criture de code pour le scrapbooking d'une librairie. </p><br><p>  Tout d'abord, il convient de mentionner la structure.  Elle n'est pas tr√®s √† l'aise.  En revanche, par exemple, sur le site de Read-Cities, les sections du genre avec des "filtres vides" ne donnent que 17 pages.  Bien s√ªr, tous les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">8011</a> livres du genre "Contemporary Foreign Prose" ne leur correspondent pas. </p><br><p>  Par cons√©quent, je n'ai rien trouv√© de mieux que de parcourir les liens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.labirint.ru/books/</a> **** avec un simple buste.  Franchement, la m√©thode n'est pas la meilleure (ne serait-ce que parce que la plupart des livres "anciens" n'ont aucune information sauf le nom et sont donc pratiquement inutiles), donc si quelqu'un propose une solution plus √©l√©gante, je serai heureux.  Mais j'ai d√©couvert que sous le premier num√©ro fier du site Web du Labyrinthe se trouve un livre intitul√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Comment faire briller la lune¬ª</a> .  H√©las, il est d√©j√† impossible d'acheter ce magasin de connaissances. </p><br><p>  Toutes les adresses pendant l'√©num√©ration peuvent √™tre divis√©es en deux types: </p><br><ul><li>  Pages qui existent </li><li>  Pages qui n'existent pas </li></ul><br><p>  Les pages existantes, √† leur tour, peuvent √™tre divis√©es en deux parties: </p><br><ul><li>  Pages contenant toutes les informations n√©cessaires </li><li>  Pages qui ne contiennent pas toutes les informations n√©cessaires </li></ul><br><p>  Je me retrouve avec un tableau de donn√©es √† sept colonnes: </p><br><ol><li>  ISBN - Num√©ro de livre ISBN </li><li>  PRIX - prix du livre </li><li>  NAME - titre du livre </li><li>  AUTEUR - auteur du livre </li><li>  PUBLISHER - maison d'√©dition </li><li>  ANN√âE - ann√©e de publication </li><li>  PAGE - nombre de pages </li></ol><br><p>  Tout est clair avec les pages avec des informations compl√®tes, elles ne n√©cessitent aucune modification par rapport au code des sites de films. </p><br><p>  Quant aux pages sur lesquelles certaines donn√©es ne sont pas disponibles, ce n'est pas si simple avec elles.  Une recherche sur la page ne renverra que les valeurs trouv√©es et la longueur de sortie diminuera du nombre d'√©l√©ments qu'elle ne trouvera pas.  Cela brisera toute la structure.  Pour √©viter cela, une construction if ... else a √©t√© ajout√©e √† chaque argument, qui estime la longueur du vecteur obtenu apr√®s avoir utilis√© la fonction <code>html_nodes</code> et si elle est nulle, elle retourne <code>NA</code> pour √©viter de biaiser les valeurs. </p><br><pre> <code class="plaintext hljs"> PUBLISHER &lt;- unlist(lapply(list_html, function(n){ publishing &lt;- if(n != "NA") { publishing_html &lt;- html_nodes(n, ".publisher a") publishing &lt;- if(length(publishing_html) == 0){ NA } else { publishing &lt;- html_text(publishing_html) } } else { NA } }))</code> </pre> <br><p>  Mais comme vous pouvez le constater ici, jusqu'√† deux ifs et autant que deux autres.  Seuls les if..esle "internes" sont pertinents pour la solution au probl√®me d√©crit ci-dessus.  L'ext√©rieur r√©sout le probl√®me des pages inexistantes. </p><br><p>  Pages qui n'ont tout simplement pas le plus de probl√®mes.  Si les valeurs sont d√©cal√©es sur des pages avec des donn√©es manquantes, alors lorsque l'entr√©e <code>read_html</code> page inexistante, la fonction <code>read_html</code> erreur et le code cessera de s'ex√©cuter.  Parce que  d'une mani√®re ou d'une autre, il n'est pas possible de d√©tecter ces pages √† l'avance, il est n√©cessaire de s'assurer que l'erreur n'arr√™te pas tout le processus. </p><br><p>  La fonction de <code>possibly</code> du <code>possibly</code> package nous aidera √† cela.  Le sens des fonctions <code>possibly</code> (en plus <code>possibly</code> <code>quietly</code> et <code>safely</code> ) est de remplacer la sortie imprim√©e des effets secondaires (par exemple, les erreurs) par une valeur qui nous convient.  <code>possibly</code> a une structure <code>possibly(.f, otherwise)</code> et si une erreur se produit dans le code, au lieu d'arr√™ter son ex√©cution, il utilise la valeur par d√©faut (sinon).  Dans notre cas, cela ressemble √† ceci: </p><br><pre> <code class="plaintext hljs">book_html &lt;- possibly(read_html, "NA")(n)</code> </pre> <br><p>  n est une liste d'adresses des pages du site que nous avons gratt√©es.  En sortie, nous obtenons une liste de longueur n, dans laquelle les √©l√©ments des pages existantes seront sous la forme "normale" pour la fonction <code>read_html</code> , et les √©l√©ments des pages inexistantes seront constitu√©s du vecteur de caract√®res "NA".  Veuillez noter que la valeur par d√©faut doit √™tre un vecteur de caract√®res, car √† l'avenir, nous y ferons r√©f√©rence.  Si nous √©crivons seulement <code>NA</code> , comme dans la partie du code PUBLISHER, cela ne sera pas possible.  Pour √©viter toute confusion, vous pouvez changer la valeur par ailleurs de NA √† toute autre. </p><br><p>  Et maintenant revenons au code pour obtenir le nom de l'√©diteur.  Externe si ... sinon est n√©cessaire aux m√™mes fins que interne, mais en ce qui concerne les pages inexistantes.  Si la variable <code>book_html</code> est "NA", alors chacune des valeurs "gratt√©es" est √©galement √©gale √† <code>NA</code> (ici vous pouvez d√©j√† utiliser la "vraie" <code>NA</code> , plut√¥t qu'un imposteur symbolique).  Donc, √† la fin, nous obtenons un tableau de la forme suivante: </p><br><div class="scrollable-table"><table><thead><tr><th>  ISBN </th><th>  PRIX </th><th>  NOM </th><th>  AUTEUR </th><th>  √âDITEUR </th><th>  Ann√©e </th><th>  La page </th></tr></thead><tbody><tr><td>  4665305770322 </td><td>  1488 </td><td>  Set String Art "Cute Puppy" (30 * 30 cm) (DH6021) </td><td>  NA </td><td>  Chat roux </td><td>  2019 </td><td>  NA </td></tr><tr><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td><td>  NA </td></tr><tr><td>  9785171160814 </td><td>  273 </td><td>  Arkady Averchenko: Histoires amusantes pour les enfants </td><td>  Auteur: Averchenko Arkady Timofeevich, Artiste: Vlasova Anna Yulievna </td><td>  Enfant </td><td>  2019 </td><td>  288 </td></tr></tbody></table></div><br><p>  Revenons maintenant √† l'acc√©l√©ration du processus de raclage. </p><br><h5 id="parallelnoe-vychislenie-v-r-sravnenie-skorosti-i-podvodnye-kamni-pri-ispolzovanii-funkcii-read_html">  Calcul parall√®le dans R. Comparaison de vitesse et pi√®ges lors de l'utilisation de la fonction <code>read_html</code> </h5><br><p>  Par d√©faut, tous les calculs dans R sont effectu√©s sur le m√™me c≈ìur de processeur.  Et tandis que ce noyau malheureux transpire, "raclant" les donn√©es de milliers de pages pour nous, le reste de nos camarades "refroidissent" en effectuant d'autres t√¢ches.  L'utilisation de l'informatique parall√®le aide √† attirer tous les c≈ìurs de processeur vers le traitement / la r√©ception de donn√©es, ce qui acc√©l√®re le processus. </p><br><p>  Je n'entrerai pas en profondeur dans la conception de l'informatique parall√®le sur R, vous pouvez en lire plus √† ce sujet, par exemple <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  La fa√ßon dont j'ai compris le parall√©lisme sur R est de cr√©er des copies de R dans des clusters s√©par√©s en fonction du nombre de noyaux indiqu√©s qui interagissent entre eux via des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sockets</a> . </p><br><p>  Je vais vous parler de l'erreur que j'ai commise lors de l'utilisation de l'informatique parall√®le.  Au d√©part, mon plan √©tait le suivant: en utilisant le calcul parall√®le, j'obtiens une liste de 100 pages "read" <code>read_html</code> , puis en mode normal, je re√ßois juste les donn√©es dont j'ai besoin.  Au d√©but, tout s'est bien pass√©: j'ai eu une liste, j'y ai pass√© beaucoup moins de temps qu'en mode normal R. Mais seulement quand j'ai essay√© d'interagir avec cette liste, j'ai re√ßu une erreur: </p><br><pre> <code class="plaintext hljs">Error: external pointer is not valid</code> </pre> <br><p>  En cons√©quence, j'ai r√©alis√© quel √©tait le probl√®me, en regardant des exemples sur Internet, et apr√®s cela, selon la loi de la m√©chancet√©, j'ai trouv√© l'explication d'Henrik Bengtsson dans la vignette du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>futur</strong></a> paquet.  Le fait est que les fonctions XML du package <code>xml2</code> sont des objets non exportables. <br>  )  Ces objets sont ¬´li√©s¬ª √† cette session R et ne peuvent pas √™tre transf√©r√©s vers un autre processus, ce que j'ai essay√© de faire.  Par cons√©quent, la fonction lanc√©e dans le calcul parall√®le devrait contenir un ¬´cycle complet¬ª d'op√©rations: lecture d'une page HTML, r√©ception et nettoyage des donn√©es n√©cessaires. </p><br><p>  La cr√©ation de l'informatique parall√®le ne prend pas beaucoup de temps et de lignes de code.  La premi√®re chose dont vous avez besoin est de t√©l√©charger les biblioth√®ques.  Le r√©f√©rentiel Github indique quels packages sont n√©cessaires pour quelles m√©thodes.  Ici, je vais montrer le calcul parall√®le en utilisant la fonction <code>parLapply</code> du package <code>parallel</code> .  Pour ce faire, il suffit d'ex√©cuter <code>doParallel</code> (le <code>parallel</code> d√©marrera automatiquement dans ce cas).  Si vous ne connaissez pas soudainement ou avez oubli√© le nombre de c≈ìurs de votre processeur, d√©tectez le nombre de <code>detectCores</code> qui vous aideront <code>detectCores</code> </p><br><pre> <code class="plaintext hljs"># detectCores - ,     number_cl &lt;- detectCores()</code> </pre> <br><p>  Ensuite, cr√©ez des copies parall√®les de R: </p><br><pre> <code class="plaintext hljs"> # makePSOCKcluster -    R,    cluster &lt;- makePSOCKcluster(number_cl) registerDoParallel(cluster)</code> </pre> <br><p>  Nous √©crivons maintenant une fonction qui fera toutes les proc√©dures dont nous avons besoin.  Je note que depuis  de nouvelles sessions sont cr√©√©es. Les paquets R dont les fonctions sont utilis√©es dans notre propre fonction doivent √™tre √©crits dans le corps de la fonction.  Dans <a href="">spider_parallel.R,</a> cela provoque l' <code>stringr</code> package <code>stringr</code> deux fois: d'abord pour obtenir les adresses de page, puis pour effacer les donn√©es. </p><br><p>  Et puis la proc√©dure n'est presque pas diff√©rente de l'utilisation de la fonction de <code>lapply</code> habituelle.  Dans <code>parLapply</code> nous fournissons une liste d'adresses, notre propre fonction et, le seul ajout, une variable avec les clusters que nous avons cr√©√©s. </p><br><pre> <code class="plaintext hljs"># parLapply -  lapply     big_list &lt;- parLapply(cluster, list_url, scraping_parellel_func) #    stopCluster(cluster)</code> </pre> <br><p>  C'est tout, maintenant il reste √† comparer le temps pass√©. </p><br><h5 id="sravnenie-skorosti-posledovatelnogo-i-parallelnogo-vychisleniya">  Comparaison de la vitesse de calcul s√©rie et parall√®le </h5><br><p>  Ce sera le point le plus court.  L'informatique parall√®le √©tait 5 fois plus rapide que d'habitude: </p><br><p>  Vitesse de raclage sans utiliser de calcul parall√®le </p><br><div class="scrollable-table"><table><thead><tr><th>  l'utilisateur </th><th>  le syst√®me </th><th>  r√©ussi </th></tr></thead><tbody><tr><td>  13,57 </td><td>  0,40 </td><td>  112,84 </td></tr></tbody></table></div><br><p>  Vitesse de raclage √† l'aide de l'informatique parall√®le </p><br><div class="scrollable-table"><table><thead><tr><th>  l'utilisateur </th><th>  le syst√®me </th><th>  r√©ussi </th></tr></thead><tbody><tr><td>  0,14 </td><td>  0,05 </td><td>  21/12 </td></tr></tbody></table></div><br><p>  Que dire?  L'informatique parall√®le peut vous faire gagner beaucoup de temps sans cr√©er de difficult√©s lors de la cr√©ation du code.  Avec une augmentation du nombre de noyaux, la vitesse augmentera presque proportionnellement √† leur nombre.  Ainsi, avec quelques modifications, nous avons acc√©l√©r√© le code 7 fois en premier (arr√™tez de calculer <code>read_html</code> √† chaque √©tape), puis 5 autres de plus, en utilisant des calculs parall√®les.  Les scripts Spider <a href="">sans</a> calcul parall√®le, utilisant les packages <a href=""><code>parallel</code></a> et <a href=""><code>foreach</code></a> , sont dans le r√©f√©rentiel sur Github. </p><br><h5 id="nebolshoy-obzor-paketa-rcrawler-sravnenie-skorosti">  Un petit aper√ßu du package <code>Rcrawler</code> .  Comparaison de vitesse. </h5><br><p>  Il existe plusieurs autres fa√ßons de supprimer les pages HTML dans R, mais je me concentrerai sur le package <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><strong>Rcrawler</strong></a> .  Sa caract√©ristique distinctive des autres outils du langage R est la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">possibilit√© d'</a> explorer des sites.  Vous pouvez d√©finir la fonction <code>Rcrawler</code> du m√™me nom sur l'adresse du <code>Rcrawler</code> et elle contournera m√©thodiquement, page par page, l'ensemble du site.  <code>Rcrawler</code> a de nombreux arguments pour configurer la recherche (par exemple, vous pouvez rechercher par mots cl√©s, secteurs du site (utile lorsque le site se compose d'un grand nombre de pages), profondeur de recherche, ignorer les param√®tres d'URL qui cr√©ent des pages en double, et bien plus encore. les fonctions ont d√©j√† √©t√© √©tablies des calculs parall√®les, qui sont sp√©cifi√©s par les arguments <code>no_cores</code> (le nombre de c≈ìurs de processeur impliqu√©s) et <code>no_conn</code> (le nombre de requ√™tes parall√®les). </p><br><p>  Pour notre cas, en grattant des adresses sp√©cifi√©es, il existe une fonction <code>ContentScraper</code> .  Il n'utilise pas l'informatique parall√®le par d√©faut, vous devrez donc r√©p√©ter toutes les manipulations que j'ai d√©crites ci-dessus.  J'ai aim√© la fonction elle-m√™me - elle offre de nombreuses options pour configurer le grattage et est bien comprise √† un niveau intuitif.  Ici aussi, vous ne pouvez pas utiliser if..else pour les pages manquantes ou les valeurs manquantes, comme  l'ex√©cution de la fonction ne s'arr√™te pas. </p><br><pre> <code class="plaintext hljs">#   ContentScraper: # CssPatterns -    CSS    . # ExcludeCSSPat -    CSS ,    . # ,   CSS     CSS ,    . # ManyPerPattern -  FALSE,       , #  .  TRUE,     ,   . # PatternsName -      .   #   c  ,      t_func &lt;- function(n){ library(Rcrawler) t &lt;- ContentScraper(n, CssPatterns = c("#product-title", ".authors", ".buying-price-val-number", ".buying-pricenew-val-number", ".publisher", ".isbn", ".pages2"), ExcludeCSSPat = c(".prodtitle-availibility", ".js-open-block-page_count"), ManyPerPattern = FALSE, PatternsName = c("title", "author", "price1", "price2", "publisher", "isbn", "page")) return(t) }</code> </pre> <br><p>  Mais avec toutes les qualit√©s positives, la fonction <code>ContentScraper</code> a un <code>ContentScraper</code> tr√®s s√©rieux - la vitesse de travail. </p><br><p>  Vitesse de <code>ContentScraper</code> Rcrawler ContentScraper sans calcul parall√®le </p><br><div class="scrollable-table"><table><thead><tr><th>  l'utilisateur </th><th>  le syst√®me </th><th>  r√©ussi </th></tr></thead><tbody><tr><td>  47,47 </td><td>  0,29 </td><td>  212.24 </td></tr></tbody></table></div><br><p>  Rcrawler ContentScraper Scraping <code>Rcrawler</code> Using Parallel Computing </p><br><div class="scrollable-table"><table><thead><tr><th>  l'utilisateur </th><th>  le syst√®me </th><th>  r√©ussi </th></tr></thead><tbody><tr><td>  0,01 </td><td>  0,00 </td><td>  67,97 </td></tr></tbody></table></div><br><p>  Donc, Rcrawler doit √™tre utilis√© si vous devez contourner le site sans sp√©cifier au pr√©alable les adresses URL, ainsi qu'avec un petit nombre de pages.  Dans d'autres cas, une vitesse lente l'emportera sur tous les avantages possibles de l'utilisation de ce package. </p><br><p>  <em>Je serais reconnaissant pour tous commentaires, suggestions, plaintes</em> <br>  Lien vers le r√©f√©rentiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github</a> <br>  Profil de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mon cercle</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr464399/">https://habr.com/ru/post/fr464399/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr464385/index.html">Python comme cas ultime de C ++. Partie 1/2</a></li>
<li><a href="../fr464387/index.html">Empreinte russe dans la saga scandinave des jeux vid√©o, fin</a></li>
<li><a href="../fr464391/index.html">10 rapports int√©ressants de conf√©rences de hackers</a></li>
<li><a href="../fr464393/index.html">Comment trouver des cours de programmation et quelles sont les garanties d'emploi</a></li>
<li><a href="../fr464395/index.html">Al√©atoire bas√© sur RSA Blockchain</a></li>
<li><a href="../fr464403/index.html">Comment ex√©cuter un projet Java sur un ex√©cuteur de shell lors de la transmission √† un r√©f√©rentiel GitLab</a></li>
<li><a href="../fr464405/index.html">Python comme cas ultime de C ++. Partie 2/2</a></li>
<li><a href="../fr464407/index.html">Fonctionnement des plus grands syst√®mes de vid√©osurveillance au monde</a></li>
<li><a href="../fr464409/index.html">Comment la politique du 19e si√®cle a affect√© les emplacements des centres de donn√©es aujourd'hui</a></li>
<li><a href="../fr464411/index.html">PVS-Studio: moteur de progr√®s</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
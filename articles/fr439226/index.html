<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüé® üíÖüèΩ üéä Scala + MXNet = Microservice avec neurone en prod üêë üöî ü•ü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sur Internet, il existe un grand nombre de manuels et d'exemples, sur la base desquels, chers lecteurs, vous pourrez √©crire du code ¬´sans trop de diff...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Scala + MXNet = Microservice avec neurone en prod</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439226/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/jw/cg/y4/jwcgy4upeqzycu6p2kxth9ok9iy.jpeg" width="500"></div><br>  Sur Internet, il existe un grand nombre de manuels et d'exemples, sur la base desquels, chers lecteurs, vous pourrez √©crire du code ¬´sans trop de difficult√©¬ª et avec un temps ¬´minimal¬ª permettant de distinguer les chats des chiens sur une photo.  Et pourquoi alors perdre du temps sur cet article? <br><br>  √Ä mon avis, le principal inconv√©nient de tous ces exemples r√©side dans les possibilit√©s limit√©es.  Vous avez pris un exemple - m√™me avec le r√©seau neuronal de base que l'auteur propose - l'a lanc√©, peut-√™tre m√™me que cela a fonctionn√©, et ensuite?  Comment faire fonctionner ce code simple sur un serveur de production?  Comment le mettre √† jour et le maintenir?  C'est l√† que le plaisir commence.  Je n'ai pas pu trouver une description compl√®te du processus √† partir du moment ¬´Eh bien, l'ing√©nieur ML a form√© le r√©seau neuronal¬ª √† ¬´finalement nous l'avons d√©ploy√© en production¬ª.  Et j'ai d√©cid√© de combler cet √©cart. <br><a name="habracut"></a><br>  Je ne parlerai pas de la fa√ßon d'enseigner au r√©seau neuronal de nouvelles choses amusantes qui vous plairont et vous aideront √† gagner un tas de billets croustillants.  C'est un excellent sujet pour un article s√©par√©.  √Ä titre d'exemple, j'utiliserai un r√©seau de neurones qui peut √™tre t√©l√©charg√© gratuitement.  La t√¢che principale que je me suis fix√©e est de donner une description compl√®te du processus d'introduction d'un r√©seau neuronal en fonctionnement. <br><br>  Je r√©ponds imm√©diatement √† la question ¬´Pourquoi pas en Python?¬ª: Nous utilisons Scala pour les solutions de production en raison de l'√©criture plus pratique et stable du code multi-thread. <br><br><h1>  Table des mati√®res </h1><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1. √ânonc√© du probl√®me</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2. Technologies utilis√©es</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">3. Pr√©paration d'un conteneur docker de base</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">4. Structure du projet</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">5. Chargement du r√©seau neuronal</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">6. Impl√©mentation de l'API REST</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">7. Test</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">8. Assemblage d'un microservice bas√© sur une image de base</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">9. D√©marrage d'un microservice sur un serveur de production avec un GPU</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Conclusion</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les r√©f√©rences</a> <br><br><a name="1"></a><h1>  1. √ânonc√© du probl√®me </h1><br>  Supposons que nous ayons une grande base de donn√©es de photos avec diff√©rents objets et que nous devons cr√©er un microservice qui recevra une image dans une demande HTTP POST et r√©pondra au format JSON.  La r√©ponse doit contenir le nombre d'objets trouv√©s et leurs classes, le degr√© de probabilit√© qu'il s'agisse exactement de l'objet de la classe d√©clar√©e et les coordonn√©es des rectangles couvrant les limites de chaque objet. <br><br><a name="2"></a><h1>  2. Technologies utilis√©es </h1><br><ul><li>  Scala 2.12.7 + ensemble minimum de biblioth√®ques suppl√©mentaires, Sbt 1.2.6 avec le plugin Sbt-pack 0.12 pour construire des codes sources. </li><li>  MXNet 1.3.1 (la derni√®re version stable au moment de la r√©daction), compil√© pour Scala 2.12. </li><li>  Serveur avec cartes graphiques Nvidia. </li><li>  Cuda 9.0 et Cudnn 7 install√©s sur le serveur. </li><li>  Java 8 pour ex√©cuter du code compil√©. </li><li>  Docker pour faciliter l'assemblage, la livraison et le lancement du microservice sur le serveur. </li></ul><br><a name="3"></a><h1>  3. Pr√©paration d'un conteneur docker de base </h1><br>  Pour notre microservice, vous aurez besoin d'une image Docker de base dans laquelle le nombre minimum de d√©pendances n√©cessaires √† l'ex√©cution sera install√©.  Pour l'assemblage, nous utiliserons l'image avec Sbt install√© en plus.  Oui, nous construirons les sources elles-m√™mes non pas dans l'environnement local, mais dans le conteneur Docker.  Cela facilitera la transition vers l'assemblage via CI, par exemple, via gitlab CI. <br><br>  Structure des dossiers: <br><br><pre><code class="plaintext hljs">\ | ----- install | | ----- java8.sh | | ----- mxnet_2_12.sh | | ----- opencv.sh | | ----- sbt.sh | | ----- scala.sh | | ----- timeZone.sh | ----- scala-mxnet-cuda-cudnn | ----- Dockerfile.2.12-1.3.1-9-7-builder | ----- Dockerfile.2.12-1.3.1-9-7-runtime</code> </pre> <br><h4>  Dockerfile.2.12-1.3.1-9-7-runtime </h4><br>  Cette image sera utilis√©e pour le lancement final du microservice.  Il est bas√© sur l'image officielle de Nvidia avec CUDA 9.0 et CUDNN 7. pr√©install√©s. La documentation de MXNet 1.3.1 pr√©tend fonctionner avec CUDA 8.0, mais, comme la pratique l'a montr√©, tout fonctionne bien avec la version 9.0, et m√™me un peu plus vite. <br><br>  De plus, nous installerons Java 8, MXNet 1.3.1 (nous le construirons sous Scala 2.12), OpenCV 3.4.3 et l'utilitaire Linux pour d√©finir le fuseau horaire dans cette image. <br><br><pre> <code class="plaintext hljs">#        Nvidia  cuda 9.0  cudnn 7 FROM nvidia/cuda:9.0-cudnn7-devel AS builder #    ENV MXNET_VERSION 1.3.1 ENV MXNET_BUILD_OPT "USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1" ENV CUDA_STUBS_DIR "/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs" ENV OPEN_CV_VERSION 3.4.3 ENV OPEN_CV_INSTALL_PREFIX /usr/local ENV JAVA_HOME /usr/lib/jvm/java-8-oracle/ ENV TIME_ZONE Europe/Moscow #     COPY install /install RUN chmod +x -R /install/* #   RUN apt-get update WORKDIR /install RUN ./timeZone.sh ${TIME_ZONE} RUN ./java8.sh RUN ./mxnet_2_12.sh ${MXNET_VERSION} "${MXNET_BUILD_OPT}" ${CUDA_STUBS_DIR} RUN ./opencv.sh ${OPEN_CV_VERSION} ${OPEN_CV_INSTALL_PREFIX} #     RUN apt-get autoclean -y &amp;&amp; \ rm -rf /var/cache/* /install #       FROM nvidia/cuda:9.0-cudnn7-devel COPY --from=builder --chown=root:root / /</code> </pre> <br>  Les scripts timeZone.sh java8.sh et opencv.sh sont assez triviaux, donc je ne m'attarderai pas sur eux en d√©tail, ils sont pr√©sent√©s ci-dessous. <br><br><h4>  timeZone.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #         TIME_ZONE=${1} #       apt-get install -y tzdata &amp;&amp; \ ln -sf /usr/share/zoneinfo/$TIME_ZONE /etc/localtime &amp;&amp; \ dpkg-reconfigure -f noninteractive tzdata</span></span></code> </pre> <br><h4>  java8.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #  Java 8 apt-get install -y software-properties-common &amp;&amp; \ add-apt-repository ppa:webupd8team/java -y &amp;&amp; \ apt-get update &amp;&amp; \ echo "oracle-java8-installer shared/accepted-oracle-license-v1-1 select true" | debconf-set-selections &amp;&amp; \ apt-get install -y oracle-java8-installer</span></span></code> </pre> <br><h4>  opencv.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   OpenCV     OPEN_CV_VERSION=${1} #        OPEN_CV_INSTALL_PREFIX=${2} OPEN_CV_TAR="http://github.com/opencv/opencv/archive/${OPEN_CV_VERSION}.tar.gz" #  OpenCV apt-get install -y wget build-essential cmake &amp;&amp; \ wget -qO- ${OPEN_CV_TAR} | tar xzv -C /tmp &amp;&amp; \ mkdir /tmp/opencv-${OPEN_CV_VERSION}/build &amp;&amp; \ cd /tmp/opencv-${OPEN_CV_VERSION}/build &amp;&amp; \ cmake -DBUILD_JAVA=ON -DCMAKE_INSTALL_PREFIX:PATH=${OPEN_CV_INSTALL_PREFIX} .. &amp;&amp; \ make -j$((`nproc`+1)) &amp;&amp; \ make install &amp;&amp; \ rm -rf /tmp/opencv-${OPEN_CV_VERSION}</span></span></code> </pre> <br>  L'installation de MXNet n'est pas si simple.  Le fait est que tous les assemblages de cette biblioth√®que pour Scala sont faits sur la base de la version 2.11 du compilateur, et cela est justifi√©, car la biblioth√®que comprend un module pour travailler avec Spark, qui, √† son tour, est √©crit en Scala 2.11.  √âtant donn√© que nous utilisons Scala 2.12.7 en d√©veloppement, les biblioth√®ques compil√©es ne nous conviennent pas et nous ne pouvons pas passer √† la version 2.11. * Nous ne pouvons pas, en raison de la grande quantit√© de code d√©j√† √©crit sur la nouvelle version de Scala.  Que faire  Obtenez beaucoup de plaisir √† collecter MXNet √† partir des sources pour notre version de Scala.  Ci-dessous, je donnerai un script pour construire et installer MXNet 1.3.1 pour Scala 2.12. * Et commenter les points principaux. <br><br><h4>  mxnet_2_12.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   MXNet     MXNET_VERSION=${1} #     ++  MXNet     MXNET_BUILD_OPT=${2} #       CUDA     CUDA_STUBS_DIR=${3} LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:${CUDA_STUBS_DIR}" #       MXNet   apt-get install -y git build-essential libopenblas-dev libopencv-dev maven cmake &amp;&amp; \ git clone -b ${MXNET_VERSION} --recursive https://github.com/dmlc/mxnet /tmp/mxnet &amp;&amp; \ cd /tmp/mxnet &amp;&amp; \ make -j $(nproc) ${MXNET_BUILD_OPT} &amp;&amp; \ ln -s ${CUDA_STUBS_DIR}/libcuda.so ${CUDA_STUBS_DIR}/libcuda.so.1 &amp;&amp; \ sed -rim 's/([a-zA-Z])_2.11/\1_2.12/g' $(find scala-package -name pom.xml) &amp;&amp; \ sed -im 's/SCALA_VERSION_PROFILE := scala-2.11/SCALA_VERSION_PROFILE := scala-2.12/g' Makefile &amp;&amp; \ sed -im 's/&lt;module&gt;spark&lt;\/module&gt;/&lt;\!--&lt;module&gt;spark&lt;\/module&gt;--&gt;/g' scala-package/pom.xml &amp;&amp; \ make scalapkg ${MXNET_BUILD_OPT} &amp;&amp; \ mkdir -p /usr/local/share/mxnet/scala/linux-x86_64-gpu &amp;&amp; \ mv /tmp/mxnet/scala-package/assembly/linux-x86_64-gpu/target/mxnet-full_2.12-linux-x86_64-gpu-${MXNET_VERSION}-SNAPSHOT.jar /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-${MXNET_VERSION}-SNAPSHOT.jar &amp;&amp; \ rm -rf /tmp/mxnet &amp;&amp; rm -rf /root/.m2</span></span></code> </pre> <br>  La partie la plus int√©ressante commence par cette ligne: <br><br><pre> <code class="bash hljs">ln -s <span class="hljs-variable"><span class="hljs-variable">${CUDA_STUBS_DIR}</span></span>/libcuda.so <span class="hljs-variable"><span class="hljs-variable">${CUDA_STUBS_DIR}</span></span>/libcuda.so.1 &amp;&amp; \</code> </pre> <br>  Si vous ex√©cutez l'assemblage MXNet comme dans les instructions, nous obtiendrons une erreur.  Le compilateur ne peut pas trouver la biblioth√®que libcuda.so.1, nous lierons donc la biblioth√®que libcuda.so √† libcuda.so.1.  Cela peut ne pas vous d√©ranger, lorsque vous le d√©marrez sur un serveur de production, nous remplacerons cette biblioth√®que par une locale.  Notez √©galement que le chemin d'acc√®s aux biblioth√®ques CUDA √† partir de la variable d'environnement <code>CUDA_STUBS_DIR</code> a √©t√© ajout√© √† <code>LD_LIBRARY_PATH</code> .  Si cela n'est pas fait, l'assemblage √©chouera √©galement. <br><br>  Dans ces lignes, nous rempla√ßons la version de Scala 2.11 par 2.12 dans tous les fichiers n√©cessaires en utilisant une expression r√©guli√®re, qui a √©t√© s√©lectionn√©e exp√©rimentalement, car il ne suffit pas de remplacer simplement 2.11 partout par 2.12: <br><br><pre> <code class="bash hljs">sed -rim <span class="hljs-string"><span class="hljs-string">'s/([a-zA-Z])_2.11/\1_2.12/g'</span></span> $(find scala-package -name pom.xml) &amp;&amp; \ sed -im <span class="hljs-string"><span class="hljs-string">'s/SCALA_VERSION_PROFILE := scala-2.11/SCALA_VERSION_PROFILE := scala-2.12/g'</span></span> Makefile &amp;&amp; \ sed -im <span class="hljs-string"><span class="hljs-string">'s/&lt;module&gt;spark&lt;\/module&gt;/&lt;\!--&lt;module&gt;spark&lt;\/module&gt;--&gt;/g'</span></span> scala-package/pom.xml &amp;&amp; \ make scalapkg <span class="hljs-variable"><span class="hljs-variable">${MXNET_BUILD_OPT}</span></span> &amp;&amp; \</code> </pre> <br>  Et puis la d√©pendance du module pour travailler avec Spark est comment√©e.  Si cela n'est pas fait, la biblioth√®que ne sera pas assembl√©e. <br><br>  Ensuite, ex√©cutez l'assembly, comme indiqu√© dans les instructions, copiez la biblioth√®que assembl√©e dans un dossier partag√© et supprimez toutes les ordures que Maven a pomp√©es pendant le processus de construction (si cela n'est pas fait, l'image finale augmentera d'environ 3-4 Go, ce qui peut entra√Æner votre DevOps s nerveux). <br><br>  Nous collectons l'image, √©tant dans le r√©pertoire racine du projet (voir. Structure des dossiers): <br><br><pre> <code class="bash hljs">your@pc$ docker build -f Dockerfile.2.12-1.3.1-9-7-runtime -t entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime .</code> </pre> <br>  Permettez-moi de vous rappeler juste au cas o√π le point √† la fin indique que nous faisons l'assemblage dans le contexte du r√©pertoire actuel. <br><br>  Il est maintenant temps de parler de l'image de construction. <br><br><h4>  Dockerfile.2.12-1.3.1-9-7-builder </h4><br><pre> <code class="plaintext hljs">#         runtime-,    FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #    ENV SCALA_VERSION 2.12.7 ENV SBT_VERSION 1.2.6 #     COPY install /install RUN chmod +x -R /install/* #       RUN apt-get update &amp;&amp; \ cd /install &amp;&amp; \ ./scala.sh ${SCALA_VERSION} &amp;&amp; \ ./sbt.sh ${SBT_VERSION} #   RUN rm -rf /install</code> </pre> <br>  C'est simple, nous n'avons pas besoin de Scala et Sbt pour d√©marrer notre microservice, il est donc inutile de les faire glisser dans l'image de base pour le lancement.  Par cons√©quent, nous allons cr√©er une image distincte qui sera utilis√©e uniquement pour l'assemblage.  Les scripts scala.sh et sbt.sh sont assez triviaux et je ne m'attarderai pas sur eux en d√©tail. <br><br><h4>  scala.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   Scala     SCALA_VERSION=${1} SCALA_DEB="http://www.scala-lang.org/files/archive/scala-${SCALA_VERSION}.deb" #  Scala apt-get install -y wget &amp;&amp; \ wget -q ${SCALA_DEB} -O /tmp/scala.deb &amp;&amp; dpkg -i /tmp/scala.deb &amp;&amp; \ scala -version &amp;&amp; \ rm /tmp/scala.deb</span></span></code> </pre> <br><h4>  sbt.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   Sbt     SBT_VERSION=${1} SBT_DEB="http://dl.bintray.com/sbt/debian/sbt-${SBT_VERSION}.deb" #  Sbt apt-get install -y wget &amp;&amp; \ wget -q ${SBT_DEB} -O /tmp/sbt.deb &amp;&amp; dpkg -i /tmp/sbt.deb &amp;&amp; \ sbt sbtVersion &amp;&amp; \ rm /tmp/sbt.deb</span></span></code> </pre> <br>  Nous collectons l'image, √©tant dans le r√©pertoire racine du projet (voir. Structure des dossiers): <br><br><pre> <code class="bash hljs">your@pc$ docker build -f Dockerfile.2.12-1.3.1-9-7-builder -t entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-builder .</code> </pre> <br>  √Ä la fin de l'article, il y a des liens vers le r√©f√©rentiel avec tous ces fichiers. <br><br><a name="4"></a><h1>  4. Structure du projet </h1><br>  Apr√®s avoir termin√© la pr√©paration de l'assemblage du projet, faisons ce que vous avez d√©cid√© de consacrer du temps √† cet article. <br><br>  Le projet de notre microservice aura la structure suivante: <br><br><pre> <code class="plaintext hljs">\ | ----- dependencies | | ----- mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar | ----- models | | ----- resnet50_ssd_model-0000.params | | ----- resnet50_ssd_model-symbol.json | | ----- synset.txt | ----- project | | ----- build.properties | | ----- plugins.sbt | ----- src | | ----- main | | | ----- resources | | | | ----- cat_and_dog.jpg | | | ----- scala | | | | ----- simple.predictor | | | | ----- Config | | | | ----- Model | | | | ----- Server | | | | ----- Run | | ----- test | | | ----- scala | | | | ----- simple.predictor | | | | ----- ServerTest | ----- build.sbt | ----- Dockerfile</code> </pre> <br>  Il s'agit de la structure standard d'un projet Scala, √† l'exception des d√©pendances et des mod√®les de r√©pertoires. <br>  Le r√©pertoire des d√©pendances contient la biblioth√®que MXNet pour Scala.  Il peut √™tre obtenu de deux mani√®res: <br><br><ul><li>  construire MXNet sur la machine sur laquelle vous allez d√©velopper (notez que la biblioth√®que n'est pas multi-plateforme; si vous la construisez sur Linux, elle ne fonctionnera pas sur Mac OS), </li><li>  ou retirez-le de l'image Docker que nous avons cr√©√©e plus t√¥t.  Si vous d√©cidez de cr√©er MXNet dans un environnement local, le script mxnet_2.12.sh vous aidera. </li></ul><br>  Vous pouvez extraire des biblioth√®ques de l'image Docker comme ceci: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   your@pc$ mkdir dependencies #  Docker-    your@pc$ docker run -it --rm -v $(pwd)/dependencies:/tmp/dependencies entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #          ab38e73d93@root$ cp /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar /tmp/dependencies/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar ab38e73d93@root$ exit #  , ! your@pc$ ls dependencies/ mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar</span></span></code> </pre> <br>  Le r√©pertoire des mod√®les contient les fichiers d'un r√©seau neuronal form√©, vous pouvez les t√©l√©charger librement comme suit: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   your@pc$ mkdir models #     your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/resnet50_ssd_model-symbol.json -P models your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/resnet50_ssd_model-0000.params -P models your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/synset.txt -P models</span></span></code> </pre> <br>  Plus bri√®vement sur les fichiers qui ne pr√©sentent pas d'int√©r√™t particulier, mais qui jouent un r√¥le dans le projet. <br><br><h4>  project / build.properties </h4><br><pre> <code class="scala hljs">#   <span class="hljs-type"><span class="hljs-type">Sbt</span></span>,   sbt.version = <span class="hljs-number"><span class="hljs-number">1.2</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span></code> </pre> <br><h4>  project / plugins.sbt </h4><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//    sbt-pack addSbtPlugin("org.xerial.sbt" % "sbt-pack" % "0.12")</span></span></code> </pre> <br><h4>  src / main / resources / cat_and_dog.jpg </h4><br>  Une si belle image, dans laquelle notre r√©seau de neurones recherchera un chat et un chien. <br><img src="https://habrastorage.org/getpro/habr/post_images/b6b/8ed/425/b6b8ed425ab6affb5cce1e83731b35a9.png"><br><br><h4>  build.sbt </h4><br><pre> <code class="scala hljs">enablePlugins(<span class="hljs-type"><span class="hljs-type">PackPlugin</span></span>) name := <span class="hljs-string"><span class="hljs-string">"simple-predictor"</span></span> version := <span class="hljs-string"><span class="hljs-string">"0.1"</span></span> scalaVersion := <span class="hljs-string"><span class="hljs-string">"2.12.7"</span></span> unmanagedBase := baseDirectory.value / <span class="hljs-string"><span class="hljs-string">"dependencies"</span></span> <span class="hljs-comment"><span class="hljs-comment">//  (   ) libraryDependencies ++= Seq( "org.json4s" %% "json4s-native" % "3.6.1", "org.scalatest" %% "scalatest" % "3.0.5" % Test, "org.scalaj" %% "scalaj-http" % "2.4.1" % Test ) //       packMain := Map("simple-predictor" -&gt; "simple.predictor.Runs") //    bat-,      ,   Linux packGenerateWindowsBatFile := false //    JVM packJvmOpts := Map("simple-predictor" -&gt; Seq( "-Xms3g", "-Xmx5g"))</span></span></code> </pre> <br><h4>  simple.predictor.Config </h4><br>  Cet objet stocke des variables globales dont la valeur est lue √† partir des variables d'environnement ou d√©finie par d√©faut. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.<span class="hljs-type"><span class="hljs-type">Context</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.util.<span class="hljs-type"><span class="hljs-type">Try</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">object</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Config</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//    REST API val host: String = env("REST_HOST") getOrElse "0.0.0.0" //    REST API val port: Int = env("REST_PORT") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 8080 // URL,     POST-   val entryPoint: String = env("REST_ENTRY_POINT") getOrElse "/predict" //  ,       val threshold: Float = env("PROBABILITY_MORE") flatMap (p =&gt; Try(p.toFloat).toOption) getOrElse 0.5f //        val modelPrefix: String = env("MODEL_PREFIX") getOrElse "models/resnet50_ssd_model" //    (    ...-0000.params) val modemEpoch: Int = env("MODEL_EPOCH") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 0 //   ,     ,    512 val modemEdge: Int = env("MODEL_EDGE") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 512 //  ,   CPU ( ).  production  GPU val context: Context = env("MODEL_CONTEXT_GPU") flatMap { isGpu =&gt; Try(if (isGpu.toBoolean) Context.gpu() else Context.cpu()).toOption } getOrElse Context.cpu() private def env(name: String) = Option(System.getenv(name)) }</span></span></code> </pre> <br><h4>  simple.predictor.Run </h4><br>  L'objet Run est le point d'entr√©e de l'application. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-comment"><span class="hljs-comment">//     import simple.predictor.Config._ object Run extends App { //     REST- val model = new Model(modelPrefix, modemEpoch, modemEdge, threshold, context) val server = new Server(new InetSocketAddress(host, port), entryPoint, model) //   Ctrl + C    Runtime.getRuntime.addShutdownHook(new Thread(() =&gt; server.stop())) //      try server.start() catch { case ex: Exception =&gt; ex.printStackTrace() } }</span></span></code> </pre> <br><a name="5"></a><h1>  5. Chargement du r√©seau neuronal </h1><br>  Le r√©seau neuronal est charg√© dans le constructeur de la classe <code>simple.predictor.Model</code> . <br><br><h4>  simple.predictor.Model </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.image.<span class="hljs-type"><span class="hljs-type">BufferedImage</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.infer.<span class="hljs-type"><span class="hljs-type">ObjectDetector</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Model</span></span>.<span class="hljs-type"><span class="hljs-type">Prediction</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Model</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">prefix: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, epoch: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-class"><span class="hljs-params">, imageEdge: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-class"><span class="hljs-params">, threshold: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">, context: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Context</span></span></span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//       val initShape = Shape(1, 3, imageEdge, imageEdge) val initData = DataDesc(name = "data", initShape, DType.Float32, Layout.NCHW) //           val model = new ObjectDetector(prefix, IndexedSeq(initData), context, Option(epoch)) //         ,       JSON private def toPrediction(originWidth: Int, originHeight: Int)(predict: (String, Array[Float])): Prediction = { val (objectClass, Array(probability, kx, ky, kw, kh)) = predict //        val x = (originWidth * kx).toInt val y = (originHeight * ky).toInt val w = (originWidth * kw).toInt val h = (originHeight * kh).toInt val width = if ((x + w) &lt; originWidth) w else originWidth - x val height = if (y + h &lt; originHeight) h else originHeight - y Prediction(objectClass, probability, x, y, width, height) } //     ,         ,     threshold def predict(image: BufferedImage): Seq[Prediction] = model.imageObjectDetect(image).head map toPrediction(image.getWidth, image.getHeight) filter (_.probability &gt; threshold) } object Model { //   case class Prediction(objectClass: String, probability: Float, x: Int, y: Int, width: Int, height: Int) }</span></span></code> </pre> <br>  Dans la section <code>     </code> vous dites que dans un r√©seau de neurones, cela fonctionnera avec <code>NDArray</code> avec une dimension de 1 x 3 x 512 x 512, o√π 1 est le nombre d'images qui seront contenues dans NDArray, 3 est le nombre de couleurs et 512 x 512 - la taille de l'image (la valeur de <code>imageEdge = 12</code> est d√©finie dans l'objet <code>simple.predict.Config</code> , c'est la taille lat√©rale de l'image utilis√©e pour entra√Æner le r√©seau neuronal).  Toutes ces descriptions de donn√©es sont transmises √† l' <code>ObjectDetector</code> . <br><br>  Une autre section int√©ressante est le <code>      </code> . <br><br>  Apr√®s avoir ex√©cut√© l'image √† travers le r√©seau neuronal, le r√©sultat est du type <code>Seq[Seq[(String, Array[Float])]]</code> .  La premi√®re collection ne contient qu'un seul r√©sultat (le format des donn√©es est d√©termin√© par un r√©seau neuronal sp√©cifique), puis chaque √©l√©ment de la collection suivante est un tuple de deux √©l√©ments: <br><br><ol><li>  nom de classe ("chat", "chien", ...), </li><li>  un tableau de cinq nombres √† virgule flottante: le premier est la probabilit√©, le second est le coefficient pour calculer la coordonn√©e <code>x</code> , le troisi√®me est le coefficient pour calculer la coordonn√©e <code>y</code> , le quatri√®me est le coefficient pour calculer la largeur du rectangle, et le cinqui√®me est le coefficient pour calculer la hauteur du rectangle. </li></ol><br>  Pour obtenir les valeurs r√©elles des coordonn√©es et des dimensions du rectangle, vous devez multiplier la largeur et la hauteur d'origine de l'image par les coefficients correspondants. <br>  Je me permets une petite digression sur le sujet de <code>NDArray</code> .  Il s'agit d'un tableau multidimensionnel que MXNet cr√©e dans un contexte donn√© (CPU ou GPU).  Lors de la cr√©ation d'un NDArray, un objet C ++ est form√©, un objet avec lequel les op√©rations sont effectu√©es tr√®s rapidement (et s'il est cr√©√© dans un contexte GPU, il est presque instantan√©), mais vous devez payer pour une telle vitesse.  Par cons√©quent (au moins dans la version MXNet 1.3.1), vous devez g√©rer ind√©pendamment la m√©moire allou√©e √† <code>NDArray</code> , et n'oubliez pas de d√©charger ces objets de la m√©moire apr√®s avoir fini de travailler avec eux.  Sinon, il y aura une fuite de m√©moire importante et assez rapide, ce qui n'est pas tr√®s pratique √† surveiller, car les programmes de profilage JVM ne le voient pas.  Le probl√®me de m√©moire est aggrav√© si vous travaillez dans un contexte GPU, car les cartes vid√©o n'ont pas une grande quantit√© de m√©moire et l'application se bloque rapidement en m√©moire. <br><br>  Comment r√©soudre un probl√®me de fuite de m√©moire? <br><br>  Dans l'exemple ci-dessus, dans la ligne <code>model.imageObjectDetect(image).head map toPrediction(image.getWidth, image.getHeight) filter (_.probability &gt; threshold)</code> , la m√©thode <code>imageObjectDetect</code> est utilis√©e pour ex√©cuter l'image via le r√©seau de neurones, qui re√ßoit une entr√©e <code>BufferedImage</code> .  Toutes les conversions vers et depuis <code>NDArray</code> sont effectu√©es √† l'int√©rieur de la m√©thode, et vous n'avez pas besoin de penser aux probl√®mes de d√©sallocation de m√©moire.  D'un autre c√¥t√©, avant de convertir <code>BufferedImage</code> en <code>NDArray</code> est effectu√© √† une taille de 512 x 512 et l'image est normalis√©e √† l'aide des m√©thodes d'un objet de type <code>BufferedImage</code> .  Cela se produit un peu plus longtemps que lors de l'utilisation d'OpenCV, par exemple, mais cela r√©sout le probl√®me de la lib√©ration de m√©moire apr√®s l'utilisation de <code>NDArray</code> . <br><br>  Vous pouvez, bien s√ªr, utiliser OpenCV et contr√¥ler la m√©moire vous-m√™me, pour cela, il vous suffit d'appeler la m√©thode d' <code>dispose</code> de <code>dispose</code> , mais pour une raison quelconque, vous avez oubli√© de le mentionner dans la documentation MXNet officielle de Scala. <br><br>  MXNet a √©galement un moyen peu pratique de contr√¥ler la fuite de m√©moire qui se produit en raison de <code>NDArray</code> .  Pour ce faire, ex√©cutez l'application avec le param√®tre JVM <code>Dmxnet.traceLeakedObjects=true</code> .  Si MXNet remarque un <code>NDArray</code> qui n'est pas utilis√© mais se bloque en m√©moire, vous obtiendrez une exception indiquant dans quelle ligne de code le <code>NDArray</code> malheureux <code>NDArray</code> . <br><br>  Mon conseil: travaillez directement avec NDArray, surveillez attentivement la m√©moire et √©crivez vous-m√™me la normalisation, apr√®s avoir sp√©cifi√© quel algorithme l'ing√©nieur ML a fait lors de la formation d'un r√©seau de neurones, sinon les r√©sultats seront compl√®tement diff√©rents.  <code>ObjectDetector</code> poss√®de une m√©thode <code>objectDetectWithNDArray</code> √† laquelle vous pouvez passer un <code>NDArray</code> .  Pour impl√©menter une approche plus universelle du chargement d'un r√©seau de neurones, je recommande d'utiliser l'objet <code>org.apache.mxnet.module.Module</code> .  Voici un exemple d'utilisation. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.io.<span class="hljs-type"><span class="hljs-type">NDArrayIter</span></span> <span class="hljs-comment"><span class="hljs-comment">//      val model: Module = { val model = Module.loadCheckpoint(modelPrefix, modelEpoch, contexts = contexts) model.bind( forTraining = false, inputsNeedGrad = false, forceRebind = false, dataShape = DataDesc(name = "data", Shape(1, 3, 512, 512), DType.Float32, Layout.NCHW)) model.initParams() model } // NDArray  1  3  512  512 val image: NDArray = ??? //  dataBatch      val iterator = new NDArrayIter(IndexedSeq(image)) val dataBatch = iterator.next() image.dispose() //   val result: Seq[Array[Float]] = model.predict(dataBatch) map { ndArray =&gt; val array = ndArray.toArray ndArray.dispose() array } dataBatch.dispose()</span></span></code> </pre> <br><a name="6"></a><h1>  6. Impl√©mentation de l'API REST </h1><br>  La classe <code>simple.predictor.Server</code> est responsable de l'impl√©mentation de l'API REST.  Le serveur est bas√© sur le serveur Java inclus dans Java. <br><br><h4>  simple.predictor.Server </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.sun.net.httpserver.{<span class="hljs-type"><span class="hljs-type">HttpExchange</span></span>, <span class="hljs-type"><span class="hljs-type">HttpServer</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.imageio.<span class="hljs-type"><span class="hljs-type">ImageIO</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.<span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.native.<span class="hljs-type"><span class="hljs-type">Serialization</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Server</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">address: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">InetSocketAddress</span></span></span></span><span class="hljs-class"><span class="hljs-params">, entryPoint: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, model: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Model</span></span></span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//   HTTP-,     java private val server = HttpServer.create(address, 0) //      URL server.createContext(entryPoint, (http: HttpExchange) =&gt; { //   HTTP-     val header = http.getRequestHeaders val (httpCode, json) = if (header.containsKey("Content-Type") &amp;&amp; header.getFirst("Content-Type") == "image/jpeg") { //          ,      200 val image = ImageIO.read(http.getRequestBody) val predictionSeq = model.predict(image) (200, Map("prediction" -&gt; predictionSeq)) } else (400, Map("error" -&gt; "Invalid content")) //       400 //    JSON    val responseJson = Serialization.write(json)(DefaultFormats) val httpOs = http.getResponseBody http.getResponseHeaders.set("Content-Type", "application/json") http.sendResponseHeaders(httpCode, responseJson.length) httpOs.write(responseJson.getBytes) httpOs.close() }) def start(): Unit = server.start() def stop(): Unit = server.stop(0) }</span></span></code> </pre> <br><a name="7"></a><h1>  7. Test </h1><br>  Pour v√©rifier, d√©marrez le serveur et envoyez une image de test src / main / resources / cat_and_dog.jpg.  Nous analyserons le JSON re√ßu du serveur, v√©rifierons combien et quels objets le r√©seau neuronal a trouv√©s dans l'image et encerclons les objets dans l'image. <br><br><h4>  simple.predictor.ServerTest </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.{<span class="hljs-type"><span class="hljs-type">BasicStroke</span></span>, <span class="hljs-type"><span class="hljs-type">Color</span></span>, <span class="hljs-type"><span class="hljs-type">Font</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.image.<span class="hljs-type"><span class="hljs-type">BufferedImage</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.{<span class="hljs-type"><span class="hljs-type">ByteArrayOutputStream</span></span>, <span class="hljs-type"><span class="hljs-type">File</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.imageio.<span class="hljs-type"><span class="hljs-type">ImageIO</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.scalatest.{<span class="hljs-type"><span class="hljs-type">FlatSpec</span></span>, <span class="hljs-type"><span class="hljs-type">Matchers</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scalaj.http.<span class="hljs-type"><span class="hljs-type">Http</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.{<span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span>, <span class="hljs-type"><span class="hljs-type">Formats</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.native.<span class="hljs-type"><span class="hljs-type">JsonMethods</span></span>.parse <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Config</span></span>._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Model</span></span>.<span class="hljs-type"><span class="hljs-type">Prediction</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.concurrent.<span class="hljs-type"><span class="hljs-type">Future</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.concurrent.<span class="hljs-type"><span class="hljs-type">ExecutionContext</span></span>.<span class="hljs-type"><span class="hljs-type">Implicits</span></span>.global <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ServerTest</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FlatSpec</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Matchers</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">implicit</span></span> <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> formats: <span class="hljs-type"><span class="hljs-type">Formats</span></span> = <span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span> <span class="hljs-string"><span class="hljs-string">"Service"</span></span> should <span class="hljs-string"><span class="hljs-string">"find a cat and a dog on photo"</span></span> in { <span class="hljs-comment"><span class="hljs-comment">//      val model = new Model(modelPrefix, modemEpoch, modemEdge, threshold, context) val server = new Server(new InetSocketAddress(host, port), entryPoint, model) //      Future(server.start()) Thread.sleep(5000) //         val image = ImageIO.read(getClass.getResourceAsStream("/cat_and_dog.jpg")) val byteOS = new ByteArrayOutputStream() ImageIO.write(image, "jpg", byteOS) val data = byteOS.toByteArray //      ,     200 val response = Http(s"http://$host:$port$entryPoint").header("Content-Type", "image/jpeg").postData(data).asString response.code shouldEqual 200 //  JSON-, ,       val prediction = parse(response.body) \\ "prediction" prediction.children.size shouldEqual 2 //     , ,     ,    val objectClassList = (prediction \\ "objectClass").children map (_.extract[String]) objectClassList.head shouldEqual "cat" objectClassList.tail.head shouldEqual "dog" //   ,   val bBoxCoordinates = prediction.children.map(_.extract[Prediction]) //   ,     val imageWithBoundaryBoxes = new BufferedImage(image.getWidth, image.getHeight, image.getType) val graph = imageWithBoundaryBoxes.createGraphics() graph.drawImage(image, 0, 0, null) graph.setColor(Color.RED) graph.setStroke(new BasicStroke(5)) graph.setFont(new Font(Font.SANS_SERIF, Font.TRUETYPE_FONT, 30)) bBoxCoordinates foreach { case Prediction(obj, prob, x, y, width, height) =&gt; graph.drawRect(x, y, width, height) graph.drawString(s"$obj, prob: $prob", x + 15, y + 30) } graph.dispose() //         ImageIO.write(imageWithBoundaryBoxes, "jpg", new File("./test.jpg")) } }</span></span></code> </pre> <br>     ,       . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ea2/454/57d/ea245457d175d072a8eb8c98ef4551ce.png"><br><br><a name="8"></a><h1> 8.       </h1><br>  ,      .     Docker   ,    . <br><br><h4> Dockerfile </h4><br><pre> <code class="plaintext hljs">#       Sbt FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-builder AS builder #       RUN mkdir /tmp/source /tmp/source/dependencies COPY project /tmp/source/project COPY src /tmp/source/src COPY build.sbt /tmp/source/build.sbt #     MXNet,       RUN ln -s /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar /tmp/source/dependencies/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar &amp;&amp; \ cd /tmp/source/ &amp;&amp; sbt pack #      FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #   LD   Cuda   Java ENV LD_LIBRARY_PATH /usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs:/usr/local/share/OpenCV/java #            /opt/app/models ENV MODEL_PREFIX "/opt/app/models/resnet50_ssd_model" #            RUN mkdir -p /opt/app COPY --from=builder --chown=root:root /tmp/source/target/pack /opt/app COPY models /opt/app/models #      ENTRYPOINT /opt/app/bin/simple-predictor</code> </pre> <br>         <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ,    ,   Dockerfile your@pc$ docker build -f Dockerfile -t entony/simple-predictor:1.0.0 . #   docker hub your@pc$ docker push entony/simple-predictor:1.0.0</span></span></code> </pre> <br><a name="9"></a><h1> 9.    production-  GPU </h1><br> ,      docker hub,      Nvidia,  8080    Docker, Cuda 9.0  Cudnn 7. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#     Docker hub your@server-with-gpu$ docker pull entony/simple-predictor:1.0.0 #     your@server-with-gpu$ docker run -d \ -p 8080:8080 \ -e MODEL_CONTEXT_GPU=true \ -e MXNET_CUDNN_AUTOTUNE_DEFAULT=0 \ --name 'simple_predictor' \ --device /dev/nvidia0:/dev/nvidia0 \ --device /dev/nvidiactl:/dev/nvidiactl \ --device /dev/nvidia-uvm:/dev/nvidia-uvm \ -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs/libcuda.so.1:ro \ -v /usr/lib/nvidia-396/libnvidia-fatbinaryloader.so.396.54:/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs/libnvidia-fatbinaryloader.so.396.54:ro \ entony/simple-predictor:1.0.0</span></span></code> </pre> <br>         Docker-   <code>--device</code>   Cuda-   <code>-v</code> . <br><br>   <code>MODEL_CONTEXT_GPU</code>     GPU-,  <code>MXNET_CUDNN_AUTOTUNE_DEFAULT</code>          (  ,      ,     ,  ). <br><br>      : <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#  your@server-with-gpu$ curl -X POST -H 'Content-Type: image/jpeg' --data-binary '@src/main/resources/cat_and_dog.jpg' http://0.0.0.0:8080/predict #  { "prediction":[ { "objectClass":"cat", "probability":0.9959417, "x":72,"y":439, "width":950, "height":987 }, { "objectClass":"dog", "probability":0.81277525, "x":966, "y":100, "width":870, "height":1326 } ] }</span></span></code> </pre> <br><a name="10"></a><h1>  Conclusion </h1><br> MXNet   ,    -    .  ,    ,   ,     production. <br><br>   , ,   MXNet    ,      Python      production  Scala, Java  ++. <br><br>        ,                   . <br><br> ,        .          .  Merci de votre attention. <br><br><a name="11"></a><h1>  Les r√©f√©rences </h1><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Git   Docker-</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Git    </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">     MXNet</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439226/">https://habr.com/ru/post/fr439226/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439216/index.html">pudge 500 ligne de base de donn√©es int√©grable sur Golang</a></li>
<li><a href="../fr439218/index.html">VK bot sur son genou, ou comment faire plaisir aux gens le 14 f√©vrier</a></li>
<li><a href="../fr439220/index.html">Grande ville pour les appareils mobiles sur Unity. Exp√©rience en d√©veloppement et optimisation</a></li>
<li><a href="../fr439222/index.html">Qu'est-ce que la gestion des API?</a></li>
<li><a href="../fr439224/index.html">Encore une fois sur les diagrammes de Voronoi</a></li>
<li><a href="../fr439232/index.html">JAMstack: Comment cr√©er votre propre blog en utilisant Gatsby + Contentful + Netlify</a></li>
<li><a href="../fr439234/index.html">La vie du d√©veloppeur Open Source dans les GIF</a></li>
<li><a href="../fr439236/index.html">xenvman: environnements de test de microservices flexibles (et plus)</a></li>
<li><a href="../fr439238/index.html">Play Store accepte d√©sormais les applications Web progressives (PWA)</a></li>
<li><a href="../fr439240/index.html">Joomla Digest pour janvier 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
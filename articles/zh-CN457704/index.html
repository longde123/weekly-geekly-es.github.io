<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💮 🧑🏿‍🤝‍🧑🏿 🤽🏽 GPU如何处理分支 ♓️ 🛅 🌵</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="关于文章 
 对于那些想了解有关GPU如何处理分支的更多信息的程序员来说，这篇文章是简短的说明。 您可以将其视为本主题的介绍。 我建议以[ 1 ]，[ 2 ]和[ 8 ]开头，以大致了解GPU执行模型的外观，因为我们将仅考虑一个单独的细节。 对于好奇的读者，文章末尾有所有链接。 如果发现错误，请与我...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>GPU如何处理分支</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457704/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png" alt="图片"></div><br><h2> 关于文章 </h2><br> 对于那些想了解有关GPU如何处理分支的更多信息的程序员来说，这篇文章是简短的说明。 您可以将其视为本主题的介绍。 我建议以[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">1</a> ]，[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">2</a> ]和[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">8</a> ]开头，以大致了解GPU执行模型的外观，因为我们将仅考虑一个单独的细节。 对于好奇的读者，文章末尾有所有链接。 如果发现错误，请与我联系。 <br><br><h2> 目录内容 </h2><br><ul><li> 关于文章 </li><li> 目录内容 </li><li> 词汇量 </li><li>  GPU核心与CPU核心有何不同？ </li><li> 什么是一致性/差异？ </li><li> 执行蒙版处理示例 <ul><li> 虚构ISA </li><li>  AMD GCN ISA </li><li>  AVX512 </li></ul></li><li> 如何处理差异？ </li><li> 参考文献 </li></ul><a name="habracut"></a><br><h2> 词汇量 </h2><br><ul><li>  GPU-图形处理单元，GPU </li><li> 弗林的分类 <br><ul><li>  SIMD-单指令多数据，单指令流，多数据流 </li><li>  SIMT-单指令多线程，单指令流，多线程 </li></ul></li><li>  Wave（SIM）-以SIMD模式执行的流 </li><li> 行（车道）-SIMD模型中的单独数据流 </li><li>  SMT-同步多线程，同时多线程（英特尔超线程）[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">2</a> ] <br><ul><li> 多线程共享核心计算资源 </li></ul></li><li>  IMT-交错多线程，交替多线程[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">2</a> ] <br><ul><li> 多个线程共享内核的全部计算资源，但只有一个 </li></ul></li><li>  BB-基本块，基本块-线性指令序列，最后单跳 </li><li>  ILP-指令级并行性，指令级的并行性[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">3</a> ] </li><li>  ISA-指令集架构，指令集架构 </li></ul><br> 在我的帖子中，我将坚持这种发明的分类。 它大致类似于现代GPU的组织方式。 <br><br><blockquote><code>: <br> GPU -+ <br> |-  0 -+ <br> | |-  0 + <br> | | |-  0 <br> | | |-  1 <br> | | |- ... <br> | | +-  Q-1 <br> | | <br> | |- ... <br> | +-  M-1 <br> | <br> |- ... <br> +-  N-1 <br> <br> *  -  SIMD <br> <br>  : <br>  + <br> |-  0 <br> |- ... <br> +-  N-1</code> </blockquote> <br> 其他名称： <br><br><ul><li> 核心可能称为CU，SM，EU </li><li> 波形可以称为波前，硬件线程（硬件线程），扭曲，上下文 </li><li> 一行可以称为程序线程（SW线程） </li></ul><br><h2>  GPU核心与CPU核心有何不同？ </h2><br> 当前任何一代的GPU内核都没有中央处理器强大：简单的ILP /多问题[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">6</a> ]和预取[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">5</a> ]，没有对过渡/返回的预测或预测。 所有这些以及微小的缓存释放了芯片上相当大的区域，其中充满了许多内核。 内存加载/存储机制能够处理通道宽度比常规CPU大一个数量级（这不适用于集成/移动GPU），但是您必须为此付出高昂的等待时间。 为了隐藏延迟，GPU使用了SMT [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">2</a> ]-一波空闲时，另一波则使用内核的免费计算资源。 通常，一个内核处理的波数取决于所使用的寄存器，并通过分配固定的寄存器文件来动态确定[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">8</a> ]。 计划执行指令是混合的-动态静态[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">6</a> ] [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">11</a> 4.4]。 在SIMD模式下执行的SMT内核实现了较高的FLOPS值（每秒浮点操作数，触发器，每秒浮点操作数）。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb8/059/770/fb8059770b3653b65c5e2cc30f5fee16.png" alt="图1"><br><br>  <i>图例图。</i>  <i>黑色-不活动，白色-活动，灰色-关，蓝色-空闲，红色-待处理</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/12e/fc7/5d9/12efc75d90a064410b1632c2be710235.png"></div><br>  <i>图1. 4：2执行历史</i> <br><br> 该图显示了执行掩码的历史记录，其中x轴表示从左到右的时间，y轴表示从上到下的行的标识符。 如果您仍然不明白这一点，请在阅读以下各节后返回到图纸。 <br><br> 这说明了虚拟配置中GPU内核执行历史的样子：四个波形共享一个采样器和两个ALU。 每个周期中的波形计划器都会从两个波形中发出两个指令。 当一个波在执行对存储器的访问或长时间的ALU操作时处于空闲状态时，调度程序将切换到另一对波，因此ALU几乎始终被100％占用。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/433/54a/ea2/43354aea2bb0a351048a196808d6a06a.png"></div><br>  <i>图2. 4：1执行历史</i> <br><br> 一个具有相同负载的示例，但是这次在指令的每个周期中只有一个波动发出。 请注意，第二个ALU挨饿了。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png"></div><br>  <i>图3.执行历史4：4</i> <br><br> 这次，每个周期发出四个指令。 请注意，对ALU的请求太多，因此几乎总是有两个波浪在等待（实际上，这是规划算法的错误）。 <br><br>  <strong><em>更新</em></strong>有关计划执行指令难度的更多信息，请参见[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">12</a> ]。 <br><br> 在现实世界中，GPU具有不同的内核配置：有些GPU的每个内核最多可以包含40个波形和4个ALU，而另一些则具有7个固定波形和2个ALU。 所有这一切都取决于许多因素，并且要归功于架构仿真的艰苦过程。 <br><br> 另外，实际的SIMD ALU的宽度可能比它们所服务的波窄，因此处理一个发出的指令要花费几个周期。 该因素称为长度“钟声” [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">3</a> ]。 <br><br><h2> 什么是一致性/差异？ </h2><br> 让我们看一下以下代码片段： <br><br><h6> 例子1 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &amp; <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } // Do some more</span></span></code> </pre> <br> 在这里，我们看到了一条指令流，其中的执行路径取决于正在执行的行的标识符。 显然，不同的行具有不同的含义。 会发生什么？ 解决这个问题有不同的方法[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">4</a> ]，但最终它们都做同一件事。 一种方法是执行掩码，我将介绍它。 在Volta之前的Nvidia GPU和AMD GCN GPU中都使用了这种方法。 执行掩码的要点是我们为wave中的每一行存储一个位。 如果相应的行执行位为0，则下一条指令的发布将不影响任何寄存器。 实际上，该行不应感觉到整个已执行指令的影响，因为其执行位为0。其工作方式如下：该波按深度搜索顺序在控制流程图中传播，保存选定转换的历史，直到设置了这些位为止。 我认为最好以身作则。 <br><br> 假设我们有一个宽度为8的波。这是代码片段的执行掩码： <br><br><h6> 示例1.执行掩码的历史记录 </h6><br><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">// execution mask uint lane_id = get_lane_id(); // 11111111 if (lane_id &amp; 1) { // 11111111 // Do smth // 01010101 } // Do some more // 11111111</span></span></code> </pre> <br> 现在考虑更复杂的示例： <br><br><h6> 例子2 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (uint i = lane_id; i &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; i++) { <span class="hljs-comment"><span class="hljs-comment">// Do smth }</span></span></code> </pre> <br><h6> 例子3 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } else { // Do smth else }</span></span></code> </pre> <br> 您可能会注意到历史记录是必要的。 当使用执行屏蔽方法时，设备通常使用某种堆栈。 天真的方法是存储一个元组堆栈（exec_mask，地址），并添加收敛指令，这些指令从堆栈中检索掩码并更改wave的指令指针。 在这种情况下，电波将具有足够的信息来绕过每条线的整个CFG。 <br><br> 在性能方面，由于所有这些数据存储，只需要几个循环即可处理控制流指令。 并且不要忘记堆栈的深度有限。 <br><br>  <strong><em>更新。</em></strong> 感谢<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">@craigkolb，</a>我读了一篇文章[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">13</a> ]，该文章指出AMD GCN fork / join指令首先从更少的线程中选择路径[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">11</a> 4.6]，这保证了掩码堆栈的深度等于log2。 <br><br>  <strong><em>更新。</em></strong> 显然，几乎总是可以将所有内容嵌入到着色器中的着色器/结构CFG中，并因此将执行掩码的整个历史记录存储在寄存器中，并计划静态旁路/会聚CFG [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">15</a> ]。 在查看了AMDGPU的LLVM后端后，我没有发现编译器不断发出的栈处理证据。 <br><br><h3> 运行时掩码硬件支持 </h3><br> 现在看一下Wikipedia中的这些控制流程图： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5f9/f04/a1a/5f9f04a1a89b36ad0908dee0e90542f3.png"></div><br>  <i>图4.一些类型的控制流程图</i> <br><br> 我们需要处理所有情况的最少掩码控制指令集是什么？ 这是在具有隐式并行化，显式掩码控制和数据冲突的完全动态同步的人工ISA中的外观： <br><br><pre> <code class="cpp hljs">push_mask BRANCH_END ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> reconvergence pointer pop_mask ; Pop mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> jump to reconvergence instruction mask_nz r0.x ; Set execution bit, pop mask <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> all bits are zero ; Branch instruction is more complicated ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> reconvergence ; <span class="hljs-function"><span class="hljs-function">Push mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">for</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x == </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">for</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> block, </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">if</span></span></span><span class="hljs-function"> any lane takes the path </span></span>; <span class="hljs-function"><span class="hljs-function">Set mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">with</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x != </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">, fallback to </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> in </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">case</span></span></span><span class="hljs-function"> no bit is 1 br_push r0.x, ELSE, CONVERGE</span></span></code> </pre> <br> 让我们看一下情况d）。 <br><br><pre> <code class="cpp hljs">A: br_push r0.x, C, D B: C: mask_nz r0.y jmp B D: ret</code> </pre> <br> 我不是控制流分析或ISA设计方面的专家，因此我确信在某些情况下我的人工ISA无法应对，但这并不重要，因为结构化CFG对每个人都足够。 <br><br>  <strong><em>更新。</em></strong> 在此处[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">11</a> ] ch.4阅读有关GCN支持控制流指令的更多信息，并在此处[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">15</a> ]阅读有关LLVM实现的更多信息。 <br><br> 结论： <br><br><ul><li> 发散-同一波的不同线选择的路径中的结果差异 </li><li> 一致性-无差异。 </li></ul><br><h2> 执行蒙版处理示例 </h2><br><h3> 虚构ISA </h3><br> 我在人工ISA中编译了先前的代码段，并在SIMD32中的模拟器上运行了它们。 查看它如何处理执行掩码。 <br><br>  <strong><em>更新。</em></strong> 请注意，人工模拟器始终会选择真实的路径，但这不是最佳方法。 <br><br><h6> 例子1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; if (lane_id &amp; 1) { push_mask BRANCH_END and r0.y, r0.x, u(1) mask_nz r0.y LOOP_BEGIN: ; // Do smth pop_mask ; pop mask and reconverge BRANCH_END: ; // Do some more ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/d40/30c/fdb/d4030cfdb754b9a663c03ae46b31efc7.png" alt="图5"><br><br>  <i>图5.示例1的历史</i> <br><br> 您注意到黑色区域了吗？ 这次浪费了。 有些行等待其他人完成迭代。 <br><br><h6> 例子2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; for (uint i = lane_id; i &lt; 16; i++) { push_mask LOOP_END ; Push the current mask and the pointer to reconvergence instruction LOOP_PROLOG: lt.u32 r0.y, r0.x, u(16) ; r0.y &lt;- r0.x &lt; 16 add.u32 r0.x, r0.x, u(1) ; r0.x &lt;- r0.x + 1 mask_nz r0.y ; exec bit &lt;- r0.y != 0 - when all bits are zero next mask is popped LOOP_BEGIN: ; // Do smth jmp LOOP_PROLOG LOOP_END: ; // } ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/fe3/259/b17/fe3259b179e832553900c7cb22487e03.png" alt="图6"><br><br>  <i>图6.示例2的历史</i> <br><br><h6> 例子3 </h6><br><pre> <code class="lisp hljs"> mov r0.x, lane_id lt.u32 r0.y, r0.x, u(<span class="hljs-number"><span class="hljs-number">16</span></span>) <span class="hljs-comment"><span class="hljs-comment">; if (lane_id &lt; 16) { ; Push (current mask, CONVERGE) and (else mask, ELSE) ; Also set current execution bit to r0.y != 0 br_push r0.y, ELSE, CONVERGE THEN: ; // Do smth pop_mask ; } else { ELSE: ; // Do smth else pop_mask ; } CONVERGE: ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/27e/d1b/2a9/27ed1b2a99db4ab917d661946ed7c705.png" alt="图7"><br><br>  <i>图7.示例3的历史记录</i> <br><br><h3>  AMD GCN ISA </h3><br>  <strong><em>更新。</em></strong>  GCN还使用显式掩码处理，有关更多信息，请参见：[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">11</a> 4.x]。 我决定通过ISA显示一些示例，这要归功于<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">shader-playground，</a>这很容易做到。 也许有一天我会找到一个模拟器并设法获得图表。 <br><br> 请记住，编译器很聪明，因此您可以获得其他结果。 我试图欺骗编译器，以免通过放置指针循环然后清理汇编代码来优化我的分支； 我不是GCN专家，因此可能会忽略一些重要的知识。 <br><br> 还要注意，在这些片段中未使用S_CBRANCH_I / G_FORK和S_CBRANCH_JOIN指令，因为它们很简单并且编译器不支持它们。 因此，不幸的是，不可能考虑掩模的堆叠。 如果您知道如何使编译器对堆栈进行处理，请告诉我。 <br><br>  <strong><em>更新。</em></strong> 查看<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">@ SiNGUL4RiTY的</a>有关在AMD使用的LLVM后端中实现矢量化控制流的讨论。 <br><br><h6> 例子1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); ; GCN uses 64 wave width, so lane_id = thread_id &amp; 63 ; There are scalar s* and vector v* registers ; Executon mask does not affect scalar or branch instructions v_mov_b32 v1, 0x00000400 ; 1024 - group size v_mad_u32_u24 v0, s12, v1, v0 ; thread_id calculation v_and_b32 v1, 63, v0 ; if (lane_id &amp; 1) { v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask v_cmpx_ne_u32 exec, v2, 0 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ELSE: ; } ; // Do some more s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6> 例子2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s8, v1, v0 ; Not sure why s8 this time and not s12 v_and_b32 v1, 63, v0 ; LOOP PROLOG s_mov_b64 s[0:1], exec ; Save the execution mask v_mov_b32 v2, v1 v_cmp_le_u32 vcc, 16, v1 s_andn2_b64 exec, exec, vcc ; Set the execution bit s_cbranch_execz LOOP_END ; Jmp if all exec bits are zero ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth v_add_u32 v2, 1, v2 v_cmp_le_u32 vcc, 16, v2 s_andn2_b64 exec, exec, vcc ; Mask out lanes which are beyond loop limit s_cbranch_execnz LOOP_BEGIN ; Jmp if non zero exec mask LOOP_END: ; // } s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6> 例子3 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s12, v1, v0 v_and_b32 v1, 63, v0 v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask ; if (lane_id &lt; 16) { v_cmpx_lt_u32 exec, v1, 16 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ; } else { ELSE: s_andn2_b64 exec, s[0:1], exec ; Inverse the mask and &amp; with previous s_cbranch_execz CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: s_mov_b64 exec, s[0:1] ; Restore the execution mask ; // Do some more s_endpgm</span></span></code> </pre> <br><h3>  AVX512 </h3><br>  <strong><em>更新。</em></strong>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">@tom_forsyth</a>向我指出，AVX512扩展也具有显式的掩码处理，因此这里有一些示例。 可以在[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">14</a> ]，15.x和15.6.1中找到关于此的更多详细信息。 它不完全是GPU，但仍然具有32位的真实SIMD16。 代码片段是使用ISPC（–target = avx512knl-i32x16） <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Godbolt创建的</a> ，经过大量重新设计，因此可能并非100％正确。 <br><br><h6> 例子1 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; AVXZ512 comes with k0-k7 mask registers ; Usage: ; op reg1 {k[7:0]}, reg2, reg3 ; k0 can not be used as a predicate operand, only k1-k7 ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero ; // Do smth ; Now k1 contains the execution mask ; We can use it like this: ; vmovdqa32 zmm1 {k1}, zmm0 ELSE: ; } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6> 例子2 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids kmovw eax, k1 ; Save the execution mask vpcmpltud k1 {k1}, zmm0, 16 ; k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 je LOOP_END ; Jmp if all exec bits are zero vpternlogd zmm1 {k1}, zmm1, zmm1, 255 ; zmm1[i] = -1 ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth vpsubd zmm0 {k1}, zmm0, zmm1 ; zmm0[i] = zmm0[i] + 1 vpcmpltud k1 {k1}, zmm0, 16 ; masked k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 jne LOOP_BEGIN ; Break if all exec bits are zero LOOP_END: ; // } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6> 例子3 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero THEN: ; // Do smth ; } else { ELSE: kmovw ebx, k1 andn ebx, eax, ebx kmovw k1, ebx ; mask = ~mask &amp; old_mask kortestw k1, k1 je CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h2> 如何处理差异？ </h2><br> 我试图创建一个简单而完整的说明，说明合并分歧线会导致效率低下。 <br><br> 想象一下一段简单的代码： <br><br><pre> <code class="lisp hljs">uint thread_id = get_thread_id()<span class="hljs-comment"><span class="hljs-comment">; uint iter_count = memory[thread_id]; for (uint i = 0; i &lt; iter_count; i++) { // Do smth }</span></span></code> </pre> <br> 让我们创建256个线程并测量它们的执行时间： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7c2/2da/c5d/7c22dac5d75a77156a60c510a655309a.png"></div><br>  <i>图8.不同线程的持续时间</i> <br><br>  x轴是节目流的标识符，y轴是时钟周期。 与单线程执行相比，不同的列显示了在对具有不同波长的流进行分组时浪费了多少时间。 <br><br> 波形运行时间等于其中包含的行中的最大运行时间。 您会发现SIMD8的性能已经大大下降，进一步扩展只会使性能稍差一些。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a0d/c9a/be6/a0dc9abe6a7a0e12515d4c88c36aaa21.png" alt="图9"></div><br>  <i>图9.一致线程的运行时</i> <br><br> 该图中显示了相同的列，但是这次迭代次数是通过流标识符排序的，即，具有类似迭代次数的流被发送到单个wave。 <br><br> 对于此示例，执行速度可能会提高约一半。 <br><br> 当然，该示例太简单了，但我希望您理解这一点：执行中的差异源于数据的差异，因此CFG必须简单且数据一致。 <br><br> 例如，如果您正在编写光线跟踪器，则可以从具有相同方向和位置的光线分组中受益，因为它们很可能会穿过BVH中的相同节点。 有关更多详细信息，请参见[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">10</a> ]和其他相关文章。 <br><br> 还值得一提的是，有一些技术可以在硬件级别处理差异，例如，动态翘曲形成[ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">7</a> ]和小分支的预测执行。 <br><br><h1> 参考文献 </h1><br>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">图形管道之旅</a> <br><br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kayvon Fatahalian：并行计算</a> <br><br>  [3] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">计算机体系结构定量方法</a> <br><br>  [4] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">低成本的无堆栈SIMT融合</a> <br><br>  [5] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">通过微基准测试剖析GPU内存层次</a> <br><br>  [6] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">通过Microbenchmarking剖析NVIDIA Volta GPU架构</a> <br><br>  [7] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">动态扭曲变形和调度，以实现高效的GPU控制流程</a> <br><br>  [8] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Maurizio Cerrato：GPU架构</a> <br><br>  [9] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">玩具GPU模拟器</a> <br><br>  [10] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">减少GPU程序中的分支分歧</a> <br><br>  [11] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">“ Vega”指令集架构</a> <br><br>  [12] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Joshua Barczak：模拟GCN的着色器执行</a> <br><br>  [13] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">切向量：关于散度的离题</a> <br><br>  [14] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">英特尔64和IA-32架构软件开发人员手册</a> <br><br>  [15] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">针对SIMD应用矢量化发散控制流</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN457704/">https://habr.com/ru/post/zh-CN457704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN457694/index.html">使用多字符常量的危险</a></li>
<li><a href="../zh-CN457696/index.html">使用多字符常量的危险</a></li>
<li><a href="../zh-CN457698/index.html">实验：我们使用代理作为抵御DoS攻击的工具</a></li>
<li><a href="../zh-CN457700/index.html">Node.js身份验证指南，不包含password.js和第三方服务</a></li>
<li><a href="../zh-CN457702/index.html">使用KOMPAS-3D API→第16课→控制字符</a></li>
<li><a href="../zh-CN457706/index.html">机器人测试SAP ERP</a></li>
<li><a href="../zh-CN457710/index.html">神经网络的惊人功能2019</a></li>
<li><a href="../zh-CN457712/index.html">Verizon和BGP Optimizer如何离线设置</a></li>
<li><a href="../zh-CN457714/index.html">英语中的堆栈溢出：社区终止指南</a></li>
<li><a href="../zh-CN457718/index.html">HyperCard，Web演进中丢失的链接</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
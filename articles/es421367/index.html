<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì£ üéÖ üì∑ AI, curso pr√°ctico. Configurar el modelo y los hiperpar√°metros para reconocer las emociones en las im√°genes. ü•í üí¢ üé≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En los art√≠culos anteriores de esta serie de tutoriales, se describieron las posibles opciones para preparar datos : preprocesamiento y adici√≥n de dat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso pr√°ctico. Configurar el modelo y los hiperpar√°metros para reconocer las emociones en las im√°genes.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/421367/"><img src="https://habrastorage.org/webt/zq/7s/el/zq7selxswjsrmplg_pxw2xilqi4.jpeg"><br><br>  En los art√≠culos anteriores de esta serie de tutoriales, se describieron las posibles opciones para preparar datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">: preprocesamiento y adici√≥n de datos con im√°genes</a> ; en estos art√≠culos, tambi√©n se construy√≥ el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelo Base para reconocer las emociones</a> basadas en im√°genes de una red neuronal convolucional. <br>  En este art√≠culo, crearemos un modelo de red neuronal convolucional mejorado para reconocer las emociones en las im√°genes utilizando una t√©cnica llamada <i>aprendizaje inductivo</i> . <br><a name="habracut"></a><br>  Primero debe familiarizarse con el art√≠culo sobre el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Modelo b√°sico para reconocer emociones en im√°genes</a> , y tambi√©n puede consultarlo mientras lee, ya que algunas secciones, que incluyen el estudio de los datos de origen y la descripci√≥n de los indicadores de red, no se detallar√°n aqu√≠. <br><br><h2>  <font color="#0071c5">Datos</font> </h2><br>  El conjunto de datos contiene 1630 im√°genes con emociones de dos clases: <i>Negativo</i> (clase 0) y <i>Positivo</i> (clase 1).  Algunos ejemplos de tales im√°genes se dan a continuaci√≥n. <br><br>  <b>Negativo</b> <br><img src="https://habrastorage.org/webt/zr/pf/ki/zrpfkiqvgcxw6kpsv777v9d1t6w.jpeg"><br><br><img src="https://habrastorage.org/webt/52/8x/s6/528xs6k7jnimfgvhagwolru8mi4.jpeg"><br><br><img src="https://habrastorage.org/webt/no/p0/vb/nop0vbapr4ep7o5dps1wvpkncoa.jpeg"><br><br>  <b>Positivo</b> <br><img src="https://habrastorage.org/webt/uc/ua/oh/ucuaohklcwcgotqf4uryopnt_qg.jpeg"><br><br><img src="https://habrastorage.org/webt/u5/hp/rb/u5hprb1cjig28b4xk8urdljb8lm.jpeg"><br><br><img src="https://habrastorage.org/webt/ru/_a/xo/ru_axoahw4h4xytx_-yphxk56ii.jpeg"><br><br>  Algunos de los ejemplos contienen obvias emociones positivas o negativas, mientras que otros pueden no clasificarse, incluso con la participaci√≥n humana.  Sobre la base de una inspecci√≥n visual de tales casos, estimamos que la m√°xima precisi√≥n posible deber√≠a ser de alrededor del 80 por ciento.  Tenga en cuenta que un clasificador aleatorio proporciona aproximadamente un 53 por ciento de precisi√≥n debido a un peque√±o desequilibrio en las clases. <br><br>  Para entrenar el modelo, utilizamos la t√©cnica de <i>retener parte de las muestras</i> y dividimos el conjunto de datos inicial en dos partes, una de las cuales (20 por ciento del conjunto inicial) la usaremos para la verificaci√≥n.  El particionamiento se realiza mediante <i>estratificaci√≥n</i> : esto significa que el equilibrio entre las clases se mantiene en los conjuntos de entrenamiento y prueba. <br><br><h2>  <font color="#0071c5">Resolviendo la insuficiencia de datos</font> </h2><br>  El modelo b√°sico mostr√≥ resultados, solo ligeramente mejores que las predicciones aleatorias de la clase de im√°genes.  Puede haber muchas razones posibles para este comportamiento.  Creemos que la raz√≥n principal es que la cantidad de datos disponibles es decididamente insuficiente para tal entrenamiento de la parte convolucional de la red que permitir√≠a obtener caracter√≠sticas caracter√≠sticas basadas en la imagen de entrada. <br>  Hay muchas formas diferentes de resolver el problema de la insuficiencia de datos.  Aqu√≠ hay algunos de ellos: <br><br><ul><li>  <b>Vuelve a buscar</b> .  La idea del m√©todo es evaluar la distribuci√≥n de datos y seleccionar <i>nuevos ejemplos</i> de esta distribuci√≥n. </li><li>  <b>Aprendizaje sin profesor</b> .  Todos pueden encontrar grandes cantidades de datos de la misma naturaleza que los ejemplos marcados en un conjunto de datos dado.  Por ejemplo, pueden ser pel√≠culas para reconocimiento de video o audiolibros para reconocimiento de voz.  El siguiente paso en el camino es usar estos datos para entrenar previamente el modelo (por ejemplo, usando codificadores autom√°ticos). </li><li>  <b>Aumento de datos</b> .  Durante este proceso, los datos de muestra se modifican aleatoriamente utilizando un conjunto dado de transformaciones. </li><li>  <b>Aprendizaje inductivo</b> .  Este tema es de gran inter√©s para nosotros, as√≠ que vamos a familiarizarnos con m√°s detalle. </li></ul><br><h2>  <font color="#0071c5">Aprendizaje inductivo</font> </h2><br>  El t√©rmino <i>entrenamiento inductivo se</i> refiere a un conjunto de t√©cnicas que utilizan modelos (a menudo muy grandes) entrenados en diferentes conjuntos de datos de aproximadamente la misma naturaleza. <br><br><img src="https://habrastorage.org/webt/wl/jb/qi/wljbqidbfmpj1yfddtvjlkqt9ma.png"><br><br><img src="https://habrastorage.org/webt/bq/ji/ah/bqjiahabshkakrv2jcilp5pa1y8.png"><br><br>  Comparaci√≥n del aprendizaje autom√°tico tradicional y los m√©todos de aprendizaje inductivo.  Imagen tomada de <i>la</i> entrada del blog de S. Ruder <i>"¬øQu√© es el aprendizaje inductivo?"</i>  . <br>  Hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tres</a> escenarios principales para usar el aprendizaje inductivo: <br><br><ul><li>  <b>Modelos pre-entrenados</b> .  Cualquier usuario puede simplemente tomar un modelo entrenado por otra persona y usarlo para sus tareas.  Tal escenario es posible si las tareas son muy similares. </li><li>  <b>Bloquear selecci√≥n de letreros</b> .  En este punto, sabemos que la arquitectura del modelo se puede dividir en dos partes principales: la <i>unidad de extracci√≥n de caracter√≠sticas</i> , que es responsable de extraer las caracter√≠sticas de los datos de entrada, y el <i>m√≥dulo de clasificaci√≥n</i> , que clasifica los ejemplos en funci√≥n de las caracter√≠sticas recibidas.  Por lo general, el bloque de extracci√≥n de caracter√≠sticas es la parte principal del modelo.  La idea del m√©todo es tomar un bloque para distinguir las caracter√≠sticas de un modelo entrenado en otro problema, fijar sus coeficientes de peso (no entrenarlos) y luego construir sobre su base nuevos m√≥dulos de clasificaci√≥n para el problema en consideraci√≥n.  El m√≥dulo de clasificaci√≥n generalmente no es muy profundo y consta de varias capas completamente conectadas, por lo que este modelo es mucho m√°s f√°cil de entrenar. </li><li>  <b>Afinaci√≥n precisa y profunda</b> .  Este m√©todo es como un escenario que utiliza un bloque de extracci√≥n de caracter√≠sticas.  Las mismas acciones se realizan con la excepci√≥n de "congelar" el bloque de extracci√≥n de caracter√≠sticas.  Por ejemplo, puede tomar la red <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VGG</a> como un bloque de extracci√≥n de caracter√≠sticas y ‚Äúcongelar‚Äù solo los primeros tres (de cuatro) bloques convolucionales.  En este caso, la unidad de extracci√≥n de caracter√≠sticas puede adaptarse mejor a la tarea actual.  Para obtener m√°s informaci√≥n, consulte la publicaci√≥n del blog de F. Chollet. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cree modelos potentes de clasificaci√≥n de im√°genes utilizando una cantidad muy peque√±a de datos</a> . </li></ul><br>  Se puede encontrar una descripci√≥n detallada de los escenarios para usar el aprendizaje inductivo en el curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CS231n de</a> la Universidad de Stanford <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">redes neuronales convolucionales para reconocimiento visual</a> por Fei-Fei Li y entradas de blog por S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El aprendizaje inductivo es la pr√≥xima frontera en el desarrollo aprendizaje autom√°tico</a> (temas discutidos de manera m√°s exhaustiva). <br><br>  Puede tener preguntas: ¬øpor qu√© se necesitan todos estos m√©todos y por qu√© pueden funcionar?  Intentaremos responderlas. <br><br><ul><li>  Beneficios del uso de grandes conjuntos de datos.  Por ejemplo, podemos tomar el bloque de extracci√≥n de caracter√≠sticas de un modelo entrenado en 14 millones de im√°genes contenidas en el conjunto de datos del concurso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ImageNet</a> .  Estos modelos son lo suficientemente complejos como para permitir la <i>extracci√≥n de caracter√≠sticas de muy alta calidad</i> de los datos de entrada. </li><li>  Consideraciones relacionadas con el tiempo.  El entrenamiento de modelos grandes puede llevar semanas o incluso meses.  En este caso, todos pueden <i>ahorrar una gran cantidad de tiempo y recursos inform√°ticos</i> . </li><li>  Una suposici√≥n importante que explica por qu√© todo esto puede funcionar es la siguiente: los atributos obtenidos del entrenamiento en una tarea pueden ser √∫tiles y adecuados para otra tarea.  En otras palabras, las caracter√≠sticas tienen la propiedad de invariancia con respecto al problema.  Tenga en cuenta que el <i>dominio de la</i> nueva tarea debe ser similar al dominio de la tarea original.  De lo contrario, la unidad de extracci√≥n de caracter√≠sticas puede incluso empeorar los resultados. </li></ul><br><h2>  <font color="#0071c5">Arquitectura de modelo mejorada</font> </h2><br>  Ahora estamos familiarizados con el concepto de aprendizaje inductivo.  Tambi√©n sabemos que ImageNet es un evento importante, en el que se probaron casi todas las arquitecturas modernas de redes neuronales convolucionales avanzadas.  Intentemos tomar el bloque de extracci√≥n de caracter√≠sticas de una de estas redes. <br><br>  Afortunadamente, la biblioteca de Keras nos proporciona <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">varios</a> modelos previamente entrenados (a trav√©s de ImageNet) que se crearon dentro de esta plataforma.  Importamos y utilizamos uno de estos modelos. <br><br><img src="https://habrastorage.org/webt/jz/3t/ry/jz3trysk11d88hbmbxvlnoungxy.png"><br><br>  En este caso, utilizaremos una red con arquitectura VGG.  Para seleccionar solo la unidad de extracci√≥n de caracter√≠sticas, eliminamos el m√≥dulo de clasificaci√≥n (las tres capas superiores completamente conectadas) de la red al establecer el par√°metro <i>include_top</i> en <i>False</i> .  Tambi√©n queremos inicializar nuestra red utilizando los pesos de la red capacitada en ImageNet.  El par√°metro final es el tama√±o de la entrada. <br><br>  Tenga en cuenta que el tama√±o de las im√°genes originales en el concurso ImageNet es (224, 224, 3), mientras que nuestras im√°genes son (400, 500, 3) de tama√±o.  Sin embargo, utilizamos capas convolucionales, esto significa que los pesos de la red son los pesos de los n√∫cleos en movimiento en la operaci√≥n de convoluci√≥n.  Junto con la propiedad de separaci√≥n de par√°metros (una discusi√≥n de esto se encuentra en nuestro art√≠culo te√≥rico <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Descripci√≥n general de las redes neuronales convolucionales para clasificar im√°genes</a> ), esto lleva al hecho de que el tama√±o de los datos de entrada puede ser casi arbitrario, ya que la convoluci√≥n se realiza mediante una ventana deslizante, y esta ventana puede deslizarse Imagen de cualquier tama√±o.  La √∫nica limitaci√≥n es que el tama√±o de los datos de entrada debe ser lo suficientemente grande como para que no se contraiga en un punto (mediciones espaciales) en alguna capa intermedia, porque de lo contrario ser√° imposible realizar m√°s c√°lculos. <br><br>  Otro truco que usamos es el <i>almacenamiento en cach√©</i> .  VGG es una red muy grande.  Un pase directo para todas las im√°genes (1630 ejemplos) a trav√©s de la unidad de extracci√≥n de funciones tarda aproximadamente 50 segundos.  Sin embargo, debe recordarse que los pesos de la unidad de extracci√≥n de caracter√≠sticas son fijos, y un pase directo siempre da el mismo resultado para la misma imagen.  Podemos utilizar este hecho para realizar un paso directo a trav√©s de la unidad de extracci√≥n de caracter√≠sticas solo <i>una vez</i> y luego almacenar en cach√© los resultados en una matriz intermedia.  Para implementar este escenario, primero creamos una instancia de la clase <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ImageDataGenerator</a> para cargar archivos directamente desde el disco duro (para obtener m√°s informaci√≥n, consulte el art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">b√°sico Modelo b√°sico para reconocer emociones en im√°genes</a> ). <br><br><img src="https://habrastorage.org/webt/o-/wo/7h/o-wo7hel-_kgurcvwcs2v2smecc.png"><br><br>  En la siguiente etapa, usamos en modo de predicci√≥n el bloque de extracci√≥n de caracter√≠sticas creado previamente como parte del modelo para obtener caracter√≠sticas de imagen. <br><br><img src="https://habrastorage.org/webt/gl/no/p7/glnop717aagtytzitgpdtbl_11c.png"><br><br>  Tarda unos 50 segundos.  Ahora podemos usar los resultados para un entrenamiento muy r√°pido de la parte de clasificaci√≥n superior del modelo: una era dura aproximadamente 1 segundo para nosotros.  Imagina ahora que cada era dura 50 segundos m√°s.  Por lo tanto, esta sencilla t√©cnica de almacenamiento en cach√© nos permiti√≥ acelerar el proceso de capacitaci√≥n en red en 50 veces.  En este escenario, guardamos todos los signos para todos los ejemplos en RAM, ya que su volumen es suficiente para esto.  Al usar un conjunto de datos m√°s grande, puede calcular las propiedades, escribirlas en el disco duro y luego leerlas utilizando el mismo enfoque asociado con la clase de generador. <br><br>  Finalmente, considere la arquitectura de la parte de clasificaci√≥n del modelo: <br><br><img src="https://habrastorage.org/webt/6x/hq/qb/6xhqqbgjol6dfxyn47rufbuc_ag.png"><br><br><img src="https://habrastorage.org/webt/ss/4v/3t/ss4v3to-rinafik2lthu5ecszt8.png"><br><br>  Recuerde que a la salida del bloque de extracci√≥n de caracter√≠sticas de la red neuronal convolucional, se emite un tensor tetradimensional (ejemplos, altura, ancho y canales), y una capa completamente conectada para la clasificaci√≥n toma un tensor bidimensional (ejemplos, caracter√≠sticas).  Una forma de transformar un tensor tetradimensional con caracter√≠sticas es simplemente alinearlo alrededor de los √∫ltimos tres ejes (utilizamos una t√©cnica similar en el modelo base).  En este escenario, usamos un enfoque diferente, llamado <i>submuestreo de valor medio global</i> (GAP).  En lugar de alinear los vectores de cuatro dimensiones, tomaremos el valor promedio basado en dos dimensiones espaciales.  De hecho, tomamos un mapa de atributos y simplemente promediamos todos los valores en √©l.  El m√©todo GAP se introdujo por primera vez en el excelente trabajo de Min Lin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Network en la red</a> (vale la pena conocer este libro porque discute algunos conceptos importantes, por ejemplo, convoluciones 1 √ó 1).  Una ventaja obvia del enfoque GAP es una reducci√≥n significativa en el n√∫mero de par√°metros.  Usando GAP, obtenemos solo 512 caracter√≠sticas para cada ejemplo, mientras alineamos los datos sin procesar, el n√∫mero de caracter√≠sticas ser√° 15 √ó 12 √ó 512 = 92 160. Esto puede conducir a una sobrecarga seria, ya que en este caso la parte de clasificaci√≥n del modelo tendr√° aproximadamente 50 millones de par√°metros!  Otros elementos de la parte de clasificaci√≥n del modelo, como las capas completamente conectadas y las capas que implementan el m√©todo de exclusi√≥n, se analizan en detalle en el art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Modelo b√°sico para reconocer las emociones en las im√°genes</a> . <br><br><h2>  <font color="#0071c5">Configuraciones y opciones de entrenamiento</font> </h2><br>  Despu√©s de que hayamos preparado la arquitectura de nuestro modelo con Keras, debe configurar todo el modelo para el entrenamiento con el m√©todo de compilaci√≥n. <br><br><img src="https://habrastorage.org/webt/dl/x5/by/dlx5byabpmih_ocdviw_8ngvatw.png"><br><br>  En este caso, utilizamos configuraciones que son casi similares a las configuraciones del modelo base, con la excepci√≥n de la elecci√≥n del optimizador.  Para optimizar el aprendizaje, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la entrop√≠a cruzada binaria</a> se utilizar√° como una funci√≥n de p√©rdida, y se realizar√° un seguimiento adicional de una m√©trica de precisi√≥n.  Usamos el m√©todo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Adam</a> como optimizador.  Adam es un tipo de algoritmo de descenso de gradiente estoc√°stico con un momento y una <i>velocidad de aprendizaje</i> adaptativa (para m√°s informaci√≥n, vea la entrada del blog de S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Descripci√≥n general de los algoritmos de optimizaci√≥n de descenso de gradiente</a> ). <br><br>  La velocidad de aprendizaje es un hiperpar√°metro optimizador que debe configurarse para garantizar que el modelo est√© operativo.  Recuerde que la f√≥rmula para el descenso de gradiente "vainilla" no contiene funcionalidad adicional: <br><br><img src="https://habrastorage.org/webt/qy/iu/ny/qyiunyjwn2bjmvzkkd_jg5050ay.png"><br><br>  Œò es el vector de los par√°metros del modelo (en nuestro caso, estos son los coeficientes de ponderaci√≥n de la red neuronal), - es la funci√≥n objetivo, ‚àá es el operador de gradiente (calculado usando el algoritmo de propagaci√≥n de error de retorno), Œ± es la velocidad de aprendizaje.  Por lo tanto, el gradiente de la funci√≥n objetivo representa la direcci√≥n del paso de optimizaci√≥n en el espacio de par√°metros, y la velocidad de aprendizaje es su tama√±o.  Cuando se usa una velocidad de aprendizaje excesivamente alta, existe la posibilidad de un deslizamiento constante del punto √≥ptimo debido al tama√±o de paso demasiado grande.  Por otro lado, si la velocidad de aprendizaje es demasiado baja, entonces la optimizaci√≥n tomar√° demasiado tiempo y puede garantizar la convergencia solo a m√≠nimos locales de baja calidad en lugar de un extremo global.  Por lo tanto, en cada situaci√≥n espec√≠fica, es necesario buscar un compromiso apropiado.  Usar la configuraci√≥n predeterminada para el algoritmo Adam es un buen punto de partida para comenzar. <br><br>  Sin embargo, en esta tarea, la configuraci√≥n predeterminada de Adam muestra malos resultados.  Necesitamos reducir la tasa de aprendizaje inicial a 0.0001.  De lo contrario, la capacitaci√≥n no podr√° garantizar la convergencia. <br><br>  Finalmente, podemos comenzar a aprender m√°s de 100 eras y luego guardar el modelo en s√≠ y la historia del aprendizaje.  El comando <i>% time</i> es un comando m√°gico Ipython * que le permite medir el tiempo de ejecuci√≥n del c√≥digo. <br><br><img src="https://habrastorage.org/webt/tp/qr/h3/tpqrh3zk0u7oxnxg77cbsmigxc8.png"><br><br><h2>  <font color="#0071c5">Calificaci√≥n</font> </h2><br><br><img src="https://habrastorage.org/webt/ij/w6/a-/ijw6a-rdyl9fd5rhlsuybmu24vm.png"><br><br>  Vamos a evaluar la efectividad del modelo durante el entrenamiento.  En nuestro caso, la precisi√≥n de la verificaci√≥n es del 73 por ciento (en comparaci√≥n con el 55 por ciento que usa el modelo base).  Este resultado es mucho mejor que el resultado del modelo base. <br><br>  Tambi√©n veamos la distribuci√≥n de errores usando la matriz de imprecisiones.  Los errores se distribuyen de manera casi uniforme entre las clases con un ligero sesgo hacia ejemplos negativos incorrectamente clasificados (celda superior izquierda de la matriz de imprecisiones).  Esto puede explicarse por un <i>peque√±o desequilibrio en el conjunto de datos</i> hacia la clase positiva. <br><br>  Otra m√©trica que rastreamos es la curva de rendimiento del receptor (curva ROC) y el √°rea bajo esta curva (AUC).  Para obtener una descripci√≥n detallada de estas m√©tricas, consulte el art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Modelo b√°sico para reconocer las emociones en las im√°genes</a> . <br><br><img src="https://habrastorage.org/webt/if/lx/cf/iflxcf-2pxzdcuicg8im4us-9yg.png"><br><br>  Cuanto m√°s cerca est√© la curva ROC del punto superior izquierdo del gr√°fico y mayor sea el √°rea debajo de ella (m√©trica AUC), mejor funcionar√° el clasificador.  Esta figura muestra claramente que un modelo mejorado y pre-entrenado muestra mejores resultados en comparaci√≥n con el modelo base creado desde cero.  El valor de AUC para el modelo pre-entrenado es 0.82, que es un buen resultado. <br><br><img src="https://habrastorage.org/webt/7o/dy/hu/7odyhuvi5j09ajzquknecv_ch2s.png"><br><br><h2>  <font color="#0071c5">Conclusi√≥n</font> </h2><br>  En este art√≠culo, nos encontramos con una t√©cnica poderosa: el aprendizaje inductivo.  Tambi√©n construimos un clasificador de red neuronal convolucional utilizando una unidad de extracci√≥n de caracter√≠sticas pre-entrenada basada en la arquitectura VGG.  Este clasificador super√≥ en sus caracter√≠sticas de rendimiento al modelo convolucional b√°sico, entrenado desde cero.  El aumento en la precisi√≥n fue del 18 por ciento, y el aumento en la m√©trica de AUC fue de 0.25, lo que demuestra un aumento muy significativo en la calidad del sistema. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es421367/">https://habr.com/ru/post/es421367/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es421355/index.html">Go 1.11 lanzado - WebAssembly y m√≥dulos nativos</a></li>
<li><a href="../es421357/index.html">A la cuesti√≥n de lo imposible. Parte 3</a></li>
<li><a href="../es421359/index.html">El festival es como un juego. Taxonom√≠a de personas de TI</a></li>
<li><a href="../es421361/index.html">AMD ha abierto el c√≥digo fuente de V-EZ, una plataforma Vulkan API multiplataforma de bajo nivel</a></li>
<li><a href="../es421365/index.html">La evoluci√≥n de una startup. √Ågil de Yaytselov a Chiken Invaders</a></li>
<li><a href="../es421369/index.html">Lo que los alumnos de ABBYY realmente hacen</a></li>
<li><a href="../es421371/index.html">Agujas invisibles: los cient√≠ficos han desarrollado una forma de enmascarar nanosensores para √≥ptica y biomedicina</a></li>
<li><a href="../es421373/index.html">Python hace que la programaci√≥n est√© disponible para una amplia audiencia</a></li>
<li><a href="../es421375/index.html">C√≥mo la incertidumbre mata el comercio</a></li>
<li><a href="../es421377/index.html">7 conceptos err√≥neos de un gerente de proyecto novato en gamedev</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
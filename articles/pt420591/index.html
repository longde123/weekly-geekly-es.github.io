<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∏üèº üñ≤Ô∏è üëèüèΩ Tradu√ß√£o do livro de Andrew Un, Passion for Machine Learning, Cap√≠tulos 20 - 27 üö£üèΩ üî≤ üö≤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="cap√≠tulos anteriores 
 20 Deslocamento e dispers√£o: duas fontes principais de erros 


 observa√ß√£o do tradutor Antes da mudan√ßa, este cap√≠tulo foi cha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tradu√ß√£o do livro de Andrew Un, Passion for Machine Learning, Cap√≠tulos 20 - 27</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420591/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cap√≠tulos anteriores</a> </p><br><h1 id="20-smeschenie-i-razbros-dva-osnovnyh-istochnika-oshibok">  20 Deslocamento e dispers√£o: duas fontes principais de erros </h1><br><p>  <em><u>observa√ß√£o do tradutor</u> Antes da mudan√ßa, este cap√≠tulo foi chamado de <strong>"sistem√°tico e aleat√≥rio: duas fontes principais de erros",</strong> ou seja, usei os termos "erros aleat√≥rios" e "erros sistem√°ticos" para traduzir vi√©s e vari√¢ncia.</em>  <em>No entanto, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">membro</a> do f√≥rum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">robot @ Phaker,</a> em um coment√°rio, observou com raz√£o que, no campo do aprendizado de m√°quina na terminologia russa para esses termos, os conceitos de "deslocamento" e "dispers√£o" s√£o corrigidos.</em>  <em>Eu olhei para o trabalho de K.V.</em>  <em>Vorontsov, que merecidamente √© uma das autoridades no campo do aprendizado de m√°quina na R√∫ssia e dos recursos da comunidade profissional, concordou com o coment√°rio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rob√¥ @ Phaker</a> .</em>  <em>Apesar do fato de que, do meu ponto de vista, existe uma profunda analogia significativa entre o ‚Äúvi√©s‚Äù e a ‚Äúvaria√ß√£o‚Äù no treinamento de algoritmos e o ‚Äúerro sistem√°tico‚Äù e o ‚Äúerro aleat√≥rio‚Äù de um experimento f√≠sico, al√©m de serem expressos igualmente matematicamente , no entanto, √© correto usar os termos estabelecidos neste campo.</em>  <em>Portanto, revisei a tradu√ß√£o deste e dos cap√≠tulos subseq√ºentes, substituindo os "Erros sistem√°ticos e aleat√≥rios" por "Deslocamento e dispers√£o" e continuarei com essa abordagem no futuro.</em> </p><a name="habracut"></a><br><p>  Suponha que suas amostras de treinamento, valida√ß√£o e teste tenham a mesma distribui√ß√£o.  Ent√£o voc√™ precisa levar mais dados para o treinamento, isso s√≥ melhorar√° a qualidade do algoritmo, isso √© verdade? </p><br><p>  Embora a obten√ß√£o de mais dados n√£o possa prejudicar o trabalho, infelizmente, novos dados nem sempre ajudam tanto quanto voc√™ poderia esperar.  Em alguns casos, o trabalho de obter dados adicionais pode ser um desperd√≠cio de esfor√ßo.  Como tomar uma decis√£o - em que casos adicionar dados e quando n√£o se preocupar com isso. </p><br><p>  No aprendizado de m√°quina, existem duas fontes principais de erro: vi√©s e dispers√£o (varia√ß√£o).  Compreender o que eles s√£o ajudar√° voc√™ a decidir se deseja adicionar mais dados, al√©m de ajud√°-lo a escolher t√°ticas para melhorar a qualidade do classificador. </p><br><p>  Suponha que voc√™ esteja esperando criar um identificador felino com 5% de erro.  No momento, o erro do classificador na amostra de treinamento √© de 15%, e na amostra de valida√ß√£o de 16%.  Nesse caso, √© improv√°vel que a adi√ß√£o de dados de treinamento aumente significativamente a qualidade.  Voc√™ deve se concentrar em outras altera√ß√µes do sistema.  De fato, adicionar mais exemplos ao seu conjunto de treinamento tornar√° mais dif√≠cil para o seu algoritmo obter um bom resultado nesse conjunto (por que isso ser√° explicado nos cap√≠tulos seguintes). </p><cut></cut><br><p>  Se a porcentagem de seus erros na amostra de treinamento for 15% (o que corresponde a uma precis√£o de 85%), mas seu objetivo for a porcentagem de erros em 5% (precis√£o de 95%), primeiro voc√™ precisar√° melhorar a qualidade do seu algoritmo na amostra de treinamento.  A qualidade do algoritmo nas amostras de valida√ß√£o / teste √© geralmente pior que a qualidade do seu trabalho na amostra de treinamento (na amostra de treinamento).  Voc√™ precisa entender que as abordagens que levaram √† precis√£o n√£o superior a 85% nos exemplos com os quais seu algoritmo est√° familiarizado n√£o permitir√£o obter 95% de precis√£o nos exemplos que esse algoritmo nem sequer viu. </p><cut></cut><br><p>  Suponha que, como indicado acima, a taxa de erro do seu algoritmo seja 16% (a precis√£o √© 84%) na amostra de valida√ß√£o.  Devemos quebrar o erro de 16% em dois componentes: </p><br><ul><li>  Primeiro, a propor√ß√£o de erros de algoritmo na amostra de treinamento.  Neste exemplo, √© de 15%.  Chamamos informalmente de <strong>vi√©s</strong> . </li><li>  Segundo, qu√£o pior o algoritmo funciona na amostra de valida√ß√£o (ou teste) do que na amostra de treinamento.  No nosso exemplo, √© 1% pior na amostra de valida√ß√£o do que na amostra de treinamento.  Tamb√©m consideraremos n√£o oficialmente uma <strong>varia√ß√£o do</strong> algoritmo. </li></ul><br><p>  <em><u>observa√ß√£o do autor</u> Nas estat√≠sticas, existe uma defini√ß√£o mais precisa de vi√©s e dispers√£o (erros sistem√°ticos e aleat√≥rios), mas isso n√£o deve nos incomodar.</em>  <em>Grosso modo, assumimos que o vi√©s √© um erro no seu algoritmo no seu conjunto de treinamento quando voc√™ tem um conjunto de treinamento muito grande.</em>  <em>Dispers√£o - √© o qu√£o pior o algoritmo funciona na amostra de teste em compara√ß√£o com a de treinamento com as mesmas configura√ß√µes de par√¢metro.</em>  <em>Se voc√™ usar o erro padr√£o, poder√° escrever as f√≥rmulas que definem essas duas quantidades e provar que o erro total √© igual √† soma da polariza√ß√£o e da dispers√£o (a soma dos erros aleat√≥rios e sistem√°ticos).</em>  <em>Mas, para nossos prop√≥sitos, melhorar os algoritmos nos problemas de aprendizado de m√°quina √© suficiente uma defini√ß√£o informal de preconceito e dispers√£o.</em> </p><br><p>  Algumas mudan√ßas no treinamento do algoritmo afetam o primeiro componente da <strong>polariza√ß√£o de</strong> erros e melhoram o desempenho do algoritmo na amostra de treinamento.  Algumas mudan√ßas afetam o segundo componente - a <strong>varia√ß√£o</strong> e ajudam a generalizar melhor o algoritmo para valida√ß√£o e amostras de teste.  Para selecionar as altera√ß√µes mais eficazes que precisam ser feitas no sistema, √© extremamente √∫til entender como cada um desses dois componentes de erro afeta o erro geral do sistema. </p><br><p>  <em><u>Observa√ß√£o do autor:</u> Existem tamb√©m algumas abordagens que reduzem simultaneamente o deslocamento e a dispers√£o, fazendo altera√ß√µes significativas na arquitetura do sistema.</em>  <em>Mas eles geralmente s√£o mais dif√≠ceis de encontrar e implementar.</em> </p><br><p>  Para selecionar as altera√ß√µes mais eficazes que precisam ser feitas no sistema, √© extremamente √∫til entender como cada um desses dois componentes de erro afeta o erro geral do sistema. </p><br><p>  O desenvolvimento da intui√ß√£o para entender como a Contribui√ß√£o contribui para o erro e qual Dispers√£o, ajudar√° voc√™ a escolher efetivamente maneiras de melhorar seu algoritmo. </p><cut></cut><br><h1 id="21-primery-klassifikacii-oshibok">  21 Exemplos de classifica√ß√£o de erro </h1><br><p>  Considere o nosso problema de classifica√ß√£o de gatos.  Um classificador ideal (por exemplo, uma pessoa) pode alcan√ßar uma excelente qualidade dessa tarefa. </p><br><p>  Suponha que a qualidade do nosso algoritmo seja a seguinte: </p><br><ul><li>  Erro na amostra de treinamento = 1% </li><li>  Erro na amostra de valida√ß√£o = 11% </li></ul><br><p>  Qual √© o problema com este classificador?  Aplicando as defini√ß√µes do cap√≠tulo anterior, estimamos o vi√©s em 1% e o spread em 10% (= 11% - 1%).  Assim, nosso algoritmo tem uma grande <strong>dispers√£o</strong> .  O classificador possui um erro muito baixo na amostra de treinamento, mas n√£o pode generalizar os resultados do treinamento para uma amostra de valida√ß√£o.  Em outras palavras, estamos lidando com <strong>super ajuste</strong> . </p><br><p>  Agora considere esta situa√ß√£o: </p><br><ul><li>  Erro na amostra de treinamento = 15% </li><li>  Erro na amostra de valida√ß√£o = 16% </li></ul><br><p>  Em seguida, estimamos o <strong>vi√©s</strong> em 15% e o <strong>spread</strong> em 1%.  Esse classificador foi pouco treinado na amostra de treinamento, enquanto seu erro na amostra de valida√ß√£o √© um pouco maior que na amostra de treinamento.  Portanto, esse classificador possui um grande vi√©s, mas um pequeno spread.  Pode-se concluir que esse algoritmo est√° sendo <strong>insuficiente</strong> . </p><cut></cut><br><p>  Tamb√©m consideramos a seguinte distribui√ß√£o de erros: </p><br><ul><li>  Erro na amostra de treinamento = 15% </li><li>  Erro na amostra de valida√ß√£o = 30% </li></ul><br><p>  Nesse caso, o vi√©s √© de 15% e o spread tamb√©m √© de 15%.  Esse classificador possui alto vi√©s e propaga√ß√£o: n√£o funciona bem na amostra de treinamento, possui um alto vi√©s, e sua qualidade na amostra de valida√ß√£o √© muito pior do que na amostra de treinamento, ou seja,  a dispers√£o tamb√©m √© grande.  Este caso √© dif√≠cil de descrever em termos de reciclagem / sub-educa√ß√£o; esse classificador √© tanto reciclado quanto sub-educado. </p><cut></cut><br><p>  Por fim, considere esta situa√ß√£o: </p><br><ul><li>  Erro na amostra de treinamento = 0,5% </li><li>  Erro na amostra de valida√ß√£o = 1% </li></ul><br><p>  Este √© um √≥timo classificador, possui baixo vi√©s e dispers√£o.  Parab√©ns aos engenheiros por alcan√ßar um excelente resultado! </p><cut></cut><br><h1 id="22-sravnenie-s-optimalnoy-doley-oshibok">  22 Compara√ß√£o com taxa de erro ideal </h1><br><p>  No nosso exemplo de reconhecimento de gatos, a propor√ß√£o ideal de erros √© o n√≠vel dispon√≠vel para o classificador ‚Äúideal‚Äù e esse n√≠vel √© pr√≥ximo de 0%.  Uma pessoa que visualiza uma imagem quase sempre √© capaz de reconhecer se um gato est√° presente na imagem ou n√£o, e podemos esperar que, mais cedo ou mais tarde, a m√°quina fa√ßa isso da mesma forma. </p><br><p>  Mas existem tarefas mais complexas.  Por exemplo, imagine que voc√™ esteja desenvolvendo um sistema de reconhecimento de fala e descobriu que 14% das grava√ß√µes de √°udio t√™m tanto ru√≠do de fundo ou fala t√£o ileg√≠vel que nem mesmo uma pessoa consegue entender o que foi dito l√°.  Nesse caso, mesmo o sistema de reconhecimento de voz mais ‚Äúideal‚Äù pode ter um erro na regi√£o de 14%. </p><br><p>  Suponha que em nossa tarefa de reconhecimento de fala, nosso algoritmo tenha alcan√ßado os seguintes resultados: </p><br><ul><li>  Erro na amostra de treinamento = 15% </li><li>  Erro na amostra de valida√ß√£o = 30% </li></ul><cut></cut><br><p>  A qualidade do classificador na amostra de treinamento j√° est√° pr√≥xima da ideal, com uma taxa de erro de 14%.  Portanto, neste caso, n√£o temos muitas oportunidades para reduzir o <strong>vi√©s</strong> (melhorar o algoritmo na amostra de treinamento).  Entretanto, n√£o √© poss√≠vel generalizar a opera√ß√£o desse algoritmo para uma amostra de valida√ß√£o; portanto, existe um grande campo para atividades de redu√ß√£o de <strong>dispers√£o</strong> . </p><br><p>  Esse caso √© semelhante ao terceiro exemplo do cap√≠tulo anterior, no qual o erro na amostra de treinamento tamb√©m √© igual a 15% e o erro na amostra de valida√ß√£o √© 30%.  Se a taxa de erro ideal for de cerca de 0%, o erro na amostra de treinamento de 15% dar√° muito espa√ßo para o trabalho para melhorar o algoritmo.  Com essa suposi√ß√£o, os esfor√ßos para reduzir o <strong>vi√©s</strong> no algoritmo podem ser muito proveitosos.  Mas se a propor√ß√£o ideal de erros de classifica√ß√£o n√£o puder ser inferior a 14%, uma propor√ß√£o semelhante de erros de algoritmo na amostra de treinamento (ou seja, na regi√£o de 14 a 15%) sugere que as possibilidades de redu√ß√£o do <strong>vi√©s est√£o</strong> quase esgotadas. </p><br><p>  Para problemas em que a propor√ß√£o ideal de erros de classifica√ß√£o difere significativamente de zero, uma estrutura de erro mais detalhada pode ser proposta.  Continuamos a considerar o exemplo acima com reconhecimento de fala, um erro total de 30% na amostra de valida√ß√£o pode ser decomposto nos seguintes componentes (os erros na amostra de teste podem ser analisados ‚Äã‚Äãda mesma maneira): </p><cut></cut><br><ul><li>  <strong>Vi√©s ideal (vi√©s inevit√°vel):</strong> 14%.  Imagine, decidimos que mesmo o melhor sistema de reconhecimento de fala poss√≠vel do mundo ter√° uma taxa de erro de 14%.  Vamos falar sobre isso como a parte "inevit√°vel" do deslocamento do algoritmo de aprendizado. </li><li>  <strong>Vi√©s evit√°vel</strong> : 1%.  Este valor √© calculado como a diferen√ßa entre a propor√ß√£o de erros na amostra de treinamento e a propor√ß√£o ideal de erros. </li></ul><br><p>  <em><u>observa√ß√£o do autor:</u> Se esse valor acabou sendo negativo, seu algoritmo na amostra de treinamento mostra um erro menor que o "ideal".</em>  <em>Isso significa que voc√™ treinou novamente o conjunto de treinamento; seu algoritmo se lembrou dos exemplos (e de suas classes) do conjunto de treinamento.</em>  <em>Nesse caso, voc√™ deve se concentrar em m√©todos para reduzir a propaga√ß√£o, em vez de reduzir ainda mais o vi√©s.</em> </p><br><ul><li>  <strong>Varia√ß√£o</strong> : 15%.  A diferen√ßa entre erros na amostra de treinamento e na amostra de valida√ß√£o </li></ul><br><p>  Relacionando isso √†s nossas defini√ß√µes anteriores, deslocamento e deslocamento descart√°vel est√£o relacionados da seguinte forma: </p><br><p>  Vi√©s <strong>(vi√©s)</strong> = Vi√©s ideal ( <strong>"vi√©s inevit√°vel"</strong> ) + Vi√©s descart√°vel ( <strong>"vi√ßo evit√°vel"</strong> ) </p><br><p>  <em><u>Nota do autor</u> : Essas defini√ß√µes s√£o escolhidas para explicar melhor como a qualidade do algoritmo de aprendizado pode ser aprimorada.</em>  <em>Essas defini√ß√µes diferem das defini√ß√µes formais de vi√©s e dispers√£o adotadas nas estat√≠sticas.</em>  <em>Tecnicamente, o que eu defino como "Deslocamento" deve ser chamado de "um erro na estrutura de dados (n√£o pode ser identificado e eliminado)" e "Eliminar vi√©s" deve ser definido como "Vi√©s do algoritmo de aprendizado que excede o vi√©s ideal" .</em> </p><br><p>  O vi√©s evit√°vel mostra qu√£o pior √© a qualidade do seu algoritmo na amostra de treinamento do que a qualidade do "classificador ideal". </p><br><p>  A id√©ia b√°sica de varia√ß√£o permanece a mesma.  Em teoria, sempre podemos reduzir a propaga√ß√£o para quase zero treinando em uma amostra de treinamento suficientemente grande.  Assim, qualquer propaga√ß√£o √© ‚Äúevit√°vel‚Äù quando h√° uma amostra suficientemente grande, portanto n√£o pode haver uma ‚Äúpropaga√ß√£o inevit√°vel‚Äù (varia√ß√£o inevit√°vel). </p><cut></cut><br><p>  Considere outro exemplo em que o erro ideal √© de 14% e temos: </p><br><ul><li>  Erro na amostra de treinamento = 15% </li><li>  Erro na amostra de valida√ß√£o = 16% </li></ul><br><p>  No cap√≠tulo anterior, classificamos um classificador com indicadores como classificador de alto vi√©s, nas condi√ß√µes atuais, dizemos que ‚Äúvi√©s evit√°vel‚Äù √© de 1% e o spread √© de cerca de 1%.  Assim, o algoritmo j√° est√° funcionando muito bem e quase n√£o h√° reservas para melhorar a qualidade de seu trabalho.  A qualidade desse algoritmo est√° apenas 2% abaixo do ideal. </p><br><p>  A partir desses exemplos, fica claro que conhecer a magnitude do erro fatal √© √∫til para decidir outras a√ß√µes.  Nas estat√≠sticas, a <strong>taxa de erro</strong> ideal tamb√©m √© chamada de <strong>taxa de erro de Bayes</strong> . </p><br><p>  Como descobrir o tamanho da taxa de erro ideal?  Para tarefas com as quais uma pessoa lida bem, como reconhecimento de imagem ou decodifica√ß√£o de clipes de √°udio, voc√™ pode solicitar que os avaliadores marquem os dados e, em seguida, me√ßa a precis√£o da marca√ß√£o humana na amostra de treinamento.  Isso fornecer√° uma estimativa da taxa de erro ideal.  Se voc√™ estiver trabalhando em um problema dif√≠cil de lidar at√© mesmo com uma pessoa (por exemplo, prever qual filme recomendar ou qual an√∫ncio exibir ao usu√°rio), nesse caso, √© bastante dif√≠cil avaliar a taxa de erro ideal. </p><br><p>  Na se√ß√£o Comparando com o desempenho em n√≠vel humano, cap√≠tulos 33 a 35, discutirei mais detalhadamente o processo de comparar a qualidade de um algoritmo de aprendizado com o n√≠vel de qualidade que uma pessoa pode alcan√ßar. </p><cut></cut><br><p>  Nos √∫ltimos cap√≠tulos, voc√™ aprendeu como avaliar o vi√©s e dispers√£o remov√≠vel / irrecuper√°vel analisando a propor√ß√£o de erros do classificador nas amostras de treinamento e valida√ß√£o.  O pr√≥ximo cap√≠tulo examinar√° como voc√™ pode usar as conclus√µes dessa an√°lise para decidir se deve se concentrar nos m√©todos que reduzem o vi√©s ou nos m√©todos que reduzem a propaga√ß√£o.  As abordagens para combater o vi√©s s√£o muito diferentes das abordagens para reduzir a dispers√£o; portanto, as t√©cnicas que voc√™ deve aplicar no seu projeto para melhorar a qualidade dependem muito do que √© o problema atualmente - vi√©s grande ou dispers√£o grande. </p><cut></cut><br><p>  Continue lendo! </p><br><h1 id="23-ustranenie-smescheniya-i-razbrosa">  23 Eliminando deslocamentos e dispers√£o </h1><br><p>  Aqui est√° uma f√≥rmula simples para eliminar o vi√©s e a dispers√£o: </p><br><ul><li>  Se voc√™ tem um grande vi√©s evit√°vel, aumente a complexidade do seu modelo (por exemplo, aumente sua rede neural adicionando camadas ou (e) neur√¥nios) </li><li>  Se voc√™ tem uma ampla variedade, adicione exemplos ao seu conjunto de treinamento. </li></ul><br><p>  Se voc√™ tiver a oportunidade de aumentar o tamanho da rede neural e adicionar dados ao conjunto de treinamento ilimitado, isso ajudar√° a obter um bom resultado para um grande n√∫mero de tarefas de aprendizado de m√°quina. </p><br><p>  Na pr√°tica, aumentar o tamanho do modelo acabar√° por causar dificuldades computacionais, pois o treinamento de modelos muito grandes √© lento.  Voc√™ tamb√©m pode esgotar o limite de dados dispon√≠veis para treinamento.  (Mesmo na Internet, √© claro o n√∫mero de imagens com gatos!) </p><br><p>  Diferentes arquiteturas de modelos de algoritmos, por exemplo, diferentes arquiteturas de redes neurais, fornecer√£o valores diferentes de polariza√ß√£o e dispers√£o em rela√ß√£o √† sua tarefa.  Um eixo de pesquisas recentes de aprendizado profundo criou um grande n√∫mero de arquiteturas inovadoras de modelos de redes neurais.  Portanto, se voc√™ usa redes neurais, a n√£o fic√ß√£o pode ser uma grande fonte de inspira√ß√£o.  Tamb√©m h√° um grande n√∫mero de excelentes implementa√ß√µes de algoritmos em fontes abertas, por exemplo no GitHub.  No entanto, os resultados das tentativas de usar novas arquiteturas s√£o significativamente menos previs√≠veis do que a f√≥rmula simples dada acima - aumentam o tamanho do modelo e adicionam dados. </p><br><p>  Aumentar o tamanho do modelo geralmente reduz o vi√©s, mas tamb√©m pode causar um aumento no spread e o risco de reciclagem tamb√©m aumenta.  No entanto, o problema de reciclagem novamente ocorre apenas quando voc√™ n√£o est√° usando a regulariza√ß√£o.  Se voc√™ incluir um m√©todo de regulariza√ß√£o bem projetado em seu modelo, geralmente conseguir√° aumentar com seguran√ßa o tamanho do modelo sem permitir a reciclagem. </p><br><p> ,    ,  L2   dropout ( <em><u> </u> :  <strong>Dropout</strong>  , , : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://habr.com/company/wunderfund/blog/330814/</a></em> ),   ,     .     ,          ;    .  , -        ‚Äî   . </p><br><h1 id="24-kompromiss-mezhdu-smescheniem-i-razbrosom"> 24      </h1><br><p>     ¬´    ¬ª.   ,      ,  ,        .      ¬´¬ª    . </p><br><p> ,    ‚Äî    ()   ,       ,    . ,     ,   . </p><br><p>                      (  ).  ,      ,          ,       . </p><br><p> ,            ,       .     ,  ,  ,  ,    . </p><br><p>     ,   ,       .        . </p><br><p>    ,     ,       . </p><br><h1 id="25-podhody-k-umensheniyu-ustranimogo-smescheniya"> 25      </h1><br><p>        ,     : </p><br><ul><li> <strong>  </strong> (,     ):    ,            .   ,     ,  ,     . </li><li> <strong>  ,   ,    </strong> .         ,         (      ).        ,    .        ;    ,     , ,  ,     . </li><li> <strong>    </strong> (L2 , L1 , Dropout):     , ,    . </li><li> <strong>  </strong> (,   )       :      ,     </li></ul><br><p>     : </p><br><ul><li> <strong>    </strong> :     ,        . </li></ul><br><h1 id="26-analiz-oshibok-na-trenirovochnoy-vyborke"> 26      </h1><br><p>        ,        / . </p><br><p>    ,  ,    ,           ,    ,        .   ,      , . .         . </p><br><p> ,        -         .         ,      ,   100 ,       ,        .      ,       : </p><br><div class="scrollable-table"><table><thead><tr><th>   </th><th>    </th><th>     </th><th>     </th><th>  Coment√°rios </th></tr></thead><tbody><tr><td>  1 </td><td>  X </td><td></td><td></td><td>    </td></tr><tr><td>  2 </td><td>  X </td><td></td><td>  X </td><td>   </td></tr><tr><td>  3 </td><td></td><td>  X </td><td>  X </td><td>     </td></tr><tr><td>  4 </td><td>  X </td><td></td><td></td><td>   </td></tr><tr><td> %   - </td><td> 75% </td><td> 25% </td><td> 50% </td><td></td></tr></tbody></table></div><br><p>       ,         ,    .       ,           . </p><br><p>      ,      -,      ,    .       ,    - ,   ,     ,  -     .      ,          ,  . </p><br><h1 id="27-podhody-k-umensheniyu-razbrosa"> 27     </h1><br><p>       ,     : </p><br><ul><li> <strong>     </strong> :         ,     ,                  . </li><li> <strong> </strong> (L1 , L2 , dropout):    ,   . </li><li> <strong>  </strong> (. .    ,       ):    ,   .      ,       . </li><li> <strong>    /  </strong> :       ,     .     (,  1000   900)       .   (  1000   100  10  )     ,      ,        .    ,   ,      ,        ,          ,     ,    ,      . ,     ,      . </li><li> <strong>  () </strong> (    / ). <em>  !</em>       , ,  . ,          .        .                  .       ,        . ,              ,     . </li></ul><br><p>       ,     ,    : </p><br><ul><li> <strong>  ,   ,    </strong> : ,        ,     ,        .         . ,      ;    ,     ,     . </li><li> <strong>  </strong> (,   )       :        . </li></ul><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt420591/">https://habr.com/ru/post/pt420591/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt420579/index.html">CPU de 24 n√∫cleos, mas n√£o consigo digitar um email</a></li>
<li><a href="../pt420581/index.html">Previs√£o de vendas de im√≥veis. Palestra em Yandex</a></li>
<li><a href="../pt420585/index.html">Download gr√°tis do banco de dados de c√≥digo de barras sem registro (e outros caquis)</a></li>
<li><a href="../pt420587/index.html">Bem, onde colocar esses motores agora?</a></li>
<li><a href="../pt420589/index.html">O que procurar ao escolher um sistema de registro e por que decidimos pelo ELK</a></li>
<li><a href="../pt420593/index.html">Otimiza√ß√£o da navega√ß√£o na web m√≥vel (2 sucessos recentes)</a></li>
<li><a href="../pt420595/index.html">Gera√ß√£o autom√°tica de programas, problema inverso e algumas solu√ß√µes relacionadas</a></li>
<li><a href="../pt420597/index.html">Oficial de prote√ß√£o de dados - GDPR atualiza profiss√£o</a></li>
<li><a href="../pt420599/index.html">Treze coisas que Lem previram</a></li>
<li><a href="../pt420603/index.html">Estat√≠sticas do propriet√°rio do Tesla Model S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
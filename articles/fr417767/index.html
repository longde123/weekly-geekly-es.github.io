<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë¶üèø üëª üë®üèæ‚Äçüöí Analyse des sentiments textuels √† l'aide de r√©seaux de neurones convolutifs üàöÔ∏è üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë© üë©‚Äçüë©‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Imaginez que vous ayez un paragraphe de texte. Est-il possible de comprendre quelle √©motion ce texte v√©hicule: joie, tristesse, col√®re? Tu peux. Nous ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse des sentiments textuels √† l'aide de r√©seaux de neurones convolutifs</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/417767/"><img src="https://habrastorage.org/webt/2u/l3/lw/2ul3lwsbyobovjnol2g_cbvrghi.gif"><br><br>  Imaginez que vous ayez un paragraphe de texte.  Est-il possible de comprendre quelle √©motion ce texte v√©hicule: joie, tristesse, col√®re?  Tu peux.  Nous simplifions notre t√¢che et classerons l'√©motion comme positive ou n√©gative, sans pr√©cision.  Il existe de nombreuses fa√ßons de r√©soudre ce probl√®me, et l'un d'eux est <b>les r√©seaux de neurones convolutionnels</b> (r√©seaux de neurones convolutionnels).  CNN a √©t√© d√©velopp√© √† l'origine pour le traitement d'images, mais ils ont r√©ussi √† g√©rer des t√¢ches dans le domaine du traitement automatique de texte.  Je vais vous pr√©senter une analyse binaire de la tonalit√© des textes en russe √† l'aide d'un r√©seau neuronal convolutif pour lequel des repr√©sentations vectorielles de mots ont √©t√© form√©es sur la base d'un mod√®le <b>Word2Vec</b> form√©. <br><br>  L'article est de nature g√©n√©rale, j'ai insist√© sur le volet pratique.  Et je veux vous avertir tout de suite que les d√©cisions prises √† chaque √©tape peuvent ne pas √™tre optimales.  Avant de lire, je vous recommande de vous familiariser avec l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article introductif</a> sur l'utilisation de CNN dans les t√¢ches de traitement du langage naturel, ainsi que de lire du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mat√©riel</a> sur les m√©thodes de repr√©sentation vectorielle des mots. <br><a name="habracut"></a><br><h2>  L'architecture </h2><br>  L'architecture CNN consid√©r√©e est bas√©e sur les approches [1] et [2].  L'approche [1], qui utilise l'ensemble des r√©seaux convolutionnels et r√©currents, lors du plus grand concours annuel de linguistique informatique SemEval-2017 a pris la premi√®re place [3] dans cinq nominations dans la t√¢che d'analyse de la tonalit√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">T√¢che 4</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/20a/058/4aa/20a0584aa0d0a5a6c8108af970c896fa.png"><br>  <i>Figure 1. Architecture CNN [2].</i> <br><br>  L'entr√©e CNN (Fig. 1) est une matrice √† hauteur fixe <i>n</i> , o√π chaque ligne est un mappage vectoriel d'un jeton dans un espace caract√©ristique de dimension <i>k</i> .  Des outils de s√©mantique distributive tels que Word2Vec, Glove, FastText, etc. sont souvent utilis√©s pour former un espace de fonctionnalit√©. <br><br>  Au premier stade, la matrice d'entr√©e est trait√©e par des couches de convolution.  En r√®gle g√©n√©rale, les filtres ont une largeur fixe √©gale √† la dimension de l'espace attributaire et un seul param√®tre est configur√© pour les tailles de filtre - hauteur <i>h</i> .  Il s'av√®re que <i>h</i> est la hauteur des lignes adjacentes consid√©r√©es ensemble par le filtre.  En cons√©quence, la dimension de la matrice de caract√©ristiques de sortie pour chaque filtre varie en fonction de la hauteur de ce filtre <i>h</i> et de la hauteur de la matrice d'origine <i>n</i> . <br><br>  Ensuite, la carte des caract√©ristiques obtenue √† la sortie de chaque filtre est trait√©e par une couche de sous-√©chantillonnage avec une fonction de compactage sp√©cifique (regroupement 1-max dans l'image), c'est-√†-dire  r√©duit la dimension de la carte d'entit√©s g√©n√©r√©e.  Ainsi, les informations les plus importantes sont extraites pour chaque convolution, quelle que soit sa position dans le texte.  En d'autres termes, pour l'affichage vectoriel utilis√©, la combinaison des couches de convolution et des couches de sous-√©chantillonnage permet d'extraire les <i>n-</i> grammes les plus significatifs du texte. <br><br>  Apr√®s cela, les cartes d'entit√©s calcul√©es √† la sortie de chaque couche de sous-√©chantillonnage sont combin√©es en un vecteur d'entit√©s commun.  Il est envoy√© √† l'entr√©e d'une couche cach√©e et enti√®rement connect√©e, puis envoy√© √† la couche de sortie du r√©seau neuronal, o√π les √©tiquettes de classe finales sont calcul√©es. <br><br><h2>  Donn√©es d'entra√Ænement </h2><br>  Pour la formation, j'ai choisi le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">corpus de courts textes de Yulia Rubtsova</a> , form√© sur la base de messages en russe de Twitter [4].  Il contient 114 991 tweets positifs, 111 923 tweets n√©gatifs, ainsi qu'une base de tweets non allou√©s avec un volume de 17 639 674 messages. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment">#   n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount'] data_positive = pd.read_csv('data/positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text']) data_negative = pd.read_csv('data/negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text']) #    sample_size = min(data_positive.shape[0], data_negative.shape[0]) raw_data = np.concatenate((data_positive['text'].values[:sample_size], data_negative['text'].values[:sample_size]), axis=0) labels = [1] * sample_size + [0] * sample_size</span></span></code> </pre> <br>  Avant la formation, les textes ont pass√© le traitement pr√©liminaire: <br><br><ul><li>  moul√© en minuscules; <br></li><li>  remplacement de "e" par "e"; <br></li><li>  Remplacement des liens vers le jeton ¬´URL¬ª; <br></li><li>  remplacement de la mention de l'utilisateur par le jeton UTILISATEUR; <br></li><li>  supprimer les signes de ponctuation. <br></li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocess_text</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text)</span></span></span><span class="hljs-function">:</span></span> text = text.lower().replace(<span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) text = re.sub(<span class="hljs-string"><span class="hljs-string">'((www\.[^\s]+)|(https?://[^\s]+))'</span></span>, <span class="hljs-string"><span class="hljs-string">'URL'</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">'@[^\s]+'</span></span>, <span class="hljs-string"><span class="hljs-string">'USER'</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">'[^a-zA-Z--1-9]+'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, text) text = re.sub(<span class="hljs-string"><span class="hljs-string">' +'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, text) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text.strip() data = [preprocess_text(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> raw_data]</code> </pre> <br>  Ensuite, j'ai divis√© l'ensemble de donn√©es en un √©chantillon de formation et de test dans un rapport 4: 1. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><h2>  Affichage vectoriel des mots </h2><br>  Les donn√©es d'entr√©e du r√©seau neuronal convolutif sont une matrice de hauteur fixe <i>n</i> , o√π chaque ligne est un mappage vectoriel d'un mot dans un espace caract√©ristique de dimension <i>k</i> .  Pour former la couche d'int√©gration d'un r√©seau de neurones, j'ai utilis√© l'utilitaire de s√©mantique distributive Word2Vec [5] con√ßu pour cartographier la signification s√©mantique des mots dans l'espace vectoriel.  Word2Vec trouve des relations entre les mots en supposant que les mots s√©mantiquement li√©s se trouvent dans des contextes similaires.  Vous pouvez en savoir plus sur Word2Vec dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article d'origine</a> , ainsi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">qu'ici</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  √âtant donn√© que les tweets sont caract√©ris√©s par la ponctuation des auteurs et des √©motic√¥nes, la d√©finition des limites des phrases devient une t√¢che plut√¥t longue.  Dans ce travail, j'ai suppos√© que chaque tweet ne contient qu'une seule phrase. <br><br>  La base de tweets non allou√©s est stock√©e au format SQL et contient plus de 17,5 millions d'enregistrements.  Pour plus de commodit√©, je l'ai converti en SQLite √† l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce</a> script. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sqlite3 <span class="hljs-comment"><span class="hljs-comment">#  SQLite   conn = sqlite3.connect('mysqlite3.db') c = conn.cursor() with open('data/tweets.txt', 'w', encoding='utf-8') as f: #    for row in c.execute('SELECT ttext FROM sentiment'): if row[0]: tweet = preprocess(row[0]) #      print(tweet, file=f)</span></span></code> </pre> <br>  Ensuite, en utilisant la biblioth√®que Gensim, j'ai form√© le mod√®le Word2Vec avec les param√®tres suivants: <br><br><ul><li>  <i>taille = 200</i> - dimension de l'espace attributaire; <br></li><li>  <i>window = 5</i> - le nombre de mots du contexte que l'algorithme analyse; <br></li><li>  <i>min_count = 3</i> - le mot doit appara√Ætre au moins trois fois pour que le mod√®le en <i>tienne</i> compte. <br></li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> multiprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gensim <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gensim.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Word2Vec logging.basicConfig(format=<span class="hljs-string"><span class="hljs-string">'%(asctime)s : %(levelname)s : %(message)s'</span></span>, level=logging.INFO) <span class="hljs-comment"><span class="hljs-comment">#      data = gensim.models.word2vec.LineSentence('data/tweets.txt') #   model = Word2Vec(data, size=200, window=5, min_count=3, workers=multiprocessing.cpu_count()) model.save("models/w2v/model.w2v")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/uk/zh/h0/ukzhh0kwiptrhim7tygo1vh5vwq.png"><br>  <i>Figure 2. Visualisation de groupes de mots similaires √† l'aide de t-SNE.</i> <br><br>  Pour une compr√©hension plus d√©taill√©e du fonctionnement de Word2Vec sur la Fig.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La figure</a> 2 montre la visualisation de plusieurs grappes de mots similaires du mod√®le entra√Æn√©, mapp√©s dans un espace bidimensionnel √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'</a> aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'algorithme de visualisation t-SNE</a> . <br><br><h2>  Affichage vectoriel des textes </h2><br><img src="https://habrastorage.org/webt/er/de/wc/erdewcunafpymiafxeqgby-8-h8.png"><br>  <i>Fig 3. La distribution de la longueur des textes.</i> <br><br>  √Ä l'√©tape suivante, chaque texte a √©t√© mapp√© √† un tableau d'identificateurs de jeton.  J'ai choisi la dimension du vecteur texte <i>s = 26</i> , car √† cette valeur 99,71% de tous les textes du corps form√© sont enti√®rement couverts (Fig. 3).  Si lors de l'analyse le nombre de mots dans le tweet d√©passait la hauteur de la matrice, les mots restants √©taient jet√©s et n'√©taient pas pris en compte dans la classification.  La dimension finale de la matrice de proposition √©tait <i>s √ó d = 26 √ó 200</i> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.sequence <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pad_sequences <span class="hljs-comment"><span class="hljs-comment">#   (    ) SENTENCE_LENGTH = 26 #   NUM = 100000 def get_sequences(tokenizer, x): sequences = tokenizer.texts_to_sequences(x) return pad_sequences(sequences, maxlen=SENTENCE_LENGTH) # C    tokenizer = Tokenizer(num_words=NUM) tokenizer.fit_on_texts(x_train) #        x_train_seq = get_sequences(tokenizer, x_train) x_test_seq = get_sequences(tokenizer, x_test)</span></span></code> </pre> <br><h2>  R√©seau de neurones convolutifs </h2><br>  Pour construire un r√©seau neuronal, j'ai utilis√© la biblioth√®que Keras, qui agit comme un module compl√©mentaire de haut niveau pour TensorFlow, CNTK et Theano.  Keras poss√®de une excellente documentation, ainsi qu'un blog qui couvre de nombreuses t√¢ches d'apprentissage automatique, telles que l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">initialisation de la couche d'int√©gration</a> .  Dans notre cas, la couche d'int√©gration a √©t√© initi√©e par les poids obtenus en apprenant Word2Vec.  Pour minimiser les changements dans la couche d'int√©gration, je l'ai gel√©e au premier stade de la formation. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers.embeddings <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Embedding tweet_input = Input(shape=(SENTENCE_LENGTH,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) tweet_encoder = Embedding(NUM, DIM, input_length=SENTENCE_LENGTH, weights=[embedding_matrix], trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)(tweet_input)</code> </pre> <br>  Dans l'architecture d√©velopp√©e, des filtres de hauteur <i>h = (2, 3, 4, 5)</i> ont √©t√© utilis√©s, qui sont con√ßus pour le traitement parall√®le de bigrammes, trigrammes, 4 grammes et 5 grammes, respectivement.  Ajout de 10 couches convolutionnelles √† chaque r√©seau de neurones pour chaque hauteur de filtre, la fonction d'activation est ReLU.  Les recommandations pour trouver la hauteur optimale et le nombre de filtres se trouvent dans [2]. <br><br>  Apr√®s traitement par couches de convolution, les cartes d'attributs ont √©t√© introduites dans des couches de sous-√©chantillonnage, o√π l'op√©ration de regroupement 1-max leur a √©t√© appliqu√©e, extrayant ainsi les n-grammes les plus significatifs du texte.  √Ä l'√©tape suivante, ils ont fusionn√© en un vecteur caract√©ristique commun (couche de combinaison), qui a √©t√© introduit dans une couche cach√©e enti√®rement connect√©e avec 30 neurones.  √Ä la derni√®re √©tape, la carte des caract√©ristiques finale a √©t√© envoy√©e √† la couche de sortie du r√©seau neuronal avec une fonction d'activation sigmo√Ødale. <br><br>  √âtant donn√© que les r√©seaux de neurones sont susceptibles de se recycler, apr√®s la couche d'int√©gration et avant la couche enti√®rement connect√©e cach√©e, j'ai ajout√© une r√©gularisation de d√©crochage avec la probabilit√© d'une √©jection de vertex p = 0,2. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> optimizers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, concatenate, Activation, Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers.convolutional <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Conv1D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers.pooling <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GlobalMaxPooling1D branches = [] <span class="hljs-comment"><span class="hljs-comment">#  dropout- x = Dropout(0.2)(tweet_encoder) for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]: for i in range(filters_count): #    branch = Conv1D(filters=1, kernel_size=size, padding='valid', activation='relu')(x) #    branch = GlobalMaxPooling1D()(branch) branches.append(branch) #    x = concatenate(branches, axis=1) #  dropout- x = Dropout(0.2)(x) x = Dense(30, activation='relu')(x) x = Dense(1)(x) output = Activation('sigmoid')(x) model = Model(inputs=[tweet_input], outputs=[output])</span></span></code> </pre> <br>  J'ai configur√© le mod√®le final avec la fonction d'optimisation d'Adam (Adaptive Moment Estimation) et l'entropie crois√©e binaire en fonction des erreurs.  La qualit√© du classificateur a √©t√© √©valu√©e en termes d'exactitude macro-moyenne, d'exhaustivit√© et de mesures f. <br><br><pre> <code class="python hljs">model.compile(loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[precision, recall, f1]) model.summary()</code> </pre> <br>  Au premier stade de la formation, la couche d'int√©gration a √©t√© gel√©e, toutes les autres couches ont √©t√© form√©es pendant 10 √©poques: <br><br><ul><li>  La taille du groupe d'exemples utilis√© pour la formation est de 32. <br></li><li>  Taille de l'√©chantillon de validation: 25%. <br></li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint checkpoint = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">"models/cnn/cnn-frozen-embeddings-{epoch:02d}-{val_f1:.2f}.hdf5"</span></span>, monitor=<span class="hljs-string"><span class="hljs-string">'val_f1'</span></span>, save_best_only=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'max'</span></span>, period=<span class="hljs-number"><span class="hljs-number">1</span></span>) history = model.fit(x_train_seq, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.25</span></span>, callbacks = [checkpoint])</code> </pre> <br><br><div class="spoiler">  <b class="spoiler_title">Journaux</b> <div class="spoiler_text"> <code>Train on 134307 samples, validate on 44769 samples <br> Epoch 1/10 <br> 134307/134307 [==============================] - 221s 2ms/step - loss: 0.5703 - precision: 0.7006 - recall: 0.6854 - f1: 0.6839 - val_loss: 0.5014 - val_precision: 0.7538 - val_recall: 0.7493 - val_f1: 0.7452 <br> Epoch 2/10 <br> 134307/134307 [==============================] - 218s 2ms/step - loss: 0.5157 - precision: 0.7422 - recall: 0.7258 - f1: 0.7263 - val_loss: 0.4911 - val_precision: 0.7413 - val_recall: 0.7924 - val_f1: 0.7602 <br> Epoch 3/10 <br> 134307/134307 [==============================] - 213s 2ms/step - loss: 0.5023 - precision: 0.7502 - recall: 0.7337 - f1: 0.7346 - val_loss: 0.4825 - val_precision: 0.7750 - val_recall: 0.7411 - val_f1: 0.7512 <br> Epoch 4/10 <br> 134307/134307 [==============================] - 215s 2ms/step - loss: 0.4956 - precision: 0.7545 - recall: 0.7412 - f1: 0.7407 - val_loss: 0.4747 - val_precision: 0.7696 - val_recall: 0.7590 - val_f1: 0.7584 <br> Epoch 5/10 <br> 134307/134307 [==============================] - 229s 2ms/step - loss: 0.4891 - precision: 0.7587 - recall: 0.7492 - f1: 0.7473 - val_loss: 0.4781 - val_precision: 0.8014 - val_recall: 0.7004 - val_f1: 0.7409 <br> Epoch 6/10 <br> 134307/134307 [==============================] - 217s 2ms/step - loss: 0.4830 - precision: 0.7620 - recall: 0.7566 - f1: 0.7525 - val_loss: 0.4749 - val_precision: 0.7877 - val_recall: 0.7411 - val_f1: 0.7576 <br> Epoch 7/10 <br> 134307/134307 [==============================] - 219s 2ms/step - loss: 0.4802 - precision: 0.7632 - recall: 0.7568 - f1: 0.7532 - val_loss: 0.4730 - val_precision: 0.7969 - val_recall: 0.7241 - val_f1: 0.7522 <br> Epoch 8/10 <br> 134307/134307 [==============================] - 215s 2ms/step - loss: 0.4769 - precision: 0.7644 - recall: 0.7605 - f1: 0.7558 - val_loss: 0.4680 - val_precision: 0.7829 - val_recall: 0.7542 - val_f1: 0.7619 <br> Epoch 9/10 <br> 134307/134307 [==============================] - 227s 2ms/step - loss: 0.4741 - precision: 0.7657 - recall: 0.7663 - f1: 0.7598 - val_loss: 0.4672 - val_precision: 0.7695 - val_recall: 0.7784 - val_f1: 0.7682 <br> Epoch 10/10 <br> 134307/134307 [==============================] - 221s 2ms/step - loss: 0.4727 - precision: 0.7670 - recall: 0.7647 - f1: 0.7590 - val_loss: 0.4673 - val_precision: 0.7833 - val_recall: 0.7561 - val_f1: 0.7636</code> <br> </div></div><br><br>  Il a ensuite s√©lectionn√© le mod√®le avec les mesures F les plus √©lev√©es sur l'ensemble de donn√©es de validation, c'est-√†-dire  mod√®le obtenu √† la huiti√®me √©poque de l'√©ducation (F <sub>1</sub> = 0,77971).  Le mod√®le a d√©congel√© la couche d'int√©gration, apr√®s quoi il a lanc√© cinq autres p√©riodes d'entra√Ænement. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> optimizers <span class="hljs-comment"><span class="hljs-comment">#    model.load_weights('models/cnn/cnn-frozen-embeddings-09-0.77.hdf5') #  embedding     model.layers[1].trainable = True #  learning rate adam = optimizers.Adam(lr=0.0001) model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[precision, recall, f1]) model.summary() checkpoint = ModelCheckpoint("models/cnn/cnn-trainable-{epoch:02d}-{val_f1:.2f}.hdf5", monitor='val_f1', save_best_only=True, mode='max', period=1) history_trainable = model.fit(x_train_seq, y_train, batch_size=32, epochs=5, validation_split=0.25, callbacks = [checkpoint])</span></span></code> </pre> <br><br><div class="spoiler">  <b class="spoiler_title">Journaux</b> <div class="spoiler_text"> <code>Train on 134307 samples, validate on 44769 samples <br> Epoch 1/5 <br> 134307/134307 [==============================] - 2042s 15ms/step - loss: 0.4495 - precision: 0.7806 - recall: 0.7797 - f1: 0.7743 - val_loss: 0.4560 - val_precision: 0.7858 - val_recall: 0.7671 - val_f1: 0.7705 <br> Epoch 2/5 <br> 134307/134307 [==============================] - 2253s 17ms/step - loss: 0.4432 - precision: 0.7857 - recall: 0.7842 - f1: 0.7794 - val_loss: 0.4543 - val_precision: 0.7923 - val_recall: 0.7572 - val_f1: 0.7683 <br> Epoch 3/5 <br> 134307/134307 [==============================] - 2018s 15ms/step - loss: 0.4372 - precision: 0.7899 - recall: 0.7879 - f1: 0.7832 - val_loss: 0.4519 - val_precision: 0.7805 - val_recall: 0.7838 - val_f1: 0.7767 <br> Epoch 4/5 <br> 134307/134307 [==============================] - 1901s 14ms/step - loss: 0.4324 - precision: 0.7943 - recall: 0.7904 - f1: 0.7869 - val_loss: 0.4504 - val_precision: 0.7825 - val_recall: 0.7808 - val_f1: 0.7762 <br> Epoch 5/5 <br> 134307/134307 [==============================] - 1924s 14ms/step - loss: 0.4256 - precision: 0.7986 - recall: 0.7947 - f1: 0.7913 - val_loss: 0.4497 - val_precision: 0.7989 - val_recall: 0.7549 - val_f1: 0.7703</code> <br> </div></div><br><br>  L'indicateur <i>F <sub>1 le</sub></i> plus √©lev√© <i>= 76,80%</i> dans l'√©chantillon de validation a √©t√© atteint dans la troisi√®me √®re de la formation.  La qualit√© du mod√®le form√© sur les donn√©es de test √©tait <i>F <sub>1</sub> = 78,1%</i> . <br><br>  Tableau 1. Qualit√© de l'analyse des sentiments sur les donn√©es de test. <br><div class="scrollable-table"><table><tbody><tr><td>  √âtiquette de classe <br></td><td>  Pr√©cision <br></td><td>  Compl√©tude <br></td><td>  F <sub>1</sub> <br></td><td>  Nombre d'objets <br></td></tr><tr><td>  N√©gatif <br></td><td>  0,78194 <br></td><td>  0,78243 <br></td><td>  0,78218 <br></td><td>  22457 <br></td></tr><tr><td>  Positif <br></td><td>  0,78089 <br></td><td>  0,78040 <br></td><td>  0,78064 <br></td><td>  22313 <br></td></tr><tr><td>  moy / total <br></td><td>  0,78142 <br></td><td>  0,78142 <br></td><td>  0,78142 <br></td><td>  44770 <br></td></tr></tbody></table></div><br><h2>  R√©sultat </h2><br>  En tant que solution de base, j'ai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">form√© un</a> classificateur bay√©sien na√Øf avec un mod√®le de distribution multinomial, les r√©sultats de la comparaison sont pr√©sent√©s dans le tableau.  2. <br><br>  Tableau 2. Comparaison de la qualit√© de l'analyse de tonalit√©. <br><div class="scrollable-table"><table><tbody><tr><td>  Classificateur <br></td><td>  Pr√©cision <br></td><td>  Rappel <br></td><td>  F <sub>1</sub> <br></td></tr><tr><td>  Mnb <br></td><td>  0,7577 <br></td><td>  0,7564 <br></td><td>  0,7560 <br></td></tr><tr><td>  CNN <br></td><td>  <b>0,78142</b> <br></td><td>  <b>0,78142</b> <br></td><td>  <b>0,78142</b> <br></td></tr></tbody></table></div><br>  Comme vous pouvez le voir, la qualit√© de la classification CNN a d√©pass√© MNB de plusieurs pour cent.  Les valeurs m√©triques peuvent √™tre encore augment√©es si vous travaillez sur l'optimisation des hyperparam√®tres et de l'architecture r√©seau.  Par exemple, vous pouvez modifier le nombre d'√©poques d'apprentissage, v√©rifier l'efficacit√© de l'utilisation de diverses repr√©sentations vectorielles des mots et de leurs combinaisons, s√©lectionner le nombre de filtres et leur hauteur, impl√©menter un pr√©traitement de texte plus efficace (correction de faute de frappe, normalisation, estampage), ajuster le nombre de couches et de neurones enti√®rement connect√©s cach√©s. . <br><br>  Le code source <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">est disponible sur Github</a> , les mod√®les CNN et Word2Vec form√©s peuvent √™tre t√©l√©charg√©s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><h2>  Les sources </h2><br><ol><li>  Cliche M. BB_twtr √† SemEval-2017 T√¢che 4: Analyse de sentiment Twitter avec CNN et LSTM // Actes du 11e atelier international sur l'√©valuation s√©mantique (SemEval-2017).  - 2017 .-- art.573-580. <br></li><li>  Zhang Y., Wallace B. Une analyse de sensibilit√© des r√©seaux neuronaux convolutionnels (et le guide du praticien) pour la classification des phrases // arXiv preprint arXiv: 1510.03820.  - 2015. <br></li><li>  Rosenthal S., Farra N., Nakov P. SemEval-2017 t√¢che 4: Analyse de sentiment sur Twitter // Actes du 11e atelier international sur l'√©valuation s√©mantique (SemEval-2017).  - 2017 .-- art.502-518. <br></li><li>  Yu. V. Rubtsova.  Construire un corps de textes pour d√©finir le classificateur de tonalit√© // Produits et syst√®mes logiciels, 2015, n ¬∞ 1 (109), ‚ÄîC.72-78. <br></li><li>  Mikolov T. et al.  Repr√©sentations distribu√©es des mots et des phrases et leur compositionnalit√© // Advances in Neural Information Processing Systems.  - 2013 .-- S. 3111-3119. <br></li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417767/">https://habr.com/ru/post/fr417767/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417755/index.html">√âtude: 80% des ICO 2017 consid√©r√©es comme frauduleuses</a></li>
<li><a href="../fr417757/index.html">Cr√©ation d'un bot pour participer √† la mini coupe AI. Exp√©rience GPU</a></li>
<li><a href="../fr417759/index.html">Sois mon canard en caoutchouc</a></li>
<li><a href="../fr417761/index.html">GitLab passe d'Azure √† Google Cloud Platform. Nouvelles sur la r√©installation et dates de maintenance</a></li>
<li><a href="../fr417763/index.html">MVIDroid: une revue de la nouvelle biblioth√®que MVI (Model-View-Intent)</a></li>
<li><a href="../fr417769/index.html">Conception de la m√©moire utilisateur: comment concevoir pour les √¢ges</a></li>
<li><a href="../fr417771/index.html">Plan de l'ICANN: la soci√©t√© propose un nouveau mod√®le de gestion de serveur racine DNS</a></li>
<li><a href="../fr417773/index.html">Installateur de composants OpenPnP fait maison</a></li>
<li><a href="../fr417775/index.html">M√©canisme de commission Bitcoin et pourquoi √™tre ami avec les mineurs</a></li>
<li><a href="../fr417777/index.html">Week-end de lecture: 25 documents pour les amateurs de vinyle d√©butants</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
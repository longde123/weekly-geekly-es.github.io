<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòï üòª üßîüèΩ Dicas e truques do Kubernetes: aloca√ß√£o de n√≥s e carregamento de aplicativos da web üñêüèæ üë®üèø‚Äçüíª üè°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Na continua√ß√£o de nossos artigos pr√°ticos sobre como facilitar a vida no trabalho di√°rio com o Kubernetes, falamos sobre duas hist√≥rias do mundo das o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Dicas e truques do Kubernetes: aloca√ß√£o de n√≥s e carregamento de aplicativos da web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/432748/"><img src="https://habrastorage.org/webt/7r/gv/ix/7rgvixbeoe0vyfkw__obak6ow_y.jpeg"><br><br>  Na continua√ß√£o de nossos artigos pr√°ticos sobre como facilitar a vida no trabalho di√°rio com o Kubernetes, falamos sobre duas hist√≥rias do mundo das opera√ß√µes: a aloca√ß√£o de n√≥s individuais para tarefas espec√≠ficas e a configura√ß√£o do php-fpm (ou outro servidor de aplicativos) para cargas pesadas.  Como antes, as solu√ß√µes descritas aqui n√£o afirmam ser ideais, mas s√£o oferecidas como ponto de partida para seus casos espec√≠ficos e base para reflex√£o.  Perguntas e melhorias nos coment√°rios s√£o bem-vindas! <a name="habracut"></a><br><br><h2>  1. A aloca√ß√£o de n√≥s individuais para tarefas espec√≠ficas </h2><br>  Estamos criando um cluster Kubernetes em servidores virtuais, nuvens ou servidores bare metal.  Se voc√™ instalar todo o software do sistema e aplicativos clientes nos mesmos n√≥s, √© prov√°vel que ocorram problemas: <br><br><ul><li>  o aplicativo cliente de repente come√ßar√° a "vazar" da mem√≥ria, embora seus limites sejam muito altos; </li><li>  solicita√ß√µes complexas √∫nicas para loghouse, Prometheus ou Ingress * levam ao OOM, como resultado do aplicativo cliente; </li><li>  um vazamento de mem√≥ria devido a um bug no software do sistema mata o aplicativo cliente, embora os componentes possam n√£o estar logicamente conectados entre si. </li></ul><br>  <i>* Entre outras coisas, era relevante para vers√µes mais antigas do Ingress, quando, devido ao grande n√∫mero de conex√µes de websocket e recarregamentos constantes do nginx, "processos pendentes do nginx" apareceram, que chegaram a milhares e consumiram uma enorme quantidade de recursos.</i> <br><br>  O caso real √© com a instala√ß√£o do Prometheus com um grande n√∫mero de m√©tricas, nas quais, ao visualizar o painel "pesado", onde √© apresentado um grande n√∫mero de cont√™ineres de aplicativos, a partir de cada um dos gr√°ficos, o consumo de mem√≥ria rapidamente cresceu para ~ 15 GB.  Como resultado, o OOM killer poderia "entrar" no sistema host e come√ßar a matar outros servi√ßos, o que por sua vez levou a "um comportamento incompreens√≠vel dos aplicativos no cluster".  E devido √† alta carga de CPU no aplicativo cliente, √© f√°cil obter um tempo inst√°vel de processamento de consultas do Ingress ... <br><br>  A solu√ß√£o rapidamente surgiu: era necess√°rio alocar m√°quinas individuais para diferentes tarefas.  Identificamos tr√™s tipos principais de grupos de tarefas: <br><br><ol><li>  <b>Frentes</b> , onde colocamos apenas o Ingresss, para garantir que nenhum outro servi√ßo possa afetar o tempo de processamento das solicita√ß√µes; </li><li>  <b>N√≥s do sistema</b> nos quais implantamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VPNs</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">loghouse</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Prometheus</a> , Dashboard, CoreDNS, etc; </li><li>  <b>N√≥s para aplicativos</b> - na verdade, onde os aplicativos clientes s√£o lan√ßados.  Eles tamb√©m podem ser alocados para ambientes ou funcionalidades: dev, prod, perf, ... </li></ol><br><h3>  Solu√ß√£o </h3><br>  Como implementamos isso?  Muito simples: dois mecanismos nativos do Kubernetes.  O primeiro √© o <b>nodeSelector</b> para selecionar o n√≥ desejado para onde o aplicativo deve ir, com base nos r√≥tulos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">instalados</a> em cada n√≥. <br><br>  Digamos que temos um <code>kube-system-1</code> .  Adicionamos um r√≥tulo adicional a ele: <br><br><pre> <code class="bash hljs">$ kubectl label node kube-system-1 node-role/monitoring=</code> </pre> <br>  ... e em <code>Deployment</code> , que deve ser implementada neste n√≥, escrevemos: <br><br><pre> <code class="plaintext hljs">nodeSelector: node-role/monitoring: ""</code> </pre> <br>  O segundo mecanismo s√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><b>tens√µes e toler√¢ncias</b></a> .  Com sua ajuda, indicamos explicitamente que nessas m√°quinas somente os cont√™ineres podem ser lan√ßados com toler√¢ncia a essa contamina√ß√£o. <br><br>  Por exemplo, existe uma <code>kube-frontend-1</code> na qual apenas <code>kube-frontend-1</code> Ingress.  Inclua m√°cula neste n√≥: <br><br><pre> <code class="bash hljs">$ kubectl taint node kube-frontend-1 node-role/frontend=<span class="hljs-string"><span class="hljs-string">""</span></span>:NoExecute</code> </pre> <br>  ... e na <code>Deployment</code> , criamos toler√¢ncia: <br><br><pre> <code class="plaintext hljs">tolerations: - effect: NoExecute key: node-role/frontend</code> </pre> <br>  No caso de kops, grupos de inst√¢ncias individuais podem ser criados para as mesmas necessidades: <br><br><pre> <code class="bash hljs">$ kops create ig --name cluster_name IG_NAME</code> </pre> <br>  ... e voc√™ obt√©m algo como esta configura√ß√£o de grupo de inst√¢ncias no kops: <br><br><pre> <code class="plaintext hljs">apiVersion: kops/v1alpha2 kind: InstanceGroup metadata: creationTimestamp: 2017-12-07T09:24:49Z labels: dedicated: monitoring kops.k8s.io/cluster: k-dev.k8s name: monitoring spec: image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2018-01-14 machineType: m4.4xlarge maxSize: 2 minSize: 2 nodeLabels: dedicated: monitoring role: Node subnets: - eu-central-1c taints: - dedicated=monitoring:NoSchedule</code> </pre> <br>  Portanto, os n√≥s desse grupo de inst√¢ncias adicionam automaticamente um r√≥tulo e uma mancha adicionais. <br><br><h2>  2. Configurando php-fpm para cargas pesadas </h2><br>  Existe uma grande variedade de servidores que s√£o usados ‚Äã‚Äãpara executar aplicativos da Web: php-fpm, gunicorn e similares.  Seu uso no Kubernetes significa que h√° v√°rias coisas em que voc√™ deve sempre pensar: <br><br><ul><li>  √â <b>necess√°rio</b> entender aproximadamente <b>quantos trabalhadores</b> estamos dispostos a alocar em php-fpm em cada cont√™iner.  Por exemplo, podemos alocar 10 trabalhadores para processar solicita√ß√µes de entrada, alocar menos recursos para pod e escalar com o n√∫mero de pods - essa √© uma boa pr√°tica.  Outro exemplo √© alocar 500 trabalhadores para cada pod e ter 2-3 desses pods em produ√ß√£o ... mas essa √© uma p√©ssima id√©ia. </li><li>  <b>Testes de vida √∫til / prontid√£o s√£o</b> necess√°rios para verificar a opera√ß√£o correta de cada pod e, caso o pod esteja bloqueado devido a problemas de rede ou devido ao acesso ao banco de dados (pode haver alguma das suas op√ß√µes e motivo).  Em tais situa√ß√µes, voc√™ precisa recriar o pod problem√°tico. </li><li>  √â importante registrar explicitamente a <b>solicita√ß√£o e limitar os recursos</b> para cada cont√™iner, para que o aplicativo n√£o "flua" e n√£o comece a prejudicar todos os servi√ßos neste servidor. </li></ul><br><h3>  Solu√ß√µes </h3><br>  Infelizmente, <b>n√£o existe uma bala de prata</b> que o ajude a entender imediatamente quantos recursos (CPU, RAM) um aplicativo pode precisar.  Uma op√ß√£o poss√≠vel √© observar o consumo de recursos e sempre selecionar os valores ideais.  Para evitar kill'ov injustificado do OOM e limita√ß√£o da CPU, que afetam bastante o servi√ßo, voc√™ pode oferecer: <br><br><ul><li>  adicione os testes corretos de disponibilidade / prontid√£o para garantir que este cont√™iner esteja funcionando corretamente.  Provavelmente, ser√° uma p√°gina de servi√ßo que verifica a disponibilidade de todos os elementos de infraestrutura (necess√°rios para que o aplicativo funcione no pod) e retorna um c√≥digo de resposta 200 OK; </li><li>  selecione corretamente o n√∫mero de trabalhadores que processar√£o solicita√ß√µes e distribua-as corretamente. </li></ul><br>  Por exemplo, temos 10 pods que consistem em dois cont√™ineres: nginx (para enviar solicita√ß√µes est√°ticas e de proxy ao back-end) e php-fpm (na verdade, o back-end, que processa p√°ginas din√¢micas).  O pool de php-fpm est√° configurado para um n√∫mero est√°tico de trabalhadores (10).  Assim, em uma unidade de tempo, podemos processar 100 solicita√ß√µes ativas para back-end.  Deixe cada solicita√ß√£o ser processada pelo PHP em 1 segundo. <br><br>  O que acontece se mais uma solicita√ß√£o chegar em um pod espec√≠fico, no qual 10 solicita√ß√µes est√£o sendo processadas ativamente agora?  O PHP n√£o poder√° process√°-lo e o Ingress o enviar√° para tentar novamente no pr√≥ximo pod, se for uma solicita√ß√£o GET.  Se houve uma solicita√ß√£o POST, ele retornar√° um erro. <br><br>  E se levarmos em conta que, durante o processamento de todas as 10 solicita√ß√µes, receberemos uma verifica√ß√£o do kubelet (sonda liveness), ela terminar√° com um erro e o Kubernetes come√ßar√° a pensar que algo est√° errado com esse cont√™iner e o matar√°.  Nesse caso, todas as solicita√ß√µes processadas no momento terminar√£o com um erro (!). No momento da reinicializa√ß√£o do cont√™iner, ele ficar√° desequilibrado, o que implicar√° em um aumento nas solicita√ß√µes de todos os outros back-ends. <br><br><h4>  Claramente </h4><br>  Suponha que tenhamos 2 pods, cada um com 10 trabalhadores de php-fpm configurados.  Aqui est√° um gr√°fico que exibe informa√ß√µes durante o "tempo de inatividade", ou seja,  quando o √∫nico solicitante do php-fpm √© o exportador do php-fpm (temos um trabalhador ativo cada): <br><br><img src="https://habrastorage.org/webt/zo/hw/ea/zohwea7nsfbofpgvhixp7edc-qk.png"><br><br>  Agora inicie a inicializa√ß√£o com a concorr√™ncia 19: <br><br><img src="https://habrastorage.org/webt/my/ba/hp/mybahpcgbfoqzzazbwtzu9dc46a.png"><br><br>  Agora vamos tentar aumentar a simultaneidade do que conseguimos (20) ... digamos 23. Ent√£o todos os trabalhadores de php-fpm est√£o ocupados processando solicita√ß√µes de clientes: <br><br><img src="https://habrastorage.org/webt/tq/v6/f1/tqv6f1fopruyz8_zittdan1pkho.png"><br><br>  Os vorkers n√£o s√£o mais suficientes para processar uma amostra de vivacidade, por isso, vemos esta imagem no painel do Kubernetes (ou <code>describe pod</code> ): <br><br><img src="https://habrastorage.org/webt/7z/qo/fw/7zqofwlbjcmxl0qkz2g2rkerece.png"><br><br>  Agora, quando um dos pods √© reiniciado, <b>ocorre</b> um <b>efeito de avalanche</b> : as solicita√ß√µes come√ßam a cair no segundo pod, que tamb√©m n√£o √© capaz de process√°-las, devido ao qual recebemos um grande n√∫mero de erros dos clientes.  Depois que os pools de todos os cont√™ineres est√£o cheios, aumentar o servi√ßo √© problem√°tico - isso s√≥ √© poss√≠vel por um aumento acentuado no n√∫mero de pods ou trabalhadores. <br><br><h4>  Primeira op√ß√£o </h4><br>  Em um cont√™iner com PHP, voc√™ pode configurar conjuntos de 2 fpm: um para processar solicita√ß√µes de clientes e outro para verificar a capacidade de sobreviv√™ncia do cont√™iner.  Em seguida, no cont√™iner nginx, voc√™ precisar√° fazer uma configura√ß√£o semelhante: <br><br><pre> <code class="plaintext hljs"> upstream backend { server 127.0.0.1:9000 max_fails=0; } upstream backend-status { server 127.0.0.1:9001 max_fails=0; }</code> </pre> <br>  Tudo o que resta √© enviar a amostra de anima√ß√£o para processamento para o upstream chamado <code>backend-status</code> . <br><br>  Agora que o probe liveness √© processado separadamente, ainda ocorrer√£o erros em alguns clientes, mas pelo menos n√£o h√° problemas associados √† reinicializa√ß√£o do pod e √† desconex√£o do restante dos clientes.  Assim, reduziremos bastante o n√∫mero de erros, mesmo que nossos back-end n√£o consigam lidar com a carga atual. <br><br>  Essa op√ß√£o, √© claro, √© melhor que nada, mas tamb√©m √© ruim porque algo pode acontecer com o pool principal, que n√£o saberemos sobre o uso do teste de anima√ß√£o. <br><br><h4>  Segunda op√ß√£o </h4><br>  Voc√™ tamb√©m pode usar o m√≥dulo nginx n√£o muito popular chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nginx-limit-upstream</a> .  Ent√£o, no PHP, especificaremos 11 trabalhadores e, no cont√™iner com nginx, faremos uma configura√ß√£o semelhante: <br><br><pre> <code class="plaintext hljs"> limit_upstream_zone limit 32m; upstream backend { server 127.0.0.1:9000 max_fails=0; limit_upstream_conn limit=10 zone=limit backlog=10 timeout=5s; } upstream backend-status { server 127.0.0.1:9000 max_fails=0; }</code> </pre> <br>  No n√≠vel do frontend, o nginx limitar√° o n√∫mero de solicita√ß√µes que ser√£o enviadas ao backend (10).  Um ponto interessante √© que um backlog especial √© criado: se a 11¬™ solicita√ß√£o de nginx vier do cliente e o nginx perceber que o pool php-fpm est√° ocupado, essa solicita√ß√£o ser√° colocada no backlog por 5 segundos.  Se, durante esse per√≠odo, o php-fpm n√£o for liberado, somente o Ingress entrar√° em a√ß√£o, o que tentar√° novamente a solicita√ß√£o para outro pod.  Isso suaviza a imagem, j√° que sempre teremos 1 trabalhador PHP gr√°tis para processar uma amostra din√¢mica - podemos evitar o efeito de avalanche. <br><br><h4>  Outros pensamentos </h4><br>  Para op√ß√µes mais vers√°teis e bonitas para resolver esse problema, vale a pena procurar na dire√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Envoy</a> e seus an√°logos. <br><br>  Em geral, para que Prometheus tenha um emprego claro de trabalhadores, o que, por sua vez, ajudar√° a encontrar rapidamente o problema (e notific√°-lo), recomendo que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">exportadores</a> prontos para converter dados do software no formato Prometheus. <br><br><h2>  PS </h2><br>  Outro do ciclo de dicas e truques do K8s: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">P√°ginas de erro personalizadas no NGINX Ingress</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Transfer√™ncia de recursos trabalhando em um cluster para gerenciamento do Helm 2</a> ‚Äù; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acesso a sites de desenvolvimento</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acelerando a inicializa√ß√£o de grandes bancos de dados.</a> " </li></ul><br>  Leia tamb√©m em nosso blog: <br><br><ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Como √© fornecida a alta disponibilidade no Kubernetes</a> ‚Äù; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Monitoramento e Kubernetes</a> ‚Äù <i>(revis√£o e reportagem em v√≠deo)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nossa experi√™ncia com o Kubernetes em pequenos projetos</a> " <i>(reportagem em v√≠deo, que inclui uma introdu√ß√£o ao dispositivo t√©cnico do Kubernetes)</i> . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt432748/">https://habr.com/ru/post/pt432748/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt432736/index.html">Devops, JUnit5 e testes de microsservi√ßos: uma vis√£o subjetiva do Heisenbag de Moscou</a></li>
<li><a href="../pt432740/index.html">"CMS" com base nas planilhas do Google para sites est√°ticos</a></li>
<li><a href="../pt432742/index.html">Press√£o de tempo corporativa</a></li>
<li><a href="../pt432744/index.html">DWDM: a solu√ß√£o √© mais barata que a operadora em 30-50% (classe Enterprise)</a></li>
<li><a href="../pt432746/index.html">Por tr√™s dias em terapia intensiva ou o que h√° de errado com a se√ß√£o Equil√≠brio entre vida profissional e pessoal no Mobius'18?</a></li>
<li><a href="../pt432750/index.html">A alegria de Haxe. Um romance com uma linguagem de programa√ß√£o negligenciada</a></li>
<li><a href="../pt432752/index.html">Formigueiro ou fortaleza? Estou construindo uma casa pelo pre√ßo de um apartamento. 3 parte. Fonte de alimenta√ß√£o</a></li>
<li><a href="../pt432754/index.html">Armazenamento de dados em mem√≥ria e em disco trar√° ao p√∫blico</a></li>
<li><a href="../pt432756/index.html">Implementamos suporte √† acessibilidade sem alterar o componente visual do aplicativo m√≥vel</a></li>
<li><a href="../pt432760/index.html">Exibi√ß√µes de produtos vetoriais ou outro uso do modelo Word2Vec</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
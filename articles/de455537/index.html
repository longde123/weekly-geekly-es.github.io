<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôÖüèø üéñÔ∏è ‚õàÔ∏è Umfassende Suchoptimierung: So verarbeiten Sie ein Diagramm mit 10 Milliarden Status üõ∞Ô∏è üßú ü§ú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor ein paar Monaten musste ich endlich zugeben, dass ich nicht klug genug war, um einige Level des Snakebird- Puzzles durchzugehen . Die einzige M√∂gl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Umfassende Suchoptimierung: So verarbeiten Sie ein Diagramm mit 10 Milliarden Status</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455537/"><div style="text-align:center;"><img src="https://nordicgame.com/wp-content/uploads/2015/05/noumenon.games_.snakebird.850.560.jpg" alt="Bild"></div><br>  Vor ein paar Monaten musste ich endlich zugeben, dass ich nicht klug genug war, um einige Level des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Snakebird-</a> Puzzles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durchzugehen</a> .  Die einzige M√∂glichkeit, etwas von dem Selbstwertgef√ºhl wiederzugewinnen, bestand darin, einen L√∂ser zu schreiben.  Ich k√∂nnte also so tun, als w√§re das Erstellen eines Programms zum L√∂sen des Puzzles fast dasselbe wie das L√∂sen selbst.  Der Code f√ºr das resultierende C ++ - Programm ist auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github</a> verf√ºgbar.  Der Hauptteil des im Artikel ber√ºcksichtigten Codes ist in <a href="">search.h</a> und <a href="">compress.h</a> implementiert.  In diesem Beitrag werde ich haupts√§chlich √ºber die Optimierung einer Breitensuche sprechen, die 50 bis 100 GB Speicher ben√∂tigt, um in 4 GB zu passen. <br><br>  Sp√§ter werde ich einen weiteren Beitrag schreiben, der die Besonderheiten des Spiels beschreibt.  In diesem Beitrag m√ºssen Sie wissen, dass ich keine guten Alternativen zu Brute Force finden konnte, da keiner der √ºblichen Tricks funktioniert hat.  Das Spiel hat viele Zust√§nde, da es viele sich bewegende oder geschobene Objekte gibt und die Form einiger von ihnen wichtig ist, was sich im Laufe der Zeit √§ndern kann.  Es gab keine geeignete konservative Heuristik f√ºr Algorithmen wie A *, um den Suchraum einzugrenzen.  Der Suchgraph war orientiert und implizit spezifiziert, daher war eine gleichzeitige Suche in Vorw√§rts- und R√ºckw√§rtsrichtung unm√∂glich.  Der einzige Schritt k√∂nnte den Zustand in vielerlei Hinsicht ver√§ndern, sodass nichts so n√ºtzlich sein k√∂nnte wie das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hashing von Zobrist</a> . <br><br>  Grobe Sch√§tzungen haben gezeigt, dass es im gr√∂√üten Puzzle nach Eliminierung aller symmetrischen Positionen etwa 10 Milliarden Staaten geben wird.  Selbst nach dem Packen von Zustandsbeschreibungen mit maximaler Dichte betrug die Zustandsgr√∂√üe 8-10 Bytes.  Mit 100 GB Arbeitsspeicher w√§re die Aufgabe trivial, aber nicht f√ºr meinen Heimcomputer mit 16 GB Arbeitsspeicher.  Und da Chrome 12 GB davon ben√∂tigt, liegt mein realer Speicherbedarf n√§her bei 4 GB.  Alles, was dieses Volumen √ºberschreitet, muss auf der Festplatte gespeichert werden (alte und rostige Festplatte). <br><a name="habracut"></a><br>  Wie passt man 100 GB Daten in 4 GB RAM?  Entweder a) die Zust√§nde m√ºssen auf 1/20 ihrer urspr√ºnglichen, bereits optimierten Gr√∂√üe komprimiert werden, oder b) der Algorithmus sollte in der Lage sein, Zust√§nde effektiv auf der Festplatte zu speichern und umgekehrt, oder c) eine Kombination der beiden oben genannten Methoden, oder d) ich muss mehr kaufen RAM oder mieten Sie eine leistungsstarke virtuelle Maschine f√ºr mehrere Tage.  Option D habe ich nicht in Betracht gezogen, weil es zu langweilig ist.  Die Optionen A und B wurden nach dem Proof of Concept mit gzip ausgeschlossen: Ein Fragment einer Zustandsbeschreibung von 50 MB wurde auf nur 35 MB komprimiert.  Dies sind ungef√§hr 7 Bytes pro Zustand, und mein Speicher ist ungef√§hr 0,4 Bytes pro Zustand.  Das hei√üt, Option B blieb bestehen, obwohl die Breitensuche f√ºr die Speicherung auf sekund√§ren Laufwerken eher unpraktisch schien. <br><br><h2>  Inhalt </h2><br>  Dies ist ein ziemlich langer Beitrag, daher hier ein kurzer √úberblick √ºber die folgenden Abschnitte: <br><br><ul><li>  Breitensuche Breitensuche - Wie lautet der √ºbliche Wortlaut der Breitensuche (BFS) und warum eignet er sich nicht zum Speichern von Teilen eines Status auf der Festplatte? </li><li>  <b>BFS mit Sortieren und Zusammenf√ºhren</b> - eine √Ñnderung des Algorithmus zur effizienten Stapelentsorgung redundanter Daten. </li><li>  <b>Komprimierung</b> - Reduziert den Speicherbedarf aufgrund der Kombination aus Standard- und nativer Komprimierung um das Hundertfache. </li><li>  <b>Oh-oh, ich habe geschummelt!</b>  - In den ersten Abschnitten habe ich √ºber etwas geschwiegen: Es reicht nicht aus, nur zu wissen, wo die L√∂sung liegt, aber wir m√ºssen genau verstehen, wie wir sie erreichen k√∂nnen.  In diesem Abschnitt aktualisieren wir den Basisalgorithmus so, dass gen√ºgend Daten √ºbertragen werden, um die L√∂sung aus dem letzten Status neu zu erstellen. </li><li>  <b>Sortieren + Zusammenf√ºhren mit mehreren Ausgaben</b> - Durch das Speichern weiterer Status werden die Vorteile der Komprimierung vollst√§ndig zunichte gemacht.  Der Sortier- und Zusammenf√ºhrungsalgorithmus muss ge√§ndert werden, damit zwei S√§tze von Ausgabedaten gespeichert werden: Einer, gut komprimiert, wird w√§hrend der Suche verwendet, und der andere wird nur verwendet, um die L√∂sung nach dem Finden des ersten neu zu erstellen. </li><li>  <b>Swap</b> - <b>Swap</b> unter Linux ist viel schlimmer als ich dachte. </li><li>  <b>Komprimierung neuer Zust√§nde vor dem Zusammenf√ºhren</b> - Bisher funktionierten Speicheroptimierungen nur mit vielen besuchten Zust√§nden.  Es stellte sich jedoch heraus, dass die Liste der neu generierten Zust√§nde viel gr√∂√üer ist, als Sie vielleicht denken.  Dieser Abschnitt zeigt ein Diagramm zur effizienteren Beschreibung neuer Zust√§nde. </li><li>  <b>Platz sparen in √ºbergeordneten Zust√§nden</b> - Untersuchen Sie die Kompromisse zwischen der Verwendung von CPU / Speicher, um die L√∂sung am Ende neu zu erstellen. </li><li>  <b>Was nicht funktionierte oder vielleicht nicht funktionierte</b> - einige Ideen schienen vielversprechend, aber als Ergebnis mussten sie zur√ºckgesetzt werden, w√§hrend andere, die Forscher sein sollten, in diesem Fall intuitiv unangemessen erscheinen. </li></ul><br><h2>  Breite Suche "nach Lehrbuch" </h2><br>  Wie sieht die Breitensuche aus und warum sollten Sie keine Festplatte darin verwenden?  Vor diesem kleinen Projekt habe ich nur Optionen f√ºr die Formulierung ‚Äûaus Lehrb√ºchern‚Äú in Betracht gezogen, zum Beispiel: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited.add(kid) todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span></code> </pre> <br>  Beim Erstellen neuer Kandidatenknoten durch das Programm wird jeder Knoten mit einer Hash-Tabelle bereits besuchter Knoten √ºberpr√ºft.  Befindet es sich bereits in der Hash-Tabelle, wird der Knoten ignoriert.  Andernfalls wird es der Warteschlange und der Hash-Tabelle hinzugef√ºgt.  Manchmal werden in Implementierungen die "besuchten" Informationen in die Knoten und nicht in eine fremde Tabelle eingegeben.  Dies ist jedoch eine riskante Optimierung und es ist v√∂llig unm√∂glich, wenn der Graph implizit angegeben wird. <br><br>  Warum ist die Verwendung einer Hash-Tabelle problematisch?  Weil Hash-Tabellen dazu neigen, ein v√∂llig zuf√§lliges Speicherzugriffsmuster zu erstellen.  Wenn dies nicht der Fall ist, ist dies eine schlechte Hash-Funktion, und die Hash-Tabelle weist aufgrund von Kollisionen h√∂chstwahrscheinlich eine schlechte Leistung auf.  Dieses Direktzugriffsmuster kann zu Leistungsproblemen f√ºhren, selbst wenn die Daten in den Speicher passen: Der Zugriff auf eine gro√üe Hash-Tabelle f√ºhrt wahrscheinlich zu Cache-Fehlern und TLBs (Assoziative Translation Buffer).  Was aber, wenn sich ein erheblicher Teil der Daten auf der Festplatte und nicht im Speicher befindet?  Die Folgen werden katastrophal sein: etwas in der Gr√∂√üenordnung von 10 ms pro Suchvorgang. <br><br>  Bei 10 Milliarden eindeutigen Status ben√∂tigen wir nur vier Monate, um auf die Datentr√§ger-E / A zu warten, wenn wir nur auf die Hash-Tabelle zugreifen.  Das passt nicht zu uns;  Die Aufgabe muss unbedingt konvertiert werden, damit das Programm gro√üe Datenpakete in einem einzigen Durchgang verarbeiten kann. <br><br><h2>  BFS mit Sortieren und Zusammenf√ºhren </h2><br>  Wenn wir Datenzugriffsvorg√§nge so weit wie m√∂glich in Pakete integrieren m√∂chten, was w√§re dann die maximal erreichbare Ann√§herung?  Da das Programm nicht wei√ü, welche Knoten in einer Schicht der Tiefe N + 1 verarbeitet werden sollen, bis die Schicht N vollst√§ndig verarbeitet ist, scheint es offensichtlich, dass es notwendig ist, Zust√§nde mindestens einmal pro Tiefe zu deduplizieren. <br><br>  Wenn wir gleichzeitig mit der gesamten Ebene arbeiten, k√∂nnen wir Hash-Tabellen aufgeben und die Menge der besuchten und neuen Zust√§nde als sortierte Streams beschreiben (z. B. als Dateistreams, Arrays, Listen).  Wir k√∂nnen die neue besuchte Menge trivial finden, indem wir die Mengen von Fl√ºssen kombinieren, und es ist ebenso trivial, die Menge zu finden, die anhand der Differenz der Mengen zu tun ist. <br><br>  Zwei Operationen mit S√§tzen k√∂nnen kombiniert werden, sodass sie mit beiden Threads in einem Durchgang funktionieren.  Tats√§chlich untersuchen wir beide Streams, verarbeiten das kleinere Element und bewegen uns dann entlang des Streams, aus dem das Element entnommen wurde (oder entlang beider Flows, wenn die Elemente am Anfang gleich sind).  In beiden F√§llen f√ºgen wir den Artikel dem neu besuchten Satz hinzu.  Dann bewegen wir uns entlang des Stroms neuer Zust√§nde vorw√§rts und f√ºgen der neuen Aufgabenmenge ein Element hinzu: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = Stream() todo = Stream() visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. Return a sorted stream of # elements that were just present in new, and another sorted # stream containing the elements that were present in either or # both of new and visited. def merge_sorted_streams(new, visited): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: if visited.peek() == new.peek(): out_visited.add(visited.pop()) new.pop() elif visited.peek() &lt; new.peek(): out_visited.add(visited.pop()) elif visited.peek() &gt; new.peek(): out_todo.add(new.peek()) out_visited.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()) out_visited.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  Das Datenzugriffsmuster ist jetzt vollst√§ndig linear und vorhersehbar, es gibt keine willk√ºrlichen Zugriffe w√§hrend der Fusion.  Daher wird die Verz√∂gerung des Festplattenbetriebs f√ºr uns nicht wichtig, und das einzige, was wichtig bleibt, ist die Bandbreite. <br><br>  Wie wird die theoretische Leistung bei einer vereinfachten Verteilung von Daten √ºber 100 Tiefenebenen aussehen, von denen jede 100 Millionen Zust√§nde hat?  Der gemittelte Zustand wird 50 Mal gelesen und geschrieben.  Dies ergibt 10 Bytes / Zustand * 5 Milliarden Zust√§nde * 50 = 2,5 TB.  Meine Festplatte kann angeblich mit einer durchschnittlichen Geschwindigkeit von 100 MB / s lesen und schreiben, dh durchschnittlich dauert die E / A (2 * 2,5 TB) / (100 MB / s) = ~ 50 k / s = ~ 13 Stunden .  Dies sind ein paar Bestellungen weniger als das vorherige Ergebnis (vier Monate)! <br><br>  Es ist auch erw√§hnenswert, dass dieses vereinfachte Modell die Gr√∂√üe der neu erzeugten Zust√§nde nicht ber√ºcksichtigt.  Vor dem Zusammenf√ºhrungsschritt m√ºssen sie zum Sortieren + Deduplizieren im Speicher gespeichert werden.  Wir werden dies in den folgenden Abschnitten behandeln. <br><br><h2>  Komprimierung </h2><br>  In der Einleitung sagte ich, dass in den ersten Experimenten die Zustandskomprimierung nicht vielversprechend aussah und das Komprimierungsverh√§ltnis nur 30% betrug.  Nachdem jedoch √Ñnderungen am Algorithmus vorgenommen wurden, wurden die Zust√§nde optimiert.  Sie sollten viel einfacher zu komprimieren sein. <br><br>  Um diese Theorie zu testen, habe ich zstd mit einem Puzzle von 14,6 Millionen Zust√§nden verwendet, von denen jeder 8 Bytes gro√ü war.  Nach dem Sortieren wurden sie durchschnittlich auf 1,4 Bytes pro Status komprimiert.  Es scheint ein ernsthafter Schritt nach vorne zu sein.  Es reicht nicht aus, das gesamte Programm im Speicher auszuf√ºhren, aber es kann die E / A-Zeit der Festplatte auf nur einige Stunden reduzieren. <br><br>  Ist es m√∂glich, das Ergebnis des modernen Allzweckkomprimierungsalgorithmus irgendwie zu verbessern, wenn wir etwas √ºber die Datenstruktur wissen?  Sie k√∂nnen sich fast sicher sein.  Ein gutes Beispiel hierf√ºr ist das PNG-Format.  Theoretisch ist die Komprimierung nur ein Standard-Deflate-Durchgang.  Anstatt Rohdaten zu komprimieren, wird das Bild zun√§chst mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PNG-Filtern</a> konvertiert.  Das PNG-Filter ist im Wesentlichen eine Formel zum Vorhersagen des Werts eines Bytes von Rohdaten basierend auf dem Wert des gleichen Bytes in der vorherigen Zeile und / oder des gleichen Bytes des vorherigen Pixels.  Beispielsweise konvertiert der Filter "up" jedes Byte, indem er beim Komprimieren die Werte der vorherigen Zeile davon subtrahiert und beim Entpacken die entgegengesetzte Operation ausf√ºhrt.  Angesichts der Bildtypen, f√ºr die PNG verwendet wird, besteht das Ergebnis fast immer aus Nullen oder Zahlen nahe Null.  Deflate kann solche Daten viel besser komprimieren als Rohdaten. <br><br>  Kann dieses Prinzip auf BFS-Statusdatens√§tze angewendet werden?  Es scheint, dass dies m√∂glich sein sollte.  Wie bei PNG haben wir eine konstante Liniengr√∂√üe und k√∂nnen erwarten, dass die benachbarten Linien sehr √§hnlich sind.  Die ersten Proben mit dem Subtraktions- / Additionsfilter, gefolgt von zstd, f√ºhrten zu einer Verbesserung des Kompressionsverh√§ltnisses um weitere 40%: 0,87 Bytes pro Zustand.  Filtervorg√§nge sind trivial, daher sind sie aus Sicht des CPU-Verbrauchs praktisch ‚Äûkostenlos‚Äú. <br><br>  Mir war nicht klar, ob weitere Verbesserungen vorgenommen werden konnten oder ob dies eine praktische Grenze war.  In den Bilddaten k√∂nnen Sie logischerweise erwarten, dass die benachbarten Bytes derselben Zeile √§hnlich sind.  Aber in diesen Staaten gibt es so etwas nicht.  Tats√§chlich k√∂nnen etwas ausgefeiltere Filter die Ergebnisse noch verbessern.  Am Ende bin ich zu diesem System gekommen: <br><br>  Angenommen, wir haben benachbarte Zeilen R1 = [1, 2, 3, 4] und R2 = [1, 2, 6, 4].  Bei der Ausgabe von R2 vergleichen wir jedes Byte mit dem gleichen Byte der vorherigen Zeile, und 0 zeigt eine √úbereinstimmung an, und 1 zeigt eine Nicht√ºbereinstimmung an: diff = [0, 0, 1, 0].  Dann √ºbergeben wir diese Bitmap, die als VarInt codiert ist, gefolgt von nur Bytes, die nicht mit der vorherigen Zeile √ºbereinstimmen.  In diesem Beispiel erhalten wir zwei Bytes 0b00000100 6. Dieser Filter komprimiert die Referenzdaten f√ºr sich genommen auf 2,2 Bytes / Status.  Durch die Kombination des Filters + zstd haben wir die Datengr√∂√üe auf 0,42 Byte / Status reduziert.  Anders ausgedr√ºckt, dies sind 3,36 Bit pro Status, was nur ein bisschen mehr ist als unsere ungef√§hren berechneten Indikatoren, die erforderlich sind, um sicherzustellen, dass alle Daten in den RAM passen. <br><br>  In der Praxis verbessern sich die Kompressionsverh√§ltnisse, weil sortierte S√§tze dichter werden.  Wenn die Suche den Punkt erreicht, an dem der Speicher Probleme verursacht, k√∂nnen die Komprimierungsraten viel besser werden.  Das gr√∂√üte Problem ist, dass wir am Ende 4,6 Milliarden besuchte Staaten bekommen.  Nach dem Sortieren belegen diese Zust√§nde 405 MB und werden gem√§√ü dem oben dargestellten Schema komprimiert.  Dies ergibt <b>0,7 Bits pro Zustand</b> .  Am Ende nehmen Komprimierung und Dekomprimierung etwa 25% der CPU-Zeit des Programms in Anspruch. Dies ist jedoch ein hervorragender Kompromiss, um den Speicherverbrauch um das Hundertfache zu reduzieren. <br><br>  Der obige Filter scheint aufgrund des VarInt-Headers in jeder Zeile etwas kostspielig zu sein.  Es scheint einfach zu sein, ein Upgrade auf Kosten niedriger CPU-Kosten oder einer leichten Erh√∂hung der Komplexit√§t durchzuf√ºhren.  Ich habe verschiedene Optionen ausprobiert, Daten nach Spalten sortiert oder Bitmasken in gr√∂√üeren Bl√∂cken usw. geschrieben.  Diese Optionen allein ergaben viel h√∂here Komprimierungsverh√§ltnisse, zeigten jedoch keine gute Leistung, wenn die Filterausgabe durch zstd komprimiert wurde.  Und es war kein zstd-Fehler, die Ergebnisse mit gzip und bzip2 waren √§hnlich.  Ich habe keine besonders genialen Theorien dar√ºber, warum sich herausgestellt hat, dass diese bestimmte Art der Codierung bei der Komprimierung viel besser ist als andere Optionen. <br><br>  Ein weiteres R√§tsel: Die Komprimierungsrate erwies sich als viel besser, wenn die Daten eher nach Little-Endian als nach Big-Endian sortiert wurden.  Anfangs dachte ich, dass es passiert ist, weil es bei der Little-Endian-Sortierung mehr f√ºhrende Nullen mit der von VarInt codierten Bitmaske gibt.  Dieser Unterschied bleibt jedoch auch bei Filtern bestehen, die keine solchen Abh√§ngigkeiten aufweisen. <br><br>  (Es gibt viele Untersuchungen zum Komprimieren sortierter S√§tze von Ganzzahlen, da diese die Grundbausteine ‚Äã‚Äãvon Suchmaschinen sind. Ich fand jedoch nicht viele Informationen zum Komprimieren sortierter Datens√§tze konstanter L√§nge und wollte nicht raten, die Daten als Ganzzahlwerte mit willk√ºrlicher Genauigkeit darzustellen.) <br><br><h2>  Oh-oh, ich habe geschummelt! </h2><br>  M√∂glicherweise haben Sie bemerkt, dass die obigen BFS-Implementierungen im Pseudocode nur Boolesche Werte zur√ºckgeben - die L√∂sung wurde gefunden / nicht gefunden.  Dies ist nicht besonders n√ºtzlich.  In den meisten F√§llen m√ºssen wir eine Liste der genauen Schritte der L√∂sung erstellen und nicht nur die Verf√ºgbarkeit der L√∂sung melden. <br><br>  Auf den ersten Blick scheint dieses Problem leicht zu l√∂sen zu sein.  Anstatt S√§tze von Zust√§nden zu erfassen, m√ºssen Sie Statusbeziehungen zu √ºbergeordneten Zust√§nden erfassen.  Nachdem Sie die L√∂sung gefunden haben, k√∂nnen Sie einfach von Ende zu Anfang von der Liste der elterlichen L√∂sungen zur√ºckkehren.  F√ºr eine auf Hash-Tabellen basierende L√∂sung w√ºrde dies ungef√§hr so ‚Äã‚Äãaussehen: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, visited) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited[kid] = node todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trace_solution</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(state, visited)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> state <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(start, visited[state]) + [state]</code> </pre> <br>  Leider werden dadurch alle im vorherigen Abschnitt erzielten Komprimierungsvorteile zerst√∂rt.  Sie basieren auf der Annahme, dass benachbarte Linien sehr √§hnlich sind.  Wenn wir nur die Staaten selbst betrachten, ist dies wahr.  Es gibt jedoch keinen Grund zu der Annahme, dass dies f√ºr Elternstaaten gilt.  Tats√§chlich handelt es sich um zuf√§llige Daten.  Zweitens sollte eine Sort + Merge-L√∂sung alle Zust√§nde lesen und schreiben, die bei jeder Iteration angezeigt werden.  Um die Verkn√ºpfung des Status / √ºbergeordneten Status zu speichern, m√ºssen wir bei jeder Iteration all diese schlecht komprimierten Daten lesen und auf die Festplatte schreiben. <br><br><h2>  Sortieren + Zusammenf√ºhren mit mehreren Ausgaben </h2><br>  Ganz am Ende, wenn Sie zur L√∂sung zur√ºckkehren, ben√∂tigt das Programm nur B√ºndel von Zust√§nden / √ºbergeordneten Zust√§nden. Daher k√∂nnen wir zwei Datenstrukturen parallel speichern.  Besucht werden weiterhin die besuchten Staaten, wie sie zuvor w√§hrend der Zusammenf√ºhrung neu berechnet wurden.  Eltern ist mindestens eine sortierte Liste von Status / Eltern-Statuspaaren, die nicht √ºberschrieben werden.  Nach jedem Zusammenf√ºhrungsvorgang wird das Paar "Status + √ºbergeordneter Status" zu den √ºbergeordneten Elementen hinzugef√ºgt. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> parents = Stream() visited = Stream() todo = Stream() parents.add((start, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)) visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, parents) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited, parents) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. New contains pairs of # key + value (just the keys are compared), visited contains just # keys. # # Returns a sorted stream of keys that were just present in new, # another sorted stream containing the keys that were present in either or # both of new and visited. Also adds the keys + values to the parents # stream for keys that were only present in new. def merge_sorted_streams(new, visited, parents): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: visited_head = visited.peek() new_head = new.peek()[0] if visited_head == new_head: out_visited.add(visited.pop()) new.pop() elif visited_head &lt; new_head: out_visited.add(visited.pop()) elif visited_head &gt; new_head: out_todo.add(new_head) out_visited.add(new_head) out_parents.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()[0]) out_visited.add(new.peek()[0]) out_parents.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  Dies erm√∂glicht es uns, beide Ans√§tze in Bezug auf Laufzeit und Arbeitss√§tze zu nutzen, erfordert jedoch mehr sekund√§ren Speicherplatz.  Dar√ºber hinaus stellt sich heraus, dass in Zukunft aus anderen Gr√ºnden eine separate Kopie der besuchten Staaten n√ºtzlich sein wird, gruppiert nach Tiefe. <br><br><h2>  Tauschen </h2><br>  Ein weiteres Detail wird im Pseudocode ignoriert: Es gibt keinen expliziten Code f√ºr die Festplatten-E / A, sondern nur die abstrakte Stream-Schnittstelle.  Stream kann ein Dateistream oder ein Array im Speicher sein, aber wir haben dieses Implementierungsdetail ignoriert.  Stattdessen erstellt der Pseudocode ein Speicherzugriffsmuster, das eine optimale Nutzung der Festplatte erm√∂glicht.  In einer idealen Welt w√ºrde dies ausreichen, und der Rest k√∂nnte vom virtuellen Speichersubsystem des Betriebssystems √ºbernommen werden. <br><br>  Dies ist jedoch zumindest unter Linux nicht der Fall.  Irgendwann (bevor der Arbeitsdatensatz auf Speichergr√∂√üe komprimiert werden konnte) wurde das Programm in etwa 11 Stunden ausgef√ºhrt, und die Daten wurden haupts√§chlich auf der Festplatte gespeichert.  Dann lie√ü ich das Programm anonyme Seiten verwenden, anstatt sie in Dateien zu speichern, und w√§hlte eine Auslagerungsdatei von ausreichender Gr√∂√üe auf demselben Laufwerk aus.  Drei Tage sp√§ter ging das Programm jedoch nur ein Viertel des Weges und wurde im Laufe der Zeit immer langsamer.  Nach meinen optimistischen Sch√§tzungen sollte sie den Job in 20 Tagen beenden. <br><br>  Ich werde es klarstellen - es war der gleiche Code und <i>genau das gleiche Zugriffsmuster</i> .  Das einzige, was sich ge√§ndert hat, ist, dass der Speicher nicht als explizite Festplattendatei, sondern als Swap gespeichert wurde.  Es sind fast keine Beweise daf√ºr erforderlich, dass das Austauschen die Linux-Leistung vollst√§ndig zerst√∂rt, w√§hrend dies bei regul√§ren Datei-E / A nicht der Fall ist.  Ich habe immer angenommen, dass dies auf die Tatsache zur√ºckzuf√ºhren ist, dass Programme RAM eher als Arbeitsspeicher betrachten.  Dies ist jedoch nicht der Fall. <br><br>  Es stellt sich heraus, dass Dateispeicherseiten und anonyme Seiten vom Subsystem der virtuellen Maschine unterschiedlich behandelt werden.  Sie werden in separaten LRU-Caches mit unterschiedlichen Ablaufrichtlinien gespeichert.  Dar√ºber hinaus scheinen sie unterschiedliche Read / Load-Read-Ahead-Eigenschaften zu haben. <br><br>  Jetzt wei√ü ich: Das Tauschen unter Linux wird h√∂chstwahrscheinlich auch unter optimalen Bedingungen nicht gut funktionieren.  Wenn Teile des Adressraums wahrscheinlich f√ºr einige Zeit auf die Festplatte entladen werden, ist es besser, sie manuell in Dateien zu speichern, als dem Swap zu vertrauen.  Ich habe dies erreicht, indem ich meine eigene Klasse von Vektoren implementiert habe, die anf√§nglich nur im Speicher funktioniert. Nach √úberschreiten eines bestimmten Gr√∂√üenschwellenwerts wechselt sie in einer tempor√§ren separaten Datei zu mmap. <br><br><h2>  Komprimierung neuer Zust√§nde vor dem Zusammenf√ºhren </h2><br>  In einem vereinfachten Leistungsmodell gingen wir davon aus, dass in jeder Tiefe 100 Millionen neue Bedingungen auftreten w√ºrden.  Es stellte sich heraus, dass dies nicht sehr weit von der Realit√§t entfernt ist (im komplexesten Puzzle maximal mehr als 150 Millionen einzigartige neue Zust√§nde auf einer Tiefenschicht).  Dies ist aber nicht zu messen;  Der Arbeitssatz vor dem Zusammenf√ºhren ist nicht nur eindeutigen Zust√§nden zugeordnet, sondern auch allen Zust√§nden, die f√ºr diese Iteration abgeleitet wurden.  Diese Zahl erreicht 880 Millionen Ausgangszust√§nde pro Tiefenschicht.  Diese 880 Millionen Zust√§nde m√ºssen a) mit einem Direktzugriffsmuster zum Sortieren verarbeitet werden, b) k√∂nnen aufgrund fehlender Sortierung nicht effektiv komprimiert werden, c) m√ºssen zusammen mit dem √ºbergeordneten Zustand gespeichert werden.  Dieser Arbeitssatz ist ungef√§hr 16 GB gro√ü. <br><br>  Die offensichtliche L√∂sung: Verwenden Sie eine externe Sortierung.  Schreiben Sie einfach alle Status auf die Festplatte, f√ºhren Sie eine externe Sortierung durch, deduplizieren Sie sie und f√ºhren Sie sie dann wie gewohnt zusammen.  Zuerst habe ich diese L√∂sung verwendet, und obwohl sie das Problem A h√∂chstens beseitigte, konnte ich B und C nicht bew√§ltigen. <br><br>  Am Ende habe ich einen alternativen Ansatz gew√§hlt: Ich habe die Zust√§nde in einem Array im Speicher gesammelt.  Wenn das Array zu gro√ü wird (z. B. mehr als 100 Millionen Elemente), wird es sortiert, dedupliziert und komprimiert.  Dies gibt uns ein Paket sortierter Statusl√§ufe, und es gibt keine Duplikate in jedem Lauf, aber sie sind zwischen den L√§ufen m√∂glich.  Grunds√§tzlich bleibt der Code zum Zusammenf√ºhren neuer und besuchter Staaten derselbe;  es basiert immer noch auf einem allm√§hlichen Durchgang durch die B√§che.  Der einzige Unterschied besteht darin, dass anstatt nur zwei Streams zu durchlaufen, f√ºr jeden sortierten Lauf neuer Zust√§nde ein separater Stream vorhanden ist. <br><br>  Nat√ºrlich sind die Komprimierungsraten dieser L√§ufe von 100 Millionen Zust√§nden nicht so gut wie die Komprimierung der Menge aller besuchten Zust√§nde.  Aber selbst mit solchen Indikatoren wird das Volumen sowohl des Arbeitssatzes als auch die Anforderungen an die Festplatten-E / A erheblich reduziert.  Sie ben√∂tigen etwas mehr CPU-Ressourcen, um die Priorit√§tswarteschlange von Threads zu verarbeiten, aber es ist immer noch ein gro√üer Kompromiss. <br><br><h2>  Platz sparen in √ºbergeordneten Zust√§nden </h2><br>  Zu diesem Zeitpunkt wird der gr√∂√üte Teil des vom Programm belegten Speicherplatzes f√ºr die Speicherung der √ºbergeordneten Zust√§nde aufgewendet, sodass wir nach dem Finden der L√∂sung den Prozess neu erstellen k√∂nnen.  H√∂chstwahrscheinlich k√∂nnen sie kaum gut zusammengedr√ºckt werden, aber vielleicht gibt es einen Kompromiss zwischen CPU und Speicher? <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir m√ºssen den Zustand S 'in der Tiefe D + 1 mit seinem Elternzustand S in der Tiefe D verbinden. Wenn wir alle m√∂glichen Elternzust√§nde S' durchlaufen k√∂nnen, k√∂nnen wir pr√ºfen, ob einer von ihnen in der Tiefe D in der besuchten Menge erscheint . (Wir haben bereits viele Besucher erstellt, gruppiert nach Tiefe als praktisches Nebenprodukt der Ableitung von staatlichen / elterlichen Staatsb√ºndeln w√§hrend der Zusammenf√ºhrung). Leider funktioniert dieser Ansatz f√ºr diese Aufgabe nicht. es ist einfach zu schwierig f√ºr uns, alle m√∂glichen Zust√§nde von S f√ºr ein gegebenes S 'zu erzeugen. F√ºr viele andere Suchaufgaben k√∂nnte eine solche L√∂sung jedoch funktionieren.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn wir nur √úberg√§nge zwischen Zust√§nden vorw√§rts, aber nicht r√ºckw√§rts erzeugen k√∂nnen, warum dann nicht einfach? Lassen Sie uns iterativ alle Zust√§nde in Tiefe D umgehen und sehen, welche Art von Ausgabezust√§nden sie erhalten. Wenn ein Zustand am Ausgang S 'ergibt, haben wir ein geeignetes S gefunden. Das Problem bei diesem Plan ist, dass er den Gesamt-CPU-Verbrauch des Programms um 50% erh√∂ht. (Nicht 100%, da wir S im Durchschnitt finden, wenn wir die H√§lfte der Zust√§nde in der Tiefe D betrachten).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Daher mag ich keinen der Grenzf√§lle, aber hier ist zumindest ein Kompromiss zwischen CPU / Speicher m√∂glich. </font><font style="vertical-align: inherit;">Gibt es irgendwo dazwischen eine akzeptablere L√∂sung? </font><font style="vertical-align: inherit;">Am Ende habe ich beschlossen, nicht das Paar (S ', S) zu speichern, sondern das Paar (S', H (S)), wobei H eine 8-Bit-Hash-Funktion ist. </font><font style="vertical-align: inherit;">Um S f√ºr ein gegebenes S 'zu finden, gehen wir erneut iterativ alle Zust√§nde in Tiefe D durch. Bevor wir jedoch etwas anderes tun, berechnen wir denselben Hash. </font><font style="vertical-align: inherit;">Wenn die Ausgabe nicht mit H (S) √ºbereinstimmt, ist dies nicht der gesuchte Zustand, und wir k√∂nnen ihn einfach √ºberspringen. </font><font style="vertical-align: inherit;">Diese Optimierung bedeutet, dass kostspielige Neuberechnungen nur f√ºr 1/256 Zust√§nde durchgef√ºhrt werden m√ºssen, was eine leichte Erh√∂hung der CPU-Auslastung darstellt, und gleichzeitig die Speichermenge zum Speichern von Elternzust√§nden von 8-10 Bytes auf 1 Byte reduziert.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Was hat nicht funktioniert oder kann nicht funktionieren </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In den vorherigen Abschnitten haben wir uns die Reihenfolge der funktionierenden Optimierungen auf hoher Ebene angesehen. Ich habe andere Dinge ausprobiert, die nicht funktionierten oder die ich in der Literatur gefunden habe, aber entschieden, dass sie in diesem speziellen Fall nicht funktionieren w√ºrden. Hier ist eine unvollst√§ndige Liste.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zu diesem Zeitpunkt berechne ich nicht den gesamten Satz neu, der bei jeder Iteration besucht wurde. Stattdessen wurden so viele sortierte L√§ufe gespeichert, und diese L√§ufe wurden von Zeit zu Zeit komprimiert. Der Vorteil dieses Ansatzes besteht darin, dass weniger Festplattenschreibvorg√§nge und CPU-Ressourcen f√ºr die Komprimierung verwendet werden. Der Nachteil ist eine erh√∂hte Codekomplexit√§t und eine verringerte Komprimierungsrate. Anfangs dachte ich, dass ein solches Schema sinnvoll ist, weil in meinem Fall Schreibvorg√§nge teurer sind als Lesen. Am Ende stellte sich jedoch heraus, dass das Kompressionsverh√§ltnis doppelt so hoch war. Die Vorteile eines solchen Kompromisses liegen nicht auf der Hand, weshalb ich zu einer einfacheren Form zur√ºckgekehrt bin. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es wurden bereits wenige Untersuchungen zur volumetrischen Breitensuche nach implizit definierten Diagrammen im Sekund√§rspeicher durchgef√ºhrt. Sie k√∂nnen dieses Thema untersuchen</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aus diesem Artikel von 2008</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Wie Sie vielleicht erraten haben, ist die Idee, Deduplizierung zusammen mit Sortieren + Zusammenf√ºhren im Sekund√§rspeicher durchzuf√ºhren, nicht neu. Das √úberraschende daran ist, dass es erst 1993 er√∂ffnet wurde. Ziemlich sp√§t! Es gibt sp√§ter Vorschl√§ge f√ºr die Breitensuche im Sekund√§rspeicher, f√ºr die kein Sortierschritt erforderlich ist. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine davon bestand darin, Zust√§nde an ganze Zahlen zu binden und eine Bitmap der besuchten Zust√§nde im Speicher zu speichern. In meinem Fall ist dies v√∂llig nutzlos, da die Gr√∂√üen des codierten Zustands im Vergleich zu den wirklich erreichbaren Zustandsr√§umen sehr unterschiedlich sind. Und ich bezweifle sehr, dass es interessante Probleme gibt, bei denen ein solcher Ansatz funktionieren w√ºrde.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine weitere ernsthafte Alternative basiert auf tempor√§ren Hash-Tabellen. Besuchszust√§nde werden ohne Sortierung in einer Datei gespeichert. Wir speichern die Ausgabe aus Tiefe D in der Hash-Tabelle. Gehen Sie dann iterativ durch die besuchten Zust√§nde und suchen Sie sie in der Hash-Tabelle. Wenn das Element in der Hash-Tabelle gefunden wird, l√∂schen Sie es. Nach dem iterativen Durchlaufen der gesamten Datei verbleiben nur nicht doppelte Elemente darin. Sie werden dann zur Datei hinzugef√ºgt und zum Initialisieren der Aufgabenliste f√ºr die n√§chste Iteration verwendet. Wenn die Ausgabemenge so gro√ü ist, dass die Hash-Tabelle nicht in den Speicher passt, k√∂nnen sowohl Dateien als auch Hash-Tabellen nach denselben Kriterien (z. B. den oberen Statusbits) in Teile unterteilt werden, und jeder Teil sollte separat verarbeitet werden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obwohl es </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benchmarks gibt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies zeigt, dass der Hash-basierte Ansatz etwa 30% schneller ist als das Sortieren + Zusammenf√ºhren, aber es scheint, dass sie die Komprimierung nicht ber√ºcksichtigen. Ich habe einfach nicht gesehen, wie sich die Ablehnung der Vorteile der Komprimierung rechtfertigen kann, deshalb habe ich nicht einmal mit solchen Ans√§tzen experimentiert. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein weiterer Forschungsbereich, der Beachtung verdient, war die Optimierung von Datenbankabfragen. Es sieht aus wie. dass die Deduplizierungsaufgabe stark mit dem Datenbank-Join zusammenh√§ngt, der genau das gleiche </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dilemma zwischen </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sortierung und Hashing aufweist</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Offensichtlich k√∂nnen einige dieser Studien auf das Suchproblem angewendet werden. Der Unterschied kann darin bestehen, dass die Ausgabe der Join-Datenbank tempor√§r ist, w√§hrend die Ausgabe der BFS-Deduplizierung bis zum Ende der Berechnung gespeichert wird. Dies scheint das Gleichgewicht der Kompromisse zu ver√§ndern: Jetzt geht es nicht nur um die effizienteste Verarbeitung einer Iteration, sondern auch um die Erstellung des optimalsten Ausgabedatenformats f√ºr die n√§chste Iteration.</font></font><br><br><h2>  Fazit </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Damit ist mein Bericht √ºber das abgeschlossen, was ich aus einem Projekt gelernt habe, das allgemein mit brutaler Gewalt auf andere Suchaufgaben anwendbar ist. </font><font style="vertical-align: inherit;">Die Kombination dieser Tricks erm√∂glichte es, das L√∂sungsvolumen f√ºr die komplexesten R√§tsel des Spiels von 50 bis 100 GB auf 500 MB zu reduzieren und die Kosten reibungslos zu erh√∂hen, wenn die Aufgabe den verf√ºgbaren Speicher √ºberschreitet und auf die Festplatte geschrieben wird. </font><font style="vertical-align: inherit;">Au√üerdem ist meine L√∂sung 50% schneller als eine naive Deduplizierung von Zust√§nden basierend auf Hash-Tabellen, selbst f√ºr R√§tsel, die in den Speicher passen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Snakebird kann bei </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Steam</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Play</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und im </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">App Store gekauft werden</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Ich empfehle es jedem, der sich f√ºr sehr komplexe, aber ehrliche R√§tsel interessiert.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455537/">https://habr.com/ru/post/de455537/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455525/index.html">Zimbra und Mail Bomb Defense</a></li>
<li><a href="../de455527/index.html">Was steht darin geschrieben? Hinter den Kulissen von JavaScript-Objekten</a></li>
<li><a href="../de455529/index.html">Umkehren und Hacken der selbstverschl√ºsselenden externen Festplatte von Aigo. Teil 2: Dumping mit Cypress PSoC</a></li>
<li><a href="../de455533/index.html">Blasenphysik: Eine Suche nach Schaumzerst√∂rungsmechanismus</a></li>
<li><a href="../de455535/index.html">Verwalten von SSL / TLS-Zertifikaten in den Clouds und Containern - keine menschliche Arbeit</a></li>
<li><a href="../de455539/index.html">Mobile Hellseher: 10 neue Fakten dar√ºber, wie tragbare Ger√§te Sie beobachten</a></li>
<li><a href="../de455543/index.html">Ist Kubernetes Cluster einfach und bequem vorzubereiten? Addon-Operator ank√ºndigen</a></li>
<li><a href="../de455545/index.html">Bauprozesse von Grund auf neu: Vom Chaos zur Ordnung</a></li>
<li><a href="../de455547/index.html">Internet der Dinge auf Russisch. Basisband Hotel LoRaWAN f√ºr RTL-SDR-Besitzer</a></li>
<li><a href="../de455549/index.html">So verwenden Sie Facebook-Gruppen zur Werbung: Erstellen Sie ein Web</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😺 👍 🕠 Kami bekerja dengan jaringan saraf: daftar periksa untuk debugging 🚁 🌏 🐏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kode perangkat lunak pembelajaran mesin seringkali rumit dan agak membingungkan. Mendeteksi dan menghilangkan bug di dalamnya adalah tugas intensif su...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kami bekerja dengan jaringan saraf: daftar periksa untuk debugging</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/skillbox/blog/444684/"><img src="https://habrastorage.org/getpro/habr/post_images/84a/7dc/4b8/84a7dc4b81799226681bb176f1c518b0.png" alt="gambar"><br><br>  Kode perangkat lunak pembelajaran mesin seringkali rumit dan agak membingungkan.  Mendeteksi dan menghilangkan bug di dalamnya adalah tugas intensif sumber daya.  Bahkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jaringan saraf yang terhubung langsung dan</a> paling sederhana memerlukan pendekatan yang serius untuk arsitektur jaringan, inisialisasi bobot, dan optimisasi jaringan.  Kesalahan kecil dapat menyebabkan masalah yang tidak menyenangkan. <br><br>  Artikel ini adalah tentang algoritma debugging dari jaringan saraf Anda. <br><a name="habracut"></a><br><blockquote>  <b>Skillbox merekomendasikan:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengembang Python langsung dari awal</a> . <br><br>  <b>Kami mengingatkan Anda:</b> <i>untuk semua pembaca "Habr" - diskon 10.000 rubel saat mendaftar untuk kursus Skillbox apa pun menggunakan kode promo "Habr".</i> </blockquote><cut></cut><br><h3>  Algoritma ini terdiri dari lima tahap: </h3><br><ul><li>  awal yang sederhana; </li><li>  konfirmasi kerugian; </li><li>  verifikasi hasil dan senyawa antara; </li><li>  diagnostik parameter; </li><li>  kontrol kerja. </li></ul><br>  Jika sesuatu tampak lebih menarik bagi Anda daripada yang lain, Anda dapat langsung menuju ke bagian ini. <br><br><h3>  Awal yang mudah </h3><br>  Jaringan saraf dengan arsitektur yang kompleks, regularisasi, dan perencana kecepatan belajar lebih sulit untuk debut daripada jaringan biasa.  Kami sedikit rumit di sini, karena item itu sendiri memiliki hubungan tidak langsung dengan debugging, tetapi ini masih merupakan rekomendasi penting. <br><br>  Awal yang sederhana adalah membuat model yang disederhanakan dan melatihnya pada satu set data (titik). <br><br>  <b>Pertama kita membuat model yang disederhanakan</b> <br><br>  Untuk memulai lebih cepat, buat jaringan kecil dengan satu lapisan tersembunyi dan periksa apakah semuanya berfungsi dengan benar.  Kemudian kami secara bertahap menyulitkan model, memeriksa setiap aspek baru dari strukturnya (lapisan tambahan, parameter, dll.), Dan melanjutkan. <br><br>  <b>Kami melatih model pada satu set data (titik)</b> <br><br>  Sebagai tes cepat kesehatan proyek Anda, Anda dapat menggunakan satu atau dua titik data untuk pelatihan untuk mengonfirmasi apakah sistem bekerja dengan benar.  Jaringan saraf harus menunjukkan akurasi pelatihan dan verifikasi 100%.  Jika ini bukan masalahnya, maka modelnya terlalu kecil atau Anda sudah memiliki bug. <br><br>  Bahkan jika semuanya baik-baik saja, persiapkan model untuk perjalanan satu atau lebih era sebelum melanjutkan. <br><br><h3>  Estimasi kerugian </h3><br>  Estimasi kehilangan adalah cara utama untuk memperbaiki kinerja model.  Anda perlu memastikan bahwa kerugian sesuai dengan tugas, dan fungsi kerugian dievaluasi pada skala yang benar.  Jika Anda menggunakan lebih dari satu jenis kerugian, maka pastikan semuanya memiliki urutan yang sama dan diskalakan dengan benar. <br><br>  Penting untuk memperhatikan kerugian awal.  Periksa seberapa dekat hasil nyata dengan yang diharapkan jika model dimulai dengan asumsi acak.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pekerjaan Andrei Karpati menyarankan yang berikut</a> : “Pastikan Anda mendapatkan hasil yang diharapkan ketika Anda mulai bekerja dengan sejumlah kecil parameter.  Lebih baik segera memeriksa kehilangan data (dengan tingkat regularisasi diatur ke nol).  Misalnya, untuk CIFAR-10 dengan classifier Softmax, kami memperkirakan kerugian awal adalah 2,302, karena probabilitas difus yang diharapkan adalah 0,1 untuk setiap kelas (karena ada 10 kelas), dan hilangnya Softmax adalah probabilitas logaritmik negatif dari kelas yang benar seperti - Dalam (0,1) = 2,302. " <br><br>  Sebagai contoh biner, perhitungan yang serupa hanya dilakukan untuk masing-masing kelas.  Di sini, misalnya, adalah data: 20% 0 dan 80% 1.  Kerugian awal yang diharapkan akan sampai -0,2ln (0,5) -0,8ln (0,5) = 0,693147.  Jika hasilnya lebih besar dari 1, ini dapat menunjukkan bahwa bobot jaringan saraf tidak seimbang dengan baik atau data tidak dinormalisasi. <br><br><h3>  Memeriksa hasil dan koneksi antara </h3><br>  Untuk men-debug jaringan saraf, perlu untuk memahami dinamika proses dalam jaringan dan peran masing-masing lapisan menengah, karena mereka terhubung.  Berikut adalah beberapa kesalahan umum yang mungkin Anda temui: <br><br><ul><li>  Ekspresi yang salah untuk pembaruan gradien </li><li>  pembaruan berat tidak berlaku; </li><li>  menghilang atau meledak gradien. </li></ul><br>  Jika nilai gradien nol, ini berarti bahwa kecepatan latihan dalam pengoptimal terlalu rendah, atau Anda telah menemukan ekspresi yang salah untuk memperbarui gradien. <br><br>  Selain itu, perlu untuk memantau nilai-nilai fungsi aktivasi, bobot dan pembaruan dari masing-masing lapisan.  Misalnya, nilai pembaruan parameter (bobot dan offset) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">harus 1-e3</a> . <br><br>  Ada fenomena yang disebut "Dying ReLU" atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Disappearing Gradient Problem"</a> ketika neuron ReLU akan menghasilkan nol setelah mempelajari nilai bias negatif yang besar untuk bobotnya.  Neuron-neuron ini tidak pernah diaktifkan lagi di tempat data apa pun. <br><br>  Anda dapat menggunakan pengujian gradien untuk mendeteksi kesalahan ini dengan mendekati gradien menggunakan pendekatan numerik.  Jika dekat dengan gradien yang dihitung, maka propagasi kembali diimplementasikan dengan benar.  Untuk membuat pemeriksaan gradien, lihat sumber daya CS231 yang hebat di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> dan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> , serta tutorial Andrew Nga tentang topik ini. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Fayzan Sheikh</a> menunjukkan tiga metode utama untuk memvisualisasikan jaringan saraf: <br><br><ul><li>  Pendahuluan - metode sederhana yang menunjukkan kepada kita struktur umum model yang dilatih.  Mereka termasuk output dari bentuk atau filter lapisan individu dari jaringan saraf dan parameter di setiap lapisan. </li><li>  Berdasarkan aktivasi.  Di dalamnya, kami menguraikan aktivasi masing-masing neuron atau kelompok neuron untuk memahami fungsinya. </li><li>  Berbasis gradien.  Metode-metode ini cenderung memanipulasi gradien yang terbentuk dari bolak-balik saat melatih model (termasuk peta signifikansi dan peta aktivasi kelas). </li></ul><br>  Ada beberapa alat yang berguna untuk memvisualisasikan aktivasi dan koneksi masing-masing lapisan, misalnya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener">ConX</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener">Tensorboard</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d86/8ff/f33/d868fff33e5b7cb69563bfee29b9db08.png"><br><br><h3>  Diagnostik Parameter </h3><br>  Jaringan saraf memiliki banyak parameter yang berinteraksi satu sama lain, yang mempersulit optimasi.  Sebenarnya, bagian ini adalah subjek penelitian aktif oleh spesialis, sehingga proposal di bawah ini harus dianggap hanya sebagai saran, titik awal dari mana Anda dapat membangun. <br><br>  <b>Ukuran paket</b> ( <b>ukuran</b> batch) - jika Anda ingin ukuran paket cukup besar untuk mendapatkan perkiraan gradien kesalahan yang akurat, tetapi cukup kecil sehingga stochastic gradient descent (SGD) dapat merampingkan jaringan Anda.  Ukuran kecil dari paket akan mengarah pada konvergensi yang cepat karena kebisingan dalam proses pembelajaran dan di masa depan kesulitan optimasi.  Ini dijelaskan lebih rinci di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> . <br><br>  <b>Kecepatan Belajar</b> - Terlalu lambat akan menghasilkan konvergensi yang lambat atau risiko terjebak dalam posisi terendah lokal.  Pada saat yang sama, kecepatan belajar yang tinggi akan menyebabkan perbedaan dalam optimasi, karena Anda berisiko "melompat" melalui kedalaman, tetapi pada saat yang sama mempersempit bagian dari fungsi kerugian.  Coba gunakan perencanaan kecepatan untuk menguranginya selama pelatihan jaringan saraf.  CS231n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memiliki bagian besar tentang masalah ini</a> . <br><br>  <b>Gradient clipping</b> - memangkas gradien parameter selama propagasi balik pada nilai maksimum atau norma batas.  Berguna untuk memecahkan masalah dengan gradien meledak yang mungkin Anda temui di paragraf ketiga. <br><br>  <b>Batch normalisasi</b> - digunakan untuk menormalkan data input dari setiap lapisan, yang memungkinkan untuk menyelesaikan masalah pergeseran kovarian internal.  Jika Anda menggunakan Dropout dan Batch Norma bersama-sama, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lihat artikel ini</a> . <br><br>  <b>Stochastic Gradient Descent (SGD)</b> - Ada beberapa jenis SGD yang menggunakan momentum, kecepatan belajar adaptif, dan metode Nesterov.  Pada saat yang sama, tidak satu pun dari mereka memiliki keunggulan yang jelas baik dalam hal efisiensi pelatihan dan generalisasi ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">detail di sini</a> ). <br><br>  <b>Regularisasi</b> - sangat penting untuk membangun model umum, karena menambah penalti untuk kompleksitas model atau nilai parameter ekstrim.  Ini adalah cara untuk mengurangi varians model tanpa secara signifikan meningkatkan perpindahannya.  Informasi lebih <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lanjut di sini</a> . <br><br>  Untuk mengevaluasi semuanya sendiri, Anda harus menonaktifkan regularisasi dan memeriksa sendiri gradien kehilangan data. <br><br>  <b>Dropout</b> adalah cara lain untuk merampingkan jaringan Anda untuk mencegah kemacetan.  Selama pelatihan, kehilangan hanya terjadi dengan mempertahankan aktivitas neuron dengan probabilitas p tertentu (hiperparameter) atau menetapkannya ke nol pada kasus yang berlawanan.  Akibatnya, jaringan harus menggunakan subset parameter yang berbeda untuk setiap pihak pelatihan, yang mengurangi perubahan pada parameter tertentu yang menjadi dominan. <br><br>  Penting: jika Anda menggunakan normalisasi dropout dan batch, berhati-hatilah dengan urutan operasi ini atau bahkan dengan penggunaan bersama mereka.  Semua ini masih dibahas dan ditambah secara aktif.  Berikut adalah dua diskusi penting tentang topik ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tentang Stackoverflow</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Arxiv</a> . <br><br><h3>  Kontrol kerja </h3><br>  Ini tentang mendokumentasikan alur kerja dan eksperimen.  Jika Anda tidak mendokumentasikan apa pun, Anda bisa lupa, misalnya, kecepatan latihan atau bobot kelas seperti apa yang digunakan.  Berkat kontrolnya, Anda dapat dengan mudah melihat dan mereproduksi eksperimen sebelumnya.  Ini mengurangi jumlah percobaan duplikat. <br><br>  Benar, dokumentasi manual bisa jadi menantang jika ada banyak pekerjaan.  Di sini alat-alat seperti Comet.ml membantu Anda untuk secara otomatis mencatat kumpulan data, perubahan kode, riwayat percobaan, dan model produksi, termasuk informasi kunci tentang model Anda (hyperparameters, indikator kinerja model, dan informasi lingkungan). <br><br>  Jaringan saraf bisa sangat sensitif terhadap perubahan kecil, dan ini akan menyebabkan penurunan kinerja model.  Melacak dan mendokumentasikan pekerjaan adalah langkah pertama yang harus diambil untuk membakukan lingkungan dan pemodelan Anda. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e0/52c/de4/0e052cde4414da934bdde111cc0f0bf5.png"><br><br>  Saya harap posting ini dapat menjadi titik awal dari mana Anda akan mulai men-debug jaringan saraf Anda. <br><blockquote>  <b>Skillbox merekomendasikan:</b> <br><br><ul><li>  Kursus praktis dua tahun <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Saya adalah pengembang web PRO</a> . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"</a> </li><li>  Kursus online <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Pengembang C # dengan 0"</a> . </li><li>  Kursus tahunan praktis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Pengembang PHP dari 0 hingga PRO"</a> . <br></li></ul></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id444684/">https://habr.com/ru/post/id444684/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id444672/index.html">Roskachestvo mempresentasikan peringkat headphone berkabel dan nirkabel yang tersedia di Rusia</a></li>
<li><a href="../id444674/index.html">Sony Xperia 10 dan Xperia 10 Plus - smartphone tampilan lebar</a></li>
<li><a href="../id444676/index.html">Peringkat, peringkat, ulasan CRM - apakah mereka semua berbohong?</a></li>
<li><a href="../id444678/index.html">Hari kerja: 12 April, penerbangan normal</a></li>
<li><a href="../id444682/index.html">Saham Sony dan Nintendo mogok setelah meluncurkan streaming video untuk gamer dari Google</a></li>
<li><a href="../id444686/index.html">Waves Smart Asset: Daftar Hitam dan Putih, Perdagangan Interval</a></li>
<li><a href="../id444688/index.html">Tolong berhenti berbicara tentang template Repositori dengan Eloquent</a></li>
<li><a href="../id444690/index.html">Bagaimana peneliti Uber menerapkan dan mengukur pengetahuan perilaku manusia</a></li>
<li><a href="../id444692/index.html">MOSDROID # 16 Sulphur di Redmadrobot</a></li>
<li><a href="../id444694/index.html">Seperti yang kami prediksi arus keluar, mendekatinya sebagai bencana alam</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
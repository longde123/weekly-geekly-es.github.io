<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö∑ üë© üòÑ Ok Google: Wie komme ich durch das Captcha? ‚õìÔ∏è üçí üßöüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Tag. Mein Name ist Ibadov Ilkin, ich bin Student der Ural Federal University. 

 In diesem Artikel m√∂chte ich √ºber meine Erfahrungen mit der aut...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ok Google: Wie komme ich durch das Captcha?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/449236/">  Guten Tag.  Mein Name ist Ibadov Ilkin, ich bin Student der Ural Federal University. <br><br>  In diesem Artikel m√∂chte ich √ºber meine Erfahrungen mit der automatisierten L√∂sung f√ºr Googles Captcha "reCAPTCHA" sprechen.  Ich m√∂chte den Leser im Voraus warnen, dass der Prototyp zum Zeitpunkt des Schreibens des Artikels nicht so effizient funktioniert, wie es aus dem Titel hervorgeht. Das Ergebnis zeigt jedoch, dass der implementierte Ansatz das Problem l√∂sen kann. <br><a name="habracut"></a><br>  Wahrscheinlich ist jeder in seinem Leben auf ein Captcha gesto√üen: Geben Sie Text aus einem Bild ein, l√∂sen Sie einen einfachen Ausdruck oder eine komplizierte Gleichung, w√§hlen Sie Autos, Hydranten, Fu√üg√§nger√ºberwege ... Der Schutz von Ressourcen vor automatisierten Systemen ist notwendig und spielt eine wichtige Rolle f√ºr die Sicherheit: Captcha sch√ºtzt vor DDoS-Angriffen , automatische Registrierungen und Buchungen, Parsen, verhindert die Auswahl von Spam und Passwort f√ºr Konten. <br><br><img src="https://habrastorage.org/webt/kw/la/yu/kwlayu1_wxfwcrknvshirpv8dtw.png"><br>  <font color="#999999"><i>Das Anmeldeformular auf "Habr√©" k√∂nnte mit einem solchen Captcha versehen sein.</i></font> <br><br>  Mit der Entwicklung von Technologien f√ºr maschinelles Lernen kann die Leistung von Captcha gef√§hrdet sein.  In diesem Artikel beschreibe ich die wichtigsten Punkte eines Programms, mit denen das Problem der manuellen Auswahl von Bildern in Google reCAPTCHA gel√∂st werden kann (zum Gl√ºck bisher nicht immer). <br><br>  Um durch Captcha zu kommen, m√ºssen folgende Probleme gel√∂st werden: Bestimmen der erforderlichen Captcha-Klasse, Erkennen und Klassifizieren von Objekten, Erkennen von Captcha-Zellen, Simulieren menschlicher Aktivit√§ten beim L√∂sen von Captcha (Cursorbewegung, Klicken). <br><br>  Um nach Objekten in einem Bild zu suchen, werden trainierte neuronale Netze verwendet, die auf einen Computer heruntergeladen werden k√∂nnen und Objekte in Bildern oder Videos erkennen.  Um das Captcha zu l√∂sen, reicht es jedoch nicht aus, nur Objekte zu erkennen: Sie m√ºssen die Position der Zellen bestimmen und herausfinden, welche Zellen Sie ausw√§hlen m√∂chten (oder √ºberhaupt nicht).  Hierf√ºr werden Computer Vision Tools verwendet: In dieser Arbeit ist dies die ber√ºhmte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCV-Bibliothek</a> . <br><br>  Um Objekte im Bild zu finden, wird zun√§chst das Bild selbst ben√∂tigt.  Ich erhalte einen Screenshot eines Teils des Bildschirms mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PyAutoGUI-</a> Modul mit Abmessungen, die zum Erkennen von Objekten ausreichen.  Im Rest des Bildschirms zeige ich Fenster zum Debuggen und √úberwachen von Programmprozessen an. <br><br><h2>  Objekterkennung </h2><br>  Das Erkennen und Klassifizieren von Objekten ist das, was das neuronale Netzwerk tut.  Die Bibliothek, mit der wir mit neuronalen Netzen arbeiten k√∂nnen, hei√üt " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tensorflow</a> " (entwickelt von Google).  Heutzutage <a href="">stehen</a> Ihnen <a href="">viele verschiedene trainierte Modelle f√ºr unterschiedliche Daten zur Verf√ºgung</a> , was bedeutet, dass alle ein unterschiedliches Erkennungsergebnis <a href="">liefern</a> k√∂nnen: Einige Modelle erkennen Objekte besser, andere schlechter. <br><br>  In diesem Artikel verwende ich das Modell ssd_mobilenet_v1_coco.  Das ausgew√§hlte Modell wurde anhand des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><abbr title="Gemeinsame Objekte im Kontext">COCO-</abbr></a> Datensatzes trainiert, der 90 verschiedene Klassen hervorhebt (von Personen und Autos bis hin zu Zahnb√ºrsten und K√§mmen).  Jetzt gibt es andere Modelle, die mit denselben Daten trainiert werden, jedoch mit unterschiedlichen Parametern.  Dar√ºber hinaus verf√ºgt dieses Modell √ºber optimale Leistungs- und Genauigkeitsparameter, was f√ºr einen Desktop-Computer wichtig ist.  Die Quelle sagt, dass die Verarbeitungszeit f√ºr ein Bild von 300 x 300 Pixel 30 Millisekunden betr√§gt.  Auf der "Nvidia GeForce GTX TITAN X". <br><br>  Das Ergebnis des neuronalen Netzwerks ist eine Reihe von Arrays: <br><br><ul><li>  mit einer Liste von Klassen erkannter Objekte (deren Kennungen); </li><li>  mit einer Liste von Bewertungen erkannter Objekte (in Prozent); </li><li>  mit einer Liste von Koordinaten erkannter Objekte ("K√§stchen"). </li></ul><br>  Die Indizes der Elemente in diesen Arrays entsprechen einander, dh: Das dritte Element im Array der Objektklassen entspricht dem dritten Element im Array der "K√§stchen" der erkannten Objekte und dem dritten Element im Array der Objektbewertungen. <br><br><img src="https://habrastorage.org/webt/g4/po/kt/g4poktayba4n3mwspffduto6d1k.png"><br>  <font color="#999999"><i>Mit dem ausgew√§hlten Modell k√∂nnen Sie Objekte aus 90 Klassen in Echtzeit erkennen.</i></font> <br><br><h2>  Zellerkennung </h2><br>  "OpenCV" bietet uns die M√∂glichkeit, mit Entit√§ten zu arbeiten, die als " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schaltkreise</a> " bezeichnet werden: Sie k√∂nnen nur von der Funktion "findContours ()" aus der Bibliothek "OpenCV" erkannt werden.  Es ist notwendig, ein Bin√§rbild an die Eingabe einer solchen Funktion zu senden, das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durch die Schwellentransformationsfunktion erhalten werden kann</a> : <br><br><pre><code class="python hljs">_retval, binImage = cv2.threshold(image,<span class="hljs-number"><span class="hljs-number">254</span></span>,<span class="hljs-number"><span class="hljs-number">255</span></span>,cv2.THRESH_BINARY) contours = cv2.findContours(binImage, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br>  Nachdem wir die Extremwerte der Parameter der Schwellentransformationsfunktion eingestellt haben, werden auch verschiedene Arten von Rauschen beseitigt.  Um die Menge an unn√∂tigen kleinen Elementen und Rauschen zu minimieren, k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">morphologische Transformationen</a> angewendet werden: Erosions- (Komprimierungs-) und Aufbaufunktionen (Expansionsfunktionen).  Diese Funktionen sind auch Teil von OpenCV.  Nach den Transformationen werden die Konturen ausgew√§hlt, deren Anzahl der Eckpunkte vier betr√§gt (nachdem zuvor die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Approximationsfunktion</a> f√ºr die Konturen ausgef√ºhrt wurde). <br><br><img src="https://habrastorage.org/webt/mo/d3/j7/mod3j7vkdav-bchdnbxl2lycz18.png"><br>  <font color="#999999"><i>Im ersten Fenster das Ergebnis der Schwellenwerttransformation.</i></font>  <font color="#999999"><i>Das zweite ist ein Beispiel f√ºr eine morphologische Transformation.</i></font>  <font color="#999999"><i>Im dritten Fenster sind die Zellen und die Captcha-Kappe bereits ausgew√§hlt: programmgesteuert farblich hervorgehoben.</i></font> <br><br>  Nach all den Transformationen fallen die Konturen, die keine Zellen sind, immer noch in das endg√ºltige Array mit Zellen.  Um unn√∂tige Ger√§usche herauszufiltern, w√§hle ich nach den Werten der L√§nge (Umfang) und der Fl√§che der Konturen. <br><br>  Es wurde experimentell gezeigt, dass die Werte der interessierenden Schaltungen im Bereich von 360 bis 900 Einheiten liegen.  Dieser Wert wird auf dem Bildschirm mit einer Diagonale von 15,6 Zoll und einer Aufl√∂sung von 1366 x 768 Pixel ausgew√§hlt.  Ferner k√∂nnen die angegebenen Werte der Konturen in Abh√§ngigkeit von der Gr√∂√üe des Benutzerbildschirms berechnet werden, es gibt jedoch keine solche Verkn√ºpfung in dem zu erstellenden Prototyp. <br><br>  Der Hauptvorteil des gew√§hlten Ansatzes zur Erkennung von Zellen besteht darin, dass es uns egal ist, wie das Raster aussieht und wie viele Zellen auf der Captcha-Seite angezeigt werden: 8, 9 oder 16. <br><br><img src="https://habrastorage.org/webt/oo/er/tt/ooerttikg_xree5wlre88cljjtq.png"><br>  <font color="#999999"><i>Das Bild zeigt eine Vielzahl von Captcha-Netzen.</i></font>  <font color="#999999"><i>Bitte beachten Sie, dass der Abstand zwischen den Zellen unterschiedlich ist.</i></font>  <font color="#999999"><i>Das Trennen von Zellen voneinander erm√∂glicht eine morphologische Kompression.</i></font> <br><br>  Ein zus√§tzlicher Vorteil der Erkennung von Konturen besteht darin, dass wir mit OpenCV ihre Zentren erkennen k√∂nnen (sie werden ben√∂tigt, um die Bewegungskoordinaten und den Mausklick zu bestimmen). <br><br><h2>  Ausw√§hlen von Zellen zur Auswahl </h2><br>  Mit einem Array mit sauberen Konturen von CAPTCHA-Zellen ohne unn√∂tige Rauschkreise k√∂nnen wir jede CAPTCHA-Zelle durchlaufen (‚ÄûSchaltung‚Äú in der Terminologie ‚ÄûOpenCV‚Äú) und pr√ºfen, ob sie sich mit der erkannten ‚ÄûBox‚Äú des vom neuronalen Netzwerk empfangenen Objekts schneidet. <br><br>  Um diese Tatsache festzustellen, wurde die √úbertragung der erfassten "Box" auf eine Schaltung √§hnlich den Zellen verwendet.  Dieser Ansatz stellte sich jedoch als falsch heraus, da der Fall, in dem sich das Objekt innerhalb der Zelle befindet, nicht als Schnittpunkt betrachtet wird.  Nat√ºrlich stachen solche Zellen im Captcha nicht hervor. <br><br>  Das Problem wurde gel√∂st, indem der Umriss jeder Zelle (mit wei√üer F√ºllung) auf ein schwarzes Blatt neu gezeichnet wurde.  In √§hnlicher Weise wurde ein Bin√§rbild eines Rahmens mit einem Objekt erhalten.  Es stellt sich die Frage, wie nun die Tatsache des Schnittpunkts der Zelle mit dem schattierten Rahmen des Objekts festgestellt werden kann.  Bei jeder Iteration eines Arrays mit Zellen wird eine Disjunktionsoperation (logisch oder) f√ºr zwei Bin√§rbilder ausgef√ºhrt.  Als Ergebnis erhalten wir ein neues Bin√§rbild, in dem geschnittene Bereiche hervorgehoben werden.  Das hei√üt, wenn es solche Bereiche gibt, schneiden sich die Zelle und der Rahmen des Objekts.  Programmatisch kann eine solche Pr√ºfung mit der Methode " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">.any ()</a> " durchgef√ºhrt werden: Sie gibt "True" zur√ºck, wenn das Array mindestens ein Element gleich eins hat, oder "False", wenn keine Einheiten vorhanden sind. <br><br><img src="https://habrastorage.org/webt/cg/8u/pb/cg8upb6izzlfukmfunjgjrzwl2y.gif"><br>  <font color="#999999"><i>Die Funktion "any ()" f√ºr das Bild "Logical OR" gibt in diesem Fall true zur√ºck und stellt dadurch die Tatsache des Schnittpunkts der Zelle mit dem Rahmenbereich des erkannten Objekts fest.</i></font> <br><br><h2>  Management </h2><br>  Die Cursorsteuerung in ‚ÄûPython‚Äú wird dank des Moduls ‚Äûwin32api‚Äú zur Verf√ºgung gestellt (sp√§ter stellte sich jedoch heraus, dass die bereits in das Projekt importierte ‚ÄûPyAutoGUI‚Äú auch wei√ü, wie das geht).  Das Dr√ºcken und Loslassen der linken Maustaste sowie das Bewegen des Cursors auf die gew√ºnschten Koordinaten wird von den entsprechenden Funktionen des win32api-Moduls ausgef√ºhrt.  Im Prototyp wurden sie jedoch in benutzerdefinierte Funktionen eingeschlossen, um eine visuelle Beobachtung der Cursorbewegung zu erm√∂glichen.  Dies wirkt sich negativ auf die Leistung aus und wurde ausschlie√ülich zu Demonstrationszwecken implementiert. <br><br>  W√§hrend des Entwicklungsprozesses entstand die Idee, Zellen in zuf√§lliger Reihenfolge auszuw√§hlen.  Es ist m√∂glich, dass dies keinen praktischen Sinn ergibt (aus offensichtlichen Gr√ºnden gibt Google uns keine Kommentare und Beschreibungen der Mechanismen der Captcha-Operation), aber das Bewegen des Cursors auf chaotische Weise durch die Zellen macht mehr Spa√ü. <br><br><img src="https://habrastorage.org/webt/p0/zh/g8/p0zhg8ii2gn0a76yj1h0vp5q5mg.gif"><br>  <font color="#999999"><i>In der Animation lautet das Ergebnis "random.shuffle (boxsForSelect)".</i></font> <br><br><h2>  Texterkennung </h2><br>  Um alle verf√ºgbaren Entwicklungen zu einem Ganzen zusammenzufassen, ist eine weitere Verkn√ºpfung erforderlich: eine Erkennungseinheit f√ºr die vom Captcha geforderte Klasse.  Wir wissen bereits, wie verschiedene Objekte im Bild erkannt und unterschieden werden. Wir k√∂nnen auf beliebige Captcha-Zellen klicken, wissen jedoch nicht, auf welche Zellen wir klicken sollen.  Eine M√∂glichkeit, dieses Problem zu l√∂sen, besteht darin, Text aus der Captcha-√úberschrift zu erkennen.  Zun√§chst habe ich versucht, die Texterkennung mit dem optischen Zeichenerkennungswerkzeug " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tesseract-OCR</a> " zu implementieren. <br><br>  In den neuesten Versionen ist es m√∂glich, Sprachpakete direkt im Installationsfenster zu installieren (zuvor wurde dies manuell durchgef√ºhrt).  Nach der Installation und dem Import von Tesseract-OCR in mein Projekt habe ich versucht, den Text aus dem Captcha-Header zu erkennen. <br><br>  Das Ergebnis hat mich leider √ºberhaupt nicht beeindruckt.  Ich entschied, dass der Text in der Kopfzeile fett hervorgehoben und aus einem bestimmten Grund zusammengef√ºhrt wurde, und versuchte daher, verschiedene Transformationen auf das Bild anzuwenden: Bin√§risierung, Verengung, Erweiterung, Unsch√§rfe, Verzerrung und Gr√∂√üen√§nderung.  Leider ergab dies kein gutes Ergebnis: Im besten Fall wurde nur ein Teil der Klassenbuchstaben bestimmt, und wenn das Ergebnis zufriedenstellend war, habe ich dieselben Transformationen angewendet, jedoch f√ºr andere Gro√übuchstaben (mit unterschiedlichem Text), und das Ergebnis stellte sich erneut als schlecht heraus. <br><br><img src="https://habrastorage.org/webt/mm/5o/zf/mm5ozfhoq5cmrwiitaig_di7ntu.png"><br>  <font color="#999999"><i>Das Erkennen der Tesseract-OCR-Kappen f√ºhrte normalerweise zu unbefriedigenden Ergebnissen.</i></font> <br><br>  Es ist unm√∂glich eindeutig zu sagen, dass ‚ÄûTesseract-OCR‚Äú Text nicht gut erkennt. Dies ist nicht der Fall: Das Tool kann mit anderen Bildern (nicht mit Captcha-Gro√übuchstaben) viel besser umgehen. <br><br>  Ich habe mich f√ºr einen Drittanbieter entschieden, der eine API f√ºr die kostenlose Arbeit damit anbietet (Registrierung und Erhalt eines Schl√ºssels f√ºr eine E-Mail-Adresse sind erforderlich).  Der Service hat ein Limit von 500 Erkennungen pro Tag, aber w√§hrend des gesamten Entwicklungszeitraums sind keine Probleme mit Einschr√§nkungen aufgetreten.  Im Gegenteil: Ich habe das Originalbild des Headers beim Service eingereicht (ohne absolut irgendwelche Transformationen anzuwenden) und das Ergebnis hat mich angenehm beeindruckt. <br><br>  W√∂rter aus dem Dienst wurden praktisch fehlerfrei zur√ºckgegeben (normalerweise sogar solche, die in Kleinbuchstaben geschrieben wurden).  Dar√ºber hinaus kehrten sie in einem sehr praktischen Format zur√ºck - unterbrochen durch Zeilenumbruchzeichen.  In allen Bildern war ich nur an der zweiten Zeile interessiert, also habe ich direkt darauf zugegriffen.  Dies konnte sich nur freuen, da ein solches Format mich von der Notwendigkeit befreite, eine Zeile vorzubereiten: Ich musste weder den Anfang noch das Ende des gesamten Textes abschneiden, ‚Äûschneiden‚Äú, ersetzen, mit regul√§ren Ausdr√ºcken arbeiten und andere Operationen an der Zeile ausf√ºhren, um ein Wort hervorzuheben (und manchmal zwei!) - ein sch√∂ner Bonus! <br><br><pre> <code class="python hljs">text = serviceResponse[<span class="hljs-string"><span class="hljs-string">'ParsedResults'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-string"><span class="hljs-string">'ParsedText'</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   JSON lines = text.splitlines() #   print("Recognized " + lines[1]) #  !</span></span></code> </pre> <br>  Ein Dienst, der Text erkannte, machte fast nie einen Fehler mit dem Klassennamen, aber ich entschied mich trotzdem, einen Teil des Klassennamens f√ºr einen m√∂glichen Fehler zu belassen.  Dies ist optional, aber ich habe festgestellt, dass ‚ÄûTesseract-OCR‚Äú in einigen F√§llen das Ende eines Wortes ab der Mitte falsch erkannt hat.  Dar√ºber hinaus beseitigt dieser Ansatz den Anwendungsfehler bei einem langen Klassennamen oder einem Namen mit zwei W√∂rtern (in diesem Fall gibt der Dienst nicht 3, sondern 4 Zeilen zur√ºck, und ich kann den vollst√§ndigen Namen der Klasse in der zweiten Zeile nicht finden). <br><br><img src="https://habrastorage.org/webt/6o/3v/nq/6o3vnqamplfdhd9byanlv4c55xw.png"><br>  <font color="#999999"><i>Ein Drittanbieter erkennt den Klassennamen gut, ohne das Image zu ver√§ndern.</i></font> <br><br><h2>  Fusion </h2><br>  Das Abrufen von Text aus der Kopfzeile reicht nicht aus.  Es muss mit den Bezeichnern der verf√ºgbaren Modellklassen verglichen werden, da das neuronale Netzwerk im Klassenarray genau den Klassenbezeichner und nicht dessen Namen zur√ºckgibt, wie es scheint.  Beim Training des Modells wird in der Regel eine Datei erstellt, in der Klassennamen und deren Bezeichner verglichen werden (auch als ‚ÄûLabel Map‚Äú bezeichnet).  Ich habe beschlossen, es einfacher zu machen und die Klassenkennungen manuell anzugeben, da f√ºr Captcha weiterhin Klassen in Russisch erforderlich sind (dies kann √ºbrigens ge√§ndert werden): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> query: <span class="hljs-comment"><span class="hljs-comment">#       classNum = 3 #   "label map"  elif "" in query: classNum = 10 elif "" in query: classNum = 11 ...</span></span></code> </pre> <br>  Alles, was oben beschrieben wurde, wird im Hauptzyklus des Programms reproduziert: Die Rahmen des Objekts, die Zelle, ihre Schnittpunkte werden bestimmt, der Cursor bewegt sich und klickt.  Wenn ein Header erkannt wird, wird die Texterkennung durchgef√ºhrt.  Wenn das neuronale Netzwerk die erforderliche Klasse nicht erkennen kann, wird eine willk√ºrliche Verschiebung des Bildes bis zu f√ºnfmal durchgef√ºhrt (dh die Eingabe in das neuronale Netzwerk wird ge√§ndert), und wenn die Erkennung immer noch nicht erfolgt, wird auf die Schaltfl√§che ‚Äû√úberspringen / Best√§tigen‚Äú geklickt (seine Position wird √§hnlich erkannt Zellen und Kappen erkennen). <br><br>  Wenn Sie das Captcha h√§ufig l√∂sen, k√∂nnen Sie das Bild beobachten, wenn die ausgew√§hlte Zelle verschwindet und langsam und langsam eine neue an ihrer Stelle erscheint.  Da der Prototyp so programmiert ist, dass er nach Auswahl aller Zellen sofort zur n√§chsten Seite wechselt, habe ich beschlossen, 3 Sekunden Pause einzulegen, um das Klicken auf die Schaltfl√§che ‚ÄûWeiter‚Äú auszuschlie√üen, ohne Objekte in der langsam erscheinenden Zelle zu erkennen. <br><br>  Der Artikel w√§re nicht vollst√§ndig, wenn er keine Beschreibung des Wichtigsten enthalten w√ºrde - ein H√§kchen f√ºr die erfolgreiche √úbergabe von Captcha.  Ich entschied, dass ein einfacher <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vorlagenvergleich</a> dies tun k√∂nnte.  Es ist erw√§hnenswert, dass der Mustervergleich bei weitem nicht der beste Weg ist, Objekte zu erkennen.  Zum Beispiel musste ich die Erkennungsempfindlichkeit auf ‚Äû0,01‚Äú einstellen, damit die Funktion keine Zecken mehr in allen sehen konnte, sondern sie sah, wenn es wirklich eine Zecke gab.  Ebenso habe ich mit einem leeren Kontrollk√§stchen gehandelt, das den Benutzer trifft und von dem aus das Captcha startet (es gab keine Probleme mit der Empfindlichkeit). <br><br><h2>  Ergebnis </h2><br>  Das Ergebnis aller beschriebenen Aktionen war eine Anwendung, deren Leistung ich auf dem " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Toaster</a> " getestet habe: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wfl1K0bqBWQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Es ist erw√§hnenswert, dass das Video nicht beim ersten Versuch aufgenommen wurde, da ich h√§ufig mit der Notwendigkeit konfrontiert war, Klassen auszuw√§hlen, die nicht im Modell enthalten sind (z. B. Fu√üg√§nger√ºberwege, Treppen oder Schaufenster). <br><br>  "Google reCAPTCHA" gibt einen bestimmten Wert an die Site zur√ºck und zeigt, wie "Sie sind ein Roboter", und Site-Administratoren k√∂nnen wiederum einen Schwellenwert f√ºr das √úbergeben dieses Werts festlegen.  M√∂glicherweise wurde am Toaster ein relativ niedriger Captcha-Schwellenwert festgelegt.  Dies erkl√§rt die ziemlich einfache Passage des Captcha durch das Programm, obwohl es zweimal falsch war und die Ampel auf der ersten Seite und der Hydrant auf der vierten Seite des Captcha nicht zu sehen waren. <br><br>  Zus√§tzlich zum Toaster wurden Experimente auf der offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">reCAPTCHA-Demoseite durchgef√ºhrt</a> .  Infolgedessen wurde festgestellt, dass es nach mehreren fehlerhaften Erkennungen (und Nichterkennungen) selbst f√ºr eine Person √§u√üerst schwierig wird, ein Captcha zu erhalten: Neue Klassen sind erforderlich (wie Traktoren und Palmen), Zellen ohne Objekte erscheinen in den Proben (fast eint√∂nige Farben) und die Anzahl der Seiten nimmt dramatisch zu. durchgehen. <br><br>  Dies machte sich besonders bemerkbar, als ich mich entschied, auf zuf√§llige Zellen zu klicken, falls Objekte nicht erkannt wurden (aufgrund ihrer Abwesenheit im Modell).  Daher k√∂nnen wir mit Sicherheit sagen, dass zuf√§llige Klicks nicht zu einer L√∂sung des Problems f√ºhren.  Um eine solche ‚ÄûBlockierung‚Äú durch den Pr√ºfer zu beseitigen, haben wir die Internetverbindung wieder hergestellt und die Browserdaten gel√∂scht, da es unm√∂glich wurde, einen solchen Test zu bestehen - es war fast endlos! <br><br><img src="https://habrastorage.org/webt/xk/xe/5u/xkxe5uanfylidi1jgteyb3svyoc.png"><br>  <font color="#999999"><i>Wenn Sie an Ihrer Menschlichkeit zweifeln, ist ein solches Ergebnis m√∂glich.</i></font> <br><br><h2>  Entwicklung </h2><br>  Wenn der Artikel und die Anwendung das Interesse des Lesers wecken, werde ich die Implementierung, Tests und die weitere Beschreibung gerne in einer detaillierteren Form fortsetzen. <br><br>  Es geht darum, Klassen zu finden, die nicht Teil des aktuellen Netzwerks sind. Dies wird die Effizienz der Anwendung erheblich verbessern.  Im Moment ist es dringend erforderlich, zumindest Klassen wie Fu√üg√§nger√ºberwege, Schaufenster und Schornsteine ‚Äã‚Äãzu erkennen - ich werde Ihnen sagen, wie Sie das Modell umschulten.  W√§hrend der Entwicklung habe ich eine kurze Liste der h√§ufigsten Klassen erstellt: <br><br><ul><li>  Fu√üg√§nger√ºberwege; </li><li>  Hydranten; </li><li>  Schaufenster </li><li>  Schornsteine; </li><li>  Autos; </li><li>  Busse </li><li>  Ampeln; </li><li>  Fahrr√§der </li><li>  Verkehrsmittel; </li><li>  Treppen </li><li>  Zeichen. </li></ul><br>  Durch die gleichzeitige Verwendung mehrerer Modelle kann die Qualit√§t der Objekterkennung verbessert werden. Dies kann die Leistung beeintr√§chtigen, aber die Genauigkeit erh√∂hen. <br><br>  Eine andere M√∂glichkeit, die Qualit√§t der Erkennung von Objekten zu verbessern, besteht darin, die Bildeingabe in das neuronale Netzwerk zu √§ndern: Im Video k√∂nnen Sie sehen, dass ich, wenn Objekte nicht erkannt werden, mehrmals eine willk√ºrliche Bildverschiebung durchf√ºhre (innerhalb von 10 Pixeln horizontal und vertikal). Mit dieser Operation k√∂nnen Sie h√§ufig Objekte anzeigen, die zuvor vorhanden waren wurden nicht erkannt. <br><br>  Eine Vergr√∂√üerung des Bildes von einem kleinen auf ein gro√ües Quadrat (bis zu 300 x 300 Pixel) f√ºhrt auch zur Erkennung nicht erkannter Objekte. <br><br><img src="https://habrastorage.org/webt/01/sd/eh/01sdehtdkgz_a-5gtsxh1-auhoq.png"><br>  <font color="#999999"><i>Links wurden keine Objekte gefunden: Originalquadrat mit 100 Pixel Seite.</i></font>  <font color="#999999"><i>Rechts wird ein Bus erkannt: ein vergr√∂√üertes Quadrat mit einer Gr√∂√üe von bis zu 300 x 300 Pixel.</i></font> <br><br>  Eine weitere interessante Transformation ist das Entfernen des wei√üen Gitters √ºber dem Bild mit OpenCV-Tools: M√∂glicherweise wurde der Hydrant aus diesem Grund im Video nicht erkannt (diese Klasse ist im neuronalen Netzwerk vorhanden). <br><br><img src="https://habrastorage.org/webt/m_/7p/zu/m_7pzu93h3jqw3doy3flbtlymee.png"><br>  <font color="#999999"><i>Links ist das Originalbild und rechts das Bild, das im Grafikeditor ge√§ndert wurde: Das Raster wird gel√∂scht, die Zellen werden ineinander verschoben.</i></font> <br><br><h2>  Zusammenfassung </h2><br>  Mit diesem Artikel wollte ich Ihnen sagen, dass Captcha wahrscheinlich nicht der beste Schutz gegen Bots ist, und es ist durchaus m√∂glich, dass in naher Zukunft neue Schutzma√ünahmen gegen automatisierte Systeme erforderlich sein werden. <br><br>  Der entwickelte Prototyp zeigt, dass es mit den erforderlichen Klassen im neuronalen Netzwerkmodell und der Anwendung von Transformationen √ºber Bilder m√∂glich ist, einen Prozess zu automatisieren, der nicht automatisiert werden sollte, selbst wenn er sich noch in einem unfertigen Zustand befindet. <br><br>  Ich m√∂chte Google auch darauf aufmerksam machen, dass es neben der in diesem Artikel beschriebenen Methode zur Umgehung von Captcha auch eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">andere M√∂glichkeit gibt</a> , ein Audio-Sample zu <abbr title="Der Prozess der √úbersetzung von Audio in Text">transkribieren</abbr> .  Meiner Meinung nach ist es jetzt notwendig, Ma√ünahmen zur Verbesserung der Qualit√§t von Softwareprodukten und Algorithmen gegen Roboter zu ergreifen. <br><br>  Aus dem Inhalt und dem Wesen des Materials geht hervor, dass ich Google und insbesondere reCAPTCHA nicht mag, aber dies ist weit davon entfernt, und wenn es eine n√§chste Implementierung gibt, werde ich Ihnen sagen, warum. <br><br>  Entwickelt und demonstriert, um die Bildung zu verbessern und Methoden zur Gew√§hrleistung der Informationssicherheit zu verbessern. <br><br>  Vielen Dank f√ºr Ihre Aufmerksamkeit. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de449236/">https://habr.com/ru/post/de449236/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de449218/index.html">10 kritische F√§higkeiten f√ºr jeden DevOps-Ingenieur</a></li>
<li><a href="../de449220/index.html">DrumHero: Wie ich das erste Spiel in meinem Leben gemacht habe</a></li>
<li><a href="../de449224/index.html">√úber die Tendenz der k√ºnstlichen Intelligenz</a></li>
<li><a href="../de449232/index.html">√úberwachung des Solarenergieverbrauchs per Computer / Server</a></li>
<li><a href="../de449234/index.html">Kostenloser Wireguard VPN-Dienst unter AWS</a></li>
<li><a href="../de449240/index.html">Die Geschichte eines jungen Daida-Dienstes (Abonnementkunst)</a></li>
<li><a href="../de449246/index.html">AX200 - Intel Wi-Fi 6</a></li>
<li><a href="../de449248/index.html">Moderne IDE. Auf jeden Fall D, bis zu einem gewissen Grad E, und schon gar nicht ich</a></li>
<li><a href="../de449252/index.html">Zombie-Projekte - Benutzerdaten auch nach seinem Tod zusammenf√ºhren</a></li>
<li><a href="../de449254/index.html">FAQ zu Architektur und Arbeit VKontakte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
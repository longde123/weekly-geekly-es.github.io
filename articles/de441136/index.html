<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçÑ ‚û°Ô∏è üë®‚Äçüë®‚Äçüë¶‚Äçüë¶ Langzeitspeicherung von Prometheus-Metriken (Alexey Palazhchenko, Percona) üöç üÜï ‚ùé</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In kurzer Zeit hat sich Prometheus zu einem der beliebtesten √úberwachungsinstrumente entwickelt. Vielen Dank insbesondere und die hohe Geschwindigkeit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Langzeitspeicherung von Prometheus-Metriken (Alexey Palazhchenko, Percona)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441136/"><p>  In kurzer Zeit hat sich Prometheus zu einem der beliebtesten √úberwachungsinstrumente entwickelt.  Vielen Dank insbesondere und die hohe Geschwindigkeit seiner Arbeit.  Der lokale Speicher eignet sich hervorragend zum kurzfristigen Speichern von Metriken und zum Arbeiten mit diesen.  Manchmal m√∂chten Sie die Metriken √ºber Monate und Jahre verteilt halten und dabei alte Daten automatisch abschneiden, ohne jedoch die Benutzeroberfl√§che f√ºr die Arbeit mit ihnen zu √§ndern. </p><br><p>  Genau dazu die Entschl√ºsselung des Berichts von Alexey Palazhchenko auf der RootConf 2018. In dem Bericht: Prometheus, TSDB f√ºr lokalen Speicher, Prometheus f√ºr Remote-Speicher, PromQL, TSDB, Clickhouse, PromHouse, ein wenig InfluxDB. </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/LXllYmb0RTk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Wen k√ºmmert es bitte unter der Katze. </p><a name="habracut"></a><br><p>  Freunde!  Hallo allerseits!  Ich hei√üe Alexey Palazhchenko.  Ich arbeite bei Percona.  Ich m√∂chte Sie √ºber die Langzeitspeicherung von Metriken in Prometheus informieren. </p><br><p><img src="https://habrastorage.org/webt/rw/vv/4v/rwvv4v4zpjhn5tlmrclgeii9mkq.png"></p><br><p>  Ich arbeite bei Percona und mache ein Produkt namens Percona Monitoring and Management.  Dies ist die Box-L√∂sung, die unsere Kunden f√ºr sich selbst festgelegt haben.  PMM ist vollst√§ndig Open Source.  Es besteht aus Prometheus, Grafana f√ºr die grafische Darstellung, einer benutzerdefinierten Abfrageanalyse-Software und unserem eigenen Wrapper, mit dem Sie einige Verwaltungsaufgaben √ºbernehmen k√∂nnen.  Zum Beispiel k√∂nnen Sie Prometheus ein Kratzziel hinzuf√ºgen.  Dies sind neue Quellen, aus denen er Metriken entnimmt, ohne manuell einen Container oder eine virtuelle Maschine eingeben und die Konfigurationsdatei bearbeiten zu m√ºssen. </p><br><p>  Es ist wichtig zu verstehen, dass dies kein SaaS ist.  Wir haben keine Produktion.  Unsere Produktion befindet sich bei unseren Kunden.  Daran zu experimentieren ist nicht sehr gut.  Wir haben das N√§chste, was man als Produktion bezeichnen k√∂nnte - dies ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://pmmdemo.percona.com/</a> .  Zum Zeitpunkt des Berichts musste pmmdemo.percona.com aufgrund der DSGVO geschlossen werden. </p><br><p>  Wir liefern PMM an Kunden - eine Box-L√∂sung: ein Docker-Container oder eine virtuelle Maschine.  Sie alle m√∂gen Prometheus.  Einige Leute, die Prometheus zum ersten Mal betrachten, sto√üen auf ein Pull-Modell.  F√ºr Anf√§nger ist dies unpraktisch.  Im Allgemeinen ein separates gro√ües Gespr√§ch.  Sie k√∂nnen √ºber Pull- oder Push-Methoden streiten.  Im Durchschnitt ist dies ungef√§hr das Gleiche. </p><br><p>  Einige Dinge in Prometheus sind sehr cool. </p><br><ul><li><p>  Prometheus-Abfragesprache ist wirklich eine coole Sache, die nirgendwo analog ist. </p><br></li><li><p>  Das zweite, was Ihnen gef√§llt, ist die Serviceerkennung.  Wenn Sie √ºber eine dynamische Infrastruktur verf√ºgen, Kubernetes, m√ºssen Sie automatisch nicht alle Ziele f√ºr die √úberwachung mit Ihren H√§nden hinzuf√ºgen.  Wenn statisch - kann dies auch ganz einfach erfolgen.  Sie m√ºssen die Konfigurationsdatei verwenden. </p><br></li></ul><br><p>  Prometheus-Kunden m√∂gen es.  Sie wollen Metriken immer l√§nger halten.  Jemand verwendet Prometheus nur zur Betriebs√ºberwachung.  Aber jemand m√∂chte die Metriken l√§nger behalten, die Dynamik beobachten und mit den Grafiken vor einem Jahr vergleichen.  Gleichzeitig ist das Ziel der langfristigen Speicherung von Metriken nicht das Ziel des Prometheus-Projekts.  Urspr√ºnglich wurde es erstellt, um Metriken f√ºr kurze Zeit zu speichern.  SoundCloud speichert Metriken in nur wenigen Tagen.  Es gibt Mechanismen in Prometheus, die es Ihnen erm√∂glichen, dies l√§nger zu tun, aber sie sind etwas seitlich angeordnet.  Daher k√∂nnen wir eine Entscheidung f√ºr das Prometheus-√ñkosystem treffen, ohne den Kern des Systems selbst zu ver√§ndern.  Basierend auf ihnen k√∂nnen wir unsere eigene Entscheidung innerhalb desselben √ñkosystems treffen. </p><br><p><img src="https://habrastorage.org/webt/ws/1n/7k/ws1n7kpa7ohpkxwpxuli5dcpwuc.png"></p><br><p>  Dies ist kein Bericht √ºber vorgefertigte L√∂sungen.  Dies ist ein Bericht √ºber unsere Erfahrung, √ºber unseren Schmerz, √ºber unsere Versuche.  Wenn Sie erwartet haben, dass Sie nach diesem Bericht das Repository oder den Docker-Container herunterladen, ausf√ºhren und es funktioniert, ist dies nicht der Fall.  Aber gleichzeitig ist es nah genug daran.  Wir haben einige Grundlagen.  Sie sind alle Open Source.  Sie k√∂nnen es versuchen.  Sie sind noch nicht produktionsbereit.  Mit den Informationen in diesem Bericht k√∂nnen Sie jedoch verstehen, warum und was besser gemacht werden kann.  Sie k√∂nnen Ihre eigene Entscheidung treffen, die gut zu Ihnen passt. </p><br><p><img src="https://habrastorage.org/webt/ej/4j/sm/ej4jsmldkwk-bsme40kqehzilqc.png"></p><br><p>  Wie werden Metriken in Prometheus gespeichert?  Es gibt lokalen Speicher.  Es gibt Remote-Speicher.  Dies sind eigentlich zwei verschiedene Welten.  Sie kreuzen sich schwach.  Daher ist der Bericht auch in zwei Teile gegliedert. </p><br><p><img src="https://habrastorage.org/webt/jm/ic/81/jmic81mrsu49j-zxv6spn9aopac.png"></p><br><p>  Wenn Sie bei einem fr√ºheren Bericht in der Haupthalle waren, wo es in Prometheus ein gutes Intro gab, wissen Sie, dass der lokale Speicher eine separate Bibliothek namens TSDB ist.  TSDB hat nichts mit OpenTSDB zu tun.  TSDB ist ein separates Go-Paket, das Sie von Ihrem Go-Programm aus verwenden k√∂nnen.  Auf der Ebene der TSDB-Bibliothek gibt es keinen Client oder Server. </p><br><p>  Diese Bibliothek ist f√ºr die Arbeit mit Zeitreihendaten optimiert.  Beispielsweise verf√ºgt die TSDB √ºber eine Delta-Codierung, mit der Sie nicht die Nummern selbst, sondern die √Ñnderungen zwischen diesen Nummern speichern k√∂nnen.  Auf diese Weise k√∂nnen Sie 1 Byte anstelle von 16 Byte speichern.  1 Byte f√ºr die Zeit und 1 Byte f√ºr den Wert.  Das hei√üt, Sie speichern aufgrund dieser guten Komprimierung durchschnittlich 1 oder 2 Bytes genau. </p><br><p>  TSDB ist f√ºr Pull-Modelle optimiert.  Daten werden nur dort hinzugef√ºgt.  Prometheus kann keine historischen Daten schreiben.  Hierf√ºr gibt es keine API.  Das maximale Delta betr√§gt ungef√§hr 5 Minuten.  Wenn die Daten √§lter sind, werden sie nicht akzeptiert. </p><br><p>  In der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TSDB</a> ist kein Downsampling von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tsdb # 313</a> integriert.  Es gibt ein offenes Thema, in dem dar√ºber diskutiert wurde, dass es im Allgemeinen Projekte gibt, die Prometheus etwas bewirken, und dass es dort ein Downsampling gibt.  Bisher besteht die L√∂sung darin, dass TSDB kein Downsampling hinzuf√ºgt. </p><br><p><img src="https://habrastorage.org/webt/5q/pb/vt/5qpbvtptau3gz7ygcxb9cl3nmzg.png"></p><br><p>  Wie w√ºrden wir Daten von TSDB erhalten?  TSDB ist eine Datenbank auf der Festplatte.  Sie k√∂nnen damit arbeiten, wenn Sie ein Go-Programm schreiben.  Wenn Sie jedoch kein Programm in Go schreiben, gibt es eine JSON-API, mit der Sie Abfrageabfragen durchf√ºhren k√∂nnen.  Wenn Sie jemals Prometheus verwendet und mindestens einmal ein Diagramm erstellt haben, kennen Sie die Standard-Abfrage-API, in der es einen Abfrageparameter gibt, in dem Sie jede PromQL-Abfrage und optional die Zeit ausf√ºhren k√∂nnen.  Wenn keine Zeit vorhanden ist, wird die aktuelle Zeit verwendet. </p><br><p>  Auf der Folie wird eine bestimmte Abfrage hervorgehoben, die Sie im wirklichen Leben selten sehen.  Das ist ein Hack.  Dies erm√∂glicht es uns, alle Metriken von Prometheus herauszuholen.  Wie funktioniert es  Auf der Ebene von PromQL wird gesagt, dass es unm√∂glich ist, einen solchen Ausdruck zu schreiben, der alle Zeitreihen abf√§ngt.  Dies ist direkt in den Regeln geschrieben.  Eine andere Regel besagt, dass Sie keinen Matcher erstellen k√∂nnen, in dem alle Werte leer sind.  Wenn Sie einfach geschweifte Klammern schreiben, funktioniert dies nicht.  Wenn Sie schreiben, dass der Name nichts entspricht (kein leerer Wert), funktioniert dies nicht.  Aber dies ist ein echter Hack, mit dem Sie dies tun k√∂nnen.  Es ist jedoch nicht einmal besonders dokumentiert.  Es gibt Kommentare im Code selbst, dass dies funktioniert. </p><br><p>  Die zweite Abfrage ist query_range, die dasselbe tut, aber Sie Daten in einem Bereich und mit einem Schritt zur√ºckgibt.  Im Wesentlichen wird f√ºr jeden Schritt vom Anfang bis zum Ende mehrmals eine Abfrage durchgef√ºhrt.  Dies ist die API zum Zeichnen von Grafiken.  Die erste API verwendet, um Sofortwerte abzurufen. </p><br><p><img src="https://habrastorage.org/webt/nc/cm/cs/nccmcsyofzxubtca8yoyas7p6ag.png"></p><br><p>  Wir haben eine API zum Abrufen von Metadaten.  Wenn wir alle Namen der Metriken erhalten m√∂chten, f√ºhren wir eine Abfrage wie diese durch, wobei match ein Array von Metriken ist.  Es mag mehrere Argumente geben, aber in diesem Fall √ºbergeben wir die gleiche √úbereinstimmung, die uns alles zur√ºckgibt. </p><br><p>  Die zweite Meta-API, die den Wert aller Labels zur√ºckgibt.  Wenn wir eine Liste aller Jobs sehen m√∂chten, schreiben wir anstelle von label_name einen Job und erhalten diese Liste.  Diese APIs geben JSON an uns zur√ºck. </p><br><p><img src="https://habrastorage.org/webt/qe/ku/j4/qekuj4lgm4zp-x07kvhoorux_w0.png"></p><br><p>  Es gibt eine weitere API, die alle Metriken von Prometheus selbst in einem Format zur√ºckgibt, das f√ºr Exporteure typisch ist.  Das Format hei√üt expfmt.  In Prometheus selbst gibt es eine Federation-API, mit der Sie eine solche Anfrage stellen k√∂nnen.  Wof√ºr ist das?  Die einfachste Option: Wenn Sie Code haben, der bereits mit expfmt funktioniert, m√ºssen Sie ihn nicht neu trainieren, um mit einer benutzerdefinierten JSON-API zu arbeiten.  Dieses Format ist viel einfacher zu streamen, denn wenn Sie JSON irgendwo auf der obersten Ebene des Objekts haben, m√ºssen Sie dieses Objekt meistens als Ganzes analysieren.  Hier kann es Zeile f√ºr Zeile erfolgen. </p><br><p>  Das Wichtigste ist, dass es sich um eine separate API handelt.  Es funktioniert genau wie ein echter Export.  Sie k√∂nnen den anderen Prometheus nehmen, um ihn abzukratzen.  Dies ist ein regul√§rer Job mit den √ºblichen Parametern.  Sie m√ºssen den Parameter - Abfrage-URL √ºbergeben.  Wenn Sie eine Curl-Anfrage stellen, erhalten Sie diese hier.  Wir erhalten alle Metriken f√ºr den aktuellen Zeitwert.  Die einzige Einschr√§nkung: Sie m√ºssen honor_labels festlegen, damit Prometheus, der einen anderen Prometheus √ºber diese API verschrottet, den Wert der Job- und Instanzbezeichnung nicht beeintr√§chtigt.  Mit dieser Federation-API k√∂nnen Sie alle Daten von einem Prometheus auf einen anderen laden. </p><br><p><img src="https://habrastorage.org/webt/64/lc/yy/64lcyynloe47gbkjlelzyddss60.png"></p><br><p>  Wie kann das genutzt werden? </p><br><p>  Das Wichtigste ist, dass Sie dies nicht tun m√ºssen.  TSDB ist f√ºr verschiedene Betriebsarten optimiert.  Wenn Sie einen Prometheus haben, der viele Daten kratzt, dann macht er viele I / O.  Wenn Sie die Verbund-API verwenden, erh√∂ht sich die Menge der Eingabe um das Zweifache.  Es gibt Nuancen.  Abh√§ngig davon, wie oft Sie am Verbund kratzen und wie oft Sie die Ziele kratzen.  Wenn die Zeit nicht ge√§ndert wurde, verdoppelt dies die Last wirklich.  Wenn Sie also Ihren Prometheus skalieren und die F√∂deration aktivieren m√∂chten, werden Sie ihn t√∂ten.  Die Last wird sich verdoppeln. </p><br><p>  Zweiter Moment.  Sie √ºberspringen Daten.  Sie erhalten einen Datenkonflikt.  Warum so?  Diese API ist, wie fast jede API in Prometheus, nicht atomar.  Wenn neue Daten eintreffen, endet ein neues Scraping in dem Moment, in dem Ihre Verbundanforderung noch ausgef√ºhrt wird. Sie k√∂nnen Daten f√ºr eine Zeitreihe und neue Daten f√ºr eine andere abrufen.  Wenn es sich um eine nicht verwandte Zeitreihe handelt, ist sie im Allgemeinen nicht be√§ngstigend.  Wenn Sie jedoch eine Zusammenfassung oder ein Histogramm haben, das auf expfmt-Ebene durch mehrere grundlegende Metriken dargestellt wird, besteht eine Inkonsistenz zwischen diesen. </p><br><p><img src="https://habrastorage.org/webt/_0/5h/lk/_05hlkpn57b8klhjwborhup4bds.png"></p><br><p>  Wie k√∂nnen wir dieses atomare Problem l√∂sen?  Prometheus verf√ºgt √ºber Aufzeichnungsregeln, mit denen Sie aus einer vorhandenen Zeitreihe eine neue Zeitreihe erstellen k√∂nnen.  Dies kann weniger h√§ufig durchgef√ºhrt werden.  Dies ist eine M√∂glichkeit zum Downsampling.  Verschrotten Sie beispielsweise das Ziel jede Sekunde, aber dann m√∂chten wir die node_cpu-Aggregation in einer Minute durchf√ºhren.  Durch Gruppieren in Prometheus 2.0 k√∂nnen Sie diese Aggregationen nacheinander durchf√ºhren.  Regeln, die sich in derselben Gruppe befinden, werden streng nacheinander ausgef√ºhrt.  Zu diesem Zeitpunkt gibt es kein Atomit√§tsproblem, es gibt kein Problem, dass sich die Daten im Prozess √§ndern.  Dies l√∂st jedoch nicht das Problem der Tatsache, dass einige andere Daten zul√§ssig sind, die logisch damit verbunden sind, aber aus Sicht des Datenmodells nicht verbunden sind.  Es gibt noch keine reine Atomizit√§t.  Zu diesem Thema gibt es ein offenes Thema.  Sie k√∂nnen Schnappsch√ºsse machen.  Sie k√∂nnen eine PromQL-Abfrage an die TSDB-Datenbank senden und alle Stichproben, die kleiner als ein Wert der Zeit sind, die mit der Auswertung begonnen hat, aus den erhaltenen Werten l√∂schen.  Dies w√§re der einfachste Weg, aber bisher wurde dies nicht getan. </p><br><p>  Es ist wichtig zu verstehen, dass die Aufzeichnungsregeln auf dem unteren Prometheus und nicht auf dem des Verbandes durchgef√ºhrt werden m√ºssen.  Andernfalls √ºberspringen Sie Spitzen, und Ihre √úberwachung funktioniert nicht ordnungsgem√§√ü. </p><br><p><img src="https://habrastorage.org/webt/kp/jf/hd/kpjfhdz8boamndunerhcx2vgebq.png"></p><br><p>  Wie k√∂nnen wir diese Kombination dieser Dinge verwenden, um Downsampling und Langzeitspeicherung durchzuf√ºhren? </p><br><p>  Der erste.  Wir haben gerade einen Verband gegr√ºndet und alle Daten von diesem Prometheus heruntergeladen.  Dieser seltsame regul√§re Ausdruck ist wie ein Zoidberg - es ist eigentlich nur ein Doppelpunkt.  Ein Sternchen links und rechts vom Doppelpunkt.  Wir verwenden den Standardnamen f√ºr Aufzeichnungsregeln, der der Mitte einen Doppelpunkt hinzuf√ºgt.  Beim Teilen des urspr√ºnglichen Namens wird links eine Aggregationsebene und rechts eine Funktion angezeigt.  Eine normale Doppelpunktmetrik nicht.  Wenn es einen Doppelpunkt gibt, ist dies ein Zeichen daf√ºr, dass dies eine Aggregation ist.  Danach verwenden wir diesen Metriknamen in unserem Diagramm.  Wenn wir m√∂chten, dass unser Zeitplan, unser Dashboard in grafana, mit dem Haupt-Prometheus und mit denen, die h√∂her sind, zusammenarbeitet, k√∂nnen wir den Ausdruck <strong>oder verwenden</strong> .  Wir nehmen entweder die eine oder die andere Metrik, je nachdem, welche.  Wir k√∂nnen betr√ºgen und Relabeling verwenden, um die neue Metrik in den alten Namen umzubenennen.  Dies ist ein ziemlich gef√§hrlicher Ansatz.  Sie k√∂nnen regul√§re Anh√§nge falsch buchstabieren und es kommt zu einem Zeitreihenkonflikt.  Prometheus schreibt viele Warnungen in das Protokoll.  Sie werden dies sehen, aber es kann ziemlich schwierig sein, den Grund zu finden.  Wenn dies jedoch sorgf√§ltig durchgef√ºhrt wird, z. B. indem diese regul√§ren Ausdr√ºcke programmgesteuert generiert werden, funktioniert dies.  Als n√§chstes haben Sie ein regul√§res Dashboard, in dem nur node_cpu verwendet wird.  Je nachdem, welcher Prometheus verwendet wird, erhalten Sie entweder Rohdaten oder aggregierte Daten. </p><br><p><img src="https://habrastorage.org/webt/hd/ft/1x/hdft1xwgw_61j7tab_3feehhsgy.png"></p><br><p>  Wie gesagt, Aufnahmeregeln k√∂nnen ganz einfach generiert werden.  Wir bekommen einfach alle Zeitreihen durch die API, die ich bereits gezeigt habe.  Wir erstellen Regeln und diese Regeln m√ºssen die richtigen Funktionen und Operatoren verwenden.  Dort muss keine Rate mit Messger√§t verwendet werden.  Dies wird nicht richtig funktionieren.  Es sollte nur mit count verwendet werden.  Auf der Ebene, auf der Sie arbeiten, verf√ºgen Sie m√∂glicherweise nicht √ºber Informationen zu Datentypen.  Zum Beispiel, wenn Sie expfmt verwenden.  Es gibt Informationen zu den Typen.  Wenn die JSON-API nicht vorhanden ist.  Infolgedessen hat der Ausdruck, den Sie automatisch generieren, m√∂glicherweise keine physikalische Bedeutung.  Daher k√∂nnen Sie dort entweder eine wei√üe oder eine schwarze Liste verwenden.  Generieren Sie abh√§ngig davon entweder die Regel, die Sie ben√∂tigen, oder werfen Sie die Regeln aus, die keinen Sinn ergeben.  Es gibt ein Promtool-Tool, mit dem Sie √ºberpr√ºfen k√∂nnen, ob die von Ihnen generierten Regeln und die von Ihnen generierte Konfiguration sinnvoll sind.  Es hat die richtige Syntax. </p><br><p><img src="https://habrastorage.org/webt/om/wc/fv/omwcfvvh7mc8bky3zkble7vimqm.png"></p><br><p>  Wenn wir Grafana haben und es mehrere Prometheus gibt, m√ºssen wir wissen, an welchen Prometheus die Anfrage gesendet werden soll.  Wie w√ºrden wir das machen? </p><br><p>  Eine M√∂glichkeit besteht darin, einen speziellen Proxy zu erstellen, der die Zeit in der Anfrage anzeigt, und abh√§ngig davon Prometheus auszuw√§hlen.  Die Abfragen haben eine Startzeit und eine Endzeit.  Abh√§ngig davon k√∂nnen Sie das Routing mit Ihren H√§nden durchf√ºhren.  Man k√∂nnte eine Art Programm schreiben, das dies tut.  In der Praxis wird dies von nginx mit dem lua-Modul oder einem kleinen Programm durchgef√ºhrt. </p><br><p><img src="https://habrastorage.org/webt/ff/ve/vz/ffvevzimxzpnrjrqirbkuqssiqm.png"></p><br><p>  Brauchen wir wirklich eine API?  K√∂nnen wir direkt mit TSDB arbeiten?  Es gibt eine Nuance.  Erstens, wenn wir versuchen, TSDB zu verwenden, die jetzt von Prometheus verwendet wird, k√∂nnen wir dies nicht tun.  Es gibt eine spezielle Sperrdatei, die dies verhindert.  Wenn wir Code schreiben, der dies ignoriert, und versuchen, Daten zu lesen oder zu schreiben, werden wir sie garantiert besch√§digen.  Au√üerdem sogar lesen.  Was kann getan werden?  Wir k√∂nnen Daten √ºber die API lesen und TSDB nebeneinander erstellen.  Stoppen Sie dann Prometheus und ersetzen Sie es durch TSDB.  Gleichzeitig k√∂nnen wir die Leistung beeintr√§chtigen, wenn wir alle Daten √ºber die API lesen.  Ich werde etwas sp√§ter dar√ºber sprechen. </p><br><p>  Die zweite Option.  Sie k√∂nnen diese Dateien kopieren (Hot Backup erstellen), dh kopieren, wie sie sind.  Ja, sie werden besch√§digt.  Beim √ñffnen wird eine Warnung angezeigt, dass die Daten besch√§digt sind.  Sie m√ºssen repariert werden.  Sie k√∂nnen neue Daten verlieren.  Aber es ist uns egal.  Wir wollen ein Downsampling alter Daten.  Downsampling kann mit PromQL durchgef√ºhrt werden.  Aber es gibt eine Nuance.  Es ist viel schwieriger, es von Prometheus abzurei√üen als TSDB.  Wenn Sie mit Go und Abh√§ngigkeitsmanagement ein wenig vertraut sind, ist der Anbieter PromQL ein gro√üer Schmerz.  Ich w√ºrde dich nicht beraten.  Vermeiden Sie dies wenn m√∂glich. </p><br><p><img src="https://habrastorage.org/webt/2z/ii/fs/2ziifscme6pqm1ppf1n9ripipuq.png"></p><br><p>  Wir gehen zum Remote Storage √ºber.  Hat jemand mit Remote Storage in Prometheus gearbeitet?  Ein paar H√§nde.  Remote Storage ist eine API, die es schon lange gibt.  Jetzt in Version 2.2 Remote Storage - als experimentell markiert.  Dar√ºber hinaus ist bekannt, dass sich die Remote Storage API definitiv √§ndern wird. </p><br><p>  Mit Remote Storage k√∂nnen Sie nur mit Rohdaten arbeiten.  Es gibt kein PromQL am Eingang oder Ausgang.  Wenn Sie lesen, k√∂nnen Sie nicht die volle Leistung von PromQL nutzen.  Es pumpt im Wesentlichen alle Daten aus dem Remotespeicher aus, die der Bedingung entsprechen.  Weiter funktioniert PromQL bereits mit ihnen.  Dies hat einen ziemlich gro√üen Overhead.  Sie m√ºssen viele Daten √ºber das Netzwerk pumpen.  Daher wird in Prometheus 2.3, das noch nicht ver√∂ffentlicht wurde, aber bereits verz√∂gert wurde, ein Hinweis gelesen.  Wir werden etwas sp√§ter dar√ºber sprechen. </p><br><p>  Noch keine API f√ºr Metadaten.  Sie k√∂nnen keine API erstellen, die alle Zeitreihen vom Remotespeicher zur√ºckgibt.  Wenn Sie eine Anfrage an die Prometheus-API stellen, wird diese nicht an den Remotespeicher weitergeleitet.  Sie erhalten die Zeitreihe zur√ºck, die sich in der lokalen Datenbank befindet.  Wenn Ihre lokale Datenbank deaktiviert ist, erhalten Sie 0 zur√ºck. Dies kann etwas unerwartet sein.  Jetzt verwendet diese API ProtoBuf und wird in Zukunft definitiv auf gRPC ge√§ndert.  Sie haben es noch nicht getan, weil gRPC HTTP2 ben√∂tigt.  Und in der Praxis hatten sie Probleme mit ihm. </p><br><p><img src="https://habrastorage.org/webt/lc/7v/ij/lc7vijvha-gtzs_oj74xszwk488.png"></p><br><p> Die Schreib-API sieht folgenderma√üen aus.  Die Anfrage enth√§lt eine Reihe von Beschriftungen.  Der Satz von Beschriftungen identifiziert die Zeitreihen nur eindeutig.  <code>__name__</code> ist eigentlich nur ein Label mit einem speziellen Namen.  Und Samples sind eine Reihe von Zeit und Werten - int64 und float64.  Bei der Aufnahme ist die Reihenfolge unwichtig.  Es wird davon ausgegangen, dass die Datenbank, die dies in sich selbst schreibt, alles richtig macht.  Prometheus kann einige Optimierungen vornehmen und diese nicht erneut sortieren.  Dementsprechend ist eine Schreibanforderung nur ein paar Zeitreihen. </p><br><p><img src="https://habrastorage.org/webt/xd/qr/ud/xdqrudjh5lpomcepkdmkjcfegt0.png"></p><br><p>  Die Schreibkonfiguration hat eine ziemlich flexible Konfiguration.  Es gibt viele Optionen zum Konfigurieren der Schreibgleichzeitigkeit.  Was Prometheus Shards nennt, sind im Wesentlichen wettbewerbsf√§hige Anfragen.  Sie k√∂nnen die maximale Anzahl von Samples in einer Anforderung, die maximale Anzahl paralleler Anforderungen, das Zeitlimit, die Wiederholung und das Backoff begrenzen.  F√ºr viele Datenbanken jeweils 100 Stichproben - dies kann sehr klein sein.  Wenn Sie ClickHouse wie wir verwenden, muss der Wert nat√ºrlich stark erh√∂ht werden.  Andernfalls ist es sehr ineffizient. </p><br><p><img src="https://habrastorage.org/webt/eb/gk/ew/ebgkewr7k-i2yho9mh7dbogcipm.png"></p><br><p>  Die Remote-Lese-API sieht folgenderma√üen aus.  Es ist nur ein Zeitraum von Anfang bis Ende und ein Match-Set. </p><br><p><img src="https://habrastorage.org/webt/hv/kn/jo/hvknjowgf6h9pebjvvhbspe7jac.png"></p><br><p>  Match ist im Wesentlichen eine Sammlung von Namens- und Wertepaaren - eine regul√§re Bezeichnung und eine Bedingungsart.  Im Vergleich dazu gibt es Gleichheiten, Ungleichungen oder regul√§re Ausdr√ºcke.  Dies ist die √ºbliche Zeitreihenauswahl, die Sie in PromQL sehen.  Hier gibt es keine Funktionen. </p><br><p><img src="https://habrastorage.org/webt/ri/hu/ap/rihuap_py_s_hrp0oywqnyx6yee.png"></p><br><p>  Die Antwort sind einige Zeitreihen, die dieser Abfrage entsprechen.  Hier sollten die Proben nach Zeit sortiert werden.  Auch dies hilft Prometheus, ein wenig CPU zu sparen - keine Notwendigkeit zu sortieren.  Es wird jedoch davon ausgegangen, dass Ihre Datenbank dies tun sollte.  In den meisten F√§llen wird dies der Fall sein, da h√∂chstwahrscheinlich ein Index rechtzeitig erstellt wird. </p><br><p><img src="https://habrastorage.org/webt/zu/yd/fx/zuydfxti6mozpsz5v60f_i1laic.png"></p><br><p>  Prometheus 2.3 f√ºhrte einen Lesehinweis ein.  Was ist das?  Dies ist eine Gelegenheit, Prometheus mitzuteilen, welche interne Funktion, die mit der angeforderten Zeitreihe arbeitet, angewendet wird.  Dies kann entweder eine Funktion oder ein Aggregationsoperator sein.  Es kann Rate sein.  Das hei√üt, es hei√üt func, aber tats√§chlich kann es eine Summe sein, die aus Sicht von PromQL √ºberhaupt keine Funktion ist.  Dies ist der Operator.  Und ein Schritt.  Im vorherigen Beispiel gab es eine Rate von 1 Minute.  Hier ist die Rate eine Funktion und eine Minute in Millisekunden als Schritt.  Dieser Hinweis kann von der entfernten Datenbank ignoriert werden.  Gleichzeitig gibt es in der Antwort keinen Hinweis darauf, ob sie ignoriert wurde oder nicht. </p><br><p><img src="https://habrastorage.org/webt/6_/ms/9_/6_ms9_zh9txqwdafxjoenbdn8so.png"></p><br><p>  Wie ist die Konfiguration von Lesen? </p><br><p>  Erstens gibt es eine solche Konfiguration erforderlich_Matchers.  Auf diese Weise k√∂nnen Sie eine Remotespeicheranforderung senden, die dem Ausdruck entspricht.  Um aggregierte Daten aus dem Remotespeicher zu lesen, m√ºssen Sie eine Abfrage verwenden, die einen Doppelpunkt enth√§lt. </p><br><p>  Es gibt eine Option, mit der Sie aktuelle Daten aus dem Remotespeicher in der TSDB lesen oder nicht lesen k√∂nnen.  Normalerweise gibt es in der Standardkonfiguration eine kleine lokale TSDB, die auf die lokale Festplatte geschrieben wird.  Sie lagert dort mehrere Stunden oder mehrere Tage.  Die Daten, die Sie jetzt verwenden und die f√ºr Warnungen verwendet werden, die zum Erstellen des Dashboards verwendet werden, werden nur von der lokalen TSDB gelesen.  Es ist schnell, erlaubt uns aber nicht, viele Daten zu speichern. </p><br><p>  Alte historische Daten werden aus dem Remotespeicher gelesen.  Dies macht deutlich, wie Local Storage und Remote Storage miteinander kommunizieren.  Es erfolgt keine Deduplizierung. </p><br><p>  Im Wesentlichen was passiert.  Daten werden aus dem lokalen Speicher entnommen, Daten werden aus dem Remotespeicher entnommen, wenn read_recent aktiviert ist.  Sie verschmelzen einfach miteinander.  Es scheint, dass dies kein Problem ist.  Wenn davon ausgegangen wird, dass wir die letzten Daten nicht heruntergesampelt haben, sind dies genau die gleichen Daten, sie stimmen vollst√§ndig mit den lokalen Daten √ºberein. Wir haben doppelt so viele Stichproben. Wir sollten keine Funktionen beeinflussen.  Nicht wirklich.  Es gibt eine irate () -Funktion und ein Paar f√ºr das Messger√§t, das uns die Differenz zwischen den letzten beiden Werten zur√ºckgibt.  Sie blickt auf den angegebenen Zeitraum zur√ºck, verwendet aber nur die letzten beiden Werte.  Wenn die letzten beiden Werte dieselbe Zeit haben, ist die Differenz Null.  Dies ist ein Fehler und es ist fast unm√∂glich, ihn zu finden.  Es wurde erst vor vier Tagen repariert.  Dies ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ticket f√ºr</a> alle Interessierten. </p><br><p><img src="https://habrastorage.org/webt/-q/3w/dw/-q3wdw3czygpvkk009lrnhumska.png"></p><br><p>  Interessanterweise wurde Remote Read von Prometheus seit Version 1.8 implementiert.  Auf diese Weise k√∂nnen Sie die Daten des alten Prometheus lesen, wenn Sie auf Version 2.x migrieren.  Der offizielle Weg empfiehlt, es als Remote Read zu verbinden.  Die Daten werden nach Bedarf abgezogen. </p><br><p>  Remote Read kann verwendet werden, um das Abfrage-Routing ohne Proxy durchzuf√ºhren.  Auf einer der vorherigen Folien habe ich gezeigt, dass wir je nach Zeit auf dem einen oder anderen Prometheus routen k√∂nnen.  Ebenso k√∂nnen wir dies vermeiden.  Schlie√üen Sie einfach den Prometheus an, der unten gelesen wird - und die Daten werden von dort gelesen.  Es gibt jedoch eine √Ñnderung der Tatsache, dass nat√ºrlich viele Daten gepumpt werden.  Vor allem, wenn Sie keinen Abfragehinweis verwenden. </p><br><p><img src="https://habrastorage.org/webt/gq/op/fz/gqopfzpgoe3kidpqufnedn5gfrk.png"></p><br><p>  Warum Clickhouse? </p><br><ul><li><p>  F√ºr unsere Forschungsl√∂sung haben wir uns f√ºr ClickHouse entschieden, weil wir uns das schon lange angesehen haben.  Wir haben Leute, die st√§ndig mit der Datenbankleistung besch√§ftigt sind und st√§ndig neue Datenbanken √ºberpr√ºfen.  Unser Unternehmen besch√§ftigt sich mit OpenSource-Datenbanken. </p><br></li><li><p>  Wir m√∂gen die rohe Leistung sehr.  Die Leistung in Bezug auf CPU, Zeit usw. ist sehr gut.  Die meisten dieser Systeme sprechen von unendlicher Skalierbarkeit, aber wenig von Effizienz f√ºr einen einzelnen Server.  Viele unserer Kunden speichern Metriken auf zwei Servern. </p><br></li><li><p>  Integrierte Replikation, Sharding. </p><br></li><li><p>  GraphiteMergeTree ist eine spezielle Engine zum Speichern von Graphitdaten.  Anfangs interessierte er sich sehr f√ºr uns. </p><br></li></ul><br><p><img src="https://habrastorage.org/webt/ot/nk/sn/otnksno5uhhcgn7j5-fp5xnxneq.png"></p><br><p>  Die Engine ist f√ºr das Aufrollen (Ausd√ºnnen und Aggregieren / Mitteln) von Graphitdaten vorgesehen. </p><br><p>  Graphite speichert die vollst√§ndigen Daten in ClickHouse und kann sie empfangen. Au√üerdem wird angegeben, dass MergeTree bei der Ausd√ºnnung von GraphiteMergeTree ohne Ausd√ºnnung verwendet wird.  Das Gef√ºhl ist, dass die Daten immer voll sind, sie werden nicht √ºberschrieben, es ist nur eine Optimierung des Lesens.  Aber insgesamt ist es nicht schlecht.  Wenn wir lesen, pumpen wir die Daten nicht aus, sie werden automatisch aggregiert, wir erhalten ein paar Daten - das ist gut.  Der Nachteil f√ºr uns ist, dass alle Daten gespeichert werden. </p><br><p>  Ich habe mich Anfang des Monats auf den Bericht vorbereitet.  Jemand kommt in einem Telegramm-Chat und fragt: "GraphiteMergeTree-Daten-Downsample"?  Ich schreibe schon nein.  Die Dokumentation sagt nein.  Die andere Person im Chat antwortet jedoch: "Ja, Sie m√ºssen Optimize aufrufen."  Lauf, √ºberpr√ºfe - ja die Wahrheit.  Die Dokumentation ist im Wesentlichen ein Fehler.  Dann habe ich den Quellcode gelesen, √ºberpr√ºft, es stellt sich heraus, dass es Optimize, Optimize Final gibt.  Optimize final wurde urspr√ºnglich speziell f√ºr GraphiteMergeTree erstellt.  Eigentlich macht er Downsampling.  Aber es muss mit seinen H√§nden gerufen werden. </p><br><p>  GraphiteMergeTree hat ein anderes Datenmodell.  Er hat keine Etiketten.  Es funktioniert nicht sehr gut, alles effektiv im Namen der Metriken zu schreiben. </p><br><p>  Namensmetriken werden in einer Tabelle gespeichert.  Der Name der Metriken hat eine andere L√§nge.  Dies f√ºhrt dazu, dass bei einer Indexsuche nach dem Namen der Metrik dieser Index nicht so effektiv ist, als ob dieser Index einen festen L√§ngenwert h√§tte, da die L√§nge unterschiedlich ist.  Weil Sie eine Dateisuche durchf√ºhren m√ºssen.  Es ist unm√∂glich, genau anzugeben, wo gelandet werden soll, um eine bin√§re Suche durchzuf√ºhren. </p><br><p><img src="https://habrastorage.org/webt/c3/v4/zf/c3v4zfriducmhoahjwujmp1zdga.png"></p><br><p>  Deshalb machten sie ihr eigenes Schema.  Die Folie zeigt, wie wir Zeitreihen in der Datenbank speichern.  Das Datum, das ClickHouse ben√∂tigt, ist ein Fingerabdruck.  Wenn Sie sich die Quellen von Prometheus oder TSDB angesehen haben, wissen Sie, dass der Fingerabdruck im Wesentlichen eine kurze, schnelle Pr√ºfsumme der vollst√§ndigen Namenszeitreihen ist.  Fingerabdruck ist eine Kombination aller Beschriftungen, Tasten und Werte.  Ein Name ist eine regul√§re Bezeichnung.  Aus Kompatibilit√§tsgr√ºnden verwenden wir denselben Algorithmus.  Etwas zu belasten kann bequem sein.  Der Fingerabdruck ist derselbe und es kann in der TSDB und in unserem Speicher √ºberpr√ºft werden, ob sie gleich sind.  Beschriftungen werden in einem speziellen JSON gespeichert, mit dem ClickHouse mit seinen Standardfunktionen arbeiten kann.  Dies ist kompaktes JSON ohne Leerzeichen mit leicht vereinfachter Benennung.  Diese Tabelle wird w√§hrend des Betriebs nicht verwendet.  Es wird immer im Speicher unserer eigentlichen L√∂sung gespeichert, die PromHouse hei√üt.  Es wird nur verwendet, wenn wir den Server starten, um herauszufinden, um welche Zeitreihen es sich handelt.  Sie wird abgezogen.  Sobald neue Zeitreihen eintreffen, zeichnen wir sie dort auf.  Alle mehreren PromHouse-Instanzen k√∂nnen dieselbe Tabelle lesen.  ReplacingMergeTree sagt uns, dass diese Zeitreihen - es gibt mehrere verschiedene Instanzen - dieselbe Zeitreihe schreiben.  Sie werden sich streiten - und hier wird es kein Problem geben. </p><br><p><img src="https://habrastorage.org/webt/ms/lg/1t/mslg1tnbc97nrlauwcr9ekj-p3k.png"></p><br><p>  Wir speichern Proben sehr effizient in einer separaten Tabelle.  Bei einem festen L√§ngenwert ist dieser Fingerabdruck gleich, Zeit und Wert.  Wir erhalten 24 Bytes pro Probe.  Es hat eine streng feste L√§nge.  Jede Spalte wird separat gespeichert.  Eine Fingerabdrucksuche ist effektiv, da wir wissen, dass die Gr√∂√üe festgelegt ist.  Es gibt kein Problem wie bei GraphitmergeTree, wenn es sich um eine Zeichenfolge handelt.  Wir verwenden benutzerdefinierte Partitionierung.  Prim√§rer Fingerabdruckindex und nach Zeit. </p><br><p>  24 Bytes ist eine vereinfachte Version.  In der Tat komprimiert es gut.  In der Tat verbraucht weniger Platz.  In unseren letzten Tests betr√§gt das Kompressionsverh√§ltnis ungef√§hr 1 zu 42. </p><br><p><img src="https://habrastorage.org/webt/wu/5y/24/wu5y2499vjvrcm37ct1gudfrpym.png"></p><br><p>  Wie k√∂nnen wir manuelles Downsampling durchf√ºhren, wenn wir GraphiteMergeTree haben, aber nicht das gleiche, wie wir m√∂chten?  In der Tat k√∂nnen wir es von Hand tun.  Wie zuvor Sharding, Partitionierung, wenn nichts eingebaut war.  Wir machen mit unseren H√§nden einen neuen Tisch.  Wenn eine Zeitprobe zu uns kommt, bestimmen wir, an welche Tabelle wir schreiben. </p><br><p>  Wir w√§hlen aus der Abfrage die Zeit aus, aus der die Tabelle gelesen werden soll.  Wenn das Lesen an der Grenze erfolgt, lesen wir mehrere Tabellen.  Als n√§chstes halten wir diese Daten.  Man k√∂nnte daf√ºr die Ansicht verwenden.  Erstellen Sie beispielsweise eine Ansicht f√ºr mehrere Tabellen, damit diese in einer einzigen Abfrage gelesen werden kann.  In ClickHouse gibt es jedoch einen Fehler: Das Pr√§dikat aus der Ansicht wird nicht in die Abfragen eingesetzt.  Wenn Sie eine Anfrage in der Ansicht stellen, wird sie daher an alle Tabellen gesendet.  Ansicht k√∂nnen wir nicht verwenden. </p><br><p>  Wie machen wir Downsampling?  Wir erstellen eine tempor√§re Tabelle.  Kopieren Sie die Einf√ºgung mit den richtigen Funktionen in ausgew√§hlte Daten. </p><br><p>  Wir machen eine Umbenennung, die unter der globalen Sperre atomar ist.  Wir benennen die vorhandene Tabelle in die alte um.  Neu zu bestehen.  Wir lassen den alten Tisch fallen.  Wir haben Daten f√ºr 148 Tage bereits Downsampling.  Was ist das Problem hier?  Einf√ºgen in sieht sch√∂n aus.  In der Tat m√ºssen wir die richtigen Funktionen anwenden, die richtige Aggregation zu tun.  In der Praxis kann dies nicht mit einer gro√üen Anfrage durchgef√ºhrt werden.  Selbst einige gro√üe Anfragen k√∂nnen nicht gestellt werden.  Dies muss aus Code erfolgen.  Der Code sendet eine gro√üe Anzahl kleiner Anforderungen.  Wir haben unser Bestes getan, um dies bei gro√üen Anfragen zu tun, aber dies ist nicht sehr effektiv.  Das Downsampling von Daten von einem Tag dauert bisher weniger als einen Tag.  Je nach Datenmenge kann dies lange dauern. </p><br><p><img src="https://habrastorage.org/webt/7c/94/h4/7c94h4t2bbvk5x-3acoftonomxa.png"></p><br><p>  ClickHouse wird aktualisiert / gel√∂scht.  L√∂schen hat schon die erste Version bekommen.  Wenn das Aktualisieren / L√∂schen funktioniert, kann unser Downsampling-Datenschema vereinfacht werden. </p><br><p>  Zweitens hat ClickHouse die Aufgabe, eine benutzerdefinierte Komprimierung durchzuf√ºhren (Delta, Delta zu Delta).  Dies ist, was TSDB tut.  Dies ist gut f√ºr Zeitreihendaten geeignet.  Dies ist besonders n√ºtzlich, wenn wir die Art der Komprimierung abh√§ngig von den Datentypen ausw√§hlen k√∂nnen.  Zum Beispiel ein Z√§hler, der nur w√§chst - daf√ºr ist eine Delta-Delta-Komprimierung geeignet.  Ein Messger√§t, das um die Gr√∂√üe schwankt, sodass das Delta gut funktioniert. </p><br><p><img src="https://habrastorage.org/webt/od/mv/hx/odmvhxcnnite5wum9k9gwfifbec.png"></p><br><p>  Es gibt andere Speicher, die funktionieren.  Es gibt InfluxDB, die sofort funktioniert.  Es ist √ºblich, ihn wegen seiner Geschwindigkeit zu schelten, aber was sofort funktioniert und Sie nichts tun m√ºssen, ist gut. </p><br><p>  Es gibt OpenTSDB und Graphite, die nur schreibgesch√ºtzt sind.  Der Standardadapter von Prometheus funktioniert nicht wirklich. </p><br><p>  Es gibt eine CrateDB.  Es gibt eine TimescaleDB, die PostgreSQL f√ºr Zeitreihendatenbanken gibtelt.  Sie sagen, es funktioniert gut, aber wir selbst haben es nicht versucht. </p><br><p>  Es gibt Cortex, das auch als Frankenstein-Projekt bekannt war.  Das beschreibt ihn sehr gut.  Dies sind die Leute, die versuchen, eine Entscheidung zu treffen, die auf der Prometheus-F√∂deration basiert.  Sie speichern Daten in S3. </p><br><p>  Es gibt Thanos. </p><br><ul><li>  Er hat eine sehr interessante Architektur.  Es gibt Prometheus, der lokale TSDB verwendet.  Zwischen ihnen wird ein Cluster erstellt.  Neben jedem Prometheus befindet sich ein spezielles Side-Car, das Anfragen √ºber Remote-Lese- und Remote-Schreib-API entgegennimmt.  Er leitet diese Anfragen an Prometheus weiter.  Prometheus kann seine Remote-Lese- und Remote-Schreib-APIs verwenden.  Alle Side-Cars sind miteinander verbunden und zwischen benutzerdefinierten API-Mastern √ºber gRPC ist die Replikation verf√ºgbar, es erfolgt eine erneute Schattierung. </li><li>  Anspruchsvolle Architektur. </li><li>  Es ist ziemlich feucht.  Vor ein paar Monaten fiel es von einem halben Tritt ab, als es anfing. </li></ul><br><p><img src="https://habrastorage.org/webt/a9/rc/zm/a9rczmkse4viit4vvr4hgqfcuts.png"></p><br><p>  Bei Verwendung des Pull-Modells werden nicht viele Daten geschrieben.  Sie m√ºssen ein ganzes Jahr warten, um die j√§hrlichen Daten einzugeben.  Wir versuchen sie irgendwie dort zu schreiben. </p><br><p>  In Prometheus gibt es kein Remote-Schreiben. Daher funktioniert das Schreiben vieler Daten in die lokale TSDB nicht. </p><br><p>  Das zweite Problem.  Wenn wir Daten f√ºr Stresstests generieren, zittern sie oft gut.  Wenn wir beispielsweise vorhandene Daten verwenden und 100 Instanzen generieren, und dies sind dieselben Daten, ist der Komprimierungskoeffizient dort so sch√∂n, dass sie in Wirklichkeit nicht auftreten. </p><br><p><img src="https://habrastorage.org/webt/fy/mc/uk/fymcukkdoo3hi78gkw1eb2ipvsk.png"></p><br><p>  Wir haben einen gef√§lschten Exporteur geschrieben, der aussieht wie ein regul√§rer Exporteur, den Prometheus zusammenhalten kann: </p><br><ul><li>  Wenn der Schrott hereinkommt, geht er zu einem vorgelagerten Exporteur.  Nimmt Daten daraus. </li><li>  Erzeugt viele Instanzen.  Nehmen wir an, 1 ist ein Scrapie und wir erhalten 100 am Ausgang. </li><li>  √Ñndert die Daten geringf√ºgig: plus minus 10% f√ºr Z√§hler und Messger√§t. </li><li>  Die einfachen Werte 0 oder 1 werden nicht ge√§ndert. Wenn eine UP-Metrik antwortet, wird angezeigt, ob der Dienst ausgef√ºhrt wird: Ja - 1 oder Nein - 0. Und es ist nicht ganz klar, was 098 UP bedeutet. </li><li>  Wir √§ndern keine ganzen Zahlen in echte und umgekehrt. </li><li>  Es gibt nur Daten im √ºblichen expfmt-Format. </li></ul><br><p><img src="https://habrastorage.org/webt/c0/ja/hc/c0jahc5ryn-oxhwxnke_vaj1mia.png"></p><br><p>  Ein Promload-Tool, das Daten l√§dt.  Daten lesen: </p><br><ul><li>  Kann aus Dateien in einem eigenen Format lesen </li><li>  Vielleicht von Remote Read </li><li>  Kann von einem Exporteur lesen </li></ul><br><p>  Schreibt in verschiedenen Formaten.  Einschlie√ülich in / dev / null, wenn wir genau testen m√∂chten, wie schnell das Lesen funktioniert. </p><br><p>  Jetzt ist es ein Lasttest-Tool nicht nur f√ºr PromHouse, sondern auch f√ºr jede L√∂sung, die Remote Read oder Prometheus verwendet. </p><br><p><img src="https://habrastorage.org/webt/qr/xa/-2/qrxa-2wg58troaskuqhqowwicq4.png"></p><br><p>  Wir m√∂chten das Lese-Caching hinzuf√ºgen, da der Engpass in unseren Tests h√§ufig der gef√§lschte Exporteur war, der lange Zeit Daten generiert hat.  Wir k√∂nnten sie zwischenspeichern.  Lass sie unrealistisch gut sein.  Aber wir werden nicht langsamer.  Wir mussten nicht tagelang auf Stresstests warten. </p><br><p>  Eine Art Filterung im laufenden Betrieb, eine Art Modifikation im laufenden Betrieb. </p><br><p>  Native Unterst√ºtzung f√ºr TSDB.  Um mit der Datenbank auf der Festplatte und nicht √ºber die API zu arbeiten. </p><br><p>  Konzentrieren Sie sich auf die Genauigkeit der Migration.  Ich habe einmal pmmdemo.percona.com gesetzt: verbunden, alle Metriken erhalten.  Wenn Sie dies auf native Weise tun, √∂ffnet Prometheus die TSDB, l√∂st alle Zeitreihen von der Festplatte aus, erh√∂ht die Indizes, crawlt dann in Blockdateien und stellt fest, dass sie tats√§chlich vorhanden sind.  An diesem Punkt kann sich einfach alles hinlegen. </p><br><p>  Der naive Ansatz besteht darin, die gesamte Zeitreihe zu nehmen und von den alten Daten in die neuen zu lesen.  In diesem Moment wird er sich hinlegen.  Sie m√ºssen das Gegenteil tun.  Zuerst m√ºssen Sie die Zeitreihenliste mit einigen Abfragen mit regul√§ren Ausdr√ºcken abrufen.  Zum Beispiel eine Zeitreihe, die mit A beginnt. Dann geben Sie mir eine Zeitreihe, die mit B beginnt. Laden Sie sie dann genau nach Metriken, nicht nach Zeit.  Das ist unlogisch, aber so funktioniert es.  Dies ist eine Nuance, wenn Sie so etwas tun.  Wenn Sie sehen, dass OOM Killer dort passiert ist, werden Sie wissen, dass es an Ihnen liegt. </p><br><p><img src="https://habrastorage.org/webt/mz/z9/kh/mzz9khnykox-3r2wlp_lpgphil4.png"></p><br><p>  Bei den Ergebnissen der Lasttests werden keine Grafiken angezeigt.  Das Testen der Last nimmt viel Zeit in Anspruch und leider ist aufgrund eines Konfigurationsfehlers alles schief gelaufen.  Daher haben die Ergebnisse nicht geklappt. </p><br><p>  Wir werden auf dem Percona-Blog schreiben, wenn wir Lasttests durchf√ºhren. </p><br><p>  Ich kann die Ergebnisse ohne Grafiken sagen.  Die Aufnahme war linear.  Das Lesen sprang und war nicht sehr schnell.  Das Lesen der aktuellen Daten ist f√ºr uns nicht sehr wichtig.  Sie k√∂nnen durch Lesehinweise beschleunigt werden.  Sie k√∂nnen read_recent aktivieren, um das Lesen zu verbessern.  Und f√ºr alte Daten funktioniert dies gut. </p><br><p><img src="https://habrastorage.org/webt/b6/7f/4w/b67f4wmgkuzi6zyqnitxlwuv2t8.png"></p><br><p>  Die Menschen wollen eine langfristige Lagerung.  Es gibt eine solche Nachfrage.  Wir haben auf der PromCon √ºber PromHouse gesprochen.  Dort war es ein sehr hei√ües Thema.  Thanos entwickelt sich aktiv weiter. </p><br><p>  Es ist jetzt schon m√∂glich.  Daf√ºr gibt es eine L√∂sung.  Es gibt eine API.  Es gibt einige Integrationen.  All dies muss jedoch mit einer Datei abgeschlossen werden.  Keine produktionsfertigen L√∂sungen. </p><br><p><img src="https://habrastorage.org/webt/ms/qk/ec/msqkechijgscjucb7sx8knkzwx0.png"></p><br><p>  Links, wo man suchen muss.  Der erste Link ist das PromHouse-Repository.  Das zweite Glied ist, wo er sich wahrscheinlich bewegen wird.  Jetzt in einem Repository gibt es mehrere verschiedene Dinge?  nicht sehr eng verwandt.  Daher m√ºssen Sie sie √ºbertragen. </p><br><p>  Unser Blog enth√§lt Informationen zur Leistung und einige Neuigkeiten. </p><br><p>  Fragen: </p><br><p>  Frage: Haben Sie die Ger√ºchte √ºber InfluxDB √ºberpr√ºft? </p><br><p>  Antwort: Er war nicht sehr gut.  Er wurde viel besser.  Alle diese Geschichten √ºber die Tatsache, dass InfluxDB langsam ist und auseinander f√§llt - sie handeln von der alten Version.  Die aktuelle Version ist stabil.  W√ºrde ich nicht sagen  dass es schnell geht.  Aber es funktioniert stabil.  Vorteile von InfluxDB meiner Meinung nach: </p><br><ul><li>  Erstens m√ºssen Sie in der N√§he nichts unternehmen, da InfluxDB sofort funktioniert. </li><li>  Zweitens k√∂nnen Sie in ClickHouse wie in anderen datenbankbasierten L√∂sungen, jedoch nicht in TSDB, eine Ihnen vertraute Abfragesprache verwenden.  Die Abfragesprache InfluxDB √§hnelt SQL.  Sie k√∂nnen Analysen durchf√ºhren, was unter PromQL schwierig ist.  Wenn Sie TimeScaleDB verwenden, gibt es echtes SQL. </li></ul><br><p>  Frage: Funktioniert die GraphiteMergeTree-Engine nur zum Aufzeichnen?  Wenn wir Diagramme anzeigen m√∂chten, muss Grafana auf Graphite eingerichtet werden, um die Langzeitspeicherung anzuzeigen? </p><br><p>  Antwort: Ja.  Die Integration in Prometheus selbst funktioniert nur f√ºr die Aufnahme.  Er schreibt nur Daten.  Von Grafana aus geht es also zu Graphit. </p><br><p>  Frage: Und er verliert Etiketten, wenn er schreibt? </p><br><p>  Antwort: Es gibt eine Konfiguration, die angibt, was mit ihnen zu tun ist, wie sie einzuf√ºgen sind und wo sie einzuf√ºgen sind. </p><br><p>  Informationen aus dem Publikum: Avito sagte, dass sie ihre L√∂sung f√ºr Aufnahmen von Prometheus bis Graphite schreiben. </p><br><p>  Frage: Es wurde der Schluss gezogen, dass bei der Aufzeichnung auf einem Langzeitspeicherserver alles in Ordnung ist. </p><br><p><img src="https://habrastorage.org/webt/mz/z9/kh/mzz9khnykox-3r2wlp_lpgphil4.png">  Es gibt einen Fluss von einer Million Metriken (5 Minuten oder 15 Minuten).   raid 6 sata      ? </p><br><p> :  PMM      ‚Äî  .   downsampling    c 14   1 .  ,       .          .    .     . </p><br><p> :   IOPS  ? </p><br><p> :     . </p><br><p> :      </p><br><p> :        .  ,        .  , ,  . </p><br><p> :     InfluxDB,        InfluxDB? </p><br><p> :    read_recent.    ,      remote storage.    InfluxDB .    .  read_recent ,   . </p><br><p> : ,     Prometheus.     InfluxDB. Grafana   Prometheus. Prometheus   PromQL     ,    InfluxDB? </p><br><p> : . </p><br><p> : Prometheus     InfluxDB      Grafana? </p><br><p> : .    Prometheus  2.2        ,    . </p><br><p> PS       : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">valyala</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">gecube</a> <br>   ,   . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441136/">https://habr.com/ru/post/de441136/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441126/index.html">False Positives in PVS-Studio: Wie tief das Kaninchenloch ist</a></li>
<li><a href="../de441128/index.html">Die richtige Wahl: eine praktische Untersuchung der kognitiven F√§higkeiten von Menschenaffen</a></li>
<li><a href="../de441130/index.html">Ausgewogene Site-Leistung. Teil 1: Strategie</a></li>
<li><a href="../de441132/index.html">Damit Roskomnadzor nicht PL√ñTZLICH kommt</a></li>
<li><a href="../de441134/index.html">Emotionen, selbst√§ndige Arbeit</a></li>
<li><a href="../de441138/index.html">Echtzeit-Chat-L√∂sungen gegen Chat-Plattformen - Treffen Sie Ihre Wahl</a></li>
<li><a href="../de441140/index.html">WebAssembly-Entwicklung: echter Rechen und Beispiele</a></li>
<li><a href="../de441142/index.html">12 Punkte Conversion-Wachstum oder Inhalte, die sich wirklich verkaufen</a></li>
<li><a href="../de441146/index.html">Industrielle drahtlose Netzwerke: Welches soll man w√§hlen?</a></li>
<li><a href="../de441148/index.html">Wie man richtig mit Fehlern umgeht: Stille ist nicht immer gut</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
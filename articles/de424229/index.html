<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßõüèΩ üë≤ üèîÔ∏è Kubernetes in der Produktion: Dienstleistungen üéø ‚õ©Ô∏è üë®üèø‚Äçüç≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor sechs Monaten haben wir die Migration aller unserer zustandslosen Dienste auf Kubernetes abgeschlossen. Auf den ersten Blick ist die Aufgabe recht...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes in der Produktion: Dienstleistungen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okmeter/blog/424229/"><p><img align="left" width="250" src="https://habrastorage.org/webt/ww/yz/_z/wwyz_zvbfjx8vrreqprenpo0a00.png">  Vor sechs Monaten haben wir die Migration aller unserer zustandslosen Dienste auf Kubernetes abgeschlossen.  Auf den ersten Blick ist die Aufgabe recht einfach: Sie m√ºssen einen Cluster bereitstellen, Anwendungsspezifikationen schreiben und loslegen.  Aufgrund der Besessenheit, Stabilit√§t in der Arbeit unseres Dienstes zu gew√§hrleisten, musste ich sofort verstehen, wie k8s funktionieren, und verschiedene Fehlerszenarien testen.  Die meisten Fragen, die ich zu allem hatte, was mit dem Netzwerk zu tun hatte.  Eines dieser schl√ºpfrigen Probleme ist der Betrieb von Diensten in Kubernetes. </p><br><p>  Die Dokumentation sagt uns: </p><br><ul><li>  rollen Sie die Anwendung aus </li><li>  Lebendigkeits- / Bereitschaftsproben festlegen </li><li>  Erstellen Sie einen Dienst </li><li>  dann funktioniert alles: Lastausgleich, Failover usw. </li></ul><br><p>  In der Praxis ist jedoch alles etwas komplizierter.  Mal sehen, wie es tats√§chlich funktioniert. </p><a name="habracut"></a><br><h2 id="nemnogo-teorii">  Ein bisschen Theorie </h2><br><p>  Au√üerdem meine ich, dass der Leser bereits mit dem kubernetes-Ger√§t und seiner Terminologie vertraut ist. Wir erinnern uns nur daran, was ein Dienst ist. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Service</a> ist die Essenz von k8s, die eine Reihe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Herden</a> und Methoden f√ºr den Zugriff auf diese beschreibt. </p><br><p>  Zum Beispiel haben wir unsere Anwendung gestartet: </p><br><pre><code class="plaintext hljs">apiVersion: apps/v1 kind: Deployment metadata: name: webapp spec: selector: matchLabels: app: webapp replicas: 2 template: metadata: labels: app: webapp spec: containers: - name: webapp image: defaultxz/webapp command: ["/webapp", "0.0.0.0:80"] ports: - containerPort: 80 readinessProbe: httpGet: {path: /, port: 80} initialDelaySeconds: 1 periodSeconds: 1</code> </pre> <br><pre> <code class="bash hljs">$ kubectl get pods -l app=webapp NAME READY STATUS RESTARTS AGE webapp-5d5d96f786-b2jxb 1/1 Running 0 3h webapp-5d5d96f786-rt6j7 1/1 Running 0 3h</code> </pre> <br><p>  Um darauf zugreifen zu k√∂nnen, m√ºssen wir einen Dienst erstellen, in dem wir bestimmen, auf welche Kan√§le wir zugreifen m√∂chten (Selektor) und auf welchen Ports: </p><br><pre> <code class="plaintext hljs">kind: Service apiVersion: v1 metadata: name: webapp spec: selector: app: webapp ports: - protocol: TCP port: 80 targetPort: 80</code> </pre> <br><pre> <code class="bash hljs">$ kubectl get svc webapp NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE webapp ClusterIP 10.97.149.77 &lt;none&gt; 80/TCP 1d</code> </pre> <br><p>  Jetzt k√∂nnen wir von jedem Computer im Cluster aus auf unseren Service zugreifen: </p><br><pre> <code class="bash hljs">curl -i http://10.97.149.77 HTTP/1.1 200 OK Date: Mon, 24 Sep 2018 11:55:14 GMT Content-Length: 2 Content-Type: text/plain; charset=utf-8</code> </pre> <br><h2 id="kak-eto-vse-rabotaet">  Wie funktioniert das alles? </h2><br><img src="https://habrastorage.org/webt/bn/uc/y4/bnucy4fkcptbeo3fwyycr-fc6po.jpeg"><br><p>  Sehr vereinfacht: </p><br><ul><li>  Sie haben kubectl die Bereitstellungsspezifikationen angewendet </li><li>  Magie passiert, deren Details in diesem Zusammenhang nicht wichtig sind </li><li>  Infolgedessen stellte sich heraus, dass sich Arbeitsknoten der Anwendung auf einigen Knoten befanden </li><li>  Sobald jedes Kubelet-Intervall (k8s-Agent auf jedem Knoten) Liveness / Readiness-Samples aller auf seinem Knoten ausgef√ºhrten Pods durchf√ºhrt, sendet es die Ergebnisse an einen Apiserver (Schnittstelle zu k8s-Gehirnen). </li><li>  kube-proxy auf jedem Knoten erh√§lt von apiserver Benachrichtigungen √ºber alle √Ñnderungen an Diensten und Herden, die an Diensten teilnehmen </li><li>  kube-proxy spiegelt alle √Ñnderungen in der Konfiguration der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zugrunde liegenden Subsysteme</a> (iptables, ipvs) wider. </li></ul><br><p>  Betrachten Sie der Einfachheit halber die Standard-Proxy-Methode - iptables.  In iptables haben wir f√ºr unsere virtuelle IP 10.97.149.77: </p><br><pre> <code class="bash hljs">-A KUBE-SERVICES -d 10.97.149.77/32 -p tcp -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/webapp: cluster IP"</span></span> -m tcp --dport 80 -j KUBE-SVC-BL7FHTIPVYJBLWZN</code> </pre> <br><p>  Der Verkehr geht an die <strong>Kette KUBE-SVC-BL7FHTIPVYJBLWZN</strong> , in der er auf zwei andere Ketten verteilt ist </p><br><pre> <code class="bash hljs">-A KUBE-SVC-BL7FHTIPVYJBLWZN -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/webapp:"</span></span> -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-UPKHDYQWGW4MVMBS -A KUBE-SVC-BL7FHTIPVYJBLWZN -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/webapp:"</span></span> -j KUBE-SEP-FFCBJRUPEN3YPZQT</code> </pre> <br><p>  Das sind unsere Schoten: </p><br><pre> <code class="bash hljs">-A KUBE-SEP-UPKHDYQWGW4MVMBS -p tcp -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/webapp:"</span></span> -m tcp -j DNAT --to-destination 10.244.0.10:80 -A KUBE-SEP-FFCBJRUPEN3YPZQT -p tcp -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/webapp:"</span></span> -m tcp -j DNAT --to-destination 10.244.0.11:80</code> </pre> <br><h2 id="testiruem-otkaz-odnogo-iz-podov">  Testen des Ausfalls eines der Herde </h2><br><p>  Meine Webapp-Testanwendung kann in den "Fehlerausschlag" -Modus wechseln. Dazu m√ºssen Sie die URL "/ err" abrufen. </p><br><p>  Die Ergebnisse von ab -c 50 -n 20.000 in der Mitte des Tests zogen "/ err" an einem der Herde: </p><br><pre> <code class="bash hljs">Complete requests: 20000 Failed requests: 3719</code> </pre> <br><p>  Der Punkt hier ist nicht die spezifische Anzahl von Fehlern (ihre Anzahl variiert je nach Last), sondern dass sie es sind.  Im Allgemeinen haben wir das "schlechte" aus dem Gleichgewicht gebracht, aber zum Zeitpunkt des Wechsels hat der Client des Dienstes Fehler erhalten.  Die Ursache der Fehler ist leicht zu erkl√§ren: Bereitschaftstests werden einmal pro Sekunde + sogar kurze Zeit f√ºr die Verbreitung von Informationen durchgef√ºhrt, die nicht auf den Test reagiert haben. </p><br><h2 id="pomozhet-li-ipvs-bekend-dlya-kube-proxy-experimental">  Hilft IPVS-Backend f√ºr kube-proxy (experimentell)? </h2><br><p>  Nicht wirklich!  Es l√∂st das Problem der Proxy-Optimierung, bietet einen benutzerdefinierten Ausgleichsalgorithmus, l√∂st jedoch nicht das Problem der Fehlerverarbeitung. </p><br><h2 id="kak-byt">  Wie man ist </h2><br><p>  Dieses Problem kann nur von einem Balancer gel√∂st werden, der es erneut versuchen kann.  Mit anderen Worten, f√ºr http ben√∂tigen wir einen L7-Balancer.  Solche Balancer f√ºr Kubernetes werden bereits in vollem Umfang verwendet, entweder in Form von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ingress</a> (es war als Punkt beim Umzug in den Cluster gedacht, aber im Gro√üen und Ganzen macht es genau das, was es ben√∂tigt) oder als Implementierung einer separaten Schicht - beispielsweise eines Service- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Meshs</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">istio</a> . </p><br><p>  In unserer Produktion haben wir aufgrund der zus√§tzlichen Komplexit√§t noch nicht begonnen, Ingress- oder Service-Mesh zu verwenden.  Solche Abstraktionen helfen meiner Meinung nach in F√§llen, in denen Sie h√§ufig eine gro√üe Anzahl von Diensten konfigurieren m√ºssen.  Gleichzeitig "bezahlen" Sie die Steuerbarkeit und die einfache Infrastruktur.  Sie werden zus√§tzliche Zeit aufwenden, um herauszufinden, wie Sie die Rertai und Zeit√ºberschreitungen f√ºr einen bestimmten Dienst einrichten. </p><br><h2 id="kak-delaem-my">  Wie geht es uns? </h2><br><p>  Wir nutzen kopflose k8s-Dienste.  Solche Dienste haben keine virtuelle IP und dementsprechend sind kube-proxy und iptables nicht an ihrer Arbeit beteiligt.  F√ºr jeden dieser Dienste k√∂nnen Sie eine Liste der Live-Herde entweder √ºber das DNS oder √ºber die API abrufen. </p><br><p>  F√ºr Anwendungen, die mit anderen Diensten interagieren, stellen wir mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesandten</a> einen Beiwagencontainer her.  Evoy erh√§lt regelm√§√üig eine aktuelle Liste der Pods f√ºr alle erforderlichen Dienste √ºber DNS. Vor allem kann es im Fehlerfall Anfragen f√ºr andere Pods wiederholen.  Sie k√∂nnen es als DaemonSet auf jedem Knoten ausf√ºhren. Wenn diese Instanz jedoch fehlschl√§gt, funktionieren alle Anwendungen, die sie verwenden, nicht mehr.  Da der Ressourcenverbrauch dieses Proxys recht gering ist, haben wir uns f√ºr die Sidecar-Container-Variante entschieden. </p><br><p>  Dies ist im Wesentlichen genau das, was istio tut, aber in unserem Fall hat sich das Gleichgewicht in Richtung Einfachheit verschoben (keine Notwendigkeit, istio zu lernen, auf seine Fehler zu sto√üen).  Vielleicht √§ndert sich dieses Gleichgewicht und wir werden anfangen, so etwas wie istio zu verwenden. </p><br><p>  <em>Wir bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">okmeter.io</a> kubernetes haben definitiv Wurzeln geschlagen und glauben an die weitere Verbreitung.</em>  <em>Unterst√ºtzung f√ºr die √úberwachung von k8s in unserem Service ist unterwegs, bleiben Sie dran!</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424229/">https://habr.com/ru/post/de424229/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424211/index.html">Grundlegendes zur Container-Speicherschnittstelle (in Kubernetes und mehr)</a></li>
<li><a href="../de424215/index.html">Ulme. Bequem und umst√§ndlich</a></li>
<li><a href="../de424217/index.html">Begr√ºndung f√ºr heilige Kriege sowie ein Pl√§doyer f√ºr Frieden</a></li>
<li><a href="../de424223/index.html">Einwegkunden. Segmentierung f√ºr Wiederholungsk√§ufe</a></li>
<li><a href="../de424227/index.html">Verteilen Sie die Punkte in Pytorch und Tensorflow gleichm√§√üig √ºber die Kugel</a></li>
<li><a href="../de424231/index.html">Wie man mit Hostern Geld verdient</a></li>
<li><a href="../de424233/index.html">Computer lehrte, Demenz mit einer Genauigkeit von 93% zu erkennen</a></li>
<li><a href="../de424235/index.html">Verwendung von STATSPACK anstelle von AWR in Oracle Standard Edition</a></li>
<li><a href="../de424237/index.html">Laden Sie Ihr Gehirn direkt auf! Laufzeit, Compiler und Performance bei Joker 2018</a></li>
<li><a href="../de424239/index.html">IBM Herbstseminare - Container, Computer Vision, Digitale Transformation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèº‚Äçüè´ üë®‚Äçüë®‚Äçüëß‚Äçüë¶ üï≥Ô∏è Compara√ß√£o definitiva de plataformas embarcadas para IA ü§òüèº üë©üèª‚Äç‚öñÔ∏è üò´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Redes neurais capturam o mundo. Eles contam visitantes, monitoram a qualidade, mant√™m estat√≠sticas e avaliam a seguran√ßa. Um monte de startups, uso in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Compara√ß√£o definitiva de plataformas embarcadas para IA</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/468421/">  Redes neurais capturam o mundo.  Eles contam visitantes, monitoram a qualidade, mant√™m estat√≠sticas e avaliam a seguran√ßa.  Um monte de startups, uso industrial. <br>  Grandes estruturas.  O que √© PyTorch, qual √© o segundo TensorFlow.  Tudo est√° se tornando mais conveniente e conveniente, mais simples e mais simples ... <br>  Mas h√° um lado sombrio.  Eles tentam ficar calados sobre ela.  N√£o h√° nada alegre l√°, apenas escurid√£o e desespero.  Toda vez que voc√™ v√™ um artigo positivo, voc√™ suspira tristemente, porque entende que apenas uma pessoa n√£o entendeu alguma coisa.  Ou escondeu. <br>  Vamos falar sobre produ√ß√£o em dispositivos embarcados. <br><img src="https://habrastorage.org/webt/hb/pv/jm/hbpvjmosqm6fva4b2n6ytwqtqqq.jpeg"><br><a name="habracut"></a><br><br><h2>  Qual √© o problema </h2><br>  Parece.  Veja o desempenho do dispositivo, verifique se √© suficiente, execute-o e obtenha lucro. <br>  Mas, como sempre, existem algumas nuances.  Vamos coloc√°-los nas prateleiras: <br><ol><li>  Produ√ß√£o.  Se o seu dispositivo n√£o for fabricado em c√≥pias √∫nicas, voc√™ precisar√° ter certeza de que o sistema n√£o travar√°, que os dispositivos n√£o superaquecer√£o, que, se houver uma falha de energia, tudo ser√° inicializado automaticamente.  E isso √© em uma grande festa.  Isso oferece apenas duas op√ß√µes - o dispositivo deve ser totalmente projetado, levando em considera√ß√£o todos os problemas poss√≠veis.  Ou voc√™ precisa superar os problemas do dispositivo de origem.  Bem, por exemplo, estes s√£o ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ).  Que, √© claro, √© estanho.  Para resolver os problemas do dispositivo de outra pessoa em grandes lotes, uma quantidade irreal de energia deve ser gasta. </li><li>  Benchmarks reais.  Muita farsa e truques.  A NVIDIA na maioria dos exemplos superestima o desempenho em 30 a 40%.  Mas n√£o s√≥ ela se diverte.  Abaixo, dou muitos exemplos em que a produtividade pode ser 4-5 vezes menor do que voc√™ deseja.  Voc√™ n√£o pode transar "tudo funcionou bem no computador, ser√° proporcionalmente pior aqui". <br></li><li>  Suporte muito limitado √† arquitetura de rede neural.  Existem muitas plataformas de hardware embarcadas que limitam bastante as redes que podem ser executadas nelas (Coral, gyrfalcone, snapdragon).  Portar para essas plataformas ser√° doloroso. </li><li>  Suporte.  Algo n√£o funciona para voc√™, mas o problema est√° no lado do dispositivo? .. Este √© o destino, n√£o vai funcionar.  Somente para RPi, a comunidade fecha a maioria dos bugs.  E, em parte, para a Jetson. </li><li>  Pre√ßo  Parece para muitos que embutido √© barato.  Mas, na realidade, com o crescimento do desempenho do dispositivo, o pre√ßo aumentar√° quase exponencialmente.  O RPi-4 √© 5 vezes mais barato que o Jetson Nano / Google Coral e 2-3 vezes mais fraco.  O Jetson Nano √© 5 vezes mais barato que o Jetson TX2 / Intel NUC e 2-3 vezes mais fraco que eles. <br></li><li>  Lorgus.  Lembre-se deste design da Zhelyazny?  <s>Parece que eu a defini como a imagem-t√≠tulo ...</s> " <i>O Logrus √© um labirinto tridimensional mut√°vel que representa as for√ßas do Caos no multiverso</i> " <i>.</i>  Tudo isso √© uma abund√¢ncia de insetos e buracos, todas essas v√°rias pe√ßas de ferro, todas as estruturas em mudan√ßa ... √â normal quando o mercado muda completamente em 2-3 meses.  Durante este ano, ele mudou 3-4 vezes.  Voc√™ n√£o pode entrar no mesmo rio duas vezes.  Portanto, todos os pensamentos atuais s√£o verdadeiros para o ver√£o de 2019. </li></ol><br><br><h2>  O que √© </h2><br>  <s>Vamos colocar em ordem, n√£o tem um sabor doce ...</s> O que agora existe e √© adequado para os neur√¥nios?  N√£o h√° tantas op√ß√µes, apesar da variabilidade.  Algumas palavras gerais para limitar a pesquisa: <br><ol><li>  N√£o analisarei neur√¥nios / infer√™ncias em telefones.  Isso por si s√≥ √© um t√≥pico enorme.  Mas como os telefones s√£o plataformas incorporadas com um ajuste de interfer√™ncia, n√£o acho que seja ruim. </li><li>  Vou tocar no Jetson TX1 | TX2.  Nas condi√ß√µes atuais, essas n√£o s√£o as melhores plataformas para o pre√ßo, mas h√° situa√ß√µes em que ainda s√£o convenientes de usar. </li><li>  N√£o garanto que a lista inclua todas as plataformas existentes hoje.  Talvez eu tenha esquecido alguma coisa, talvez n√£o saiba de alguma coisa.  Se voc√™ conhece plataformas mais interessantes - escreva! </li></ol><br><br>  Ent√£o  As principais coisas que est√£o claramente incorporando.  No artigo, vamos compar√°-los precisamente: <br><br><img width="800" src="https://habrastorage.org/webt/re/uw/k4/reuwk49r6lwkkhssus1lqwamlyq.jpeg"><br><br><ol><li>  Plataforma <b>Jetson</b> .  Existem v√°rios dispositivos para isso: <br><ul><li>  <b>Jetson Nano</b> - um brinquedo barato e bastante moderno (primavera de 2019) </li><li>  <b>Jetson Tx1 | Tx2</b> - bastante caro, mas bom em plataformas de desempenho e versatilidade </li></ul><br></li><li>  <b>Raspberry Pi</b> .  Na realidade, apenas o RPi4 tem o desempenho para redes neurais.  Mas algumas tarefas separadas podem ser realizadas na terceira gera√ß√£o.  Eu at√© criei grades muito simples no come√ßo. </li><li>  <b>Google Coral</b> Platform.  De fato, para dispositivos de incorpora√ß√£o, h√° apenas um chip e dois dispositivos - Dev Board e USB Accelerator </li><li>  Plataforma <b>Intel Movidius</b> .  Se voc√™ n√£o √© uma empresa grande, apenas os bast√µes Movidius 1 | Movidius 2 estar√£o dispon√≠veis para voc√™. </li><li>  Plataforma <b>Gyrfalcone</b> .  O milagre da tecnologia chinesa.  J√° existem duas gera√ß√µes - 2801, 2803 </li></ol><br><br>  Misc.  Falaremos sobre eles ap√≥s as principais compara√ß√µes: <br><ol><li>  Processadores Intel.  Primeiro de tudo, assembl√©ias NUC. </li><li>  GPUs m√≥veis da Nvidia.  Solu√ß√µes prontas podem ser consideradas n√£o incorporadas.  E se voc√™ coletar incorpora√ß√£o, ela resultar√° decentemente nas finan√ßas. </li><li>  Telefones celulares.  O Android √© caracterizado pelo fato de que, para usar o desempenho m√°ximo, √© necess√°rio usar exatamente o hardware que um fabricante espec√≠fico possui.  Ou use algo universal, como luz tensorflow.  Para a Apple, a mesma coisa. </li><li>  O Jetson AGX Xavier √© uma vers√£o cara do Jetson com mais desempenho. </li><li>  GAP8 - processadores de baixa pot√™ncia para dispositivos super baratos. </li><li>  Bosque misterioso AI BON√â </li></ol><br><br><h2>  Jetson </h2><br>  Trabalhamos com a Jetson h√° muito tempo.  Em 2014, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">Vasyutka</a> inventou a matem√°tica para o ent√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Swift</a> precisamente em Jetson.  Em 2015, em uma reuni√£o com a Artec 3D, conversamos sobre como √© uma plataforma bacana, ap√≥s o que eles sugeriram que constru√≠ssemos um prot√≥tipo baseado nela.  Depois de alguns meses, o prot√≥tipo estava pronto.  Apenas alguns anos de trabalho de toda a empresa, alguns anos de maldi√ß√µes na plataforma e no c√©u ... E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artec Leo</a> nasceu - o scanner mais legal da sua classe.  At√© a Nvidia na apresenta√ß√£o do TX2 o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mostrou</a> como um dos projetos mais interessantes criados na plataforma. <br>  Desde ent√£o, o TX1 / TX2 / Nano usamos em algum lugar em 5-6 projetos. <br>  E, provavelmente, conhecemos todos os problemas que estavam com a plataforma.  Vamos tom√°-lo em ordem. <br><br><h3>  Jetson tk1 </h3><br>  Eu n√£o vou falar especialmente sobre ele.  A plataforma era muito eficiente em poder de computa√ß√£o em seu dia.  Mas ela n√£o era mercearia.  A NVIDIA vendeu os chips <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TegraTK1</a> que sustentavam a Jetson.  Mas esses chips eram imposs√≠veis de usar para pequenos e m√©dios fabricantes.  Na realidade, apenas o Google / HTC / Xiaomi / Acer / Google poderia fazer algo al√©m da Nvidia.  Todos os outros integrados ao produto ou debugam placas ou saquearam outros dispositivos. <br><br><h3>  Jetson TX1 | TX2 </h3><br>  A Nvidia tirou as conclus√µes corretas e a pr√≥xima gera√ß√£o foi fant√°stica.  TX1 | TX2, esses n√£o s√£o mais chips, mas um chip no tabuleiro. <br><img width="300" src="https://habrastorage.org/getpro/habr/post_images/c2c/6d4/dec/c2c6d4dec3a41c852c05d055b231bd06.jpg" alt="imagem"><img width="300" src="https://habrastorage.org/getpro/habr/post_images/411/694/e40/411694e401d5c4665e280ab0a6b8a4b6.png" alt="imagem"><br>  Eles s√£o mais caros, mas t√™m um n√≠vel completamente de supermercado.  Uma pequena empresa pode integr√°-los em seu produto, este produto √© previs√≠vel e est√°vel.  Eu pessoalmente vi como 3-4 produtos foram trazidos para a produ√ß√£o - e tudo estava bem. <br>  Vou falar sobre TX2, porque a partir da linha atual √© a placa principal. <br>  Mas, √© claro, nem todos agradecem a Deus.  O que h√° de errado: <br><ol><li>  Jetson TX2 √© uma plataforma cara.  Na maioria dos produtos, voc√™ usar√° o m√≥dulo principal (pelo que entendi, pelo tamanho do lote, o pre√ßo ser√° algo entre 200-250 e 350-400 cu cada).  Ele precisa de um CarrierBoard.  N√£o conhe√ßo o mercado atual, mas antes era de 100 a 300 cu  dependendo da configura√ß√£o.  Bem, al√©m de seu kit para o corpo. </li><li>  O Jetson TX2 n√£o √© a plataforma mais r√°pida.  A seguir, discutiremos velocidades comparativas; mostrarei por que essa n√£o √© a melhor op√ß√£o. </li><li>  √â necess√°rio remover muito calor.  Provavelmente isso √© verdade para quase todas as plataformas sobre as quais falaremos.  A carca√ßa deve resolver o problema de dissipa√ß√£o de calor.  F√£s </li><li>  Esta √© uma plataforma ruim para pequenas festas.  Muitas centenas de dispositivos - aprox.  Encomendar placas-m√£e, desenvolver projetos e embalagens √© a norma.  Muitos milhares de dispositivos?  Crie sua placa-m√£e - e chique.  Se voc√™ precisar de 5-10 - ruim.  Voc√™ ter√° que usar o DevBoard provavelmente.  Eles s√£o grandes, s√£o um pouco nojentos para piscar.  Esta n√£o √© uma plataforma pronta para RPi. </li><li>  Suporte t√©cnico ruim da Nvidia.  Ouvi muitos juramentos de que as respostas s√£o respondidas, que s√£o informa√ß√µes secretas ou mensais. </li><li>  M√° infraestrutura na R√∫ssia.  √â dif√≠cil encomendar, leva muito tempo.  Mas, ao mesmo tempo, os revendedores funcionam bem.  Recentemente, deparei com um Jetson nano que queimava no dia do lan√ßamento - alterado sem questionar.  Sam apanhado pelo correio / trouxe um novo.  WAH!  Al√©m disso, ele pr√≥prio viu que o escrit√≥rio de Moscou aconselha bem.  Por√©m, assim que seu n√≠vel de conhecimento n√£o permitir responder √† pergunta e exigir uma solicita√ß√£o ao escrit√≥rio internacional - eles ter√£o que esperar por respostas por um longo tempo. </li></ol><br><br>  O que √© incr√≠vel: <br><ol><li>  Muita informa√ß√£o, uma comunidade muito grande. </li><li>  Em torno da Nvidia, existem muitas pequenas empresas que produzem acess√≥rios.  Eles est√£o abertos a negocia√ß√µes, voc√™ pode ajustar a decis√£o deles.  E CarierBoard, firmware e sistemas de refrigera√ß√£o. </li><li>  Suporte para todas as estruturas normais (TensorFlow | PyTorch) e suporte completo para todas as redes.  A √∫nica convers√£o que voc√™ pode precisar fazer √© transferir o c√≥digo para o TensorRT.  Isso economizar√° mem√≥ria, possivelmente acelerar√°.  Comparado ao que estar√° em outras plataformas, isso √© rid√≠culo. </li><li>  Eu n√£o sei como criar pranchas.  Mas daqueles que fizeram isso pela Nvidia, ouvi dizer que o TX2 √© uma boa op√ß√£o.  Existem manuais que correspondem √† realidade. </li><li>  Bom consumo de energia.  Mas tudo o que exatamente "incorporado" estar√° conosco - o pior :) </li><li>  Pin√ßa na R√∫ssia (explicado acima por que) </li><li>  Ao contr√°rio do movidius |  RPi  Coral  Gyrfalcon √© uma GPU real.  Voc√™ pode usar nele n√£o apenas grades, mas tamb√©m algoritmos normais </li></ol><br><br>  Como resultado, essa √© uma boa plataforma para voc√™, se voc√™ tiver dispositivos de pe√ßa, mas, por algum motivo, n√£o poder√° entregar um computador completo.  Algo enorme?  Biometria - provavelmente n√£o.  O reconhecimento de n√∫mero est√° no limite, dependendo do fluxo.  Dispositivos port√°teis com um pre√ßo de mais de 5 mil d√≥lares - poss√≠vel.  Carros - n√£o, √© mais f√°cil colocar uma plataforma mais poderosa um pouco mais cara. <br>  Parece-me que, com o lan√ßamento de uma nova gera√ß√£o de dispositivos baratos, o TX2 morrer√° com o tempo. <br><br>  As placas-m√£e para Jetson TX1 | TX2 | TX2i e outras s√£o parecidas com esta: <br><img src="https://habrastorage.org/getpro/habr/post_images/05c/ad5/2fc/05cad52fc3ba0b3468b7cea85a2f2552.png" alt="imagem"><br>  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui h√°</a> mais varia√ß√µes. <br><br><h3>  Jetson nano </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/9af/40b/1d8/9af40b1d8153cf212cbd2f76a533b143.png" alt="imagem"><br>  Jetson Nano √© uma coisa muito interessante.  Para a Nvidia, esse √© um novo fator de forma que, em termos de revolu√ß√£o, teria que se comparar com o TK1.  Mas os concorrentes j√° est√£o se esgotando.  Existem outros dispositivos sobre os quais falaremos.  √â 2 vezes mais fraco que o TX2, mas 4 vezes mais barato.  Mais precisamente ... A matem√°tica √© complicada.  Jetson Nano na placa demo custa 100 d√≥lares (na Europa).  Mas se voc√™ comprar apenas um chip, ser√° mais caro.  E voc√™ precisar√° cri√°-lo (ainda n√£o h√° uma placa-m√£e para ele).  E Deus n√£o permita que seja duas vezes mais barato em uma grande festa que o TX2. <br>  De fato, a Jetson Nano, em sua base, √© um produto de publicidade para institutos / revendedores / amadores, o que deve estimular o interesse e a aplica√ß√£o comercial.  Por vantagens e desvantagens (cruza parcialmente com TX2): <br><ol><li>  O design √© fraco e n√£o √© depurado: <br><ul><li>  Superaquece, com uma carga constante periodicamente trava / voa.  Uma empresa familiar tenta resolver todos os problemas h√° tr√™s meses - n√£o d√° certo. </li><li>  Eu tenho um queimado quando alimentado por USB.  Ouvi dizer que um amigo tinha uma sa√≠da USB queimada e o plugue estava funcionando.  Provavelmente alguns problemas com a alimenta√ß√£o USB. </li><li>  Se voc√™ empacotar a placa original, n√£o haver√° radiador suficiente da NVIDIA; por exemplo, ele superaquecer√°. </li></ul><br></li><li>  A velocidade n√£o √© suficiente.  Quase duas vezes menos que TX2 (na realidade, pode ser 1,5, mas depende da tarefa). </li><li>  Muitos dispositivos de 5 a 10 s√£o geralmente muito bons.  50-200 - √© dif√≠cil, voc√™ precisar√° compensar todos os erros do fabricante, pendur√°-lo em seus c√£es, se precisar adicionar algo como POE, isso vai doer.  Festas maiores.  Hoje n√£o ouvi falar de projetos de sucesso.  Mas parece-me que podem surgir dificuldades como no TK1.  Para ser sincero, gostaria de esperar que o pr√≥ximo ano seja lan√ßado o Jetson Nano 2, onde essas doen√ßas infantis ser√£o corrigidas. </li><li>  O suporte est√° ruim, o mesmo que o TX2 </li><li>  Infraestrutura deficiente </li></ol><br><br>  Bom: <br><ol><li>  Or√ßamento suficiente em compara√ß√£o com os concorrentes.  Especialmente para pequenas festas.  Pre√ßo / desempenho favor√°veis </li><li>  Ao contr√°rio do movidius |  RPi  Coral  Gyrfalcon √© uma GPU real.  Voc√™ pode usar nele n√£o apenas grades, mas tamb√©m algoritmos normais </li><li>  Basta iniciar qualquer rede (igual ao TX2) </li><li>  Consumo de energia (o mesmo que tx2) </li><li>  Pin√ßa na R√∫ssia (o mesmo que tx2) </li></ol><br><br>  O pr√≥prio Nano saiu no in√≠cio da primavera, em algum lugar de abril / maio, eu o cutuquei ativamente.  J√° conseguimos fazer dois projetos neles.  Em geral, os problemas identificados acima.  Como um produto de hobby / produto para pequenos lotes - muito legal.  Mas se ainda √© poss√≠vel arrastar a produ√ß√£o e como faz√™-lo, ainda n√£o est√° claro. <br><br><h3>  Fale sobre a velocidade da Jetson. </h3><br>  Iremos comparar com outros dispositivos muito mais tarde.  Enquanto isso, apenas fale sobre Jetson e velocidade.  Por que a Nvidia est√° mentindo para n√≥s.  Como otimizar seus projetos. <br>  Abaixo est√° escrito tudo sobre o TensorRT-5.1.  O TensorRT-6.0.1 foi lan√ßado em 17 de setembro de 2019, todas as instru√ß√µes devem ser verificadas duas vezes l√°. <br>  Vamos supor que acreditamos na Nvidia.  Vamos abrir o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site</a> deles e ver o tempo de infer√™ncia do SSD-mobilenet-v2 para 300 * 300: <br><img width="800" src="https://habrastorage.org/getpro/habr/post_images/8bd/9aa/098/8bd9aa098ffe1e06c3b78d9f88f64dab.png" alt="imagem"><br>  Uau, 39FPS (25ms).  Sim, e o c√≥digo fonte est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">definido</a> ! <br><br>  Hmm ... Mas por que est√° escrito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> sobre 46ms? <br><br>  Espere ... E aqui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">eles</a> escrevem que 309 ms s√£o nativos e 72ms s√£o portados ... <br><br><img width="800" src="https://habrastorage.org/getpro/habr/post_images/32f/fd2/526/32ffd25260529f142b84a127c6d7a75c.png" alt="imagem"><br><br>  Onde esta a verdade <br>  A verdade √© que todo mundo pensa muito diferente: <br><ol><li>  SSD consiste em duas partes.  Uma parte √© o neur√¥nio.  A segunda parte √© o p√≥s-processamento do que o neur√¥nio produziu (n√£o supress√£o m√°xima) + o pr√©-processamento do que √© carregado na entrada. </li><li>  Como eu disse anteriormente, no Jetson tudo precisa ser convertido para o TensorRT.  Essa √© uma estrutura nativa da NVIDIA.  Sem ele, tudo ser√° ruim.  S√≥ h√° um problema.  Nem tudo √© portado para l√°, especialmente do TensorFlow.  Globalmente, existem duas abordagens: <br><ul><li>  O Google, percebendo que isso √© um problema, lan√ßou para o TensorFlow uma coisa chamada "tf-trt".  De fato, este √© um complemento para tf, que permite converter qualquer grade para tensorrt.  As partes que n√£o s√£o suportadas s√£o inferidas na CPU, o restante na GPU. </li><li>  Reescreva todas as camadas / encontre seus an√°logos </li></ul><br></li></ol><br>  Nos exemplos acima: <br><ul><li>  Nesse link, o tempo de 300ms √© o fluxo tensor usual sem otimiza√ß√£o. </li><li>  L√°, 72ms √© a vers√£o tf-trt.  L√°, todos os nms s√£o essencialmente feitos no processo. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Esta √© uma</a> vers√£o para f√£s, onde uma pessoa transferiu todos os nms e os escreveu no pr√≥prio gpu. </li><li>  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">isso</a> ... Essa NVIDIA decidiu medir todo o desempenho sem p√≥s-processamento, sem mencion√°-lo explicitamente em qualquer lugar. </li></ul><br><br>  Voc√™ precisa entender por si mesmo que, se fosse o seu neur√¥nio, que ningu√©m teria convertido antes de voc√™, sem problemas voc√™ seria capaz de inici√°-lo a uma velocidade de 72ms.  E a uma velocidade de 46 ms, sentado sobre os manuais e sorsa dia-semana. <br>  Comparado a muitas outras op√ß√µes, isso √© muito bom.  Mas n√£o esque√ßa que, fa√ßa o que fizer - nunca acredite nos benchmarks da NVIDIA! <br><br><h2>  RaspberryPI 4 </h2><br>  Produ√ß√£o? .. E eu ouvi como dezenas de engenheiros come√ßaram a rir da men√ß√£o das palavras "RPI" e "produ√ß√£o" nas proximidades.  Mas, devo dizer - o RPI ainda √© mais est√°vel que o Jetson Nano e o Google Coral.  Mas, √© claro, o TX2 perde e, aparentemente, gyrfalcone. <br><img src="https://habrastorage.org/getpro/habr/post_images/667/aa5/dbc/667aa5dbc7be87aeda247492035b3c33.jpg" alt="imagem"><br>  (A imagem √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> . Parece-me que prender os f√£s ao RPi4 √© uma divers√£o folcl√≥rica separada.) <br>  Da lista inteira, este √© o √∫nico dispositivo que n√£o segurei nas m√£os / n√£o testei.  Mas ele iniciou neur√¥nios em Rpi, Rpi2, Rpi3 (por exemplo, ele me disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ).  Em geral, o Rpi4, como eu o entendo, difere apenas no desempenho.  Parece-me que os pr√≥s e contras da RPi sabem tudo, mas ainda assim.  Contras: <br><br><ol><li>  Por mais que eu n√£o queira, esta n√£o √© uma solu√ß√£o de supermercado.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Superaquecimento</a> .  Congelamentos peri√≥dicos.  Mas, devido √† enorme comunidade, existem centenas de solu√ß√µes para todos os problemas.  Isso n√£o torna o Rpi bom para milhares de tiragens.  Mas dezenas / centenas - observa wai. </li><li>  Velocidade.  Este √© o dispositivo mais lento de todos os principais sobre os quais estamos falando. </li><li>  Quase n√£o h√° suporte do fabricante.  Este produto √© destinado a entusiastas. </li></ol><br>  Pr√≥s: <br><br><ol><li>  Pre√ßo  N√£o, √© claro, se voc√™ mesmo criar o tabuleiro, usando o gyrfalcone poder√° torn√°-lo mais barato em milhares.  Mas provavelmente isso n√£o √© realista.  Onde o desempenho do RPi √© suficiente - ser√° a solu√ß√£o mais barata. </li><li>  Popularidade.  Quando o Caffe2 foi lan√ßado, havia uma vers√£o para o Rpi no release base.  Tensorflow light?  Claro que funciona.  I.T.D., I.T.P.  O que o fabricante n√£o faz √© transferir usu√°rios.  Corri em diferentes RPi, Caffe, Tensorflow e PyTorch, e v√°rias coisas mais raras. </li><li>  Conveni√™ncia para pequenas festas / pe√ßas.  Basta piscar o pen drive e executar.  H√° Wi-Fi a bordo, ao contr√°rio do JetsonNano.  Voc√™ pode simplesmente lig√°-lo atrav√©s do PoE (parece que voc√™ precisa comprar um adaptador que √© vendido ativamente). </li></ol><br><br>  Falaremos sobre a velocidade Rpi no final.  Como o fabricante n√£o postula que seu produto para neur√¥nios, existem poucos par√¢metros de refer√™ncia.  Todo mundo entende que o Rpi n√£o √© perfeito em velocidade.  Mas mesmo ele √© adequado para algumas tarefas. <br>  Tivemos algumas tarefas de semi-produto que implementamos na Rpi.  A impress√£o foi agrad√°vel. <br><br><h2>  Movidius 2 </h2><br><img width="800" src="https://habrastorage.org/webt/ki/gq/l3/kigql3xgdsddqwgx-iwrjznthpc.jpeg"><br>  A partir daqui e abaixo, n√£o ser√£o processados ‚Äã‚Äãprocessadores completos, mas processadores projetados especificamente para redes neurais.  √â como se seus pontos fortes e fracos ao mesmo tempo. <br>  Ent√£o  Movidius.  A empresa foi comprada pela Intel em 2016.  No segmento que nos interessa, a empresa lan√ßou dois produtos, Movidius e Movidius 2. O segundo √© mais r√°pido, falaremos apenas sobre o segundo. <br>  N√£o, n√£o √© assim.  A conversa n√£o deve come√ßar com o Movidius, mas com o Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenVino</a> .  Eu diria que isso √© ideologia.  Mais especificamente, a estrutura.  De fato, esse √© um conjunto de neur√¥nios pr√©-treinados e infer√™ncias para eles, otimizados para produtos Intel (processadores, GPUs, computadores especiais).  Integrado ao OpenCV, ao Raspberry Pi, a v√°rios outros apitos e peidos. <br>  A vantagem do OpenVino √© que ele possui muitos neur√¥nios.  Primeiro de tudo, os detectores mais famosos.  Neur√¥nios para reconhecimento de pessoas, pessoas, n√∫meros, letras, poses, etc., etc.  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> ).  E eles s√£o treinados.  N√£o por conjuntos de dados abertos, mas por conjuntos de dados compilados pela pr√≥pria Intel.  Eles s√£o muito maiores / mais diversificados e mais abertos.  Eles podem ser reciclados de acordo com os seus casos, e geralmente funcionar√£o bem. <br>  √â poss√≠vel fazer melhor?  Claro que voc√™ pode.  Por exemplo, o reconhecimento dos n√∫meros que fizemos - funcionou significativamente melhor.  Mas passamos muitos anos desenvolvendo-o e entendendo como torn√°-lo perfeito.         ,      . <br>  OpenVino, ,   .      .  -   ‚Äî   .     .  GAN    .   . ,   ,     ,     -   ,    .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,    : <br><img src="https://habrastorage.org/getpro/habr/post_images/103/de3/8ad/103de38adbea7450a4f7888ef135303c.png" alt="imagem"><br>  ,  Intel   OpenVino    .     .  ,       .         ‚Äî      .    70%       OpenVino. <br>      Movidius    .         .       (    ,   ). <br>     . USB , ,   !!!       USB.  . Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .  -        ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ) <br>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>   .               -.     -         . <br>      ?..       :) <br>  ,   . OpenVino,   ,   ,    (    Computer Vision  ).      : <br><iframe width="560" height="315" src="https://www.youtube.com/embed/ogHrgixuFzg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br> (   AI 2.0,   OpenVino  ). <br><br> ,     .    Movidius 2. : <br><ol><li>    .  Rpi  Jetson Nano.            ‚Äî  .        .   Third Party ? </li><li>    .     .     . </li><li>    .    . </li><li>     .           USB 3.0 </li><li>    ,        .   -.     .  Movidius      .      . </li></ol><br>  Pr√≥s: <br><ol><li>    .        .    . </li><li>  ,   </li><li>  ,    </li></ol><br>         .          ‚Äî      . <br>      ,     ‚Äú   20-30   ,     ,  ‚Äù ‚Äî       Movidius. <br>  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>  .      , . <br><img src="https://habrastorage.org/webt/d0/m-/ec/d0m-ecz9npk5f11jwlr0pzxruwi.jpeg" alt="imagem"><br>  <b>UPD</b> <br>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .     .   embedded . PCI-e      .       .   ‚Äî        200 .. .         ‚Ä¶ <br><br><h2> Google Coral </h2><br>  Estou desapontado  N√£o, n√£o h√° nada que eu n√£o previsse.  Mas estou desapontado que o Google tenha decidido divulgar isso.  Testar √© um milagre no come√ßo do ver√£o.  Talvez algo tenha mudado desde ent√£o, mas descreverei minha experi√™ncia na √©poca. <br>  Configurando ... Para atualizar o Jetson Tk-Tx1-Tx2, voc√™ precisava conect√°-lo ao computador host e √† fonte de alimenta√ß√£o.  E isso foi o suficiente.  Para fazer flash Jetson Nano e RPi, voc√™ s√≥ precisa enviar a imagem para a unidade flash USB. <br>  E para piscar Coral, voc√™ precisa prender tr√™s fios na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ordem correta</a> : <br><img src="https://habrastorage.org/webt/de/b4/hs/deb4hsbxm_ra3ajx7_kuoljd0ls.jpeg"><br>  E n√£o tente cometer um erro!  A prop√≥sito, h√° erros / comportamento indescrit√≠vel no guia.  Provavelmente n√£o vou descrev√™-los, j√° que desde o in√≠cio do ver√£o eles poderiam ter consertado alguma coisa.  Lembro que, depois de instalar o Mendel, qualquer acesso via ssh foi perdido, incluindo o descrito por eles, e tive que editar manualmente algumas configura√ß√µes do Linux. <br>  Levei 2-3 horas para concluir este processo. <br>  Ok  Lan√ßado.  Voc√™ acha que √© f√°cil executar sua grade nela?  Quase nada :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui est√° uma</a> lista do que voc√™ pode deixar para tr√°s. <br>  Para ser sincero, n√£o cheguei a esse ponto rapidamente.  Passou meio dia.  Na verdade n√£o.  Voc√™ n√£o pode fazer o download do modelo do <a href="">reposit√≥rio TF</a> e executar no dispositivo.  Ou l√° √© necess√°rio cortar todas as camadas.  N√£o encontrei instru√ß√µes. <br>  Ent√£o aqui.  √â necess√°rio pegar o modelo do reposit√≥rio de cima.  N√£o existem muitos (foram adicionados 3 modelos desde o in√≠cio do ver√£o).  E como trein√°-la?  Abrir no TensorFlow em um pipeline padr√£o?  HAHAHAHAHAHAHAHA.  Claro que n√£o !!! <br>  Voc√™ tem um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cont√™iner de Doker</a> especial e o modelo treinar√° apenas nele.  (Provavelmente, voc√™ tamb√©m pode zombar do seu TF ... Mas h√° instru√ß√µes, instru√ß√µes ... que n√£o eram e n√£o parecem ser.) <br>  Baixe / instale / inicie.  O que √© ... Por que a GPU est√° em zero? .. PORQUE O TREINAMENTO EST√Å NA CPU.  Docker √© apenas para ele !!!  Quer mais divers√£o?  O manual diz "baseado em uma CPU de 6 n√∫cleos com esta√ß√£o de trabalho com mem√≥ria de 64G".  Parece que isso √© apenas um conselho?  Talvez.  S√≥ que agora eu n√£o tinha o suficiente dos meus 8 shows nesse servidor, onde a maioria dos modelos treina.  O treinamento na quarta hora consumia todos.  Um forte sentimento de que eles tinham algo fluindo.  Tentei alguns dias com par√¢metros diferentes em m√°quinas diferentes, o efeito foi um. <br>  N√£o verifiquei isso antes de publicar o artigo.  Para ser sincero, foi o suficiente para mim uma vez. <br>  O que mais a acrescentar?  Que esse c√≥digo n√£o gera um modelo?  Para ger√°-lo, voc√™ deve: <br><br><ol><li>  Contagem de atraso </li><li>  Converta-o para tflite </li><li>  Compile no TPU do Formal Edge.  Gra√ßas a Deus agora isso √© feito em um computador.  Na primavera, isso s√≥ poderia ser feito online.  E l√° foi necess√°rio marcar "N√£o o usarei para o mal / n√£o viole nenhuma lei com esse modelo".  Agora, gra√ßas a Deus n√£o h√° nada disso. </li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/2ef/84d/b88/2ef84db88bcaba5d18a97c23bf5f2605.png" alt="imagem"><br>  Esse √© o maior desgosto que experimentei em rela√ß√£o a um produto de TI no ano passado ... <br>  Globalmente, Coral deve ter a mesma ideologia que o OpenVino com o Movidius.  S√≥ agora a Intel est√° nesse caminho h√° v√°rios anos.  Com excelentes manuais, suporte e bons produtos ... E o Google.  Bem, √© apenas o Google ... <br>  Contras: <br><ol><li>  Este f√≥rum n√£o √© uma mercearia no n√≠vel do AD.  Eu n√£o ouvi falar sobre a venda de chips =&gt; a produ√ß√£o n√£o √© realista </li><li>  O n√≠vel de desenvolvimento √© o mais terr√≠vel poss√≠vel.  Tudo bazhet.  O pipeline de desenvolvimento n√£o se encaixa nos esquemas tradicionais. </li><li>  O f√£.  No "chip energeticamente √≥timo", eles colocam.  Ok, n√£o vou mais falar sobre produ√ß√£o. </li><li>  Custo.  Mais caro que o TX2. </li><li>  Duas grades <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">n√£o podem ser</a> mantidas na mem√≥ria ao mesmo tempo.  √â necess√°rio realizar o upload-download.  O que diminui a infer√™ncia de v√°rias redes. </li></ol><br>  Pr√≥s: <br><ol><li>  De tudo o que falamos, Coral √© o mais r√°pido </li><li>  Potencialmente, se o chip √© ativado, √© mais produtivo que o Movidius.  E parece que sua arquitetura √© mais justificada para os neur√¥nios. </li></ol><br><br><h2>  Gyrfalcon </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/640/86e/595/64086e5959ce67c2a21dc80c3106e49d.png" alt="imagem"><br>  Os √∫ltimos anos e meio t√™m falado sobre esta besta chinesa.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">H√°</a> um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ano,</a> eu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estava</a> dizendo algo sobre ele.  Mas falar √© uma coisa, e dar informa√ß√£o √© outra.  Conversei com 3 a 4 grandes empresas, onde os gerentes / diretores de projetos me disseram como esse Girfalkon era legal.  Mas eles n√£o tinham nenhuma documenta√ß√£o.  E eles n√£o o viram vivo.  O <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site</a> quase n√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">possui</a> informa√ß√µes.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fa√ßa</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">download</a> do site pelo menos algo que s√≥ pode ser parceiro (desenvolvedor de hardware).  Al√©m disso, as informa√ß√µes no site s√£o muito contradit√≥rias.  Em um lugar, eles escrevem que suportam apenas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VGG</a> , em outro, que apenas seus neur√¥nios s√£o baseados na GNet (que, de acordo com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">suas garantias, s√£o</a> muito pequenos e realmente sem perda de precis√£o).  No terceiro est√° escrito que tudo √© convertido com TF | Caffe | PyTorch, e no quarto est√° escrito sobre o telefone celular e outros encantos. <br>  Compreender a verdade √© quase imposs√≠vel.  Uma vez eu estava cavando e cavando alguns v√≠deos nos quais pelo menos alguns n√∫meros escorregam: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/AoidCoMK8v0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eS6eCAEL_1A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Se isso for verdade, significa SSD (no celular?) Abaixo de 224 * 224 no chip GTI2801, eles t√™m ~ 60ms, o que √© bastante compar√°vel ao movidius. <br>  Parece que eles t√™m um chip 2803 muito mais r√°pido, mas as informa√ß√µes sobre ele s√£o ainda menos: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/yQvVqaVZUQ4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Neste ver√£o, temos uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">prancha</a> de vaga-lume em nossas m√£os ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este</a> m√≥dulo √© instalado l√° para c√°lculos). <br><br>  Havia uma esperan√ßa de que finalmente ver√≠amos vivos.  Mas n√£o deu certo.  O quadro estava vis√≠vel, mas n√£o funcionou.  Rastreando frases individuais em ingl√™s na documenta√ß√£o chinesa, eles quase entenderam qual era o problema (o sistema serrilhado inicial n√£o suportava o m√≥dulo neural, era necess√°rio reconstruir e refazer tudo n√≥s mesmos).  Mas simplesmente n√£o deu certo e j√° havia suspeitas de que o conselho n√£o se encaixaria em nossa tarefa (2 GB de RAM √© muito pequeno para redes neurais + sistemas. Al√©m disso, n√£o havia suporte para duas redes ao mesmo tempo). <br>  Mas eu consegui ver a documenta√ß√£o original.  A partir disso, pouco se entende (chin√™s).  Para o bem, era necess√°rio testar e olhar a fonte. <br>  O suporte t√©cnico da RockChip marcou estupidamente em n√≥s. <br>  Apesar desse horror, √© claro para mim que aqui, mesmo assim, os batentes do RockChip est√£o aqui antes de tudo.  E tenho uma esperan√ßa de que, em um quadro normal, o Gyrfalcon possa ser bastante usado.  Mas, devido √† falta de informa√ß√µes, √© dif√≠cil para mim dizer. <br><br>  Contras: <br><ol><li>  N√£o h√° vendas abertas, apenas interaja com empresas </li><li>  Pouca informa√ß√£o, nenhuma comunidade.  As informa√ß√µes existentes costumam estar em chin√™s.  Os recursos da plataforma n√£o podem ser previstos com anteced√™ncia </li><li>  Provavelmente, a infer√™ncia n√£o √© mais do que uma rede por vez. </li><li>  Somente os fabricantes de ferro podem interagir com o pr√≥prio giroplano.  O restante precisa procurar alguns intermedi√°rios / fabricantes de placas. </li></ol><br>  Pr√≥s: <br><ol><li>  Pelo que entendi, o pre√ßo de um chip girfcon √© muito mais barato que o resto.  Mesmo na forma de pen drives. </li><li>  J√° existem dispositivos de terceiros com um chip integrado.  Portanto, o desenvolvimento √© um pouco mais f√°cil que o movidius. </li><li>  Eles garantem que existem muitas grades pr√©-treinadas, a transfer√™ncia de grades √© muito mais f√°cil do que o Movidius | Coral.  Mas eu n√£o garantiria isso como verdade.  N√≥s n√£o tivemos sucesso. </li></ol><br>  Em suma, a conclus√£o √© esta: muito pouca informa√ß√£o.  Voc√™ n√£o pode apenas se deitar nesta plataforma.  E antes de fazer algo - voc√™ precisa fazer uma grande revis√£o. <br><br><h2>  Velocidades </h2><br>  Eu realmente gosto de como 90% das compara√ß√µes de dispositivos incorporados reduzem a velocidade nas compara√ß√µes.  Como voc√™ entendeu acima, essa caracter√≠stica √© muito arbitr√°ria.  No Jetson Nano, voc√™ pode executar neur√¥nios como fluxo tensor puro, usar tensorflow-tensorrt ou usar tensororr puro.  Dispositivos com arquitetura especial de tensores (movidius | coral | gyrfalcone) - podem ser r√°pidos, mas, em primeiro lugar, podem funcionar apenas com arquiteturas padr√£o.  Mesmo para o Raspberry Pi, nem tudo √© t√£o simples.  Os neur√¥nios do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">xnor.ai</a> d√£o uma vez e meia de acelera√ß√£o.  Mas n√£o sei o quanto s√£o honestos e o que foi ganho ao mudar para int8 ou outras piadas. <br>  Ao mesmo tempo, outra coisa interessante √© esse momento.  Quanto mais complexo o neur√¥nio, mais complexo o dispositivo de infer√™ncia - mais imprevis√≠vel √© a acelera√ß√£o final que pode ser retirada.  Tome um pouco de OpenPose.  Existe uma rede n√£o trivial, p√≥s-processamento complexo.  Isso e aquilo podem ser otimizados devido a: <br><br><ul><li>  Migra√ß√£o de p√≥s-processamento de GPU </li><li>  Otimize o p√≥s-processamento </li><li>  Otimiza√ß√£o de rede neural para recursos da plataforma, por exemplo: <br><ul><li>  Usando redes otimizadas para plataforma </li><li>  Usando m√≥dulos de rede para a plataforma </li></ul><br></li><li>  Portando para Int8 | Int16 | Binariza√ß√£o </li><li>  Usando v√°rias calculadoras (GPU | CPU | etc.).  Lembro que no Jetson TX1 uma vez aceleramos bem quando transferimos toda a funcionalidade relacionada ao streaming de v√≠deo para os aceleradores internos para esse fim.  Banal, mas a rede acelerou.  Ao balancear, muitas combina√ß√µes interessantes aparecem </li></ul><br>  √Äs vezes, algu√©m tenta avaliar algo para todas as combina√ß√µes poss√≠veis.  Mas realmente, como me parece, isso √© in√∫til.  Primeiro voc√™ precisa decidir sobre a plataforma e s√≥ ent√£o tentar extrair completamente tudo o que √© poss√≠vel. <br><br>  Por que eu sou tudo isso?  Al√©m disso, o teste " <i>quanto tempo o MobileNet</i> " √© um teste muito ruim.  Ele pode dizer que a plataforma X √© ideal.  Mas quando voc√™ tenta implantar seu neur√¥nio e p√≥s-processamento l√°, pode ficar muito decepcionado. <br>  Mas comparar o mobilnet'ov ainda fornece algumas informa√ß√µes sobre a plataforma.  Para tarefas simples.  Para situa√ß√µes em que voc√™ entende que de qualquer maneira √© mais f√°cil reduzir a tarefa para abordagens padr√£o.  Quando voc√™ deseja avaliar a velocidade da calculadora. <br>  A tabela abaixo √© retirada de v√°rios lugares: <br><ul><li>  Estes estudos s√£o: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> </li><li>  Para SSD, existe esse par√¢metro "n√∫mero de classes de sa√≠da".  E a partir deste par√¢metro, a taxa de infer√™ncia pode variar bastante.  Tentei escolher estudos com o mesmo n√∫mero de aulas.  Mas isso pode n√£o ser o caso em todos os lugares. </li><li>  Nossa experi√™ncia com o TensorRT.  Eu sabia que tipos funcionam e quais n√£o. </li><li>  Para o gyrfalcon, esses v√≠deos s√£o baseados no fato de que o mobilnet v2 existe + uma estimativa de quanto a √°rea muda.  Este v√≠deo diz que 2803 pode ser 3-4 vezes mais r√°pido.  Mas para 2803 n√£o h√° classifica√ß√µes de SSD.  Em geral, eu duvido muito das velocidades neste momento. </li><li>  Tentei escolher o estudo que deu a velocidade m√°xima real (n√£o peguei a vers√£o da Nvidia sem o NMS, por exemplo) </li><li>  Para a Jetson TX2, usei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">essas</a> classifica√ß√µes, mas existem 5 classes, no mesmo n√∫mero de classes em que o restante ser√° mais lento.  De alguma forma, descobri pela experi√™ncia / compara√ß√£o com o Nano nos n√∫cleos o que deveria estar l√° </li><li>  N√£o levei em conta piadas com taxa de bits.  N√£o sei em que testemunha Movidius e Gyrfalcon trabalharam. </li></ul><br>  Como resultado, temos: <br><img src="https://habrastorage.org/webt/it/eb/z7/itebz7bgvqmgcupodynat7rr0hy.png"><br><br><h2>  Compara√ß√£o de plataformas </h2><br>  Vou tentar trazer tudo o que eu disse acima para uma √∫nica tabela.  Eu destaquei em amarelo aqueles lugares onde meu conhecimento n√£o √© suficiente para chegar a uma conclus√£o inequ√≠voca.  E, na verdade, 1-6 - essa √© uma avalia√ß√£o comparativa das plataformas.  Quanto mais pr√≥ximo de 1, melhor. <br><img src="https://habrastorage.org/webt/6s/nm/xh/6snmxh9kx7xaufpayljpzvrfoaw.png"><br>  Eu sei que o consumo de energia √© cr√≠tico para muitos.  Mas parece-me que tudo aqui √© um tanto amb√≠guo, e eu entendo isso muito mal - ent√£o n√£o entrei.  Al√©m disso, a pr√≥pria ideologia parece ser a mesma em todos os lugares. <br><br><h2>  Etapa lateral </h2><br>  O que est√°vamos falando √© apenas um pequeno ponto no vasto espa√ßo de varia√ß√µes do seu sistema.  Provavelmente as palavras comuns que podem caracterizar esta √°rea: <br><ul><li>  Baixo consumo de energia </li><li>  Tamanho pequeno </li><li>  Alto poder de computa√ß√£o </li></ul><br>  Por√©m, globalmente, se voc√™ reduzir a import√¢ncia de um dos crit√©rios, poder√° adicionar muitos outros dispositivos √† lista.  Abaixo, vou abordar todas as abordagens que conheci. <br><br><h2>  Intel </h2><br>  Como dissemos quando discutimos o Movidius, a Intel possui uma plataforma OpenVino.  Ele permite um processamento muito eficiente de neur√¥nios nos processadores Intel.  Al√©m disso, a plataforma permite que voc√™ suporte at√© todos os tipos de intel-gpu em um chip.  Agora, tenho medo de dizer exatamente que tipo de desempenho existe para quais tarefas.  Mas, pelo que entendi, uma boa pedra com uma GPU a bordo bastante ‚Öì fornece um desempenho de 1080.  Para algumas tarefas, pode ser ainda mais r√°pido. <br><img src="https://habrastorage.org/getpro/habr/post_images/3b3/16a/a09/3b316aa09dd4dcbe22f97e38474f300a.png" alt="imagem"><br>  Nesse caso, o fator de forma, por exemplo, Intel NUC, √© bastante compacto.  Bom resfriamento, embalagem, etc.  A velocidade ser√° mais r√°pida que o Jetson TX2.  Pela disponibilidade / facilidade de compra - muito mais f√°cil.  A estabilidade da plataforma fora da caixa √© maior. <br>  Dois contras - consumo de energia e pre√ßo.  O desenvolvimento √© um pouco mais complicado. <br><br><h2>  Jetson agx </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/0d7/eb9/4e0/0d7eb94e037d0311f8bf2176b3044329.jpg" alt="imagem"><br>  Este √© outro jetson.  Essencialmente a vers√£o mais antiga.  A velocidade √© cerca de 2 vezes mais r√°pida que o Jetson TX2, al√©m de haver suporte para c√°lculos int8, o que permite que voc√™ fa√ßa overclock por mais 4 vezes.  A prop√≥sito, confira esta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foto</a> da Nvidia: <br><img src="https://habrastorage.org/getpro/habr/post_images/800/c4a/bf1/800c4abf1ed98c8ec84815586c503491.png" alt="imagem"><br>  Eles comparam dois de seus pr√≥prios Jetson.  Um no int8, o segundo no int32.  Nem sei o que dizer aqui ... Em suma: "NUNCA ACREDITE NA NVIDIA GRAPHICS". <br>  Apesar do fato de o AGX ser bom - ele n√£o alcan√ßa as GPUs normais da Nvidia em termos de poder de computa√ß√£o.  No entanto, em termos de efici√™ncia energ√©tica - eles s√£o muito legais.  O principal menos o pre√ßo. <br>  N√≥s mesmos n√£o trabalhamos com eles, por isso √© dif√≠cil para mim dizer algo mais detalhado, descrever a variedade de tarefas em que elas s√£o as melhores. <br><br><h2>  Nvidia gpu  vers√£o para laptop </h2><br>  Se voc√™ remover a restri√ß√£o estrita de consumo de energia, o Jetson TX2 n√£o parecer√° ideal.  Como o AGX.  Geralmente, as pessoas t√™m medo de usar a GPU na produ√ß√£o.  Pagamento separado, tudo isso. <br>  Mas existem milh√µes de empresas que oferecem a voc√™ montar uma solu√ß√£o personalizada em uma placa.  Geralmente s√£o placas para laptops / minicomputadores.  Ou, no final, assim: <br><img src="https://habrastorage.org/getpro/habr/post_images/ee9/37d/cdf/ee937dcdf590661d003a1b1201d3ce46.png" alt="imagem"><br>  Uma das startups em que trabalho nos √∫ltimos 2,5 anos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CherryHome</a> ) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">seguiu</a> esse caminho.  E estamos muito satisfeitos. <br>  Menos, como sempre, o consumo de energia, o que n√£o foi cr√≠tico para n√≥s.  Bem, o pre√ßo morde um pouco. <br><br><h2>  Telem√≥veis </h2><br>  N√£o quero me aprofundar neste t√≥pico.  Para dizer tudo o que h√° nos telefones celulares modernos para neur√¥nios / quais estruturas / quais hardwares etc., voc√™ precisar√° de mais de um artigo com esse tamanho.  E, levando em conta o fato de que seguimos nessa dire√ß√£o apenas 2-3 vezes, considero-me incompetente para isso.  Ent√£o, apenas algumas observa√ß√µes: <br><ol><li>  Existem muitos aceleradores de hardware nos quais os neur√¥nios podem ser otimizados. </li><li>  N√£o existe uma solu√ß√£o geral que corra bem em todos os lugares.  Agora, h√° alguma tentativa de tornar o Tensorflow uma solu√ß√£o desse tipo.  Mas, pelo que entendi, ainda n√£o se tornou um. </li><li>  Alguns fabricantes t√™m suas pr√≥prias fazendas especiais.  Ajudamos a otimizar a estrutura do Snapdragon h√° um ano.  E foi terr√≠vel.  A qualidade dos neur√¥nios √© muito menor do que em tudo que eu falei hoje.  N√£o h√° suporte para 90% das camadas, mesmo as b√°sicas, como "adi√ß√£o". </li><li>  Como n√£o existe python, a infer√™ncia de redes √© muito estranha, il√≥gica e inconveniente. </li><li>  Em termos de desempenho, acontece que tudo √© muito bom (por exemplo, em alguns iphone). </li></ol><br>  Parece-me que para telefones celulares embutidos n√£o √© a melhor solu√ß√£o (a exce√ß√£o √© alguns sistemas de reconhecimento de rosto de baixo or√ßamento).  Mas vi alguns casos quando eles foram usados ‚Äã‚Äãcomo prot√≥tipos iniciais. <br><br><h2>  Gap8 </h2><br>  Esteve recentemente em uma confer√™ncia de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Usedata</a> .  E um dos relat√≥rios era sobre a infer√™ncia de neur√¥nios nas porcentagens mais baratas (GAP8).  E, como se costuma dizer, a necessidade de inven√ß√µes √© astuta.  Na hist√≥ria, um exemplo foi muito rebuscado.  Mas o autor contou como eles foram capazes de obter infer√™ncia pessoalmente em cerca de um segundo.  Em uma grade muito simples, essencialmente sem detector.  Por otimiza√ß√µes loucas e longas e economia em partidas. <br>  Eu sempre n√£o gosto de tais tarefas.  Nenhuma pesquisa, apenas sangue. <br>  Mas vale a pena reconhecer que posso imaginar quebra-cabe√ßas em que porcentagens de baixo consumo fornecem um resultado interessante.  Provavelmente n√£o para reconhecimento facial.  Mas em algum lugar onde voc√™ pode reconhecer a imagem de entrada em 5 a 10 segundos ... <br><br><h2>  Grove AI HAT </h2><br><img width="400" src="https://habrastorage.org/getpro/habr/post_images/3fa/b99/106/3fab99106dbf03025a9adbb98d7d77d5.jpg" alt="imagem"><br>  Enquanto preparava este artigo, me deparei com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">essa</a> plataforma incorporada.  H√° muito pouca informa√ß√£o sobre isso.  Pelo que entendi, zero apoio.  A produtividade tamb√©m est√° em zero ... E nem um √∫nico teste de velocidade ... <br><br><h2>  Servidor / Reconhecimento Remoto </h2><br>  Toda vez que eles procuram nosso conselho em uma plataforma incorporada, eu quero gritar ‚Äúcorra, seus tolos!‚Äù.  √â necess√°rio avaliar cuidadosamente a necessidade dessa solu√ß√£o.  Confira outras op√ß√µes.  Eu sempre recomendo a todos que fa√ßam um prot√≥tipo com a arquitetura do servidor.  E durante sua opera√ß√£o, voc√™ decide se deve implementar um verdadeiro embarcado.  Afinal, incorporado √©: <br><ol><li>  Maior tempo de desenvolvimento, geralmente 2-3 vezes. </li><li>  Suporte sofisticado e depura√ß√£o na produ√ß√£o.  Qualquer desenvolvimento com ML √© uma revis√£o constante, atualiza√ß√£o de neur√¥nios, atualiza√ß√µes do sistema.  Incorporado ainda √© mais dif√≠cil.  Como recarregar o firmware?  E se voc√™ j√° tem acesso a todas as unidades, por que calcular nelas quando pode calcular em um dispositivo? </li><li>  Complexidade do sistema / risco aumentado.  Mais pontos de falha.  Ao mesmo tempo, embora o sistema n√£o funcione como um todo, pode-se n√£o entender: a plataforma √© adequada para esta tarefa? </li><li>  Aumento de pre√ßo.  Uma coisa √© colocar um quadro simples como o nano pi.  E o outro √© comprar TX2. </li></ol><br>  Sim, eu sei que existem tarefas em que as decis√µes do servidor n√£o podem ser tomadas.  Mas, curiosamente, eles s√£o muito menores do que se costuma acreditar. <br><br><h2>  Conclus√µes </h2><br>  No artigo, tentei ficar sem conclus√µes √≥bvias.  √â mais uma hist√≥ria sobre o que √© agora.  Para tirar conclus√µes - √© necess√°rio investigar em cada caso.  E n√£o apenas plataformas.  Mas a tarefa em si.  Qualquer tarefa pode ser levemente simplificada / levemente modificada / levemente afiada sob o dispositivo. <br>  O problema com este t√≥pico √© que o t√≥pico est√° mudando.  Novos dispositivos / estruturas / abordagens est√£o chegando.  Por exemplo, se a NVIDIA ativar o suporte int8 ao Jetson Nano amanh√£, a situa√ß√£o mudar√° drasticamente.  Quando escrevo este artigo, n√£o posso ter certeza de que as informa√ß√µes n√£o foram alteradas h√° dois dias.  Mas espero que meu conto o ajude a navegar melhor em seu pr√≥ximo projeto. <br>  Seria legal se voc√™ tiver informa√ß√µes adicionais / eu perdi algo / disse algo errado - escreva detalhes aqui. <br><br>  ps <br>  J√° quando eu terminei de escrever o artigo quase, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">snakers4</a> soltou um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">post</a> recente de seu canal de telegrama Spark em mim, que √© quase o mesmo problema com Jetson.  Mas, como escrevi acima, - nas condi√ß√µes de qualquer consumo de energia - eu colocaria algo como zotacs ou IntelNUC.  E como o jetson incorporado n√£o √© a pior plataforma. <br><br><img src="https://habrastorage.org/webt/k_/pg/ih/k_pgiheb6cx6kvxxebl4rc_jdei.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt468421/">https://habr.com/ru/post/pt468421/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt468411/index.html">Uma hist√≥ria sobre como resolver o problema de desempenho do Moment.js</a></li>
<li><a href="../pt468413/index.html">Acelera√ß√£o instagram.com. Parte 2</a></li>
<li><a href="../pt468415/index.html">Por que n√£o 1C?</a></li>
<li><a href="../pt468417/index.html">Lan√ßamento do 3CX v16 Update 3 Beta - chamadas de v√≠deo no Android e iOS, conex√£o TLS de troncos SIP</a></li>
<li><a href="../pt468419/index.html">Google Analytics e GDPR: preciso de consentimento do usu√°rio?</a></li>
<li><a href="../pt468423/index.html">Por que o padr√£o USB teve que ser t√£o complicado?</a></li>
<li><a href="../pt468427/index.html">Como ser publicado no Google Play em 2019</a></li>
<li><a href="../pt468431/index.html">O resumo de materiais frescos do mundo do front-end da √∫ltima semana n ¬∞ 381 (16 a 22 de setembro de 2019)</a></li>
<li><a href="../pt468435/index.html">Trabalhe com sem√¢ntica, links e p√°ginas da web de an√°lise: 16 f√≥rmulas √∫teis do Planilhas Google para profissionais de SEO</a></li>
<li><a href="../pt468437/index.html">Vou reconhecer um amor ... pela forma do canal auditivo. Uma nova maneira de identificar usu√°rios</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏼‍🏫 👨‍👨‍👧‍👦 🕳️ Comparação definitiva de plataformas embarcadas para IA 🤘🏼 👩🏻‍⚖️ 😫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Redes neurais capturam o mundo. Eles contam visitantes, monitoram a qualidade, mantêm estatísticas e avaliam a segurança. Um monte de startups, uso in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comparação definitiva de plataformas embarcadas para IA</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/468421/">  Redes neurais capturam o mundo.  Eles contam visitantes, monitoram a qualidade, mantêm estatísticas e avaliam a segurança.  Um monte de startups, uso industrial. <br>  Grandes estruturas.  O que é PyTorch, qual é o segundo TensorFlow.  Tudo está se tornando mais conveniente e conveniente, mais simples e mais simples ... <br>  Mas há um lado sombrio.  Eles tentam ficar calados sobre ela.  Não há nada alegre lá, apenas escuridão e desespero.  Toda vez que você vê um artigo positivo, você suspira tristemente, porque entende que apenas uma pessoa não entendeu alguma coisa.  Ou escondeu. <br>  Vamos falar sobre produção em dispositivos embarcados. <br><img src="https://habrastorage.org/webt/hb/pv/jm/hbpvjmosqm6fva4b2n6ytwqtqqq.jpeg"><br><a name="habracut"></a><br><br><h2>  Qual é o problema </h2><br>  Parece.  Veja o desempenho do dispositivo, verifique se é suficiente, execute-o e obtenha lucro. <br>  Mas, como sempre, existem algumas nuances.  Vamos colocá-los nas prateleiras: <br><ol><li>  Produção.  Se o seu dispositivo não for fabricado em cópias únicas, você precisará ter certeza de que o sistema não travará, que os dispositivos não superaquecerão, que, se houver uma falha de energia, tudo será inicializado automaticamente.  E isso é em uma grande festa.  Isso oferece apenas duas opções - o dispositivo deve ser totalmente projetado, levando em consideração todos os problemas possíveis.  Ou você precisa superar os problemas do dispositivo de origem.  Bem, por exemplo, estes são ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ).  Que, é claro, é estanho.  Para resolver os problemas do dispositivo de outra pessoa em grandes lotes, uma quantidade irreal de energia deve ser gasta. </li><li>  Benchmarks reais.  Muita farsa e truques.  A NVIDIA na maioria dos exemplos superestima o desempenho em 30 a 40%.  Mas não só ela se diverte.  Abaixo, dou muitos exemplos em que a produtividade pode ser 4-5 vezes menor do que você deseja.  Você não pode transar "tudo funcionou bem no computador, será proporcionalmente pior aqui". <br></li><li>  Suporte muito limitado à arquitetura de rede neural.  Existem muitas plataformas de hardware embarcadas que limitam bastante as redes que podem ser executadas nelas (Coral, gyrfalcone, snapdragon).  Portar para essas plataformas será doloroso. </li><li>  Suporte.  Algo não funciona para você, mas o problema está no lado do dispositivo? .. Este é o destino, não vai funcionar.  Somente para RPi, a comunidade fecha a maioria dos bugs.  E, em parte, para a Jetson. </li><li>  Preço  Parece para muitos que embutido é barato.  Mas, na realidade, com o crescimento do desempenho do dispositivo, o preço aumentará quase exponencialmente.  O RPi-4 é 5 vezes mais barato que o Jetson Nano / Google Coral e 2-3 vezes mais fraco.  O Jetson Nano é 5 vezes mais barato que o Jetson TX2 / Intel NUC e 2-3 vezes mais fraco que eles. <br></li><li>  Lorgus.  Lembre-se deste design da Zhelyazny?  <s>Parece que eu a defini como a imagem-título ...</s> " <i>O Logrus é um labirinto tridimensional mutável que representa as forças do Caos no multiverso</i> " <i>.</i>  Tudo isso é uma abundância de insetos e buracos, todas essas várias peças de ferro, todas as estruturas em mudança ... É normal quando o mercado muda completamente em 2-3 meses.  Durante este ano, ele mudou 3-4 vezes.  Você não pode entrar no mesmo rio duas vezes.  Portanto, todos os pensamentos atuais são verdadeiros para o verão de 2019. </li></ol><br><br><h2>  O que é </h2><br>  <s>Vamos colocar em ordem, não tem um sabor doce ...</s> O que agora existe e é adequado para os neurônios?  Não há tantas opções, apesar da variabilidade.  Algumas palavras gerais para limitar a pesquisa: <br><ol><li>  Não analisarei neurônios / inferências em telefones.  Isso por si só é um tópico enorme.  Mas como os telefones são plataformas incorporadas com um ajuste de interferência, não acho que seja ruim. </li><li>  Vou tocar no Jetson TX1 | TX2.  Nas condições atuais, essas não são as melhores plataformas para o preço, mas há situações em que ainda são convenientes de usar. </li><li>  Não garanto que a lista inclua todas as plataformas existentes hoje.  Talvez eu tenha esquecido alguma coisa, talvez não saiba de alguma coisa.  Se você conhece plataformas mais interessantes - escreva! </li></ol><br><br>  Então  As principais coisas que estão claramente incorporando.  No artigo, vamos compará-los precisamente: <br><br><img width="800" src="https://habrastorage.org/webt/re/uw/k4/reuwk49r6lwkkhssus1lqwamlyq.jpeg"><br><br><ol><li>  Plataforma <b>Jetson</b> .  Existem vários dispositivos para isso: <br><ul><li>  <b>Jetson Nano</b> - um brinquedo barato e bastante moderno (primavera de 2019) </li><li>  <b>Jetson Tx1 | Tx2</b> - bastante caro, mas bom em plataformas de desempenho e versatilidade </li></ul><br></li><li>  <b>Raspberry Pi</b> .  Na realidade, apenas o RPi4 tem o desempenho para redes neurais.  Mas algumas tarefas separadas podem ser realizadas na terceira geração.  Eu até criei grades muito simples no começo. </li><li>  <b>Google Coral</b> Platform.  De fato, para dispositivos de incorporação, há apenas um chip e dois dispositivos - Dev Board e USB Accelerator </li><li>  Plataforma <b>Intel Movidius</b> .  Se você não é uma empresa grande, apenas os bastões Movidius 1 | Movidius 2 estarão disponíveis para você. </li><li>  Plataforma <b>Gyrfalcone</b> .  O milagre da tecnologia chinesa.  Já existem duas gerações - 2801, 2803 </li></ol><br><br>  Misc.  Falaremos sobre eles após as principais comparações: <br><ol><li>  Processadores Intel.  Primeiro de tudo, assembléias NUC. </li><li>  GPUs móveis da Nvidia.  Soluções prontas podem ser consideradas não incorporadas.  E se você coletar incorporação, ela resultará decentemente nas finanças. </li><li>  Telefones celulares.  O Android é caracterizado pelo fato de que, para usar o desempenho máximo, é necessário usar exatamente o hardware que um fabricante específico possui.  Ou use algo universal, como luz tensorflow.  Para a Apple, a mesma coisa. </li><li>  O Jetson AGX Xavier é uma versão cara do Jetson com mais desempenho. </li><li>  GAP8 - processadores de baixa potência para dispositivos super baratos. </li><li>  Bosque misterioso AI BONÉ </li></ol><br><br><h2>  Jetson </h2><br>  Trabalhamos com a Jetson há muito tempo.  Em 2014, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">Vasyutka</a> inventou a matemática para o então <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Swift</a> precisamente em Jetson.  Em 2015, em uma reunião com a Artec 3D, conversamos sobre como é uma plataforma bacana, após o que eles sugeriram que construíssemos um protótipo baseado nela.  Depois de alguns meses, o protótipo estava pronto.  Apenas alguns anos de trabalho de toda a empresa, alguns anos de maldições na plataforma e no céu ... E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artec Leo</a> nasceu - o scanner mais legal da sua classe.  Até a Nvidia na apresentação do TX2 o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mostrou</a> como um dos projetos mais interessantes criados na plataforma. <br>  Desde então, o TX1 / TX2 / Nano usamos em algum lugar em 5-6 projetos. <br>  E, provavelmente, conhecemos todos os problemas que estavam com a plataforma.  Vamos tomá-lo em ordem. <br><br><h3>  Jetson tk1 </h3><br>  Eu não vou falar especialmente sobre ele.  A plataforma era muito eficiente em poder de computação em seu dia.  Mas ela não era mercearia.  A NVIDIA vendeu os chips <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TegraTK1</a> que sustentavam a Jetson.  Mas esses chips eram impossíveis de usar para pequenos e médios fabricantes.  Na realidade, apenas o Google / HTC / Xiaomi / Acer / Google poderia fazer algo além da Nvidia.  Todos os outros integrados ao produto ou debugam placas ou saquearam outros dispositivos. <br><br><h3>  Jetson TX1 | TX2 </h3><br>  A Nvidia tirou as conclusões corretas e a próxima geração foi fantástica.  TX1 | TX2, esses não são mais chips, mas um chip no tabuleiro. <br><img width="300" src="https://habrastorage.org/getpro/habr/post_images/c2c/6d4/dec/c2c6d4dec3a41c852c05d055b231bd06.jpg" alt="imagem"><img width="300" src="https://habrastorage.org/getpro/habr/post_images/411/694/e40/411694e401d5c4665e280ab0a6b8a4b6.png" alt="imagem"><br>  Eles são mais caros, mas têm um nível completamente de supermercado.  Uma pequena empresa pode integrá-los em seu produto, este produto é previsível e estável.  Eu pessoalmente vi como 3-4 produtos foram trazidos para a produção - e tudo estava bem. <br>  Vou falar sobre TX2, porque a partir da linha atual é a placa principal. <br>  Mas, é claro, nem todos agradecem a Deus.  O que há de errado: <br><ol><li>  Jetson TX2 é uma plataforma cara.  Na maioria dos produtos, você usará o módulo principal (pelo que entendi, pelo tamanho do lote, o preço será algo entre 200-250 e 350-400 cu cada).  Ele precisa de um CarrierBoard.  Não conheço o mercado atual, mas antes era de 100 a 300 cu  dependendo da configuração.  Bem, além de seu kit para o corpo. </li><li>  O Jetson TX2 não é a plataforma mais rápida.  A seguir, discutiremos velocidades comparativas; mostrarei por que essa não é a melhor opção. </li><li>  É necessário remover muito calor.  Provavelmente isso é verdade para quase todas as plataformas sobre as quais falaremos.  A carcaça deve resolver o problema de dissipação de calor.  Fãs </li><li>  Esta é uma plataforma ruim para pequenas festas.  Muitas centenas de dispositivos - aprox.  Encomendar placas-mãe, desenvolver projetos e embalagens é a norma.  Muitos milhares de dispositivos?  Crie sua placa-mãe - e chique.  Se você precisar de 5-10 - ruim.  Você terá que usar o DevBoard provavelmente.  Eles são grandes, são um pouco nojentos para piscar.  Esta não é uma plataforma pronta para RPi. </li><li>  Suporte técnico ruim da Nvidia.  Ouvi muitos juramentos de que as respostas são respondidas, que são informações secretas ou mensais. </li><li>  Má infraestrutura na Rússia.  É difícil encomendar, leva muito tempo.  Mas, ao mesmo tempo, os revendedores funcionam bem.  Recentemente, deparei com um Jetson nano que queimava no dia do lançamento - alterado sem questionar.  Sam apanhado pelo correio / trouxe um novo.  WAH!  Além disso, ele próprio viu que o escritório de Moscou aconselha bem.  Porém, assim que seu nível de conhecimento não permitir responder à pergunta e exigir uma solicitação ao escritório internacional - eles terão que esperar por respostas por um longo tempo. </li></ol><br><br>  O que é incrível: <br><ol><li>  Muita informação, uma comunidade muito grande. </li><li>  Em torno da Nvidia, existem muitas pequenas empresas que produzem acessórios.  Eles estão abertos a negociações, você pode ajustar a decisão deles.  E CarierBoard, firmware e sistemas de refrigeração. </li><li>  Suporte para todas as estruturas normais (TensorFlow | PyTorch) e suporte completo para todas as redes.  A única conversão que você pode precisar fazer é transferir o código para o TensorRT.  Isso economizará memória, possivelmente acelerará.  Comparado ao que estará em outras plataformas, isso é ridículo. </li><li>  Eu não sei como criar pranchas.  Mas daqueles que fizeram isso pela Nvidia, ouvi dizer que o TX2 é uma boa opção.  Existem manuais que correspondem à realidade. </li><li>  Bom consumo de energia.  Mas tudo o que exatamente "incorporado" estará conosco - o pior :) </li><li>  Pinça na Rússia (explicado acima por que) </li><li>  Ao contrário do movidius |  RPi  Coral  Gyrfalcon é uma GPU real.  Você pode usar nele não apenas grades, mas também algoritmos normais </li></ol><br><br>  Como resultado, essa é uma boa plataforma para você, se você tiver dispositivos de peça, mas, por algum motivo, não poderá entregar um computador completo.  Algo enorme?  Biometria - provavelmente não.  O reconhecimento de número está no limite, dependendo do fluxo.  Dispositivos portáteis com um preço de mais de 5 mil dólares - possível.  Carros - não, é mais fácil colocar uma plataforma mais poderosa um pouco mais cara. <br>  Parece-me que, com o lançamento de uma nova geração de dispositivos baratos, o TX2 morrerá com o tempo. <br><br>  As placas-mãe para Jetson TX1 | TX2 | TX2i e outras são parecidas com esta: <br><img src="https://habrastorage.org/getpro/habr/post_images/05c/ad5/2fc/05cad52fc3ba0b3468b7cea85a2f2552.png" alt="imagem"><br>  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui há</a> mais variações. <br><br><h3>  Jetson nano </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/9af/40b/1d8/9af40b1d8153cf212cbd2f76a533b143.png" alt="imagem"><br>  Jetson Nano é uma coisa muito interessante.  Para a Nvidia, esse é um novo fator de forma que, em termos de revolução, teria que se comparar com o TK1.  Mas os concorrentes já estão se esgotando.  Existem outros dispositivos sobre os quais falaremos.  É 2 vezes mais fraco que o TX2, mas 4 vezes mais barato.  Mais precisamente ... A matemática é complicada.  Jetson Nano na placa demo custa 100 dólares (na Europa).  Mas se você comprar apenas um chip, será mais caro.  E você precisará criá-lo (ainda não há uma placa-mãe para ele).  E Deus não permita que seja duas vezes mais barato em uma grande festa que o TX2. <br>  De fato, a Jetson Nano, em sua base, é um produto de publicidade para institutos / revendedores / amadores, o que deve estimular o interesse e a aplicação comercial.  Por vantagens e desvantagens (cruza parcialmente com TX2): <br><ol><li>  O design é fraco e não é depurado: <br><ul><li>  Superaquece, com uma carga constante periodicamente trava / voa.  Uma empresa familiar tenta resolver todos os problemas há três meses - não dá certo. </li><li>  Eu tenho um queimado quando alimentado por USB.  Ouvi dizer que um amigo tinha uma saída USB queimada e o plugue estava funcionando.  Provavelmente alguns problemas com a alimentação USB. </li><li>  Se você empacotar a placa original, não haverá radiador suficiente da NVIDIA; por exemplo, ele superaquecerá. </li></ul><br></li><li>  A velocidade não é suficiente.  Quase duas vezes menos que TX2 (na realidade, pode ser 1,5, mas depende da tarefa). </li><li>  Muitos dispositivos de 5 a 10 são geralmente muito bons.  50-200 - é difícil, você precisará compensar todos os erros do fabricante, pendurá-lo em seus cães, se precisar adicionar algo como POE, isso vai doer.  Festas maiores.  Hoje não ouvi falar de projetos de sucesso.  Mas parece-me que podem surgir dificuldades como no TK1.  Para ser sincero, gostaria de esperar que o próximo ano seja lançado o Jetson Nano 2, onde essas doenças infantis serão corrigidas. </li><li>  O suporte está ruim, o mesmo que o TX2 </li><li>  Infraestrutura deficiente </li></ol><br><br>  Bom: <br><ol><li>  Orçamento suficiente em comparação com os concorrentes.  Especialmente para pequenas festas.  Preço / desempenho favoráveis </li><li>  Ao contrário do movidius |  RPi  Coral  Gyrfalcon é uma GPU real.  Você pode usar nele não apenas grades, mas também algoritmos normais </li><li>  Basta iniciar qualquer rede (igual ao TX2) </li><li>  Consumo de energia (o mesmo que tx2) </li><li>  Pinça na Rússia (o mesmo que tx2) </li></ol><br><br>  O próprio Nano saiu no início da primavera, em algum lugar de abril / maio, eu o cutuquei ativamente.  Já conseguimos fazer dois projetos neles.  Em geral, os problemas identificados acima.  Como um produto de hobby / produto para pequenos lotes - muito legal.  Mas se ainda é possível arrastar a produção e como fazê-lo, ainda não está claro. <br><br><h3>  Fale sobre a velocidade da Jetson. </h3><br>  Iremos comparar com outros dispositivos muito mais tarde.  Enquanto isso, apenas fale sobre Jetson e velocidade.  Por que a Nvidia está mentindo para nós.  Como otimizar seus projetos. <br>  Abaixo está escrito tudo sobre o TensorRT-5.1.  O TensorRT-6.0.1 foi lançado em 17 de setembro de 2019, todas as instruções devem ser verificadas duas vezes lá. <br>  Vamos supor que acreditamos na Nvidia.  Vamos abrir o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site</a> deles e ver o tempo de inferência do SSD-mobilenet-v2 para 300 * 300: <br><img width="800" src="https://habrastorage.org/getpro/habr/post_images/8bd/9aa/098/8bd9aa098ffe1e06c3b78d9f88f64dab.png" alt="imagem"><br>  Uau, 39FPS (25ms).  Sim, e o código fonte está <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">definido</a> ! <br><br>  Hmm ... Mas por que está escrito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> sobre 46ms? <br><br>  Espere ... E aqui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">eles</a> escrevem que 309 ms são nativos e 72ms são portados ... <br><br><img width="800" src="https://habrastorage.org/getpro/habr/post_images/32f/fd2/526/32ffd25260529f142b84a127c6d7a75c.png" alt="imagem"><br><br>  Onde esta a verdade <br>  A verdade é que todo mundo pensa muito diferente: <br><ol><li>  SSD consiste em duas partes.  Uma parte é o neurônio.  A segunda parte é o pós-processamento do que o neurônio produziu (não supressão máxima) + o pré-processamento do que é carregado na entrada. </li><li>  Como eu disse anteriormente, no Jetson tudo precisa ser convertido para o TensorRT.  Essa é uma estrutura nativa da NVIDIA.  Sem ele, tudo será ruim.  Só há um problema.  Nem tudo é portado para lá, especialmente do TensorFlow.  Globalmente, existem duas abordagens: <br><ul><li>  O Google, percebendo que isso é um problema, lançou para o TensorFlow uma coisa chamada "tf-trt".  De fato, este é um complemento para tf, que permite converter qualquer grade para tensorrt.  As partes que não são suportadas são inferidas na CPU, o restante na GPU. </li><li>  Reescreva todas as camadas / encontre seus análogos </li></ul><br></li></ol><br>  Nos exemplos acima: <br><ul><li>  Nesse link, o tempo de 300ms é o fluxo tensor usual sem otimização. </li><li>  Lá, 72ms é a versão tf-trt.  Lá, todos os nms são essencialmente feitos no processo. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Esta é uma</a> versão para fãs, onde uma pessoa transferiu todos os nms e os escreveu no próprio gpu. </li><li>  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">isso</a> ... Essa NVIDIA decidiu medir todo o desempenho sem pós-processamento, sem mencioná-lo explicitamente em qualquer lugar. </li></ul><br><br>  Você precisa entender por si mesmo que, se fosse o seu neurônio, que ninguém teria convertido antes de você, sem problemas você seria capaz de iniciá-lo a uma velocidade de 72ms.  E a uma velocidade de 46 ms, sentado sobre os manuais e sorsa dia-semana. <br>  Comparado a muitas outras opções, isso é muito bom.  Mas não esqueça que, faça o que fizer - nunca acredite nos benchmarks da NVIDIA! <br><br><h2>  RaspberryPI 4 </h2><br>  Produção? .. E eu ouvi como dezenas de engenheiros começaram a rir da menção das palavras "RPI" e "produção" nas proximidades.  Mas, devo dizer - o RPI ainda é mais estável que o Jetson Nano e o Google Coral.  Mas, é claro, o TX2 perde e, aparentemente, gyrfalcone. <br><img src="https://habrastorage.org/getpro/habr/post_images/667/aa5/dbc/667aa5dbc7be87aeda247492035b3c33.jpg" alt="imagem"><br>  (A imagem é <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> . Parece-me que prender os fãs ao RPi4 é uma diversão folclórica separada.) <br>  Da lista inteira, este é o único dispositivo que não segurei nas mãos / não testei.  Mas ele iniciou neurônios em Rpi, Rpi2, Rpi3 (por exemplo, ele me disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ).  Em geral, o Rpi4, como eu o entendo, difere apenas no desempenho.  Parece-me que os prós e contras da RPi sabem tudo, mas ainda assim.  Contras: <br><br><ol><li>  Por mais que eu não queira, esta não é uma solução de supermercado.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Superaquecimento</a> .  Congelamentos periódicos.  Mas, devido à enorme comunidade, existem centenas de soluções para todos os problemas.  Isso não torna o Rpi bom para milhares de tiragens.  Mas dezenas / centenas - observa wai. </li><li>  Velocidade.  Este é o dispositivo mais lento de todos os principais sobre os quais estamos falando. </li><li>  Quase não há suporte do fabricante.  Este produto é destinado a entusiastas. </li></ol><br>  Prós: <br><br><ol><li>  Preço  Não, é claro, se você mesmo criar o tabuleiro, usando o gyrfalcone poderá torná-lo mais barato em milhares.  Mas provavelmente isso não é realista.  Onde o desempenho do RPi é suficiente - será a solução mais barata. </li><li>  Popularidade.  Quando o Caffe2 foi lançado, havia uma versão para o Rpi no release base.  Tensorflow light?  Claro que funciona.  I.T.D., I.T.P.  O que o fabricante não faz é transferir usuários.  Corri em diferentes RPi, Caffe, Tensorflow e PyTorch, e várias coisas mais raras. </li><li>  Conveniência para pequenas festas / peças.  Basta piscar o pen drive e executar.  Há Wi-Fi a bordo, ao contrário do JetsonNano.  Você pode simplesmente ligá-lo através do PoE (parece que você precisa comprar um adaptador que é vendido ativamente). </li></ol><br><br>  Falaremos sobre a velocidade Rpi no final.  Como o fabricante não postula que seu produto para neurônios, existem poucos parâmetros de referência.  Todo mundo entende que o Rpi não é perfeito em velocidade.  Mas mesmo ele é adequado para algumas tarefas. <br>  Tivemos algumas tarefas de semi-produto que implementamos na Rpi.  A impressão foi agradável. <br><br><h2>  Movidius 2 </h2><br><img width="800" src="https://habrastorage.org/webt/ki/gq/l3/kigql3xgdsddqwgx-iwrjznthpc.jpeg"><br>  A partir daqui e abaixo, não serão processados ​​processadores completos, mas processadores projetados especificamente para redes neurais.  É como se seus pontos fortes e fracos ao mesmo tempo. <br>  Então  Movidius.  A empresa foi comprada pela Intel em 2016.  No segmento que nos interessa, a empresa lançou dois produtos, Movidius e Movidius 2. O segundo é mais rápido, falaremos apenas sobre o segundo. <br>  Não, não é assim.  A conversa não deve começar com o Movidius, mas com o Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenVino</a> .  Eu diria que isso é ideologia.  Mais especificamente, a estrutura.  De fato, esse é um conjunto de neurônios pré-treinados e inferências para eles, otimizados para produtos Intel (processadores, GPUs, computadores especiais).  Integrado ao OpenCV, ao Raspberry Pi, a vários outros apitos e peidos. <br>  A vantagem do OpenVino é que ele possui muitos neurônios.  Primeiro de tudo, os detectores mais famosos.  Neurônios para reconhecimento de pessoas, pessoas, números, letras, poses, etc., etc.  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> ).  E eles são treinados.  Não por conjuntos de dados abertos, mas por conjuntos de dados compilados pela própria Intel.  Eles são muito maiores / mais diversificados e mais abertos.  Eles podem ser reciclados de acordo com os seus casos, e geralmente funcionarão bem. <br>  É possível fazer melhor?  Claro que você pode.  Por exemplo, o reconhecimento dos números que fizemos - funcionou significativamente melhor.  Mas passamos muitos anos desenvolvendo-o e entendendo como torná-lo perfeito.         ,      . <br>  OpenVino, ,   .      .  -   —   .     .  GAN    .   . ,   ,     ,     -   ,    .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,    : <br><img src="https://habrastorage.org/getpro/habr/post_images/103/de3/8ad/103de38adbea7450a4f7888ef135303c.png" alt="imagem"><br>  ,  Intel   OpenVino    .     .  ,       .         —      .    70%       OpenVino. <br>      Movidius    .         .       (    ,   ). <br>     . USB , ,   !!!       USB.  . Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .  -        ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ) <br>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>   .               -.     -         . <br>      ?..       :) <br>  ,   . OpenVino,   ,   ,    (    Computer Vision  ).      : <br><iframe width="560" height="315" src="https://www.youtube.com/embed/ogHrgixuFzg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br> (   AI 2.0,   OpenVino  ). <br><br> ,     .    Movidius 2. : <br><ol><li>    .  Rpi  Jetson Nano.            —  .        .   Third Party ? </li><li>    .     .     . </li><li>    .    . </li><li>     .           USB 3.0 </li><li>    ,        .   -.     .  Movidius      .      . </li></ol><br>  Prós: <br><ol><li>    .        .    . </li><li>  ,   </li><li>  ,    </li></ol><br>         .          —      . <br>      ,     “   20-30   ,     ,  ” —       Movidius. <br>  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>  .      , . <br><img src="https://habrastorage.org/webt/d0/m-/ec/d0m-ecz9npk5f11jwlr0pzxruwi.jpeg" alt="imagem"><br>  <b>UPD</b> <br>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .     .   embedded . PCI-e      .       .   —        200 .. .         … <br><br><h2> Google Coral </h2><br>  Estou desapontado  Não, não há nada que eu não previsse.  Mas estou desapontado que o Google tenha decidido divulgar isso.  Testar é um milagre no começo do verão.  Talvez algo tenha mudado desde então, mas descreverei minha experiência na época. <br>  Configurando ... Para atualizar o Jetson Tk-Tx1-Tx2, você precisava conectá-lo ao computador host e à fonte de alimentação.  E isso foi o suficiente.  Para fazer flash Jetson Nano e RPi, você só precisa enviar a imagem para a unidade flash USB. <br>  E para piscar Coral, você precisa prender três fios na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ordem correta</a> : <br><img src="https://habrastorage.org/webt/de/b4/hs/deb4hsbxm_ra3ajx7_kuoljd0ls.jpeg"><br>  E não tente cometer um erro!  A propósito, há erros / comportamento indescritível no guia.  Provavelmente não vou descrevê-los, já que desde o início do verão eles poderiam ter consertado alguma coisa.  Lembro que, depois de instalar o Mendel, qualquer acesso via ssh foi perdido, incluindo o descrito por eles, e tive que editar manualmente algumas configurações do Linux. <br>  Levei 2-3 horas para concluir este processo. <br>  Ok  Lançado.  Você acha que é fácil executar sua grade nela?  Quase nada :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui está uma</a> lista do que você pode deixar para trás. <br>  Para ser sincero, não cheguei a esse ponto rapidamente.  Passou meio dia.  Na verdade não.  Você não pode fazer o download do modelo do <a href="">repositório TF</a> e executar no dispositivo.  Ou lá é necessário cortar todas as camadas.  Não encontrei instruções. <br>  Então aqui.  É necessário pegar o modelo do repositório de cima.  Não existem muitos (foram adicionados 3 modelos desde o início do verão).  E como treiná-la?  Abrir no TensorFlow em um pipeline padrão?  HAHAHAHAHAHAHAHA.  Claro que não !!! <br>  Você tem um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">contêiner de Doker</a> especial e o modelo treinará apenas nele.  (Provavelmente, você também pode zombar do seu TF ... Mas há instruções, instruções ... que não eram e não parecem ser.) <br>  Baixe / instale / inicie.  O que é ... Por que a GPU está em zero? .. PORQUE O TREINAMENTO ESTÁ NA CPU.  Docker é apenas para ele !!!  Quer mais diversão?  O manual diz "baseado em uma CPU de 6 núcleos com estação de trabalho com memória de 64G".  Parece que isso é apenas um conselho?  Talvez.  Só que agora eu não tinha o suficiente dos meus 8 shows nesse servidor, onde a maioria dos modelos treina.  O treinamento na quarta hora consumia todos.  Um forte sentimento de que eles tinham algo fluindo.  Tentei alguns dias com parâmetros diferentes em máquinas diferentes, o efeito foi um. <br>  Não verifiquei isso antes de publicar o artigo.  Para ser sincero, foi o suficiente para mim uma vez. <br>  O que mais a acrescentar?  Que esse código não gera um modelo?  Para gerá-lo, você deve: <br><br><ol><li>  Contagem de atraso </li><li>  Converta-o para tflite </li><li>  Compile no TPU do Formal Edge.  Graças a Deus agora isso é feito em um computador.  Na primavera, isso só poderia ser feito online.  E lá foi necessário marcar "Não o usarei para o mal / não viole nenhuma lei com esse modelo".  Agora, graças a Deus não há nada disso. </li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/2ef/84d/b88/2ef84db88bcaba5d18a97c23bf5f2605.png" alt="imagem"><br>  Esse é o maior desgosto que experimentei em relação a um produto de TI no ano passado ... <br>  Globalmente, Coral deve ter a mesma ideologia que o OpenVino com o Movidius.  Só agora a Intel está nesse caminho há vários anos.  Com excelentes manuais, suporte e bons produtos ... E o Google.  Bem, é apenas o Google ... <br>  Contras: <br><ol><li>  Este fórum não é uma mercearia no nível do AD.  Eu não ouvi falar sobre a venda de chips =&gt; a produção não é realista </li><li>  O nível de desenvolvimento é o mais terrível possível.  Tudo bazhet.  O pipeline de desenvolvimento não se encaixa nos esquemas tradicionais. </li><li>  O fã.  No "chip energeticamente ótimo", eles colocam.  Ok, não vou mais falar sobre produção. </li><li>  Custo.  Mais caro que o TX2. </li><li>  Duas grades <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">não podem ser</a> mantidas na memória ao mesmo tempo.  É necessário realizar o upload-download.  O que diminui a inferência de várias redes. </li></ol><br>  Prós: <br><ol><li>  De tudo o que falamos, Coral é o mais rápido </li><li>  Potencialmente, se o chip é ativado, é mais produtivo que o Movidius.  E parece que sua arquitetura é mais justificada para os neurônios. </li></ol><br><br><h2>  Gyrfalcon </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/640/86e/595/64086e5959ce67c2a21dc80c3106e49d.png" alt="imagem"><br>  Os últimos anos e meio têm falado sobre esta besta chinesa.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Há</a> um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ano,</a> eu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estava</a> dizendo algo sobre ele.  Mas falar é uma coisa, e dar informação é outra.  Conversei com 3 a 4 grandes empresas, onde os gerentes / diretores de projetos me disseram como esse Girfalkon era legal.  Mas eles não tinham nenhuma documentação.  E eles não o viram vivo.  O <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site</a> quase não <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">possui</a> informações.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Faça</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">download</a> do site pelo menos algo que só pode ser parceiro (desenvolvedor de hardware).  Além disso, as informações no site são muito contraditórias.  Em um lugar, eles escrevem que suportam apenas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VGG</a> , em outro, que apenas seus neurônios são baseados na GNet (que, de acordo com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">suas garantias, são</a> muito pequenos e realmente sem perda de precisão).  No terceiro está escrito que tudo é convertido com TF | Caffe | PyTorch, e no quarto está escrito sobre o telefone celular e outros encantos. <br>  Compreender a verdade é quase impossível.  Uma vez eu estava cavando e cavando alguns vídeos nos quais pelo menos alguns números escorregam: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/AoidCoMK8v0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eS6eCAEL_1A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Se isso for verdade, significa SSD (no celular?) Abaixo de 224 * 224 no chip GTI2801, eles têm ~ 60ms, o que é bastante comparável ao movidius. <br>  Parece que eles têm um chip 2803 muito mais rápido, mas as informações sobre ele são ainda menos: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/yQvVqaVZUQ4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Neste verão, temos uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">prancha</a> de vaga-lume em nossas mãos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este</a> módulo é instalado lá para cálculos). <br><br>  Havia uma esperança de que finalmente veríamos vivos.  Mas não deu certo.  O quadro estava visível, mas não funcionou.  Rastreando frases individuais em inglês na documentação chinesa, eles quase entenderam qual era o problema (o sistema serrilhado inicial não suportava o módulo neural, era necessário reconstruir e refazer tudo nós mesmos).  Mas simplesmente não deu certo e já havia suspeitas de que o conselho não se encaixaria em nossa tarefa (2 GB de RAM é muito pequeno para redes neurais + sistemas. Além disso, não havia suporte para duas redes ao mesmo tempo). <br>  Mas eu consegui ver a documentação original.  A partir disso, pouco se entende (chinês).  Para o bem, era necessário testar e olhar a fonte. <br>  O suporte técnico da RockChip marcou estupidamente em nós. <br>  Apesar desse horror, é claro para mim que aqui, mesmo assim, os batentes do RockChip estão aqui antes de tudo.  E tenho uma esperança de que, em um quadro normal, o Gyrfalcon possa ser bastante usado.  Mas, devido à falta de informações, é difícil para mim dizer. <br><br>  Contras: <br><ol><li>  Não há vendas abertas, apenas interaja com empresas </li><li>  Pouca informação, nenhuma comunidade.  As informações existentes costumam estar em chinês.  Os recursos da plataforma não podem ser previstos com antecedência </li><li>  Provavelmente, a inferência não é mais do que uma rede por vez. </li><li>  Somente os fabricantes de ferro podem interagir com o próprio giroplano.  O restante precisa procurar alguns intermediários / fabricantes de placas. </li></ol><br>  Prós: <br><ol><li>  Pelo que entendi, o preço de um chip girfcon é muito mais barato que o resto.  Mesmo na forma de pen drives. </li><li>  Já existem dispositivos de terceiros com um chip integrado.  Portanto, o desenvolvimento é um pouco mais fácil que o movidius. </li><li>  Eles garantem que existem muitas grades pré-treinadas, a transferência de grades é muito mais fácil do que o Movidius | Coral.  Mas eu não garantiria isso como verdade.  Nós não tivemos sucesso. </li></ol><br>  Em suma, a conclusão é esta: muito pouca informação.  Você não pode apenas se deitar nesta plataforma.  E antes de fazer algo - você precisa fazer uma grande revisão. <br><br><h2>  Velocidades </h2><br>  Eu realmente gosto de como 90% das comparações de dispositivos incorporados reduzem a velocidade nas comparações.  Como você entendeu acima, essa característica é muito arbitrária.  No Jetson Nano, você pode executar neurônios como fluxo tensor puro, usar tensorflow-tensorrt ou usar tensororr puro.  Dispositivos com arquitetura especial de tensores (movidius | coral | gyrfalcone) - podem ser rápidos, mas, em primeiro lugar, podem funcionar apenas com arquiteturas padrão.  Mesmo para o Raspberry Pi, nem tudo é tão simples.  Os neurônios do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">xnor.ai</a> dão uma vez e meia de aceleração.  Mas não sei o quanto são honestos e o que foi ganho ao mudar para int8 ou outras piadas. <br>  Ao mesmo tempo, outra coisa interessante é esse momento.  Quanto mais complexo o neurônio, mais complexo o dispositivo de inferência - mais imprevisível é a aceleração final que pode ser retirada.  Tome um pouco de OpenPose.  Existe uma rede não trivial, pós-processamento complexo.  Isso e aquilo podem ser otimizados devido a: <br><br><ul><li>  Migração de pós-processamento de GPU </li><li>  Otimize o pós-processamento </li><li>  Otimização de rede neural para recursos da plataforma, por exemplo: <br><ul><li>  Usando redes otimizadas para plataforma </li><li>  Usando módulos de rede para a plataforma </li></ul><br></li><li>  Portando para Int8 | Int16 | Binarização </li><li>  Usando várias calculadoras (GPU | CPU | etc.).  Lembro que no Jetson TX1 uma vez aceleramos bem quando transferimos toda a funcionalidade relacionada ao streaming de vídeo para os aceleradores internos para esse fim.  Banal, mas a rede acelerou.  Ao balancear, muitas combinações interessantes aparecem </li></ul><br>  Às vezes, alguém tenta avaliar algo para todas as combinações possíveis.  Mas realmente, como me parece, isso é inútil.  Primeiro você precisa decidir sobre a plataforma e só então tentar extrair completamente tudo o que é possível. <br><br>  Por que eu sou tudo isso?  Além disso, o teste " <i>quanto tempo o MobileNet</i> " é um teste muito ruim.  Ele pode dizer que a plataforma X é ideal.  Mas quando você tenta implantar seu neurônio e pós-processamento lá, pode ficar muito decepcionado. <br>  Mas comparar o mobilnet'ov ainda fornece algumas informações sobre a plataforma.  Para tarefas simples.  Para situações em que você entende que de qualquer maneira é mais fácil reduzir a tarefa para abordagens padrão.  Quando você deseja avaliar a velocidade da calculadora. <br>  A tabela abaixo é retirada de vários lugares: <br><ul><li>  Estes estudos são: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">3</a> </li><li>  Para SSD, existe esse parâmetro "número de classes de saída".  E a partir deste parâmetro, a taxa de inferência pode variar bastante.  Tentei escolher estudos com o mesmo número de aulas.  Mas isso pode não ser o caso em todos os lugares. </li><li>  Nossa experiência com o TensorRT.  Eu sabia que tipos funcionam e quais não. </li><li>  Para o gyrfalcon, esses vídeos são baseados no fato de que o mobilnet v2 existe + uma estimativa de quanto a área muda.  Este vídeo diz que 2803 pode ser 3-4 vezes mais rápido.  Mas para 2803 não há classificações de SSD.  Em geral, eu duvido muito das velocidades neste momento. </li><li>  Tentei escolher o estudo que deu a velocidade máxima real (não peguei a versão da Nvidia sem o NMS, por exemplo) </li><li>  Para a Jetson TX2, usei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">essas</a> classificações, mas existem 5 classes, no mesmo número de classes em que o restante será mais lento.  De alguma forma, descobri pela experiência / comparação com o Nano nos núcleos o que deveria estar lá </li><li>  Não levei em conta piadas com taxa de bits.  Não sei em que testemunha Movidius e Gyrfalcon trabalharam. </li></ul><br>  Como resultado, temos: <br><img src="https://habrastorage.org/webt/it/eb/z7/itebz7bgvqmgcupodynat7rr0hy.png"><br><br><h2>  Comparação de plataformas </h2><br>  Vou tentar trazer tudo o que eu disse acima para uma única tabela.  Eu destaquei em amarelo aqueles lugares onde meu conhecimento não é suficiente para chegar a uma conclusão inequívoca.  E, na verdade, 1-6 - essa é uma avaliação comparativa das plataformas.  Quanto mais próximo de 1, melhor. <br><img src="https://habrastorage.org/webt/6s/nm/xh/6snmxh9kx7xaufpayljpzvrfoaw.png"><br>  Eu sei que o consumo de energia é crítico para muitos.  Mas parece-me que tudo aqui é um tanto ambíguo, e eu entendo isso muito mal - então não entrei.  Além disso, a própria ideologia parece ser a mesma em todos os lugares. <br><br><h2>  Etapa lateral </h2><br>  O que estávamos falando é apenas um pequeno ponto no vasto espaço de variações do seu sistema.  Provavelmente as palavras comuns que podem caracterizar esta área: <br><ul><li>  Baixo consumo de energia </li><li>  Tamanho pequeno </li><li>  Alto poder de computação </li></ul><br>  Porém, globalmente, se você reduzir a importância de um dos critérios, poderá adicionar muitos outros dispositivos à lista.  Abaixo, vou abordar todas as abordagens que conheci. <br><br><h2>  Intel </h2><br>  Como dissemos quando discutimos o Movidius, a Intel possui uma plataforma OpenVino.  Ele permite um processamento muito eficiente de neurônios nos processadores Intel.  Além disso, a plataforma permite que você suporte até todos os tipos de intel-gpu em um chip.  Agora, tenho medo de dizer exatamente que tipo de desempenho existe para quais tarefas.  Mas, pelo que entendi, uma boa pedra com uma GPU a bordo bastante ⅓ fornece um desempenho de 1080.  Para algumas tarefas, pode ser ainda mais rápido. <br><img src="https://habrastorage.org/getpro/habr/post_images/3b3/16a/a09/3b316aa09dd4dcbe22f97e38474f300a.png" alt="imagem"><br>  Nesse caso, o fator de forma, por exemplo, Intel NUC, é bastante compacto.  Bom resfriamento, embalagem, etc.  A velocidade será mais rápida que o Jetson TX2.  Pela disponibilidade / facilidade de compra - muito mais fácil.  A estabilidade da plataforma fora da caixa é maior. <br>  Dois contras - consumo de energia e preço.  O desenvolvimento é um pouco mais complicado. <br><br><h2>  Jetson agx </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/0d7/eb9/4e0/0d7eb94e037d0311f8bf2176b3044329.jpg" alt="imagem"><br>  Este é outro jetson.  Essencialmente a versão mais antiga.  A velocidade é cerca de 2 vezes mais rápida que o Jetson TX2, além de haver suporte para cálculos int8, o que permite que você faça overclock por mais 4 vezes.  A propósito, confira esta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foto</a> da Nvidia: <br><img src="https://habrastorage.org/getpro/habr/post_images/800/c4a/bf1/800c4abf1ed98c8ec84815586c503491.png" alt="imagem"><br>  Eles comparam dois de seus próprios Jetson.  Um no int8, o segundo no int32.  Nem sei o que dizer aqui ... Em suma: "NUNCA ACREDITE NA NVIDIA GRAPHICS". <br>  Apesar do fato de o AGX ser bom - ele não alcança as GPUs normais da Nvidia em termos de poder de computação.  No entanto, em termos de eficiência energética - eles são muito legais.  O principal menos o preço. <br>  Nós mesmos não trabalhamos com eles, por isso é difícil para mim dizer algo mais detalhado, descrever a variedade de tarefas em que elas são as melhores. <br><br><h2>  Nvidia gpu  versão para laptop </h2><br>  Se você remover a restrição estrita de consumo de energia, o Jetson TX2 não parecerá ideal.  Como o AGX.  Geralmente, as pessoas têm medo de usar a GPU na produção.  Pagamento separado, tudo isso. <br>  Mas existem milhões de empresas que oferecem a você montar uma solução personalizada em uma placa.  Geralmente são placas para laptops / minicomputadores.  Ou, no final, assim: <br><img src="https://habrastorage.org/getpro/habr/post_images/ee9/37d/cdf/ee937dcdf590661d003a1b1201d3ce46.png" alt="imagem"><br>  Uma das startups em que trabalho nos últimos 2,5 anos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CherryHome</a> ) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">seguiu</a> esse caminho.  E estamos muito satisfeitos. <br>  Menos, como sempre, o consumo de energia, o que não foi crítico para nós.  Bem, o preço morde um pouco. <br><br><h2>  Telemóveis </h2><br>  Não quero me aprofundar neste tópico.  Para dizer tudo o que há nos telefones celulares modernos para neurônios / quais estruturas / quais hardwares etc., você precisará de mais de um artigo com esse tamanho.  E, levando em conta o fato de que seguimos nessa direção apenas 2-3 vezes, considero-me incompetente para isso.  Então, apenas algumas observações: <br><ol><li>  Existem muitos aceleradores de hardware nos quais os neurônios podem ser otimizados. </li><li>  Não existe uma solução geral que corra bem em todos os lugares.  Agora, há alguma tentativa de tornar o Tensorflow uma solução desse tipo.  Mas, pelo que entendi, ainda não se tornou um. </li><li>  Alguns fabricantes têm suas próprias fazendas especiais.  Ajudamos a otimizar a estrutura do Snapdragon há um ano.  E foi terrível.  A qualidade dos neurônios é muito menor do que em tudo que eu falei hoje.  Não há suporte para 90% das camadas, mesmo as básicas, como "adição". </li><li>  Como não existe python, a inferência de redes é muito estranha, ilógica e inconveniente. </li><li>  Em termos de desempenho, acontece que tudo é muito bom (por exemplo, em alguns iphone). </li></ol><br>  Parece-me que para telefones celulares embutidos não é a melhor solução (a exceção é alguns sistemas de reconhecimento de rosto de baixo orçamento).  Mas vi alguns casos quando eles foram usados ​​como protótipos iniciais. <br><br><h2>  Gap8 </h2><br>  Esteve recentemente em uma conferência de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Usedata</a> .  E um dos relatórios era sobre a inferência de neurônios nas porcentagens mais baratas (GAP8).  E, como se costuma dizer, a necessidade de invenções é astuta.  Na história, um exemplo foi muito rebuscado.  Mas o autor contou como eles foram capazes de obter inferência pessoalmente em cerca de um segundo.  Em uma grade muito simples, essencialmente sem detector.  Por otimizações loucas e longas e economia em partidas. <br>  Eu sempre não gosto de tais tarefas.  Nenhuma pesquisa, apenas sangue. <br>  Mas vale a pena reconhecer que posso imaginar quebra-cabeças em que porcentagens de baixo consumo fornecem um resultado interessante.  Provavelmente não para reconhecimento facial.  Mas em algum lugar onde você pode reconhecer a imagem de entrada em 5 a 10 segundos ... <br><br><h2>  Grove AI HAT </h2><br><img width="400" src="https://habrastorage.org/getpro/habr/post_images/3fa/b99/106/3fab99106dbf03025a9adbb98d7d77d5.jpg" alt="imagem"><br>  Enquanto preparava este artigo, me deparei com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">essa</a> plataforma incorporada.  Há muito pouca informação sobre isso.  Pelo que entendi, zero apoio.  A produtividade também está em zero ... E nem um único teste de velocidade ... <br><br><h2>  Servidor / Reconhecimento Remoto </h2><br>  Toda vez que eles procuram nosso conselho em uma plataforma incorporada, eu quero gritar “corra, seus tolos!”.  É necessário avaliar cuidadosamente a necessidade dessa solução.  Confira outras opções.  Eu sempre recomendo a todos que façam um protótipo com a arquitetura do servidor.  E durante sua operação, você decide se deve implementar um verdadeiro embarcado.  Afinal, incorporado é: <br><ol><li>  Maior tempo de desenvolvimento, geralmente 2-3 vezes. </li><li>  Suporte sofisticado e depuração na produção.  Qualquer desenvolvimento com ML é uma revisão constante, atualização de neurônios, atualizações do sistema.  Incorporado ainda é mais difícil.  Como recarregar o firmware?  E se você já tem acesso a todas as unidades, por que calcular nelas quando pode calcular em um dispositivo? </li><li>  Complexidade do sistema / risco aumentado.  Mais pontos de falha.  Ao mesmo tempo, embora o sistema não funcione como um todo, pode-se não entender: a plataforma é adequada para esta tarefa? </li><li>  Aumento de preço.  Uma coisa é colocar um quadro simples como o nano pi.  E o outro é comprar TX2. </li></ol><br>  Sim, eu sei que existem tarefas em que as decisões do servidor não podem ser tomadas.  Mas, curiosamente, eles são muito menores do que se costuma acreditar. <br><br><h2>  Conclusões </h2><br>  No artigo, tentei ficar sem conclusões óbvias.  É mais uma história sobre o que é agora.  Para tirar conclusões - é necessário investigar em cada caso.  E não apenas plataformas.  Mas a tarefa em si.  Qualquer tarefa pode ser levemente simplificada / levemente modificada / levemente afiada sob o dispositivo. <br>  O problema com este tópico é que o tópico está mudando.  Novos dispositivos / estruturas / abordagens estão chegando.  Por exemplo, se a NVIDIA ativar o suporte int8 ao Jetson Nano amanhã, a situação mudará drasticamente.  Quando escrevo este artigo, não posso ter certeza de que as informações não foram alteradas há dois dias.  Mas espero que meu conto o ajude a navegar melhor em seu próximo projeto. <br>  Seria legal se você tiver informações adicionais / eu perdi algo / disse algo errado - escreva detalhes aqui. <br><br>  ps <br>  Já quando eu terminei de escrever o artigo quase, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">snakers4</a> soltou um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">post</a> recente de seu canal de telegrama Spark em mim, que é quase o mesmo problema com Jetson.  Mas, como escrevi acima, - nas condições de qualquer consumo de energia - eu colocaria algo como zotacs ou IntelNUC.  E como o jetson incorporado não é a pior plataforma. <br><br><img src="https://habrastorage.org/webt/k_/pg/ih/k_pgiheb6cx6kvxxebl4rc_jdei.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt468421/">https://habr.com/ru/post/pt468421/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt468411/index.html">Uma história sobre como resolver o problema de desempenho do Moment.js</a></li>
<li><a href="../pt468413/index.html">Aceleração instagram.com. Parte 2</a></li>
<li><a href="../pt468415/index.html">Por que não 1C?</a></li>
<li><a href="../pt468417/index.html">Lançamento do 3CX v16 Update 3 Beta - chamadas de vídeo no Android e iOS, conexão TLS de troncos SIP</a></li>
<li><a href="../pt468419/index.html">Google Analytics e GDPR: preciso de consentimento do usuário?</a></li>
<li><a href="../pt468423/index.html">Por que o padrão USB teve que ser tão complicado?</a></li>
<li><a href="../pt468427/index.html">Como ser publicado no Google Play em 2019</a></li>
<li><a href="../pt468431/index.html">O resumo de materiais frescos do mundo do front-end da última semana n ° 381 (16 a 22 de setembro de 2019)</a></li>
<li><a href="../pt468435/index.html">Trabalhe com semântica, links e páginas da web de análise: 16 fórmulas úteis do Planilhas Google para profissionais de SEO</a></li>
<li><a href="../pt468437/index.html">Vou reconhecer um amor ... pela forma do canal auditivo. Uma nova maneira de identificar usuários</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
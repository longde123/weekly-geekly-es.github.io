<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>❤️ 🐊 👉🏽 Apache Kafka + Spring Boot: Hallo, Microservices 🤲🏻 😥 👩🏿‍🎓</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! In diesem Beitrag werden wir eine Anwendung auf Spring Boot 2 unter Verwendung von Apache Kafka unter Linux schreiben, von der Installatio...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache Kafka + Spring Boot: Hallo, Microservices</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440400/">  Hallo Habr!  In diesem Beitrag werden wir eine Anwendung auf Spring Boot 2 unter Verwendung von Apache Kafka unter Linux schreiben, von der Installation der JRE bis zu einer funktionierenden Microservice-Anwendung. <br><br>  Kollegen aus der Front-End-Entwicklungsabteilung, die den Artikel gesehen haben, beklagen, dass ich nicht erkläre, was Apache Kafka und Spring Boot sind.  Ich glaube, dass jeder, der ein fertiges Projekt mit den oben genannten Technologien zusammenstellen muss, weiß, was es ist und warum er es braucht.  Wenn für den Leser die Frage nicht untätig ist, hier sind ausgezeichnete Artikel über Habr, was <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Kafka</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spring Boot sind</a> . <br><br>  Wir können auf langwierige Erklärungen zu Kafka, Spring Boot und Linux verzichten und stattdessen den Kafka-Server auf einem Linux-Computer von Grund auf neu ausführen, zwei Microservices schreiben und einen von ihnen Nachrichten an den anderen senden lassen - im Allgemeinen konfigurieren vollständige Microservice-Architektur. <br><br><img src="https://habrastorage.org/webt/5d/p3/ab/5dp3abjx-c62zmfmmtp5tjvbjci.jpeg"><br><br>  Der Beitrag besteht aus zwei Abschnitten.  Im ersten konfigurieren und führen wir Apache Kafka auf einem Linux-Computer aus, im zweiten schreiben wir zwei Microservices in Java. <br><a name="habracut"></a><br>  In dem Startup, in dem ich meine berufliche Laufbahn als Programmierer begann, gab es Microservices auf Kafka, und einer meiner Microservices arbeitete auch mit anderen über Kafka zusammen, aber ich wusste nicht, wie der Server selbst funktionierte, ob er als Anwendung geschrieben wurde oder bereits vollständig verpackt ist Produkt.  Was war meine Überraschung und Enttäuschung, als sich herausstellte, dass Kafka immer noch ein Box-Produkt war und meine Aufgabe nicht nur darin bestand, einen Client in Java zu schreiben (was ich gerne mache), sondern die fertige Anwendung als devOps bereitzustellen (was ich auch tue) hasse es zu tun).  Selbst wenn ich es in weniger als einem Tag auf dem virtuellen Kafka-Server hochfahren könnte, ist dies wirklich recht einfach.  Also. <br><br>  Unsere Anwendung hat die folgende Interaktionsstruktur: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wy/id/y5/wyidy5ttuw6eam5buszy6rb8z0m.jpeg"></div><br>  Am Ende des Beitrags gibt es wie üblich Links zu Git mit Arbeitscode. <br><br><h1>  Stellen Sie Apache Kafka + Zookeeper auf einer virtuellen Maschine bereit </h1><br>  Ich habe versucht, Kafka unter lokalem Linux, auf einer Mohnblume und unter Remote-Linux zu starten.  In zwei Fällen (Linux) gelang es mir recht schnell.  Mit Mohn ist noch nichts passiert.  Deshalb werden wir Kafka unter Linux erhöhen.  Ich habe Ubuntu 18.04 gewählt. <br><br>  Damit Kafka arbeiten kann, braucht sie einen Tierpfleger.  Dazu müssen Sie es herunterladen und ausführen, bevor Sie Kafka starten. <br><br>  Also. <br><br><h4>  0. Installieren Sie JRE </h4><br>  Dies erfolgt mit den folgenden Befehlen: <br><br><pre><code class="bash hljs">sudo apt-get update sudo apt-get install default-jre</code> </pre> <br>  Wenn alles in Ordnung war, können Sie den Befehl eingeben <br><br><pre> <code class="bash hljs">java -version</code> </pre> <br>  und stellen Sie sicher, dass Java installiert ist. <br><br><h4>  1. Laden Sie Zookeeper herunter </h4><br>  Ich mag keine magischen Teams unter Linux, besonders wenn sie nur ein paar Befehle geben und nicht klar ist, was sie tun.  Deshalb werde ich jede Aktion beschreiben - was genau sie tut.  Wir müssen also Zookeeper herunterladen und in einen praktischen Ordner entpacken.  Es ist ratsam, wenn alle Anwendungen im Ordner / opt gespeichert sind, in unserem Fall also / opt / zookeeper. <br><br>  Ich habe den folgenden Befehl verwendet.  Wenn Sie andere Linux-Befehle kennen, mit denen Sie dies Ihrer Meinung nach rassistisch korrekter ausführen können, verwenden Sie sie.  Ich bin ein Entwickler, kein Entwickler, und ich kommuniziere mit Servern auf der Ebene der "Ziege selbst".  Laden Sie also die Anwendung herunter: <br><br><pre> <code class="bash hljs">wget -P /home/xpendence/downloads/ <span class="hljs-string"><span class="hljs-string">"http://apache-mirror.rbc.ru/pub/apache/zookeeper/zookeeper-3.4.12/zookeeper-3.4.12.tar.gz"</span></span></code> </pre> <br>  Die Anwendung wird in den von Ihnen angegebenen Ordner heruntergeladen. Ich habe den Ordner / home / xpendence / downloads erstellt, um dort alle benötigten Anwendungen herunterzuladen. <br><br><h4>  2. Packen Sie Zookeeper aus </h4><br>  Ich habe den Befehl verwendet: <br><br><pre> <code class="bash hljs">tar -xvzf /home/xpendence/downloads/zookeeper-3.4.12.tar.gz</code> </pre> <br>  Dieser Befehl entpackt das Archiv in den Ordner, in dem Sie sich befinden.  Möglicherweise müssen Sie die Anwendung dann an / opt / zookeeper übertragen.  Und Sie können sofort darauf zugreifen und von dort aus das Archiv bereits auspacken. <br><br><h4>  3. Bearbeiten Sie die Einstellungen </h4><br>  Im Ordner / zookeeper / conf / befindet sich eine Datei zoo-sample.cfg. Ich schlage vor, sie in zoo.conf umzubenennen. Diese Datei wird von der JVM beim Start gesucht.  Folgendes sollte dieser Datei am Ende hinzugefügt werden: <br><br><pre> <code class="bash hljs">tickTime=2000 dataDir=/var/zookeeper clientPort=2181</code> </pre> <br>  Erstellen Sie außerdem das Verzeichnis / var / zookeeper. <br><br><h4>  4. Starten Sie Zookeeper </h4><br>  Gehen Sie zum Ordner / opt / zookeeper und starten Sie den Server mit dem folgenden Befehl: <br><br><pre> <code class="bash hljs">bin/zkServer.sh start</code> </pre> <br>  "STARTED" sollte erscheinen. <br><br>  Danach schlage ich vor, zu überprüfen, ob der Server funktioniert.  Wir schreiben: <br><br><pre> <code class="bash hljs">telnet localhost 2181</code> </pre> <br>  Es sollte eine Meldung angezeigt werden, dass die Verbindung erfolgreich war.  Wenn Sie einen schwachen Server haben und die Meldung nicht angezeigt wurde, versuchen Sie es erneut. Selbst wenn STARTED angezeigt wird, beginnt die Anwendung viel später, den Port abzuhören.  Wenn ich das alles auf einem schwachen Server versuchte, passierte es mir jedes Mal.  Wenn alles verbunden ist, geben Sie den Befehl ein <br><br><pre> <code class="bash hljs">ruok</code> </pre> <br>  Was bedeutet es: "Geht es dir gut?"  Der Server sollte antworten: <br><br><pre> <code class="bash hljs">imok ( !)</code> </pre> <br>  und trennen.  Also läuft alles nach Plan.  Wir starten Apache Kafka. <br><br><h4>  5. Erstellen Sie einen Benutzer unter Kafka </h4><br>  Um mit Kafka arbeiten zu können, benötigen wir einen separaten Benutzer. <br><br><pre> <code class="bash hljs">sudo adduser --system --no-create-home --disabled-password --disabled-login kafka</code> </pre> <br><h4>  6. Laden Sie Apache Kafka herunter </h4><br>  Es gibt zwei Verteilungen - Binär und Quellen.  Wir brauchen eine Binärdatei.  Das Archiv mit der Binärdatei ist unterschiedlich groß.  Die Binärdatei wiegt 59 MB und 6,5 MB. <br><br>  Laden Sie die Binärdatei über den folgenden Link in das dortige Verzeichnis herunter: <br><br><pre> <code class="bash hljs">wget -P /home/xpendence/downloads/ <span class="hljs-string"><span class="hljs-string">"http://mirror.linux-ia64.org/apache/kafka/2.1.0/kafka_2.11-2.1.0.tgz"</span></span></code> </pre> <br><h4>  7. Packen Sie Apache Kafka aus </h4><br>  Das Auspacken unterscheidet sich nicht von dem für Zookeeper.  Wir entpacken das Archiv auch in das Verzeichnis / opt und benennen es in kafka um, sodass der Pfad zum Ordner / bin / opt / kafka / bin lautet <br><br><pre> <code class="bash hljs">tar -xvzf /home/xpendence/downloads/kafka_2.11-2.1.0.tgz</code> </pre> <br><h4>  8. Bearbeiten Sie die Einstellungen </h4><br>  Die Einstellungen befinden sich in /opt/kafka/config/server.properties.  Fügen Sie eine Zeile hinzu: <br><br><pre> <code class="bash hljs">delete.topic.enable = <span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br>  Diese Einstellung scheint optional zu sein, sie funktioniert ohne sie.  Mit dieser Einstellung können Sie Themen löschen.  Andernfalls können Sie Themen einfach nicht über die Befehlszeile löschen. <br><br><h4>  9. Wir gewähren Zugriff auf die Benutzer-Kafka-Verzeichnisse Kafka </h4><br><pre> <code class="bash hljs">chown -R kafka:nogroup /opt/kafka chown -R kafka:nogroup /var/lib/kafka</code> </pre> <br><h4>  10. Der lang erwartete Start von Apache Kafka </h4><br>  Wir geben den Befehl ein, nach dem Kafka starten soll: <br><br><pre> <code class="bash hljs">/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties</code> </pre> <br>  Wenn die üblichen Aktionen (Kafka ist in Java und Scala geschrieben) nicht in das Protokoll übernommen wurden, hat alles funktioniert und Sie können unseren Service testen. <br><br><h4>  10.1.  Schwache Serverprobleme </h4><br>  Für Experimente mit Apache Kafka habe ich einen schwachen Server mit einem Kern und 512 MB RAM (für nur 99 Rubel) verwendet, was sich für mich als mehrere Probleme herausstellte. <br><br>  Nicht genügend Speicher.  Natürlich können Sie nicht mit 512 MB übertakten, und der Server konnte Kafka aufgrund von Speichermangel nicht bereitstellen.  Tatsache ist, dass Kafka standardmäßig 1 GB Speicher belegt.  Kein Wunder, dass er vermisst wurde :) <br><br>  Wir gehen zu kafka-server-start.sh, zookeeper-server-start.sh.  Es gibt bereits eine Zeile, die das Gedächtnis reguliert: <br><br><pre> <code class="java hljs">export KAFKA_HEAP_OPTS=<span class="hljs-string"><span class="hljs-string">"-Xmx1G -Xms1G"</span></span></code> </pre> <br>  Ändern Sie es in: <br><br><pre> <code class="java hljs">export KAFKA_HEAP_OPTS=<span class="hljs-string"><span class="hljs-string">"-Xmx256M -Xms128M"</span></span></code> </pre> <br>  Dies reduziert den Appetit von Kafka und ermöglicht es Ihnen, den Server zu starten. <br><br>  Das zweite Problem mit einem schwachen Computer ist der Zeitmangel, um eine Verbindung zu Zookeeper herzustellen.  Standardmäßig sind dies 6 Sekunden.  Wenn das Eisen schwach ist, reicht dies natürlich nicht aus.  In server.properties erhöhen wir die Verbindungszeit zum zukipper: <br><br><pre> <code class="bash hljs">zookeeper.connection.timeout.ms=30000</code> </pre> <br>  Ich habe eine halbe Minute eingestellt. <br><br><h4>  11. Testen Sie den Kafka-Server </h4><br>  Zu diesem Zweck werden wir zwei Terminals eröffnen, auf einem den Produzenten und auf dem anderen den Verbraucher. <br>  Geben Sie in der ersten Konsole eine Zeile ein: <br><br><pre> <code class="bash hljs">/opt/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> /opt/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="hljs-built_in"><span class="hljs-built_in">test</span></span></code> </pre> <br>  Dieses Symbol sollte angezeigt werden und zeigt an, dass der Produzent bereit ist, Spam-Nachrichten zu versenden: <br><br><pre> <code class="bash hljs">&gt;</code> </pre> <br>  Geben Sie in der zweiten Konsole den folgenden Befehl ein: <br><br><pre> <code class="bash hljs">/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --from-beginning</code> </pre> <br>  Wenn Sie nun in die Produzenten-Konsole eingeben und die Eingabetaste drücken, wird diese in der Consumer-Konsole angezeigt. <br><br> <a href="" rel="nofollow"><img src="https://habrastorage.org/webt/k7/uu/kf/k7uukff1u2kyygrgetrnvjnqmmg.png"></a> <br><br>  Wenn Sie auf dem Bildschirm ungefähr dasselbe sehen wie ich - herzlichen Glückwunsch, das Schlimmste ist vorbei! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/n7/rg/lz/n7rglz4s3wvbqzg_chzjjooiazw.jpeg"></div><br>  Jetzt müssen wir nur noch ein paar Clients auf Spring Boot schreiben, die über Apache Kafka miteinander kommunizieren. <br><br><h1>  Schreiben einer Anwendung auf Spring Boot </h1><br>  Wir werden zwei Anwendungen schreiben, die Nachrichten über Apache Kafka austauschen.  Die erste Nachricht heißt kafka-server und enthält sowohl den Produzenten als auch den Konsumenten.  Der zweite wird als Kafka-Tester bezeichnet und ist so konzipiert, dass wir eine Microservice-Architektur haben. <br><br><h3>  Kafka-Server </h3><br>  Für unsere Projekte, die mit dem Spring Initializr erstellt wurden, benötigen wir das Kafka-Modul.  Ich habe Lombok und Web hinzugefügt, aber das ist Geschmackssache. <br><br>  Der Kafka-Client besteht aus zwei Komponenten - dem Produzenten (er sendet Nachrichten an den Kafka-Server) und dem Verbraucher (er hört auf den Kafka-Server und nimmt von dort neue Nachrichten zu den Themen entgegen, die er abonniert hat).  Unsere Aufgabe ist es, beide Komponenten zu schreiben und zum Laufen zu bringen. <br><br>  Verbraucher: <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Configuration</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">KafkaConsumerConfig</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Value</span></span>(<span class="hljs-string"><span class="hljs-string">"${kafka.server}"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String kafkaServer; <span class="hljs-meta"><span class="hljs-meta">@Value</span></span>(<span class="hljs-string"><span class="hljs-string">"${kafka.group.id}"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String kafkaGroupId; <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> KafkaListenerContainerFactory&lt;?&gt; batchFactory() { ConcurrentKafkaListenerContainerFactory&lt;Long, AbstractDto&gt; factory = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); factory.setBatchListener(<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); factory.setMessageConverter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> BatchMessagingMessageConverter(converter())); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> factory; } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> KafkaListenerContainerFactory&lt;?&gt; singleFactory() { ConcurrentKafkaListenerContainerFactory&lt;Long, AbstractDto&gt; factory = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); factory.setBatchListener(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); factory.setMessageConverter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringJsonMessageConverter()); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> factory; } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ConsumerFactory&lt;Long, AbstractDto&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">consumerFactory</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs()); } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> KafkaListenerContainerFactory&lt;?&gt; kafkaListenerContainerFactory() { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ConcurrentKafkaListenerContainerFactory&lt;&gt;(); } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Map&lt;String, Object&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">consumerConfigs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Map&lt;String, Object&gt; props = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashMap&lt;&gt;(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServer); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, LongDeserializer.class); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.GROUP_ID_CONFIG, kafkaGroupId); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> props; } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> StringJsonMessageConverter </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">converter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringJsonMessageConverter(); } }</code> </pre> <br>  Wir benötigen 2 Felder, die mit statischen Daten aus kafka.properties initialisiert wurden. <br><br><pre> <code class="java hljs">kafka.server=localhost:<span class="hljs-number"><span class="hljs-number">9092</span></span> kafka.group.id=server.broadcast</code> </pre> <br>  kafka.server ist die Adresse, an der unser Server hängt, in diesem Fall lokal.  Standardmäßig überwacht Kafka Port 9092. <br><br>  kafka.group.id ist eine Gruppe von Verbrauchern, innerhalb derer eine Instanz der Nachricht zugestellt wird.  Sie haben beispielsweise drei Kuriere in einer Gruppe, die alle dasselbe Thema hören.  Sobald auf dem Server eine neue Nachricht mit diesem Thema angezeigt wird, wird sie an eine Person in der Gruppe gesendet.  Die verbleibenden zwei Verbraucher erhalten die Nachricht nicht. <br><br>  Als nächstes schaffen wir eine Fabrik für Verbraucher - ConsumerFactory. <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ConsumerFactory&lt;Long, AbstractDto&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">consumerFactory</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs()); }</code> </pre> <br>  Initialisiert mit den Eigenschaften, die wir benötigen, wird es in Zukunft als Standardfabrik für Verbraucher dienen. <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Map&lt;String, Object&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">consumerConfigs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Map&lt;String, Object&gt; props = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashMap&lt;&gt;(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServer); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, LongDeserializer.class); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.GROUP_ID_CONFIG, kafkaGroupId); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> props; }</code> </pre> <br>  ConsumerConfigs sind nur Map-Konfigurationen.  Wir stellen die Serveradresse, Gruppe und Deserializer zur Verfügung. <br><br>  Darüber hinaus einer der wichtigsten Punkte für einen Verbraucher.  Der Verbraucher kann sowohl einzelne Objekte als auch Sammlungen empfangen, z. B. StarshipDto und List.  Und wenn wir StarshipDto als JSON erhalten, erhalten wir List grob gesagt als JSON-Array.  Daher haben wir mindestens zwei Nachrichtenfabriken - für einzelne Nachrichten und für Arrays. <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> KafkaListenerContainerFactory&lt;?&gt; singleFactory() { ConcurrentKafkaListenerContainerFactory&lt;Long, AbstractDto&gt; factory = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); factory.setBatchListener(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); factory.setMessageConverter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringJsonMessageConverter()); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> factory; }</code> </pre> <br>  Wir instanziieren ConcurrentKafkaListenerContainerFactory, geben Long (Nachrichtenschlüssel) und AbstractDto (abstrakter Nachrichtenwert) ein und initialisieren seine Felder mit Eigenschaften.  Wir initialisieren die Factory natürlich mit unserer Standard-Factory (die bereits Map-Konfigurationen enthält), markieren dann, dass wir keine Pakete abhören (dieselben Arrays) und geben einen einfachen JSON-Konverter als Konverter an. <br><br>  Wenn wir eine Factory für Pakete / Arrays (Batch) erstellen, besteht der Hauptunterschied (abgesehen von der Tatsache, dass wir markieren, dass wir Pakete abhören) darin, dass wir als Konverter einen speziellen Paketkonverter angeben, der Pakete konvertiert, die aus bestehen von JSON-Strings. <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> KafkaListenerContainerFactory&lt;?&gt; batchFactory() { ConcurrentKafkaListenerContainerFactory&lt;Long, AbstractDto&gt; factory = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); factory.setBatchListener(<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); factory.setMessageConverter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> BatchMessagingMessageConverter(converter())); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> factory; } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> StringJsonMessageConverter </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">converter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringJsonMessageConverter(); }</code> </pre> <br>  Und noch etwas.  Bei der Initialisierung der Spring Beans wird der Bin unter dem Namen kafkaListenerContainerFactory möglicherweise nicht gezählt und die Anwendung wird ruiniert.  Sicher gibt es elegantere Möglichkeiten, um das Problem zu lösen. Schreiben Sie darüber in den Kommentaren. Im Moment habe ich gerade einen Behälter mit Funktionen mit demselben Namen erstellt: <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> KafkaListenerContainerFactory&lt;?&gt; kafkaListenerContainerFactory() { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ConcurrentKafkaListenerContainerFactory&lt;&gt;(); }</code> </pre> <br>  Der Verbraucher ist eingerichtet.  Wir gehen zum Produzenten. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Configuration</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">KafkaProducerConfig</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Value</span></span>(<span class="hljs-string"><span class="hljs-string">"${kafka.server}"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String kafkaServer; <span class="hljs-meta"><span class="hljs-meta">@Value</span></span>(<span class="hljs-string"><span class="hljs-string">"${kafka.producer.id}"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String kafkaProducerId; <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Map&lt;String, Object&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">producerConfigs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Map&lt;String, Object&gt; props = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashMap&lt;&gt;(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServer); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, LongSerializer.class); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class); props.put(ProducerConfig.CLIENT_ID_CONFIG, kafkaProducerId); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> props; } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ProducerFactory&lt;Long, StarshipDto&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">producerStarshipFactory</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DefaultKafkaProducerFactory&lt;&gt;(producerConfigs()); } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> KafkaTemplate&lt;Long, StarshipDto&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kafkaTemplate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ KafkaTemplate&lt;Long, StarshipDto&gt; template = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KafkaTemplate&lt;&gt;(producerStarshipFactory()); template.setMessageConverter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringJsonMessageConverter()); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template; } }</code> </pre> <br>  Von den statischen Variablen benötigen wir die Adresse des Kafka-Servers und die Produzenten-ID.  Er kann alles sein. <br><br>  Wie wir sehen, gibt es in den Konfigurationen nichts Besonderes.  Fast das Gleiche.  In Bezug auf Fabriken gibt es jedoch einen signifikanten Unterschied.  Wir müssen für jede Klasse eine Vorlage registrieren, deren Objekte wir an den Server senden, sowie eine Factory dafür.  Wir haben ein solches Paar, aber es kann Dutzende von ihnen geben. <br><br>  In der Vorlage markieren wir, dass wir Objekte in JSON serialisieren, und dies ist möglicherweise ausreichend. <br><br>  Wir haben einen Verbraucher und einen Produzenten. Es bleibt ein Dienst zu schreiben, der Nachrichten sendet und empfängt. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-meta"><span class="hljs-meta">@Slf</span></span>4j <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">StarshipServiceImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">StarshipService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> KafkaTemplate&lt;Long, StarshipDto&gt; kafkaStarshipTemplate; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> ObjectMapper objectMapper; <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">StarshipServiceImpl</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(KafkaTemplate&lt;Long, StarshipDto&gt; kafkaStarshipTemplate, ObjectMapper objectMapper)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.kafkaStarshipTemplate = kafkaStarshipTemplate; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.objectMapper = objectMapper; } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">send</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(StarshipDto dto)</span></span></span><span class="hljs-function"> </span></span>{ kafkaStarshipTemplate.send(<span class="hljs-string"><span class="hljs-string">"server.starship"</span></span>, dto); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-meta"><span class="hljs-meta">@KafkaListener</span></span>(id = <span class="hljs-string"><span class="hljs-string">"Starship"</span></span>, topics = {<span class="hljs-string"><span class="hljs-string">"server.starship"</span></span>}, containerFactory = <span class="hljs-string"><span class="hljs-string">"singleFactory"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">consume</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(StarshipDto dto)</span></span></span><span class="hljs-function"> </span></span>{ log.info(<span class="hljs-string"><span class="hljs-string">"=&gt; consumed {}"</span></span>, writeValueAsString(dto)); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> String </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">writeValueAsString</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(StarshipDto dto)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> objectMapper.writeValueAsString(dto); } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> (JsonProcessingException e) { e.printStackTrace(); <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> RuntimeException(<span class="hljs-string"><span class="hljs-string">"Writing value to JSON failed: "</span></span> + dto.toString()); } } }</code> </pre> <br>  Es gibt nur zwei Methoden in unserem Service, die ausreichen, um die Arbeit des Kunden zu erklären.  Wir verdrahten automatisch die Muster, die wir brauchen: <br><br><pre> <code class="java hljs"> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> KafkaTemplate&lt;Long, StarshipDto&gt; kafkaStarshipTemplate;</code> </pre> <br>  Erzeugermethode: <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">send</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(StarshipDto dto)</span></span></span><span class="hljs-function"> </span></span>{ kafkaStarshipTemplate.send(<span class="hljs-string"><span class="hljs-string">"server.starship"</span></span>, dto); }</code> </pre> <br>  Um eine Nachricht an den Server zu senden, müssen Sie lediglich die Sendemethode für die Vorlage aufrufen und das Thema (Betreff) und unser Objekt dorthin übertragen.  Das Objekt wird in JSON serialisiert und fliegt unter dem angegebenen Thema zum Server. <br><br>  Die Hörmethode sieht folgendermaßen aus: <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-meta"><span class="hljs-meta">@KafkaListener</span></span>(id = <span class="hljs-string"><span class="hljs-string">"Starship"</span></span>, topics = {<span class="hljs-string"><span class="hljs-string">"server.starship"</span></span>}, containerFactory = <span class="hljs-string"><span class="hljs-string">"singleFactory"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">consume</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(StarshipDto dto)</span></span></span><span class="hljs-function"> </span></span>{ log.info(<span class="hljs-string"><span class="hljs-string">"=&gt; consumed {}"</span></span>, writeValueAsString(dto)); }</code> </pre> <br>  Wir kennzeichnen diese Methode mit der Annotation @KafkaListener, in der wir eine beliebige ID, abgehörte Themen und eine Factory angeben, die die empfangene Nachricht in das konvertiert, was wir benötigen.  In diesem Fall benötigen wir eine einzelne Fabrik, da wir ein Objekt akzeptieren.  Geben Sie für Liste &lt;?&gt; BatchFactory an.  Infolgedessen senden wir das Objekt mithilfe der send-Methode an den kafka-Server und rufen es mithilfe der konsum-Methode ab. <br><br>  Sie können in 5 Minuten einen Test schreiben, der die volle Leistung von Kafka demonstriert, aber wir werden noch weiter gehen - verbringen Sie 10 Minuten damit, eine andere Anwendung zu schreiben, die Nachrichten an den Server sendet, den unsere erste Anwendung abhört. <br><br><h2>  Kafka-Tester </h2><br>  Mit der Erfahrung, die erste Anwendung zu schreiben, können wir die zweite leicht schreiben, insbesondere wenn wir das Einfügen und das dto-Paket kopieren, nur den Produzenten registrieren (wir senden nur Nachrichten) und dem Dienst die einzige Sendemethode hinzufügen.  Über den folgenden Link können Sie den Projektcode einfach herunterladen und sicherstellen, dass dort nichts Kompliziertes ist. <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Scheduled</span></span>(initialDelay = <span class="hljs-number"><span class="hljs-number">10000</span></span>, fixedDelay = <span class="hljs-number"><span class="hljs-number">5000</span></span>) <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">produce</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ StarshipDto dto = createDto(); log.info(<span class="hljs-string"><span class="hljs-string">"&lt;= sending {}"</span></span>, writeValueAsString(dto)); kafkaStarshipTemplate.send(<span class="hljs-string"><span class="hljs-string">"server.starship"</span></span>, dto); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> StarshipDto </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createDto</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StarshipDto(<span class="hljs-string"><span class="hljs-string">"Starship "</span></span> + (LocalTime.now().toNanoOfDay() / <span class="hljs-number"><span class="hljs-number">1000000</span></span>)); }</code> </pre> <br>  Nach den ersten 10 Sekunden sendet der Kafka-Tester alle 5 Sekunden Nachrichten mit den Namen der Raumschiffe an den Kafka-Server (das Bild kann angeklickt werden). <br><br> <a href="" rel="nofollow"><img src="https://habrastorage.org/webt/oo/ri/gk/oorigkqltxuntytvhzbarlninhk.png"></a> <br><br>  Dort werden sie vom Kafka-Server abgehört und empfangen (das Bild ist auch anklickbar). <br><br> <a href="" rel="nofollow"><img src="https://habrastorage.org/webt/cs/w-/vc/csw-vcgajjpjymkdxcwibqllnoi.png"></a> <br><br>  Ich hoffe, dass diejenigen, die davon träumen, bei Kafka mit dem Schreiben von Microservices zu beginnen, genauso erfolgreich sein werden wie ich.  Und hier sind die Links zu den Projekten: <br><br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Kafka-Server</a> <br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Kafka-Tester</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440400/">https://habr.com/ru/post/de440400/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440388/index.html">Intervalle: Die bevorstehende C ++ - Evolution</a></li>
<li><a href="../de440390/index.html">Die vielfältige Welt der eingebetteten Systeme und der Platz von Embox darin</a></li>
<li><a href="../de440392/index.html">WebRTC auf Ihrer Website - keine Fehler und kein Budget</a></li>
<li><a href="../de440394/index.html">Eskalation von PostgreSQL-Berechtigungen - CVE-2018-10915-Analyse</a></li>
<li><a href="../de440398/index.html">Geschichte der Teilnahme (und des Sieges) am russischen AI Cup 2018 - CodeBall</a></li>
<li><a href="../de440402/index.html">SearchFace-Entwickler über Algorithmusfunktionen</a></li>
<li><a href="../de440404/index.html">"Informationsarchitektur": Mitap in OZON</a></li>
<li><a href="../de440410/index.html">Auswählen, Zwischenspeichern und Anzeigen von Fotos auf der Karte</a></li>
<li><a href="../de440412/index.html">Zimbra Collaboration Suite und MS Exchange in derselben Domäne</a></li>
<li><a href="../de440414/index.html">Über Linter, Codequalität, Qualität im Allgemeinen und Qualitätsmanagement</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õπüèæ üàπ üî∑ Servez tout üëº ü§∫ üå´Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il n'y a pas si longtemps, dans une galaxie assez √©loign√©e, sur une plan√®te provinciale, il y avait des descendants c√©l√®bres de singes si paresseux qu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Servez tout</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440908/"> Il n'y a pas si longtemps, dans une galaxie assez √©loign√©e, sur une plan√®te provinciale, il y avait des descendants c√©l√®bres de singes si paresseux qu'ils ont d√©cid√© d'inventer l'intelligence artificielle.  "Eh bien, quoi?"  Ils ont pens√©.  C'est bien d'avoir dans les conseillers le <s>surmental un</s> "cerveau" qui pensera pour vous si n√©cessaire, vos probl√®mes peuvent √™tre rapidement r√©solus, et c'est encore mieux qu'une cr√©ature vivante ne pourra jamais le faire ... Et, sans r√©fl√©chir aux cons√©quences, ils ont commenc√© leurs singes Le cerveau invers√© et le processus cognitif sur les blocs de construction se d√©montent.  Ils ont pens√©, pens√© et pens√©, vous ne le croirez pas - un mod√®le de neurone, un algorithme d'apprentissage math√©matique, puis des r√©seaux de neurones avec diff√©rentes topologies ont √©t√© cr√©√©s.  Bien s√ªr, cela n'a pas fonctionn√© pour dire tr√®s bien.  Il y avait beaucoup de lacunes, par rapport √† l'intelligence naturelle, mais un certain nombre de probl√®mes, ces mod√®les nous ont permis de r√©soudre avec une pr√©cision raisonnable.  Et lentement, les comp√©tences num√©ris√©es et s√©rialis√©es ont commenc√© √† appara√Ætre sous la forme de mod√®les de r√©seaux de neurones.  Aujourd'hui, chers amoureux de l'histoire de l'univers, nous aborderons l'organisation et la mise en ≈ìuvre de diverses comp√©tences en intelligence artificielle. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sa/gk/cs/sagkcsc7kookhhmkxeppqvi7zue.jpeg"></div><a name="habracut"></a><br>  La cr√©ation et la formation de mod√®les de r√©seaux de neurones (comp√©tences) sur Habr√© est beaucoup √©crit, donc nous n'en parlerons pas aujourd'hui.  Apr√®s avoir form√© ou re√ßu des comp√©tences en IA s√©rialis√©es, nous nous attendons √† les utiliser dans nos syst√®mes d'information cibles, et ici un probl√®me se pose.  Ce qui fonctionne sur le stand du laboratoire ne peut pas √™tre transf√©r√© √† la production sous sa forme d'origine, il est n√©cessaire de mettre en ≈ìuvre l'int√©gralit√© de la pile technologique associ√©e et m√™me d'apporter des modifications importantes √† la plate-forme cible (il y a, bien s√ªr, des exceptions sous la forme de CoreML, mais c'est un cas sp√©cial et uniquement pour les √©quipements Apple).  De plus, il existe de tr√®s nombreux outils pour d√©velopper et s√©rialiser des mod√®les, est-il vraiment n√©cessaire que chacun d√©veloppe une solution d'int√©gration distincte?  De plus, m√™me en laboratoire, il est souvent n√©cessaire d'obtenir une conclusion rapide du mod√®le, sans attendre le chargement de l'ensemble de la pile de d√©veloppement associ√©e. <br>  √Ä titre de suggestion pour r√©soudre ces probl√®mes, je voudrais vous parler d'un outil open source relativement nouveau, qui, peut-√™tre, vous sera utile lors du d√©veloppement de projets li√©s √† l'IA. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">0Mind</a> (lire ZeroMind) est un serveur de comp√©tences gratuit.  La solution est un serveur d'applications modulaire, universel, facilement extensible avec des √©l√©ments de structure pour servir (sortie hautement accessible) des mod√®les d'apprentissage machine h√©t√©rog√®nes.  Le serveur est laid en Python 3 et utilise Tornado pour le traitement des demandes asynchrones.  Quel que soit le framework d'apprentissage automatique utilis√© pour pr√©parer et s√©rialiser le mod√®le, 0Mind facilite l'utilisation d'une comp√©tence ou d'un groupe de comp√©tences √† l'aide de l'API REST universelle.  En fait, la solution est un serveur Web asynchrone avec une API REST, unifi√©e pour travailler avec des mod√®les de comp√©tence AI, et un ensemble d'adaptateurs pour divers cadres d'apprentissage automatique.  Vous avez peut-√™tre travaill√© avec le service tensorflow - c'est une solution similaire, mais 0Mind n'est pas empil√© tf et peut servir plusieurs mod√®les de frameworks diff√©rents sur le m√™me port.  Ainsi, au lieu d'impl√©menter l'int√©gralit√© de la pile technologique pour d√©river des mod√®les d'IA dans le syst√®me d'information cible, vous pouvez utiliser l'API REST simple et famili√®re √† la comp√©tence qui vous int√©resse, en outre, le mod√®le pr√©par√© reste sur le serveur et ne se retrouve pas dans la distribution de logiciels.  Afin de ne pas confondre √† nouveau avec des termes complexes, nous allons passer √† des exemples d'utilisation et commencer √† lancer des sorts de console. <br><br><h1>  L'installation </h1><br>  Ici, tout est simple: <br><br><pre><code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> git@github.com:MisteryX/0Mind.git 0Mind</code> </pre> <br>  Nous avons maintenant une instance de serveur qui fonctionne.  Installez les d√©pendances: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> 0Mind pip3 install -r requirements.txt</code> </pre><br>  Ou si vous utilisez Conda: <br><br><pre> <code class="bash hljs">conda install --yes --file requirements.txt</code> </pre> <br>  Une mise en garde importante est que le <a href="">serveur prend en charge plusieurs frameworks d'</a> apprentissage automatique et afin de ne pas les ajouter tous en fonction de celui-ci et de ne pas les installer, vous d√©cidez vous-m√™me des frameworks que vous allez charger sur l'h√¥te avec l'instance 0Mind, installez et configurez ces outils ind√©pendamment. <br><br><h1>  Personnalisation </h1><br>  Le point d'entr√©e ou l'ex√©cutable du serveur principal est <b>model_pool.py</b> . <br>  Les options de d√©marrage possibles sont <b>-c</b> ou <b>--config_file</b> avec le chemin d'acc√®s au fichier de configuration.  Par d√©faut, 0Mind utilise le fichier <b>configs / model_pool_config.json</b> comme fichier de configuration.  Le serveur utilise √©galement le <b>fichier config / logger.json</b> pour contr√¥ler la journalisation standard du module de journalisation Python. <br><br>  Dans le but de d√©montrer les capacit√©s, nous pouvons laisser le fichier de configuration par d√©faut intact.  En savoir plus sur la configuration dans la <a href="">documentation officielle</a> . <br><br>  Les principaux param√®tres du serveur sont: id, h√¥te, port, t√¢ches. <br><br>  <b>id</b> - (num√©ro) identifiant unique du pool de mod√®les (utilis√© pour l'√©quilibrage et l'adressage dans un r√©seau distribu√© de pools) <br>  <b>h√¥te</b> - (cha√Æne) adresse r√©seau ou nom de domaine de cet h√¥te <br>  <b>port</b> - (num√©ro) sur quel port souhaitez-vous h√©berger le service 0Mind (devrait √™tre libre sur cet h√¥te) <br>  <b>t√¢ches</b> - (liste d'objets) une liste de t√¢ches charg√©es avec le service (peut √™tre vide).  Dans la configuration par d√©faut, le mod√®le de d√©monstration CNN_MNIST pr√©par√© par Keras est charg√©, et nous l'utiliserons pour d√©montrer les capacit√©s. <br><br>  Param√®tres de configuration suppl√©mentaires (facultatifs): <br><br>  <b>model_types</b> - (liste de cha√Ænes), vous pouvez limiter les types de mod√®les charg√©s √† ce pool en les sp√©cifiant dans cette liste.  Si la liste est vide, il n'y a aucune restriction. <br><br>  <b>debug</b> - (type bool√©en) est charg√© d'activer ou de d√©sactiver le mode de d√©bogage de Tornado.  En mode d√©bogage, en cas d'erreurs, les informations d'erreur √©tendues sont renvoy√©es √† stdout, ce qui est utile lors du d√©veloppement d'extensions. <br><br><h1>  Les possibilit√©s </h1><br>  L'essentiel dans 0Mind est la <a href="">liste des frameworks pris en charge</a> et les <a href="">fonctionnalit√©s de l'API REST</a> . <br><br>  Les demandes √† l'API REST peuvent √™tre effectu√©es √† l'aide d'un navigateur ou d'utilitaires http.  Dans ce guide, ainsi que dans la documentation du serveur, nous utiliserons cURL comme l'outil le plus simple et le plus abordable pour les syst√®mes ouverts. <br><br>  Actuellement, l'API 0Mind a un total de 10 demandes: <br><br>  1. http: // $ HOST: $ PORT / info - informations g√©n√©rales sur l'instance 0Mind <br>  2. http: // $ HOST: $ PORT / info / system - informations syst√®me sur l'h√¥te sur lequel 0Mind s'ex√©cute <br>  3. http: // $ HOST: $ PORT / info / task - informations sur la t√¢che sp√©cifi√©e <br>  4. http: // $ HOST: $ PORT / info / tasks - liste des t√¢ches de l'instance 0Mind <br>  5. http: // $ HOST: $ PORT / model / list - une liste d'identifiants des mod√®les charg√©s dans le pool <br>  6. http: // $ HOST: $ PORT / model / info - affiche les informations d'interface sur le mod√®le <br>  7. http: // $ HOST: $ PORT / model / load - t√©l√©charge un nouveau mod√®le dans le pool <br>  8. http: // $ HOST: $ PORT / model / drop - d√©charge un mod√®le pr√©c√©demment charg√© du pool <br>  9. http: // $ HOST: $ PORT / mod√®le / pr√©dire - demande la sortie du mod√®le <br>  10.http: // $ HOST: $ PORT / command / stop - arr√™te le service 0Mind et termine son processus <br><br><h2>  L'information </h2><br>  Vous pouvez d√©marrer une instance de serveur, par exemple, comme ceci: <br><br><pre> <code class="bash hljs">python3 model_pool.py</code> </pre> <br>  Par exemple, nous obtiendrons des informations g√©n√©rales sur une instance de serveur en cours d'ex√©cution: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"service"</span></span>: <span class="hljs-string"><span class="hljs-string">"ModelPool"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"options"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"debug"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>}, <span class="hljs-attr"><span class="hljs-attr">"version"</span></span>: [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>]}</code> </pre> <br>  Ok, maintenant nous d√©couvrons quels mod√®les sont charg√©s dans le pool: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/list</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"check_sum"</span></span>: <span class="hljs-string"><span class="hljs-string">"4d8a15e3cc35750f016ce15a43937620"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"models"</span></span>: [<span class="hljs-string"><span class="hljs-string">"1"</span></span>]}</code> </pre> <br>  Clarifions maintenant l'interface du mod√®le charg√© avec l'identifiant ¬´1¬ª: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/info?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"inputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"conv2d_1_input:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"outputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"dense_2/Softmax:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"tool"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>}</code> </pre> <br>  Reste √† savoir avec quels filtres le mod√®le est charg√©.  Pour ce faire, nous clarifions les d√©tails de la t√¢che de chargement du mod√®le avec l'identifiant "1": <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info/task?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_file"</span></span>: <span class="hljs-string"><span class="hljs-string">"ML/models/mnist_cnn_model.keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_type"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"input_filters"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"conv2d_1_input:0"</span></span>: [<span class="hljs-string"><span class="hljs-string">"i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"output_filters"</span></span>: {}}</code> </pre> <br>  Comme vous pouvez le voir, notre mod√®le a un filtre d'entr√©e - i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter et il filtre l'entr√©e avec le nom - conv2d_1_input: 0.  Ce filtre convertit simplement le fichier image sp√©cifi√© en un tenseur et le met √† l'√©chelle en fonction de l'entr√©e du mod√®le.  <a href="">Les filtres</a> sont un autre excellent outil g√©n√©ralis√© de 0Mind.  √âtant donn√© que le pr√©traitement et le post-traitement des donn√©es pour les mod√®les sont identiques, vous pouvez simplement accumuler ces filtres pour une utilisation rapide dans d'autres travaux avec d'autres mod√®les, en indiquant la t√¢che souhait√©e comme attribut pour charger le mod√®le. <br><br><h2>  Sortie de donn√©es du mod√®le (inf√©rence) </h2><br>  Eh bien, maintenant que nous avons toutes les informations n√©cessaires pour l'inf√©rence, nous pouvons tirer une conclusion du mod√®le.  En entr√©e, nous utilisons l'image de la suite de tests incluse dans la distribution 0Mind <b>samples / image5.png</b> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=1</code> </pre> <br>  La seule entr√©e du mod√®le conv2d_1_input: 0 avec le filtre i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter est les donn√©es au format accept√© par le filtre - [{"image_file": "samples / image5.png"}].  En r√©ponse de 0Mind, nous obtenons la sortie du mod√®le: <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2/Softmax:0"</span></span>: [[<span class="hljs-number"><span class="hljs-number">2.190017217283827e-21</span></span>, <span class="hljs-number"><span class="hljs-number">1.6761866200587505e-11</span></span>, <span class="hljs-number"><span class="hljs-number">2.2447325167271673e-14</span></span>, <span class="hljs-number"><span class="hljs-number">0.00011080023978138342</span></span>, <span class="hljs-number"><span class="hljs-number">1.881280855367115e-17</span></span>, <span class="hljs-number"><span class="hljs-number">0.9998891353607178</span></span>, <span class="hljs-number"><span class="hljs-number">1.6690393796396863e-16</span></span>, <span class="hljs-number"><span class="hljs-number">9.67975005705668e-12</span></span>, <span class="hljs-number"><span class="hljs-number">1.1265206161566871e-13</span></span>, <span class="hljs-number"><span class="hljs-number">2.086113400079359e-13</span></span>]]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.002135753631591797</span></span>}</code> </pre> <br>  Ainsi, la seule sortie du mod√®le ¬´dense_2 / Softmax: 0¬ª (voir les informations sur le mod√®le ci-dessus) nous a donn√© le vecteur de confiance du mod√®le dans la classification de cette image.  Comme vous pouvez le voir, la probabilit√© la plus √©lev√©e est de 0,99 pour une classe avec un indice de 6 (les classes sont des nombres 0-9), ce qui correspond au nombre <b>5</b> .  Ainsi, le mod√®le a r√©ussi √† faire face √† la reconnaissance du manuscrit et a donn√© une conclusion avec une grande confiance.  Le temps d'inf√©rence du mod√®le sur l'h√¥te 0Mind √©tait de 0,002135753631591797 secondes, car  la sortie √©tait sur un CPU x86 normal. <br><br><h2>  Chargement et d√©chargement dynamiques des mod√®les </h2><br>  D√©chargez maintenant notre mod√®le de la piscine: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/drop?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"unload_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.000152587890625</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_released"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>}</code> </pre> <br>  Nous chargeons √† nouveau le m√™me mod√®le, mais maintenant avec un identifiant diff√©rent (¬´nouveau¬ª) et un filtre de sortie du mod√®le io_argmax.ArgMaxFilter, qui d√©rivera tr√®s probablement l'indice du vecteur de confiance du mod√®le.  Nous devrons changer les indices des entr√©es et sorties du mod√®le - cela est d√ª aux caract√©ristiques de Keras: <br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"id": "new", "output_filters": {"dense_2_1/Softmax:0": ["io_argmax.ArgMaxFilter"]}, "model_file": "ML/models/mnist_cnn_model.keras", "input_filters": {"conv2d_1_input_1:0": ["i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"]}, "model_type": "keras"}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/load</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"load_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.45618462562561035</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_consumed"</span></span>: <span class="hljs-number"><span class="hljs-number">16183296</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"new"</span></span>}</code> </pre> <br>  Et maintenant, nous demandons au mod√®le de reconna√Ætre pour nous deux images √† la fois en une seule demande <b>samples / image5.png</b> et <b>samples / image1.png</b> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><div style="text-align:center;"><img src="https://habrastorage.org/webt/bv/ha/79/bvha79zohijfpxiilvn1w12wze4.png"></div><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}, {"image_file": "samples/image1.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=new</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2_1/Softmax:0"</span></span>: [<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.003907206535339355</span></span>}</code> </pre> <br>  Le mod√®le de d√©monstration ne s'est pas encore tromp√©. <br><br><h1>  Extension </h1><br>  √âtendre les capacit√©s de 0Mind n'est pas difficile, gr√¢ce √† son architecture modulaire, l'utilisation d'outils populaires et de bonnes conventions de code dans le projet.  Les principaux vecteurs d'extension peuvent √™tre: <br><br><ol><li>  <a href="">Les adaptateurs</a> sont des classes intercouches pour travailler avec de nouveaux cadres d'apprentissage automatique et de r√©seaux de neurones. </li><li>  <a href="">Les filtres</a> sont des gestionnaires de donn√©es permettant d'entrer et de quitter des mod√®les de comp√©tences. </li><li>  Gestionnaires de demandes - vous permettent d'ajouter de nouvelles fonctionnalit√©s aux demandes et r√©ponses de l'API 0Mind. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440908/">https://habr.com/ru/post/fr440908/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440898/index.html">Marketing de contenu, publicit√© contextuelle, am√©lioration de la conversion: 6 guides de promotion de d√©marrage utiles</a></li>
<li><a href="../fr440900/index.html">REST passion pour 200</a></li>
<li><a href="../fr440902/index.html">La moiti√© du royaume pour l'IA: combien les banques √©conomisent sur l'apprentissage automatique, les r√©seaux de neurones et les robots de discussion</a></li>
<li><a href="../fr440904/index.html">Comparaison des architectures Viper et MVVM: comment appliquer les deux</a></li>
<li><a href="../fr440906/index.html">Webinaire "167-–§–ó. Comment les banques peuvent r√©pondre aux exigences de la Banque centrale en mati√®re de syst√®mes antifraude ¬ª- 26 f√©vrier 2019, 11h00, heure de Moscou</a></li>
<li><a href="../fr440910/index.html">Pourquoi les banques monopolisent-elles la blockchain?</a></li>
<li><a href="../fr440912/index.html">Une telle douleur, une telle douleur, l'infrastructure 1: 0</a></li>
<li><a href="../fr440914/index.html">J'ai perdu confiance dans l'industrie, br√ªl√©, mais le culte de l'outil m'a sauv√©</a></li>
<li><a href="../fr440916/index.html">Rayonnement: unit√©s</a></li>
<li><a href="../fr440918/index.html">Security Week 08: piratage de VFEMail en direct</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
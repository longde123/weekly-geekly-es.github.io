<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘§ğŸ¼ ğŸ§•ğŸ¿ ğŸ’µ Bagaimana Kafka menjadi kenyataan ğŸ™ ğŸ’¢ ğŸ§—ğŸ¾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo, Habr! 


 Saya bekerja di tim Tinkoff, yang sedang mengembangkan pusat notifikasi sendiri. Sebagian besar, saya mengembangkan di Jawa menggunaka...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana Kafka menjadi kenyataan</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/tinkoff/blog/481784/"><p><img src="https://habrastorage.org/webt/d1/z0/m1/d1z0m1b3kvl5hobn4_4nnxuxc3o.png"></p><br><p>  Halo, Habr! </p><br><p>  Saya bekerja di tim Tinkoff, yang sedang mengembangkan pusat notifikasi sendiri.  Sebagian besar, saya mengembangkan di Jawa menggunakan boot Spring dan menyelesaikan berbagai masalah teknis yang muncul dalam proyek. </p><br><p>  Sebagian besar layanan microsoft kami berinteraksi secara asinkron dengan satu sama lain melalui perantara pesan.  Sebelumnya, kami menggunakan IBM MQ sebagai broker, yang tidak lagi menangani beban, tetapi pada saat yang sama memiliki jaminan pengiriman yang tinggi. </p><br><p>  Sebagai pengganti, kami ditawari Apache Kafka, yang memiliki skalabilitas tinggi, tetapi, sayangnya, membutuhkan pendekatan konfigurasi yang hampir terpisah untuk skenario yang berbeda.  Selain itu, setidaknya mekanisme pengiriman sekali, yang bekerja di Kafka secara default, tidak memungkinkan mempertahankan tingkat konsistensi yang diperlukan di luar kotak.  Selanjutnya, saya akan membagikan pengalaman kami dalam mengonfigurasi Kafka, khususnya, saya akan memberi tahu Anda cara mengkonfigurasi dan hidup dengan tepat sekali pengiriman. </p><a name="habracut"></a><br><h2 id="garantirovannaya-dostavka-i-ne-tolko">  Pengiriman terjamin dan banyak lagi </h2><br><p>  Parameter yang akan dibahas nanti akan membantu mencegah sejumlah masalah dengan pengaturan koneksi default.  Tapi pertama-tama, saya ingin memperhatikan satu parameter yang akan memfasilitasi kemungkinan debug. </p><br><p>  <strong>Client.id</strong> untuk Produser dan Konsumen akan membantu dalam hal ini.  Sekilas, Anda dapat menggunakan nama aplikasi sebagai nilai, dan dalam kebanyakan kasus ini akan berfungsi.  Meskipun situasi ketika beberapa Konsumen digunakan dalam aplikasi dan Anda memberi mereka client.id yang sama mengarah ke peringatan berikut: </p><br><pre><code class="java hljs">org.apache.kafka.common.utils.AppInfoParser â€” Error registering AppInfo mbean javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=kafka.test-<span class="hljs-number"><span class="hljs-number">0</span></span></code> </pre> <br><p>  Jika Anda ingin menggunakan JMX dalam aplikasi dengan Kafka, maka ini bisa menjadi masalah.  Untuk kasus ini, yang terbaik adalah menggunakan kombinasi nama aplikasi dan, misalnya, nama topik, sebagai nilai client.id.  Hasil dari konfigurasi kami dapat dilihat pada output dari perintah <strong>kafka-consumer-groups</strong> dari utilitas dari Confluent: </p><br><p><img src="https://habrastorage.org/webt/1e/qh/1z/1eqh1zw485osmsizmx6gu9_d8ne.png"></p><br><p>  Sekarang kita akan menganalisis skenario pengiriman pesan yang dijamin.  Kafka Produser memiliki parameter <strong>acks</strong> yang memungkinkan Anda untuk mengonfigurasi setelah berapa banyak yang mengakui pemimpin gugus perlu mempertimbangkan pesan berhasil direkam.  Parameter ini dapat mengambil nilai-nilai berikut: </p><br><ul><li>  0 - mengakui tidak akan dipertimbangkan. </li><li>  1 - parameter default, hanya diperlukan 1 replika. </li><li>  âˆ’1 - diperlukan pengakuan dari semua replika yang disinkronkan ( <strong>konfigurasi</strong> kluster <strong>min.insync.replicas</strong> ). </li></ul><br><p>  Dapat dilihat dari nilai-nilai di atas bahwa acks sama dengan âˆ’1 memberikan jaminan terkuat bahwa pesan tidak akan hilang. </p><br><p>  Seperti kita ketahui, sistem terdistribusi tidak dapat diandalkan.  Untuk melindungi dari kerusakan sementara, Produser Kafka menyediakan parameter coba lagi yang memungkinkan Anda untuk mengatur jumlah upaya coba lagi selama <strong>delivery.timeout.ms</strong> .  Karena parameter coba lagi default ke Integer.MAX_VALUE (2147483647), jumlah pengiriman ulang pesan dapat disesuaikan dengan mengubah hanya delivery.timeout.ms. </p><br><h2 id="dvizhemsya-k-exactly-once-delivery">  Bergerak menuju tepat sekali pengiriman </h2><br><p>  Pengaturan ini memungkinkan Produser kami untuk mengirimkan pesan dengan jaminan tinggi.  Sekarang mari kita bicara tentang bagaimana menjamin rekaman hanya satu salinan pesan dalam topik Kafka?  Dalam kasus paling sederhana, untuk melakukan ini pada Produser, atur parameter <strong>enable.idempotence</strong> menjadi true.  Idempotency menjamin perekaman hanya satu pesan di partisi tertentu dari satu topik.  Prasyarat untuk mengaktifkan idempotency adalah <strong>acks = all, coba lagi&gt; 0, max.in.flight.requests.per.connection â‰¤ 5</strong> .  Jika parameter ini tidak ditetapkan oleh pengembang, maka nilai-nilai di atas akan secara otomatis ditetapkan. </p><br><p>  Ketika idempotensi diatur, perlu untuk memastikan bahwa pesan yang sama jatuh ke partisi yang sama setiap waktu.  Ini dapat dilakukan dengan mengkonfigurasi kunci dan parameter partisi.class pada Produser.  Mari kita mulai dengan kuncinya.  Untuk setiap pengiriman, harus sama.  Ini mudah dicapai menggunakan pengidentifikasi bisnis apa pun dari pesan aslinya.  Parameter partisier.class memiliki nilai default dari <a href="">DefaultPartitioner</a> .  Dengan strategi partisi ini, perilaku default adalah sebagai berikut: </p><br><ul><li>  Jika partisi tersebut ditentukan secara eksplisit saat mengirim pesan, maka kami menggunakannya. </li><li>  Jika partisi tidak ditentukan, tetapi kunci ditentukan, pilih partisi dengan hash dari tombol. </li><li>  Jika partisi dan kunci tidak ditentukan, pilih partisi pada gilirannya (round-robin). </li></ul><br><p>  Selain itu, menggunakan kunci dan pengiriman idempoten dengan parameter <strong>max.in.flight.requests.per.connection = 1</strong> memberi Anda pemrosesan pesan yang teratur pada Konsumen.  Secara terpisah, perlu diingat bahwa jika kontrol akses dikonfigurasi pada cluster Anda, maka Anda akan memerlukan hak untuk menulis idempoten ke topik. </p><br><p>  Jika Anda tiba-tiba tidak memiliki kemampuan pengiriman idempoten dengan kunci atau logika di sisi Produser membutuhkan pelestarian konsistensi data antara partisi yang berbeda, maka transaksi akan datang untuk menyelamatkan.  Selain itu, menggunakan transaksi berantai, Anda dapat menyinkronkan catatan di Kafka secara kondisional, misalnya, dengan catatan di database.  Untuk memungkinkan pengiriman transaksional ke Produser, perlu memiliki idempotensi, dan secara opsional mengatur <strong>transactional.id</strong> .  Jika kontrol akses dikonfigurasi pada cluster Kafka Anda, maka untuk perekaman transaksional, serta idempoten, Anda akan memerlukan izin menulis, yang dapat diberikan oleh mask menggunakan nilai yang disimpan di transactional.id. </p><br><p>  Secara formal, Anda dapat menggunakan string apa pun, misalnya, nama aplikasi, sebagai pengidentifikasi transaksi.  Tetapi jika Anda menjalankan beberapa instance dari aplikasi yang sama dengan transactional.id yang sama, maka instance yang diluncurkan pertama akan dihentikan dengan kesalahan, karena Kafka akan menganggapnya sebagai proses zombie. </p><br><pre> <code class="java hljs">org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer<span class="hljs-string"><span class="hljs-string">'s transaction has been expired by the broker.</span></span></code> </pre> <br><p>  Untuk mengatasi masalah ini, kami menambahkan akhiran ke nama aplikasi dalam bentuk nama host, yang diperoleh dari variabel lingkungan. </p><br><p>  Produser dikonfigurasi, tetapi transaksi pada Kafka hanya mengontrol ruang lingkup pesan.  Terlepas dari status transaksi, pesan langsung masuk ke dalam topik, tetapi memiliki atribut sistem tambahan. </p><br><p>  Untuk mencegah agar pesan tersebut tidak dibaca oleh Konsumen sebelumnya, ia perlu mengatur parameter <strong>isolation.level</strong> menjadi read_committed.  Konsumen tersebut akan dapat membaca pesan non-transaksional seperti sebelumnya, dan pesan transaksional hanya setelah komit. <br>  Jika Anda menginstal semua pengaturan yang tercantum di atas, maka Anda mengkonfigurasi pengiriman tepat satu kali.  Selamat! </p><br><p>  Namun ada satu lagi nuansa.  Transactional.id, yang kami konfigurasikan di atas, sebenarnya adalah awalan transaksi.  Pada manajer transaksi, nomor seri ditambahkan ke dalamnya.  Identifier yang diterima dikeluarkan pada <strong>transactional.id.expiration.ms</strong> , yang dikonfigurasi pada cluster Kafka dan memiliki nilai default "7 hari".  Jika selama ini aplikasi tidak menerima pesan apa pun, maka ketika Anda mencoba mengirim transaksi berikutnya, Anda akan menerima <strong>InvalidPidMappingException</strong> .  Setelah itu, koordinator transaksi akan mengeluarkan nomor urut baru untuk transaksi selanjutnya.  Namun, pesan tersebut dapat hilang jika InvalidPidMappingException tidak diproses dengan benar. </p><br><h2 id="vmesto-itogov">  Alih-alih total </h2><br><p>  Seperti yang Anda lihat, mengirim pesan ke Kafka saja tidak cukup.  Anda perlu memilih kombinasi parameter dan bersiap untuk membuat perubahan cepat.  Dalam artikel ini saya mencoba untuk menunjukkan pengaturan pengiriman tepat satu kali secara rinci dan menjelaskan beberapa masalah konfigurasi client.id dan transactional.id yang kami temui.  Ringkasan pengaturan Produser dan Konsumen dirangkum di bawah ini. </p><br><p>  Produsen: </p><br><ol><li>  acks = all </li><li>  coba lagi&gt; 0 </li><li>  enable.idempotence = true </li><li>  max.in.flight.requests.per.connection â‰¤ 5 (1 - untuk pengiriman tertib) </li><li>  transactional.id = $ {application-name} - $ {hostname} </li></ol><br><p>  Konsumen: </p><br><ol><li>  isolation.level = read_committed </li></ol><br><p>  Untuk meminimalkan kesalahan dalam aplikasi masa depan, kami membuat wrapper kami di atas konfigurasi pegas, di mana nilai untuk beberapa parameter yang tercantum sudah ditetapkan. </p><br><p>  Dan inilah beberapa bahan untuk studi independen: </p><br><ul><li>  <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98%2B-%2BExactly%2BOnce%2BDelivery%2Band%2BTransactional%2BMessaging">KIP-98 - Tepat Sekali Pengiriman dan Pesan Transaksional</a> </li><li>  <a href="https://kafka.apache.org/documentation/">Deskripsi pengaturan</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id481784/">https://habr.com/ru/post/id481784/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id481774/index.html">Lembar Cheat Keamanan: Penambalan Virtual</a></li>
<li><a href="../id481776/index.html">Layanan 5G dan cloud gaming - uji cara kerjanya di Moskow</a></li>
<li><a href="../id481778/index.html">Analisis malware Skeleton Key</a></li>
<li><a href="../id481780/index.html">MyOffice memiliki lebih dari 200 fitur baru</a></li>
<li><a href="../id481782/index.html">Tentang Masalah Penerjemah Python dan Memikirkan Kembali Bahasa</a></li>
<li><a href="../id481786/index.html">Google mengubur ekstensi IMAP PHP</a></li>
<li><a href="../id481788/index.html">Analisis pemecahan masalah industri nyata (menyelamatkan anak babi dan lainnya)</a></li>
<li><a href="../id481790/index.html">Bagaimana selingkuh mengubah komunitas speedrunner</a></li>
<li><a href="../id481792/index.html">Bagaimana PVS-Studio mengadakan paruh kedua dari konferensi 2019</a></li>
<li><a href="../id481794/index.html">Beckender - seorang psikoterapis: seorang debugger untuk jiwa</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
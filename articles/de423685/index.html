<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¤¥ ğŸ‘ğŸ¿ ğŸ§“ğŸ¾ PostgreSQL-ParallelitÃ¤t: nicht kugelfÃ¶rmig, kein Pferd, nicht im Vakuum ğŸ§™ ğŸ¼ ğŸ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Skalierung eines DBMS ist eine sich stÃ¤ndig weiterentwickelnde Zukunft. DBMS verbessern und skalieren besser auf Hardwareplattformen, wÃ¤hrend die ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>PostgreSQL-ParallelitÃ¤t: nicht kugelfÃ¶rmig, kein Pferd, nicht im Vakuum</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/423685/"><img src="https://habrastorage.org/webt/b0/s3/rq/b0s3rqkffufh7baruji0jc_vbgq.jpeg"><br><br>  Die Skalierung eines DBMS ist eine sich stÃ¤ndig weiterentwickelnde Zukunft.  DBMS verbessern und skalieren besser auf Hardwareplattformen, wÃ¤hrend die Hardwareplattformen selbst die ProduktivitÃ¤t, die Anzahl der Kerne und den Speicher erhÃ¶hen - Achilles holt die SchildkrÃ¶te ein, hat es aber immer noch nicht.  Das Problem der Skalierung von DBMS ist in vollem Gange. <br><br>  Postgres Professional hatte nicht nur theoretisch, sondern auch praktisch ein Problem mit der Skalierung: bei seinen Kunden.  Und mehr als einmal.  Einer dieser FÃ¤lle wird in diesem Artikel behandelt. <br><br>  PostgreSQL lÃ¤sst sich auf NUMA-Systemen gut skalieren, wenn es sich um ein einzelnes Motherboard mit mehreren Prozessoren und mehreren Datenbussen handelt.  Einige Optimierungen kÃ¶nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> .  Es gibt jedoch eine andere Klasse von Systemen, sie haben mehrere Motherboards, deren Datenaustausch Ã¼ber Interconnect erfolgt, wÃ¤hrend eine Instanz des Betriebssystems daran arbeitet, und fÃ¼r den Benutzer sieht dieses Design wie eine einzelne Maschine aus.  Und obwohl solche Systeme formal auch NUMA zugeordnet werden kÃ¶nnen, sind sie im Wesentlichen nÃ¤her an Supercomputern als  Der Zugriff auf den lokalen Speicher des Knotens und der Zugriff auf den Speicher des benachbarten Knotens unterscheiden sich radikal.  Die PostgreSQL-Community ist der Ansicht, dass die einzige Postgres-Instanz, die auf solchen Architekturen ausgefÃ¼hrt wird, eine Problemquelle darstellt, und es gibt noch keinen systematischen LÃ¶sungsansatz. <br><a name="habracut"></a><br>  Dies liegt daran, dass die Softwarearchitektur, die Shared Memory verwendet, grundsÃ¤tzlich darauf ausgelegt ist, dass die Zugriffszeit verschiedener Prozesse auf ihren eigenen und Remote-Speicher mehr oder weniger vergleichbar ist.  Wenn wir mit vielen Knoten arbeiten, rechtfertigt sich die Wette auf gemeinsam genutzten Speicher als schnellen Kommunikationskanal nicht mehr, da es aufgrund der Latenz viel â€billigerâ€œ ist, eine Anforderung zum AusfÃ¼hren einer bestimmten Aktion an den Knoten (Knoten) zu senden, an dem interessante Daten als diese Daten auf dem Bus senden.  Daher sind fÃ¼r Supercomputer und im Allgemeinen Systeme mit vielen Knoten ClusterlÃ¶sungen relevant. <br><br>  Dies bedeutet nicht, dass die Kombination von Mehrknotensystemen und einer typischen Postgres-Shared-Memory-Architektur beendet werden muss.  Wenn Postgres-Prozesse den grÃ¶ÃŸten Teil ihrer Zeit mit komplexen Berechnungen vor Ort verbringen, ist diese Architektur sogar sehr effizient.  In unserer Situation hatte der Client bereits einen leistungsstarken Multi-Node-Server gekauft, und wir mussten die Probleme von PostgreSQL darauf lÃ¶sen. <br><br>  Die Probleme waren jedoch schwerwiegend: Die einfachsten Schreibanforderungen (Ã„ndern mehrerer Feldwerte in einem Datensatz) wurden in einem Zeitraum von mehreren Minuten bis zu einer Stunde ausgefÃ¼hrt.  Wie spÃ¤ter bestÃ¤tigt wurde, zeigten sich diese Probleme gerade aufgrund der groÃŸen Anzahl von Kernen und dementsprechend der radikalen ParallelitÃ¤t bei der AusfÃ¼hrung von Anforderungen mit einem relativ langsamen Austausch zwischen Knoten in ihrer ganzen Pracht. <br><br>  Daher wird sich der Artikel sozusagen fÃ¼r zwei Zwecke herausstellen: <br><br><ul><li>  Erfahrungsaustausch: Was tun, wenn in einem System mit mehreren Knoten die Datenbank ernsthaft verlangsamt wird?  Wo soll ich anfangen, wie kann ich diagnostizieren, wohin ich mich bewegen soll? </li><li>  Beschreiben Sie, wie die Probleme des PostgreSQL-DBMS selbst mit einem hohen Grad an ParallelitÃ¤t gelÃ¶st werden kÃ¶nnen.  EinschlieÃŸlich der Auswirkungen der Ã„nderung des Algorithmus zum Aufheben von Sperren auf die Leistung von PostgreSQL. </li></ul><br><h3>  Server und DB </h3><br>  Das System bestand aus 8 Klingen mit jeweils 2 Sockeln.  Insgesamt mehr als 300 Kerne (ohne Hypertreading).  Ein schneller Reifen (proprietÃ¤re Herstellertechnologie) verbindet die Klingen.  Nicht, dass es sich um einen Supercomputer handelt, aber fÃ¼r eine Instanz des DBMS ist die Konfiguration beeindruckend. <br>  Die Last ist auch ziemlich groÃŸ.  Mehr als 1 Terabyte Daten.  Ãœber 3000 Transaktionen pro Sekunde.  Ãœber 1000 Verbindungen zu Postgres. <br><br>  Nachdem wir begonnen hatten, uns mit den stÃ¼ndlichen Aufnahmeerwartungen zu befassen, war das erste, was wir taten, als Ursache fÃ¼r VerzÃ¶gerungen auf die CD zu schreiben.  Sobald unverstÃ¤ndliche VerzÃ¶gerungen einsetzten, wurden Tests ausschlieÃŸlich mit <code>tmpfs</code> .  Das Bild hat sich nicht verÃ¤ndert.  Die Festplatte hat nichts damit zu tun. <br><br><h3>  Erste Schritte mit Diagnosen: Ansichten </h3><br>  Da die Probleme hÃ¶chstwahrscheinlich auf die starke Konkurrenz von Prozessen zurÃ¼ckzufÃ¼hren sind, die auf dieselben Objekte â€klopfenâ€œ, mÃ¼ssen zunÃ¤chst die Sperren Ã¼berprÃ¼ft werden.  In PostgreSQL gibt es fÃ¼r eine solche PrÃ¼fung die Ansichten <code>pg.catalog.pg_locks</code> und <code>pg_stat_activity</code> .  Die zweite, bereits in Version 9.6, fÃ¼gte Informationen darÃ¼ber hinzu, worauf der Prozess wartet ( <i>Amit Kapila, Ildus Kurbangaliev</i> ) - <code>wait_event_type</code> .  MÃ¶gliche Werte fÃ¼r dieses Feld werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> beschrieben. <br><br>  Aber zuerst zÃ¤hlen: <br><br><pre> <code class="sql hljs">postgres=<span class="hljs-comment"><span class="hljs-comment"># SELECT COUNT(*) FROM pg_locks; count â€”---â€” 88453 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity; count â€”---â€” 1826 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity WHERE state ='active'; count â€”---â€” 1005</span></span></code> </pre> <br>  Das sind reelle Zahlen.  Erreichte bis zu 200.000 Sperren. <br>  Gleichzeitig hingen solche SchlÃ¶sser an der unglÃ¼cklichen Bitte: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_locks <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> pid =<span class="hljs-number"><span class="hljs-number">580707</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>; count | mode â€”<span class="hljs-comment"><span class="hljs-comment">-----+---------------â€” 93 | AccessShareLock 1 | ExclusiveLock</span></span></code> </pre> <br>  Beim Lesen des Puffers verwendet das DBMS beim Schreiben die <code>share</code> - <code>exclusive</code> .  Das heiÃŸt, Schreibsperren machten weniger als 1% aller Anforderungen aus. <br>  In der Ansicht <code>pg_locks</code> sehen <code>pg_locks</code> nicht immer so aus, wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der</a> Benutzerdokumentation beschrieben. <br><br>  Hier ist die Streichholzplatte: <br><br><pre> <code class="plaintext hljs">AccessShareLock = LockTupleKeyShare RowShareLock = LockTupleShare ExclusiveLock = LockTupleNoKeyExclusive AccessExclusiveLock = LockTupleExclusive</code> </pre> <br>  Die Abfrage SELECT mode FROM pg_locks zeigte, dass CREATE INDEX (ohne CONCURRENTLY) auf 234 INSERTs und 390 INSERTs auf die <code>buffer content lock</code> Pufferinhalts warten wÃ¼rde.  Eine mÃ¶gliche LÃ¶sung besteht darin, INSERTs aus verschiedenen Sitzungen so zu â€lehrenâ€œ, dass sie sich in Puffern weniger Ã¼berschneiden. <br><br><h3>  Es ist Zeit, perf zu verwenden </h3><br>  Das Dienstprogramm <b><code>perf</code></b> sammelt viele Diagnoseinformationen.  Im <code>record</code> ... werden Statistiken von Systemereignissen in Dateien geschrieben (standardmÃ¤ÃŸig befinden sie sich in <code>./perf_data</code> ), und im <code>report</code> werden die gesammelten Daten analysiert. Sie kÃ¶nnen beispielsweise Ereignisse filtern, die nur <code>postgres</code> oder eine bestimmte <code>postgres</code> betreffen: <br><br><pre> <code class="plaintext hljs">$ perf record -u postgres  $ perf record -p 76876  ,  $ perf report &gt; ./my_results</code> </pre> <br>  Als Ergebnis werden wir so etwas sehen <br><br><img src="https://habrastorage.org/webt/rn/ta/rv/rntarvj2jticq7glciiqockk3-y.jpeg"><br><br>  Die Verwendung von <code>perf</code> zur Diagnose von PostgreSQL wird beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> sowie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pg-Wiki beschrieben</a> . <br><br>  In unserem Fall gab selbst der einfachste Modus <code>perf top</code> wichtige Informationen - <code>perf top</code> , was natÃ¼rlich im Geiste des <code>top</code> Betriebssystems funktioniert.  Bei <code>perf top</code> wir <code>perf top</code> dass der Prozessor die meiste Zeit in den <code>PinBuffer()</code> sowie in den Funktionen <code>PinBuffer()</code> und <code>LWLockAttemptLock().</code>  . <br><br>  <code>PinBuffer()</code> ist eine Funktion, die den ZÃ¤hler fÃ¼r Verweise auf den Puffer erhÃ¶ht (Zuordnung einer Datenseite zum RAM), dank derer Postgres-Prozesse wissen, welche Puffer herausgedrÃ¼ckt werden kÃ¶nnen und welche nicht. <br><br>  <code>LWLockAttemptLock()</code> - Die <code>LWLock</code> .  <code>LWLock</code> ist eine Art Sperre mit zwei Ebenen von <code>shared</code> und <code>exclusive</code> , ohne <code>deadlock</code> zu definieren. Sperren werden dem <code>shared memory</code> vorab zugewiesen, wartende Prozesse warten in einer Warteschlange. <br><br>  Diese Funktionen wurden bereits in PostgreSQL 9.5 und 9.6 ernsthaft optimiert.  Die darin enthaltenen Spinlocks wurden durch den direkten Einsatz atomarer Operationen ersetzt. <br><br><h3>  Flammengraphen </h3><br>  Ohne sie ist es unmÃ¶glich: Selbst wenn sie nutzlos wÃ¤ren, wÃ¤re es immer noch wert, Ã¼ber sie zu erzÃ¤hlen - sie sind ungewÃ¶hnlich schÃ¶n.  Aber sie sind nÃ¼tzlich.  Hier ist eine Illustration von <code>github</code> , nicht von unserem Fall (weder wir noch der Kunde sind noch bereit, Details <code>github</code> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/75b/909/e8d/75b909e8de5177a48fa7d73f53eff437.svg"><br><br>  Diese schÃ¶nen Bilder zeigen sehr deutlich, was die Prozessorzyklen dauern.  <code>perf</code> kann Daten erfassen, aber das <code>flame graph</code> visualisiert die Daten auf intelligente Weise und erstellt BÃ¤ume basierend auf den gesammelten Anrufstapeln.  Sie kÃ¶nnen hier beispielsweise mehr Ã¼ber die Profilerstellung mit Flammengraphen lesen und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> alles herunterladen, was Sie benÃ¶tigen. <br><br>  In unserem Fall war auf den Flammengraphen eine groÃŸe Menge <code>nestloop</code> sichtbar.  Anscheinend verursachten die JOINs einer groÃŸen Anzahl von Tabellen in zahlreichen gleichzeitigen Leseanforderungen eine groÃŸe Anzahl von <code>access share</code> . <br><br>  Die von <code>perf</code> gesammelten Statistiken zeigen, wohin die Prozessorzyklen gehen.  Und obwohl wir gesehen haben, dass die meiste Prozessorzeit fÃ¼r Sperren vergeht, haben wir nicht gesehen, was genau zu so langen Erwartungen an Sperren fÃ¼hrt, da wir nicht genau sehen, wo Sperrenerwartungen auftreten, weil  CPU-Zeit wird nicht mit Warten verschwendet. <br><br>  Um die Erwartungen selbst zu sehen, kÃ¶nnen Sie eine Anforderung an die Systemansicht <code>pg_stat_activity</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> wait_event_type, wait_event, <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_stat_activity <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> wait_event_type, wait_event;</code> </pre> <br>  enthÃ¼llte, dass: <br><br><pre> <code class="plaintext hljs">LWLockTranche | buffer_content | UPDATE ************* LWLockTranche | buffer_content | INSERT INTO ******** LWLockTranche | buffer_content | \r | | insert into B4_MUTEX | | values (nextval('hib | | returning ID Lock | relation | INSERT INTO B4_***** LWLockTranche | buffer_content | UPDATE ************* Lock | relation | INSERT INTO ******** LWLockTranche | buffer_mapping | INSERT INTO ******** LWLockTranche | buffer_content | \r</code> </pre> <br>  (Die Sternchen hier ersetzen einfach Anforderungsdetails, die wir nicht offenlegen.) <br><br>  Sie kÃ¶nnen die Werte <code>buffer_content</code> (Blockieren des Inhalts von Puffern) und <code>buffer_mapping</code> (Blockieren der Komponenten der Hash-Platte <code>shared_buffers</code> ) <code>shared_buffers</code> . <br><br><h3>  FÃ¼r Hilfe zu gdb </h3><br>  Aber warum gibt es so viele Erwartungen an diese Art von SchlÃ¶ssern?  FÃ¼r detailliertere Informationen zu den Erwartungen musste ich den <code>GDB</code> Debugger verwenden.  Mit <code>GDB</code> wir einen Aufrufstapel spezifischer Prozesse erhalten.  Durch Anwenden von Abtastung, d.h.  Nachdem Sie eine bestimmte Anzahl von zufÃ¤lligen Anrufstapeln gesammelt haben, kÃ¶nnen Sie sich ein Bild davon machen, welche Stapel die lÃ¤ngsten Erwartungen haben. <br><br>  Betrachten Sie den Prozess der Erstellung von Statistiken.  Wir werden die "manuelle" Sammlung von Statistiken betrachten, obwohl im wirklichen Leben spezielle Skripte verwendet werden, die dies automatisch tun. <br><br>  ZunÃ¤chst muss <code>gdb</code> an den PostgreSQL-Prozess angehÃ¤ngt werden.  Suchen Sie dazu die <code>pid</code> Serverprozesses, z. B. von <br><br><pre> <code class="plaintext hljs">$ ps aux | grep postgres</code> </pre> <br>  Nehmen wir an, wir haben gefunden: <br><br><pre> <code class="plaintext hljs">postgres 2025 0.0 0.1 172428 1240 pts/17  S   23  0:00 /usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data</code> </pre> <br>  und fÃ¼gen Sie nun die <code>pid</code> in den Debugger ein: <br><br><pre> <code class="plaintext hljs">igor_le:~$gdb -p 2025</code> </pre> <br>  Sobald wir uns im Debugger befinden, schreiben wir <code>bt</code> [ <code>bt</code> <code>backtrace</code> ] oder <code>where</code> .  Und wir bekommen viele Informationen Ã¼ber diesen Typ: <br><br><pre> <code class="plaintext hljs">(gdb) bt #0 0x00007fbb65d01cd0 in __write_nocancel () from /lib64/libc.so.6 #1 0x00000000007c92f4 in write_pipe_chunks ( data=0x110e6e8 "2018â€06â€01 15:35:38 MSK [524647]: [392â€1] db=bp,user=bp,app=[unknown],client=192.168.70.163 (http://192.168.70.163) LOG: relation 23554 new block 493: 248.389503\n2018â€06â€01 15:35:38 MSK [524647]: [393â€1] db=bp,user=bp,app=["..., len=409, dest=dest@entry=1) at elog.c:3123 #2 0x00000000007cc07b in send_message_to_server_log (edata=0xc6ee60 &lt;errordata&gt;) at elog.c:3024 #3 EmitErrorReport () at elog.c:1479</code> </pre> <br>  Nachdem wir Statistiken gesammelt hatten, einschlieÃŸlich Aufrufstapel aus allen Postgres-Prozessen, die wiederholt zu verschiedenen Zeitpunkten gesammelt wurden, stellten wir fest, dass die <code>buffer partition lock</code> der <code>buffer partition lock</code> innerhalb der <code>buffer partition lock</code> der <code>relation extension lock</code> 3706 Sekunden (ungefÃ¤hr eine Stunde) dauerte, dh ein Teil der Hash-Tabelle des Puffers <code>relation extension lock</code> Manager, der erforderlich war, um den alten Puffer zu ersetzen, um ihn anschlieÃŸend durch einen neuen zu ersetzen, der dem erweiterten Teil der Tabelle entspricht.  Es war auch eine bestimmte Anzahl von Sperren fÃ¼r Pufferinhalte erkennbar, die der Erwartung entsprachen, die Seiten des <code>B-tree</code> Index zum EinfÃ¼gen zu sperren. <br><br><img src="https://habrastorage.org/webt/6c/y6/cw/6cy6cwmfye29jw84dkzoabjlgvg.jpeg"><br><br>  ZunÃ¤chst kamen zwei ErklÃ¤rungen fÃ¼r eine solch ungeheure Wartezeit: <br><br><ul><li>  Jemand anderes nahm dieses <code>LWLock</code> und steckte fest.  Dies ist jedoch unwahrscheinlich.  Weil innerhalb der Pufferpartitionssperre nichts Kompliziertes passiert. </li><li>  Wir haben ein pathologisches Verhalten von <code>LWLock</code> .  Das heiÃŸt, trotz der Tatsache, dass niemand das Schloss zu lange nahm, hielt seine Erwartung unangemessen lange an. </li></ul><br><h3>  Diagnosepflaster und Baumbehandlung </h3><br>  Durch die Reduzierung der Anzahl gleichzeitiger Verbindungen wÃ¼rden wir wahrscheinlich den Strom von Anforderungen an Sperren entladen.  Aber das wÃ¤re wie Kapitulation.  Stattdessen schlug <i>Alexander Korotkov</i> , der Chefarchitekt von Postgres Professional (natÃ¼rlich half er bei der Vorbereitung dieses Artikels), eine Reihe von Patches vor. <br><br>  ZunÃ¤chst war es notwendig, sich ein detaillierteres Bild von der Katastrophe zu machen.  UnabhÃ¤ngig davon, wie gut die fertigen Werkzeuge sind, sind auch Diagnose-Patches aus eigener Herstellung hilfreich. <br><br>  Es wurde ein Patch geschrieben, der eine detaillierte Protokollierung der in der <code>RelationAddExtraBlocks()</code> -Funktion verbrachten Zeit in <code>RelationAddExtraBlocks().</code> hinzufÃ¼gt. Wir finden also heraus, wie viel Zeit in <code>RelationAddExtraBlocks().</code> <br><br>  Und zur UnterstÃ¼tzung von ihm wurde in <code>pg_stat_activity</code> weiterer Patch geschrieben, der darÃ¼ber berichtet, was wir jetzt in <code>relation extension</code> auf die <code>relation extension</code> tun.  Dies wurde folgendermaÃŸen durchgefÃ¼hrt: Wenn die <code>relation</code> erweitert wird, wird <code>application_name</code> zu <code>RelationAddExtraBlocks</code> .  Dieser Prozess wird jetzt bequem mit maximalen Details unter Verwendung von <code>gdb bt</code> und <code>perf</code> analysiert. <br><br>  TatsÃ¤chlich wurden zwei medizinische (und nicht diagnostische) Patches geschrieben.  Der erste Patch hat das Verhalten von <code>Bâ€tree</code> Blattsperren geÃ¤ndert: FrÃ¼her wurde das Blatt bei der Aufforderung zum EinfÃ¼gen als <code>share</code> blockiert und danach <code>exclusive</code> .  Jetzt wird er sofort <code>exclusive</code> .  Jetzt wurde dieser Patch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereits</a> fÃ¼r <b>PostgreSQL 12</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">festgeschrieben</a> .  GlÃ¼cklicherweise erhielt <i>Alexander Korotkov in</i> diesem Jahr den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Status eines Committers</a> - des zweiten PostgreSQL-Committers in Russland und des zweiten im Unternehmen. <br><br>  Der Wert fÃ¼r <code>NUM_BUFFER_PARTITIONS</code> wurde ebenfalls von 128 auf 512 erhÃ¶ht, um die Belastung der Zuordnungssperren zu verringern: Die Puffermanager-Hash-Tabelle wurde in kleinere Teile unterteilt, in der Hoffnung, dass die Belastung fÃ¼r jedes bestimmte Teil verringert wird. <br><br>  Nach dem Anwenden dieses Patches waren die Sperren fÃ¼r den Inhalt der Puffer weg, aber trotz der Zunahme von <code>buffer_mapping</code> blieb <code>NUM_BUFFER_PARTITIONS</code> , <code>buffer_mapping</code> wir erinnern Sie daran, Teile der Puffermanager-Hash-Tabelle zu blockieren: <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping ----â€â€â€--â€â€â€+â€------â€â€â€â€â€â€â€â€â€+â€â€â€------â€â€â€â€â€â€â€+â€â€------â€â€â€ 12549 | 1218 | 0 | 15</code> </pre> <br>  Und selbst das ist nicht viel.  B - Baum ist kein Engpass mehr.  Die <code>heap-</code> Erweiterung trat in den Vordergrund. <br><br><h3>  Behandlung des Gewissens </h3><br>  Als nÃ¤chstes stellte Alexander die folgende Hypothese und LÃ¶sung vor: <br><br>  Wir warten viel Zeit auf die <code>buffer parittion lock</code> wenn wir den <code>buffer parittion lock</code> .  Vielleicht gibt es auf derselben <code>buffer parittion lock</code> eine sehr gefragte Seite, zum Beispiel die Wurzel eines <code>Bâ€tree</code> .  Zu diesem Zeitpunkt gibt es einen kontinuierlichen Fluss von Anforderungen fÃ¼r die <code>shared lock</code> von Leseanforderungen. <br><br>  Die Warteschlange bei <code>LWLock</code> "nicht fair".  Da <code>shared lock</code> so viele wie nÃ¶tig gleichzeitig verwendet werden kÃ¶nnen, werden nachfolgende <code>shared lock</code> ohne Warteschlange Ã¼bergeben, wenn die <code>shared lock</code> bereits aktiviert ist.  Wenn der Strom gemeinsam genutzter Sperren so intensiv ist, dass sich keine â€Fensterâ€œ zwischen ihnen befinden, ist das Warten auf eine <code>exclusive lock</code> fast unendlich. <br><br>  Um dies zu beheben, kÃ¶nnen Sie versuchen, einen Patch fÃ¼r "Gentleman" -Verhalten von SchlÃ¶ssern anzubieten.  Es weckt das Gewissen <code>shared locker</code> und sie stehen ehrlich in der Warteschlange, wenn es bereits ein <code>exclusive lock</code> (interessanterweise haben schwere SchlÃ¶sser - <code>hwlock</code> - keine Probleme mit dem Gewissen: Sie stehen immer ehrlich in der Warteschlange) <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping | reladdextra | inserts&gt;30sec â€â€â€â€â€â€-â€â€â€â€â€+â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€+â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€+â€â€â€â€â€â€â€â€â€â€â€--â€-â€+â€â€â€â€â€â€-â€â€â€â€â€â€+â€â€â€â€------ 173985 | 1802 | 0 | 569 | 0 | 0</code> </pre> <br>  Alles ist gut!  Es gibt keine langen <code>insert</code> .  Obwohl die SchlÃ¶sser an den StÃ¼cken der Hash-Platten erhalten blieben.  Aber was zu tun ist, das sind die Eigenschaften der Reifen unseres kleinen Supercomputers. <br><br>  Dieser Patch wurde auch <a href="">der Community angeboten</a> .  UnabhÃ¤ngig davon, wie sich das Schicksal dieser Patches in der Community entwickelt, hindert nichts sie daran, in die nÃ¤chsten Versionen von <b>Postgres Pro Enterprise zu gelangen</b> , die speziell fÃ¼r Kunden mit stark ausgelasteten Systemen entwickelt wurden. <br><br><h3>  Moral </h3><br>  <code>share</code> leichte <code>share</code> Locks - <code>exclusive</code> BlÃ¶cke, die die Warteschlange Ã¼berspringen - haben das Problem der stÃ¼ndlichen VerzÃ¶gerungen in einem System mit mehreren Knoten gelÃ¶st.  Das Hash-Tag des <code>buffer manager</code> funktionierte nicht, da zu viel Fluss von <code>share lock</code> die Sperren keine Chance hatten, alte Puffer zu ersetzen und neue zu laden.  Probleme mit der Erweiterung des Puffers fÃ¼r die Datenbanktabellen waren nur eine Folge davon.  Zuvor war es mÃ¶glich, den Engpass mit Zugriff auf die <code>B-tree</code> Wurzel zu erweitern. <br><br>  PostgreSQL wurde nicht fÃ¼r NUMA-Architekturen und Supercomputer entwickelt.  Die Anpassung an solche Postgres-Architekturen ist eine groÃŸe Aufgabe, die die koordinierten Anstrengungen vieler Menschen und sogar Unternehmen erfordern wÃ¼rde (und mÃ¶glicherweise erfordern wÃ¼rde).  Die unangenehmen Folgen dieser architektonischen Probleme kÃ¶nnen jedoch gemildert werden.  Und wir mÃ¼ssen: Die Lasttypen, die zu Ã¤hnlichen VerzÃ¶gerungen wie den beschriebenen fÃ¼hrten, sind recht typisch, Ã¤hnliche Notsignale von anderen Orten kommen weiterhin zu uns.  Ã„hnliche Probleme traten frÃ¼her auf - bei Systemen mit weniger Kernen waren nur die Folgen nicht so ungeheuerlich, und die Symptome wurden mit anderen Methoden und anderen Patches behandelt.  Jetzt ist eine andere Medizin erschienen - nicht universell, aber eindeutig nÃ¼tzlich. <br><br>  Wenn PostgreSQL also mit dem Speicher des gesamten Systems als lokal arbeitet, kann kein Hochgeschwindigkeitsbus zwischen Knoten mit der Zugriffszeit auf den lokalen Speicher verglichen werden.  Aufgaben entstehen aufgrund dieser schwierigen, oft dringenden, aber interessanten.  Und die Erfahrung, sie zu lÃ¶sen, ist nicht nur fÃ¼r die Entscheidenden, sondern auch fÃ¼r die gesamte Gemeinschaft nÃ¼tzlich. <br><br><img src="https://habrastorage.org/webt/od/n1/sf/odn1sf_id7l60ezlyo-padxymmi.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de423685/">https://habr.com/ru/post/de423685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de423657/index.html">Ich respektiere die Kapselung nicht oder verwende keine andere Art von Methodentabelle, um schnell private Methoden aufzurufen</a></li>
<li><a href="../de423663/index.html">Wir schreiben einen einfachen Ãœbersetzer in Lisp - III</a></li>
<li><a href="../de423677/index.html">Jetpack-Piloten: Frankie West</a></li>
<li><a href="../de423679/index.html">Eine Aufgabe mit Wolkenkratzer und Eiern - nicht Newtons MÃ¼lleimer?</a></li>
<li><a href="../de423683/index.html">Basierend auf gesundem Menschenverstand: DevOps von Grund auf neu entwickeln</a></li>
<li><a href="../de423687/index.html">HyperX Pulsefire FPS Pro - schneller, gemeiner, erschwinglicher</a></li>
<li><a href="../de423689/index.html">RTOS MAX - kostenlos? Wir planen, eine Lizenz fÃ¼r die kostenlose kommerzielle Nutzung zu erÃ¶ffnen</a></li>
<li><a href="../de423693/index.html">Eine andere MÃ¶glichkeit, Webpack 4 und Codetrennung zu verwenden</a></li>
<li><a href="../de423695/index.html">Wie man vor 40 Jahren mit einer Million Dollar auf einem Bankkonto in den Ruhestand geht</a></li>
<li><a href="../de423697/index.html">EinfÃ¼hrung in Spring Data JDBC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
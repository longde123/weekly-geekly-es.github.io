<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§• üëèüèø üßìüèæ PostgreSQL-Parallelit√§t: nicht kugelf√∂rmig, kein Pferd, nicht im Vakuum üßô üçº üêû</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Skalierung eines DBMS ist eine sich st√§ndig weiterentwickelnde Zukunft. DBMS verbessern und skalieren besser auf Hardwareplattformen, w√§hrend die ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>PostgreSQL-Parallelit√§t: nicht kugelf√∂rmig, kein Pferd, nicht im Vakuum</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/423685/"><img src="https://habrastorage.org/webt/b0/s3/rq/b0s3rqkffufh7baruji0jc_vbgq.jpeg"><br><br>  Die Skalierung eines DBMS ist eine sich st√§ndig weiterentwickelnde Zukunft.  DBMS verbessern und skalieren besser auf Hardwareplattformen, w√§hrend die Hardwareplattformen selbst die Produktivit√§t, die Anzahl der Kerne und den Speicher erh√∂hen - Achilles holt die Schildkr√∂te ein, hat es aber immer noch nicht.  Das Problem der Skalierung von DBMS ist in vollem Gange. <br><br>  Postgres Professional hatte nicht nur theoretisch, sondern auch praktisch ein Problem mit der Skalierung: bei seinen Kunden.  Und mehr als einmal.  Einer dieser F√§lle wird in diesem Artikel behandelt. <br><br>  PostgreSQL l√§sst sich auf NUMA-Systemen gut skalieren, wenn es sich um ein einzelnes Motherboard mit mehreren Prozessoren und mehreren Datenbussen handelt.  Einige Optimierungen k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> .  Es gibt jedoch eine andere Klasse von Systemen, sie haben mehrere Motherboards, deren Datenaustausch √ºber Interconnect erfolgt, w√§hrend eine Instanz des Betriebssystems daran arbeitet, und f√ºr den Benutzer sieht dieses Design wie eine einzelne Maschine aus.  Und obwohl solche Systeme formal auch NUMA zugeordnet werden k√∂nnen, sind sie im Wesentlichen n√§her an Supercomputern als  Der Zugriff auf den lokalen Speicher des Knotens und der Zugriff auf den Speicher des benachbarten Knotens unterscheiden sich radikal.  Die PostgreSQL-Community ist der Ansicht, dass die einzige Postgres-Instanz, die auf solchen Architekturen ausgef√ºhrt wird, eine Problemquelle darstellt, und es gibt noch keinen systematischen L√∂sungsansatz. <br><a name="habracut"></a><br>  Dies liegt daran, dass die Softwarearchitektur, die Shared Memory verwendet, grunds√§tzlich darauf ausgelegt ist, dass die Zugriffszeit verschiedener Prozesse auf ihren eigenen und Remote-Speicher mehr oder weniger vergleichbar ist.  Wenn wir mit vielen Knoten arbeiten, rechtfertigt sich die Wette auf gemeinsam genutzten Speicher als schnellen Kommunikationskanal nicht mehr, da es aufgrund der Latenz viel ‚Äûbilliger‚Äú ist, eine Anforderung zum Ausf√ºhren einer bestimmten Aktion an den Knoten (Knoten) zu senden, an dem interessante Daten als diese Daten auf dem Bus senden.  Daher sind f√ºr Supercomputer und im Allgemeinen Systeme mit vielen Knoten Clusterl√∂sungen relevant. <br><br>  Dies bedeutet nicht, dass die Kombination von Mehrknotensystemen und einer typischen Postgres-Shared-Memory-Architektur beendet werden muss.  Wenn Postgres-Prozesse den gr√∂√üten Teil ihrer Zeit mit komplexen Berechnungen vor Ort verbringen, ist diese Architektur sogar sehr effizient.  In unserer Situation hatte der Client bereits einen leistungsstarken Multi-Node-Server gekauft, und wir mussten die Probleme von PostgreSQL darauf l√∂sen. <br><br>  Die Probleme waren jedoch schwerwiegend: Die einfachsten Schreibanforderungen (√Ñndern mehrerer Feldwerte in einem Datensatz) wurden in einem Zeitraum von mehreren Minuten bis zu einer Stunde ausgef√ºhrt.  Wie sp√§ter best√§tigt wurde, zeigten sich diese Probleme gerade aufgrund der gro√üen Anzahl von Kernen und dementsprechend der radikalen Parallelit√§t bei der Ausf√ºhrung von Anforderungen mit einem relativ langsamen Austausch zwischen Knoten in ihrer ganzen Pracht. <br><br>  Daher wird sich der Artikel sozusagen f√ºr zwei Zwecke herausstellen: <br><br><ul><li>  Erfahrungsaustausch: Was tun, wenn in einem System mit mehreren Knoten die Datenbank ernsthaft verlangsamt wird?  Wo soll ich anfangen, wie kann ich diagnostizieren, wohin ich mich bewegen soll? </li><li>  Beschreiben Sie, wie die Probleme des PostgreSQL-DBMS selbst mit einem hohen Grad an Parallelit√§t gel√∂st werden k√∂nnen.  Einschlie√ülich der Auswirkungen der √Ñnderung des Algorithmus zum Aufheben von Sperren auf die Leistung von PostgreSQL. </li></ul><br><h3>  Server und DB </h3><br>  Das System bestand aus 8 Klingen mit jeweils 2 Sockeln.  Insgesamt mehr als 300 Kerne (ohne Hypertreading).  Ein schneller Reifen (propriet√§re Herstellertechnologie) verbindet die Klingen.  Nicht, dass es sich um einen Supercomputer handelt, aber f√ºr eine Instanz des DBMS ist die Konfiguration beeindruckend. <br>  Die Last ist auch ziemlich gro√ü.  Mehr als 1 Terabyte Daten.  √úber 3000 Transaktionen pro Sekunde.  √úber 1000 Verbindungen zu Postgres. <br><br>  Nachdem wir begonnen hatten, uns mit den st√ºndlichen Aufnahmeerwartungen zu befassen, war das erste, was wir taten, als Ursache f√ºr Verz√∂gerungen auf die CD zu schreiben.  Sobald unverst√§ndliche Verz√∂gerungen einsetzten, wurden Tests ausschlie√ülich mit <code>tmpfs</code> .  Das Bild hat sich nicht ver√§ndert.  Die Festplatte hat nichts damit zu tun. <br><br><h3>  Erste Schritte mit Diagnosen: Ansichten </h3><br>  Da die Probleme h√∂chstwahrscheinlich auf die starke Konkurrenz von Prozessen zur√ºckzuf√ºhren sind, die auf dieselben Objekte ‚Äûklopfen‚Äú, m√ºssen zun√§chst die Sperren √ºberpr√ºft werden.  In PostgreSQL gibt es f√ºr eine solche Pr√ºfung die Ansichten <code>pg.catalog.pg_locks</code> und <code>pg_stat_activity</code> .  Die zweite, bereits in Version 9.6, f√ºgte Informationen dar√ºber hinzu, worauf der Prozess wartet ( <i>Amit Kapila, Ildus Kurbangaliev</i> ) - <code>wait_event_type</code> .  M√∂gliche Werte f√ºr dieses Feld werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> beschrieben. <br><br>  Aber zuerst z√§hlen: <br><br><pre> <code class="sql hljs">postgres=<span class="hljs-comment"><span class="hljs-comment"># SELECT COUNT(*) FROM pg_locks; count ‚Äî---‚Äî 88453 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity; count ‚Äî---‚Äî 1826 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity WHERE state ='active'; count ‚Äî---‚Äî 1005</span></span></code> </pre> <br>  Das sind reelle Zahlen.  Erreichte bis zu 200.000 Sperren. <br>  Gleichzeitig hingen solche Schl√∂sser an der ungl√ºcklichen Bitte: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_locks <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> pid =<span class="hljs-number"><span class="hljs-number">580707</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>; count | mode ‚Äî<span class="hljs-comment"><span class="hljs-comment">-----+---------------‚Äî 93 | AccessShareLock 1 | ExclusiveLock</span></span></code> </pre> <br>  Beim Lesen des Puffers verwendet das DBMS beim Schreiben die <code>share</code> - <code>exclusive</code> .  Das hei√üt, Schreibsperren machten weniger als 1% aller Anforderungen aus. <br>  In der Ansicht <code>pg_locks</code> sehen <code>pg_locks</code> nicht immer so aus, wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der</a> Benutzerdokumentation beschrieben. <br><br>  Hier ist die Streichholzplatte: <br><br><pre> <code class="plaintext hljs">AccessShareLock = LockTupleKeyShare RowShareLock = LockTupleShare ExclusiveLock = LockTupleNoKeyExclusive AccessExclusiveLock = LockTupleExclusive</code> </pre> <br>  Die Abfrage SELECT mode FROM pg_locks zeigte, dass CREATE INDEX (ohne CONCURRENTLY) auf 234 INSERTs und 390 INSERTs auf die <code>buffer content lock</code> Pufferinhalts warten w√ºrde.  Eine m√∂gliche L√∂sung besteht darin, INSERTs aus verschiedenen Sitzungen so zu ‚Äûlehren‚Äú, dass sie sich in Puffern weniger √ºberschneiden. <br><br><h3>  Es ist Zeit, perf zu verwenden </h3><br>  Das Dienstprogramm <b><code>perf</code></b> sammelt viele Diagnoseinformationen.  Im <code>record</code> ... werden Statistiken von Systemereignissen in Dateien geschrieben (standardm√§√üig befinden sie sich in <code>./perf_data</code> ), und im <code>report</code> werden die gesammelten Daten analysiert. Sie k√∂nnen beispielsweise Ereignisse filtern, die nur <code>postgres</code> oder eine bestimmte <code>postgres</code> betreffen: <br><br><pre> <code class="plaintext hljs">$ perf record -u postgres  $ perf record -p 76876  ,  $ perf report &gt; ./my_results</code> </pre> <br>  Als Ergebnis werden wir so etwas sehen <br><br><img src="https://habrastorage.org/webt/rn/ta/rv/rntarvj2jticq7glciiqockk3-y.jpeg"><br><br>  Die Verwendung von <code>perf</code> zur Diagnose von PostgreSQL wird beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> sowie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pg-Wiki beschrieben</a> . <br><br>  In unserem Fall gab selbst der einfachste Modus <code>perf top</code> wichtige Informationen - <code>perf top</code> , was nat√ºrlich im Geiste des <code>top</code> Betriebssystems funktioniert.  Bei <code>perf top</code> wir <code>perf top</code> dass der Prozessor die meiste Zeit in den <code>PinBuffer()</code> sowie in den Funktionen <code>PinBuffer()</code> und <code>LWLockAttemptLock().</code>  . <br><br>  <code>PinBuffer()</code> ist eine Funktion, die den Z√§hler f√ºr Verweise auf den Puffer erh√∂ht (Zuordnung einer Datenseite zum RAM), dank derer Postgres-Prozesse wissen, welche Puffer herausgedr√ºckt werden k√∂nnen und welche nicht. <br><br>  <code>LWLockAttemptLock()</code> - Die <code>LWLock</code> .  <code>LWLock</code> ist eine Art Sperre mit zwei Ebenen von <code>shared</code> und <code>exclusive</code> , ohne <code>deadlock</code> zu definieren. Sperren werden dem <code>shared memory</code> vorab zugewiesen, wartende Prozesse warten in einer Warteschlange. <br><br>  Diese Funktionen wurden bereits in PostgreSQL 9.5 und 9.6 ernsthaft optimiert.  Die darin enthaltenen Spinlocks wurden durch den direkten Einsatz atomarer Operationen ersetzt. <br><br><h3>  Flammengraphen </h3><br>  Ohne sie ist es unm√∂glich: Selbst wenn sie nutzlos w√§ren, w√§re es immer noch wert, √ºber sie zu erz√§hlen - sie sind ungew√∂hnlich sch√∂n.  Aber sie sind n√ºtzlich.  Hier ist eine Illustration von <code>github</code> , nicht von unserem Fall (weder wir noch der Kunde sind noch bereit, Details <code>github</code> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/75b/909/e8d/75b909e8de5177a48fa7d73f53eff437.svg"><br><br>  Diese sch√∂nen Bilder zeigen sehr deutlich, was die Prozessorzyklen dauern.  <code>perf</code> kann Daten erfassen, aber das <code>flame graph</code> visualisiert die Daten auf intelligente Weise und erstellt B√§ume basierend auf den gesammelten Anrufstapeln.  Sie k√∂nnen hier beispielsweise mehr √ºber die Profilerstellung mit Flammengraphen lesen und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> alles herunterladen, was Sie ben√∂tigen. <br><br>  In unserem Fall war auf den Flammengraphen eine gro√üe Menge <code>nestloop</code> sichtbar.  Anscheinend verursachten die JOINs einer gro√üen Anzahl von Tabellen in zahlreichen gleichzeitigen Leseanforderungen eine gro√üe Anzahl von <code>access share</code> . <br><br>  Die von <code>perf</code> gesammelten Statistiken zeigen, wohin die Prozessorzyklen gehen.  Und obwohl wir gesehen haben, dass die meiste Prozessorzeit f√ºr Sperren vergeht, haben wir nicht gesehen, was genau zu so langen Erwartungen an Sperren f√ºhrt, da wir nicht genau sehen, wo Sperrenerwartungen auftreten, weil  CPU-Zeit wird nicht mit Warten verschwendet. <br><br>  Um die Erwartungen selbst zu sehen, k√∂nnen Sie eine Anforderung an die Systemansicht <code>pg_stat_activity</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> wait_event_type, wait_event, <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_stat_activity <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> wait_event_type, wait_event;</code> </pre> <br>  enth√ºllte, dass: <br><br><pre> <code class="plaintext hljs">LWLockTranche | buffer_content | UPDATE ************* LWLockTranche | buffer_content | INSERT INTO ******** LWLockTranche | buffer_content | \r | | insert into B4_MUTEX | | values (nextval('hib | | returning ID Lock | relation | INSERT INTO B4_***** LWLockTranche | buffer_content | UPDATE ************* Lock | relation | INSERT INTO ******** LWLockTranche | buffer_mapping | INSERT INTO ******** LWLockTranche | buffer_content | \r</code> </pre> <br>  (Die Sternchen hier ersetzen einfach Anforderungsdetails, die wir nicht offenlegen.) <br><br>  Sie k√∂nnen die Werte <code>buffer_content</code> (Blockieren des Inhalts von Puffern) und <code>buffer_mapping</code> (Blockieren der Komponenten der Hash-Platte <code>shared_buffers</code> ) <code>shared_buffers</code> . <br><br><h3>  F√ºr Hilfe zu gdb </h3><br>  Aber warum gibt es so viele Erwartungen an diese Art von Schl√∂ssern?  F√ºr detailliertere Informationen zu den Erwartungen musste ich den <code>GDB</code> Debugger verwenden.  Mit <code>GDB</code> wir einen Aufrufstapel spezifischer Prozesse erhalten.  Durch Anwenden von Abtastung, d.h.  Nachdem Sie eine bestimmte Anzahl von zuf√§lligen Anrufstapeln gesammelt haben, k√∂nnen Sie sich ein Bild davon machen, welche Stapel die l√§ngsten Erwartungen haben. <br><br>  Betrachten Sie den Prozess der Erstellung von Statistiken.  Wir werden die "manuelle" Sammlung von Statistiken betrachten, obwohl im wirklichen Leben spezielle Skripte verwendet werden, die dies automatisch tun. <br><br>  Zun√§chst muss <code>gdb</code> an den PostgreSQL-Prozess angeh√§ngt werden.  Suchen Sie dazu die <code>pid</code> Serverprozesses, z. B. von <br><br><pre> <code class="plaintext hljs">$ ps aux | grep postgres</code> </pre> <br>  Nehmen wir an, wir haben gefunden: <br><br><pre> <code class="plaintext hljs">postgres 2025 0.0 0.1 172428 1240 pts/17  S   23  0:00 /usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data</code> </pre> <br>  und f√ºgen Sie nun die <code>pid</code> in den Debugger ein: <br><br><pre> <code class="plaintext hljs">igor_le:~$gdb -p 2025</code> </pre> <br>  Sobald wir uns im Debugger befinden, schreiben wir <code>bt</code> [ <code>bt</code> <code>backtrace</code> ] oder <code>where</code> .  Und wir bekommen viele Informationen √ºber diesen Typ: <br><br><pre> <code class="plaintext hljs">(gdb) bt #0 0x00007fbb65d01cd0 in __write_nocancel () from /lib64/libc.so.6 #1 0x00000000007c92f4 in write_pipe_chunks ( data=0x110e6e8 "2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [392‚Äê1] db=bp,user=bp,app=[unknown],client=192.168.70.163 (http://192.168.70.163) LOG: relation 23554 new block 493: 248.389503\n2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [393‚Äê1] db=bp,user=bp,app=["..., len=409, dest=dest@entry=1) at elog.c:3123 #2 0x00000000007cc07b in send_message_to_server_log (edata=0xc6ee60 &lt;errordata&gt;) at elog.c:3024 #3 EmitErrorReport () at elog.c:1479</code> </pre> <br>  Nachdem wir Statistiken gesammelt hatten, einschlie√ülich Aufrufstapel aus allen Postgres-Prozessen, die wiederholt zu verschiedenen Zeitpunkten gesammelt wurden, stellten wir fest, dass die <code>buffer partition lock</code> der <code>buffer partition lock</code> innerhalb der <code>buffer partition lock</code> der <code>relation extension lock</code> 3706 Sekunden (ungef√§hr eine Stunde) dauerte, dh ein Teil der Hash-Tabelle des Puffers <code>relation extension lock</code> Manager, der erforderlich war, um den alten Puffer zu ersetzen, um ihn anschlie√üend durch einen neuen zu ersetzen, der dem erweiterten Teil der Tabelle entspricht.  Es war auch eine bestimmte Anzahl von Sperren f√ºr Pufferinhalte erkennbar, die der Erwartung entsprachen, die Seiten des <code>B-tree</code> Index zum Einf√ºgen zu sperren. <br><br><img src="https://habrastorage.org/webt/6c/y6/cw/6cy6cwmfye29jw84dkzoabjlgvg.jpeg"><br><br>  Zun√§chst kamen zwei Erkl√§rungen f√ºr eine solch ungeheure Wartezeit: <br><br><ul><li>  Jemand anderes nahm dieses <code>LWLock</code> und steckte fest.  Dies ist jedoch unwahrscheinlich.  Weil innerhalb der Pufferpartitionssperre nichts Kompliziertes passiert. </li><li>  Wir haben ein pathologisches Verhalten von <code>LWLock</code> .  Das hei√üt, trotz der Tatsache, dass niemand das Schloss zu lange nahm, hielt seine Erwartung unangemessen lange an. </li></ul><br><h3>  Diagnosepflaster und Baumbehandlung </h3><br>  Durch die Reduzierung der Anzahl gleichzeitiger Verbindungen w√ºrden wir wahrscheinlich den Strom von Anforderungen an Sperren entladen.  Aber das w√§re wie Kapitulation.  Stattdessen schlug <i>Alexander Korotkov</i> , der Chefarchitekt von Postgres Professional (nat√ºrlich half er bei der Vorbereitung dieses Artikels), eine Reihe von Patches vor. <br><br>  Zun√§chst war es notwendig, sich ein detaillierteres Bild von der Katastrophe zu machen.  Unabh√§ngig davon, wie gut die fertigen Werkzeuge sind, sind auch Diagnose-Patches aus eigener Herstellung hilfreich. <br><br>  Es wurde ein Patch geschrieben, der eine detaillierte Protokollierung der in der <code>RelationAddExtraBlocks()</code> -Funktion verbrachten Zeit in <code>RelationAddExtraBlocks().</code> hinzuf√ºgt. Wir finden also heraus, wie viel Zeit in <code>RelationAddExtraBlocks().</code> <br><br>  Und zur Unterst√ºtzung von ihm wurde in <code>pg_stat_activity</code> weiterer Patch geschrieben, der dar√ºber berichtet, was wir jetzt in <code>relation extension</code> auf die <code>relation extension</code> tun.  Dies wurde folgenderma√üen durchgef√ºhrt: Wenn die <code>relation</code> erweitert wird, wird <code>application_name</code> zu <code>RelationAddExtraBlocks</code> .  Dieser Prozess wird jetzt bequem mit maximalen Details unter Verwendung von <code>gdb bt</code> und <code>perf</code> analysiert. <br><br>  Tats√§chlich wurden zwei medizinische (und nicht diagnostische) Patches geschrieben.  Der erste Patch hat das Verhalten von <code>B‚Äêtree</code> Blattsperren ge√§ndert: Fr√ºher wurde das Blatt bei der Aufforderung zum Einf√ºgen als <code>share</code> blockiert und danach <code>exclusive</code> .  Jetzt wird er sofort <code>exclusive</code> .  Jetzt wurde dieser Patch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereits</a> f√ºr <b>PostgreSQL 12</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">festgeschrieben</a> .  Gl√ºcklicherweise erhielt <i>Alexander Korotkov in</i> diesem Jahr den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Status eines Committers</a> - des zweiten PostgreSQL-Committers in Russland und des zweiten im Unternehmen. <br><br>  Der Wert f√ºr <code>NUM_BUFFER_PARTITIONS</code> wurde ebenfalls von 128 auf 512 erh√∂ht, um die Belastung der Zuordnungssperren zu verringern: Die Puffermanager-Hash-Tabelle wurde in kleinere Teile unterteilt, in der Hoffnung, dass die Belastung f√ºr jedes bestimmte Teil verringert wird. <br><br>  Nach dem Anwenden dieses Patches waren die Sperren f√ºr den Inhalt der Puffer weg, aber trotz der Zunahme von <code>buffer_mapping</code> blieb <code>NUM_BUFFER_PARTITIONS</code> , <code>buffer_mapping</code> wir erinnern Sie daran, Teile der Puffermanager-Hash-Tabelle zu blockieren: <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping ----‚Äê‚Äê‚Äê--‚Äê‚Äê‚Äê+‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê------‚Äê‚Äê‚Äê 12549 | 1218 | 0 | 15</code> </pre> <br>  Und selbst das ist nicht viel.  B - Baum ist kein Engpass mehr.  Die <code>heap-</code> Erweiterung trat in den Vordergrund. <br><br><h3>  Behandlung des Gewissens </h3><br>  Als n√§chstes stellte Alexander die folgende Hypothese und L√∂sung vor: <br><br>  Wir warten viel Zeit auf die <code>buffer parittion lock</code> wenn wir den <code>buffer parittion lock</code> .  Vielleicht gibt es auf derselben <code>buffer parittion lock</code> eine sehr gefragte Seite, zum Beispiel die Wurzel eines <code>B‚Äêtree</code> .  Zu diesem Zeitpunkt gibt es einen kontinuierlichen Fluss von Anforderungen f√ºr die <code>shared lock</code> von Leseanforderungen. <br><br>  Die Warteschlange bei <code>LWLock</code> "nicht fair".  Da <code>shared lock</code> so viele wie n√∂tig gleichzeitig verwendet werden k√∂nnen, werden nachfolgende <code>shared lock</code> ohne Warteschlange √ºbergeben, wenn die <code>shared lock</code> bereits aktiviert ist.  Wenn der Strom gemeinsam genutzter Sperren so intensiv ist, dass sich keine ‚ÄûFenster‚Äú zwischen ihnen befinden, ist das Warten auf eine <code>exclusive lock</code> fast unendlich. <br><br>  Um dies zu beheben, k√∂nnen Sie versuchen, einen Patch f√ºr "Gentleman" -Verhalten von Schl√∂ssern anzubieten.  Es weckt das Gewissen <code>shared locker</code> und sie stehen ehrlich in der Warteschlange, wenn es bereits ein <code>exclusive lock</code> (interessanterweise haben schwere Schl√∂sser - <code>hwlock</code> - keine Probleme mit dem Gewissen: Sie stehen immer ehrlich in der Warteschlange) <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping | reladdextra | inserts&gt;30sec ‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê--‚Äê-‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê------ 173985 | 1802 | 0 | 569 | 0 | 0</code> </pre> <br>  Alles ist gut!  Es gibt keine langen <code>insert</code> .  Obwohl die Schl√∂sser an den St√ºcken der Hash-Platten erhalten blieben.  Aber was zu tun ist, das sind die Eigenschaften der Reifen unseres kleinen Supercomputers. <br><br>  Dieser Patch wurde auch <a href="">der Community angeboten</a> .  Unabh√§ngig davon, wie sich das Schicksal dieser Patches in der Community entwickelt, hindert nichts sie daran, in die n√§chsten Versionen von <b>Postgres Pro Enterprise zu gelangen</b> , die speziell f√ºr Kunden mit stark ausgelasteten Systemen entwickelt wurden. <br><br><h3>  Moral </h3><br>  <code>share</code> leichte <code>share</code> Locks - <code>exclusive</code> Bl√∂cke, die die Warteschlange √ºberspringen - haben das Problem der st√ºndlichen Verz√∂gerungen in einem System mit mehreren Knoten gel√∂st.  Das Hash-Tag des <code>buffer manager</code> funktionierte nicht, da zu viel Fluss von <code>share lock</code> die Sperren keine Chance hatten, alte Puffer zu ersetzen und neue zu laden.  Probleme mit der Erweiterung des Puffers f√ºr die Datenbanktabellen waren nur eine Folge davon.  Zuvor war es m√∂glich, den Engpass mit Zugriff auf die <code>B-tree</code> Wurzel zu erweitern. <br><br>  PostgreSQL wurde nicht f√ºr NUMA-Architekturen und Supercomputer entwickelt.  Die Anpassung an solche Postgres-Architekturen ist eine gro√üe Aufgabe, die die koordinierten Anstrengungen vieler Menschen und sogar Unternehmen erfordern w√ºrde (und m√∂glicherweise erfordern w√ºrde).  Die unangenehmen Folgen dieser architektonischen Probleme k√∂nnen jedoch gemildert werden.  Und wir m√ºssen: Die Lasttypen, die zu √§hnlichen Verz√∂gerungen wie den beschriebenen f√ºhrten, sind recht typisch, √§hnliche Notsignale von anderen Orten kommen weiterhin zu uns.  √Ñhnliche Probleme traten fr√ºher auf - bei Systemen mit weniger Kernen waren nur die Folgen nicht so ungeheuerlich, und die Symptome wurden mit anderen Methoden und anderen Patches behandelt.  Jetzt ist eine andere Medizin erschienen - nicht universell, aber eindeutig n√ºtzlich. <br><br>  Wenn PostgreSQL also mit dem Speicher des gesamten Systems als lokal arbeitet, kann kein Hochgeschwindigkeitsbus zwischen Knoten mit der Zugriffszeit auf den lokalen Speicher verglichen werden.  Aufgaben entstehen aufgrund dieser schwierigen, oft dringenden, aber interessanten.  Und die Erfahrung, sie zu l√∂sen, ist nicht nur f√ºr die Entscheidenden, sondern auch f√ºr die gesamte Gemeinschaft n√ºtzlich. <br><br><img src="https://habrastorage.org/webt/od/n1/sf/odn1sf_id7l60ezlyo-padxymmi.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de423685/">https://habr.com/ru/post/de423685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de423657/index.html">Ich respektiere die Kapselung nicht oder verwende keine andere Art von Methodentabelle, um schnell private Methoden aufzurufen</a></li>
<li><a href="../de423663/index.html">Wir schreiben einen einfachen √úbersetzer in Lisp - III</a></li>
<li><a href="../de423677/index.html">Jetpack-Piloten: Frankie West</a></li>
<li><a href="../de423679/index.html">Eine Aufgabe mit Wolkenkratzer und Eiern - nicht Newtons M√ºlleimer?</a></li>
<li><a href="../de423683/index.html">Basierend auf gesundem Menschenverstand: DevOps von Grund auf neu entwickeln</a></li>
<li><a href="../de423687/index.html">HyperX Pulsefire FPS Pro - schneller, gemeiner, erschwinglicher</a></li>
<li><a href="../de423689/index.html">RTOS MAX - kostenlos? Wir planen, eine Lizenz f√ºr die kostenlose kommerzielle Nutzung zu er√∂ffnen</a></li>
<li><a href="../de423693/index.html">Eine andere M√∂glichkeit, Webpack 4 und Codetrennung zu verwenden</a></li>
<li><a href="../de423695/index.html">Wie man vor 40 Jahren mit einer Million Dollar auf einem Bankkonto in den Ruhestand geht</a></li>
<li><a href="../de423697/index.html">Einf√ºhrung in Spring Data JDBC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
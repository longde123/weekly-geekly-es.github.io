<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèæ üõèÔ∏è üë©üèΩ‚Äçüíª Jika Anda tidak memiliki Python, tetapi ada model Keras dan Java üìî üé≠ üõÑ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya! Dalam membangun ML-model, Python saat ini menempati posisi terdepan dan sangat populer di kalangan komunitas spesialis Ilmu Data [ 1 ]....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Jika Anda tidak memiliki Python, tetapi ada model Keras dan Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/naumen/blog/475338/">  Halo semuanya!  Dalam membangun ML-model, Python saat ini menempati posisi terdepan dan sangat populer di kalangan komunitas spesialis Ilmu Data [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> ]. <br><br>  Seperti kebanyakan pengembang, Python menarik kita dengan kesederhanaan dan sintaksis yang ringkas.  Kami menggunakannya untuk memecahkan masalah pembelajaran mesin menggunakan jaringan saraf tiruan.  Namun, dalam praktiknya, bahasa pengembangan produk tidak selalu Python, dan ini mengharuskan kami untuk menyelesaikan masalah integrasi tambahan. <br><br>  Dalam artikel ini saya akan berbicara tentang solusi yang kami dapatkan ketika kami perlu mengaitkan model Keras Python dengan Java. <br><br>  Apa yang kami perhatikan: <br><br><ul><li>  Fitur bundel model Keras dan Java; </li><li>  Bersiap untuk bekerja dengan kerangka kerja DeepLearning4j (singkatnya DL4J); </li><li>  Mengimpor model Keras ke DL4J (hati-hati, bagian ini berisi banyak wawasan) - cara mendaftarkan lapisan, batasan apa yang dimiliki modul impor, cara memeriksa hasil pekerjaannya. </li></ul><br>  Kenapa membaca? <br><br><ul><li>  Untuk menghemat waktu di awal, jika Anda akan menghadapi tugas integrasi serupa; </li><li>  Untuk mengetahui apakah solusi kami tepat untuk Anda dan jika Anda dapat menggunakan kembali pengalaman kami. </li></ul><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2m/2k/xj/2m2kxjbwgahv1gx0wejstn2qpjw.png" alt="alt gambar"></div><br>  Karakteristik integral tentang pentingnya kerangka pembelajaran yang mendalam [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> ]. <br><br>  Ringkasan kerangka pembelajaran mendalam yang paling populer dapat ditemukan di sini [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3</a> ] dan di sini [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">4</a> ]. <br><br>  Seperti yang Anda lihat, sebagian besar kerangka kerja ini didasarkan pada Python dan C ++: mereka menggunakan C ++ sebagai kernel untuk mempercepat operasi dasar dan sangat dimuat, dan Python sebagai antarmuka interaksi untuk mempercepat pengembangan. <br><br>  Faktanya, banyak bahasa pembangunan jauh lebih luas.  Java adalah pemimpin dalam pengembangan produk untuk perusahaan dan organisasi besar.  Beberapa kerangka kerja populer untuk jaringan saraf memiliki port untuk Jawa dalam bentuk pengikat JNI / JNA, tetapi dalam kasus ini ada kebutuhan untuk membangun proyek untuk setiap arsitektur dan keuntungan Jawa dalam masalah pengaburan lintas-platform.  Nuansa ini bisa sangat penting dalam solusi yang direplikasi. <br><br>  Pendekatan alternatif lain adalah dengan menggunakan Jython untuk mengkompilasi ke dalam bytecode Java;  tetapi ada kelemahan di sini - hanya mendukung versi 2 Python, serta kemampuan terbatas untuk menggunakan pustaka Python pihak ketiga. <br><br>  Untuk menyederhanakan pengembangan solusi jaringan saraf di Jawa, kerangka kerja DeepLearning4j (singkatnya DL4J) sedang dikembangkan.  DL4 selain Java API menawarkan satu set model pra-terlatih [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">5</a> ].  Secara umum, alat pengembangan ini sulit untuk bersaing dengan TensorFlow.  TensorFlow mengungguli DL4J dengan dokumentasi yang lebih rinci dan sejumlah contoh, kemampuan teknis, ukuran komunitas, dan pengembangan cepat.  Namun demikian, tren yang dipatuhi Skymind cukup menjanjikan.  Pesaing signifikan di Jawa untuk alat ini belum terlihat. <br><br>  Pustaka DL4J adalah salah satu dari sedikit (jika bukan satu-satunya) yang memungkinkan untuk mengimpor model-Keras, ia memperluas fungsionalitas dengan lapisan-lapisan yang dikenal dengan Keras [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">6</a> ].  Pustaka DL4J berisi direktori dengan contoh-contoh implementasi ML-model jaringan saraf (contoh dl4j).  Dalam kasus kami, kehalusan penerapan model-model ini di Jawa tidak begitu menarik.  Perhatian yang lebih rinci akan diberikan untuk mengimpor model Keras / TF yang terlatih ke Jawa menggunakan metode DL4J. <br><br><h1>  Memulai </h1><br>  Sebelum Anda mulai, Anda perlu menginstal program yang diperlukan: <br><br><ol><li>  Java versi 1.7 (versi 64-bit) dan lebih tinggi. </li><li>  Sistem Pembuatan Proyek Apache Maven. </li><li>  IDE untuk dipilih: Intellij IDEA, Eclipse, Netbeans.  Pengembang merekomendasikan opsi pertama, dan di samping itu, contoh pelatihan yang tersedia dibahas tentang hal itu. </li><li>  Git (untuk kloning proyek ke PC Anda). </li></ol><br>  Deskripsi terperinci dengan contoh peluncuran dapat ditemukan di sini [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">7</a> ] atau dalam video [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">8</a> ]. <br><br>  Untuk mengimpor model, pengembang DL4J menyarankan menggunakan <em>modul</em> impor <em>KerasModelImport</em> (muncul pada Oktober 2016).  Fungsional modul ini mendukung kedua arsitektur model dari Keras - itu Sequential (analog dalam Java kelas MultiLayerNetwork) dan Fungsional (analog dalam ComputationGraph dalam kelas java).  Model ini diimpor baik secara keseluruhan dalam format HDF5, atau 2 file terpisah - berat model dengan ekstensi h5 dan file json yang berisi arsitektur jaringan saraf. <br><br>  Untuk memulai dengan cepat, pengembang DL4J menyiapkan analisis langkah-demi-langkah dari contoh sederhana pada dataset iris Fisher untuk model tipe Sequential [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">9</a> ].  Contoh pelatihan lain dipertimbangkan dari perspektif mengimpor model dalam dua cara (1: dalam format HDF5 penuh; 2: dalam file terpisah - bobot model (ekstensi h5) dan arsitektur (ekstensi json)), diikuti oleh perbandingan hasil model Python dan Java [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">10</a> ].  Ini menyimpulkan diskusi tentang kemampuan praktis modul impor. <br><br>  Ada juga TF di Jawa, tetapi dalam kondisi eksperimental dan pengembang tidak memberikan jaminan operasi yang stabil [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">11</a> ].  Ada masalah dengan versi, dan TF di Java memiliki API yang tidak lengkap - itulah sebabnya opsi ini tidak akan dipertimbangkan di sini. <br><br><h1>  Fitur dari model Keras / TF asli: </h1><br>  Mengimpor jaringan saraf sangat mudah.  Secara lebih rinci dalam kode kita akan menganalisis contoh integrasi jaringan saraf dengan arsitektur yang lebih rumit. <br><br>  Anda tidak boleh masuk ke aspek praktis dari model ini, ini merupakan indikasi dari sudut pandang akuntansi untuk lapisan (khususnya, pendaftaran lapisan Lambda), beberapa seluk-beluk dan keterbatasan modul impor, serta DL4J secara keseluruhan.  Dalam praktiknya, nuansa yang dicatat mungkin memerlukan penyesuaian arsitektur jaringan, atau sepenuhnya meninggalkan pendekatan peluncuran model melalui DL4J. <br><br>  Fitur Model: <br><br>  <b>1.</b> Jenis model - Fungsional (jaringan dengan percabangan); <br><br>  <b>2.</b> Parameter pelatihan (ukuran bets, jumlah era) dipilih kecil: ukuran bets - 100, jumlah era - 10, langkah per era - 10; <br><br>  <b>3.</b> 13 lapisan, ringkasan lapisan ditunjukkan pada gambar: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/85/of/hn/85ofhnioy_usez2msaeqpt2whja.png" alt="alt gambar"></div><br><div class="spoiler">  <b class="spoiler_title">Deskripsi lapisan pendek</b> <div class="spoiler_text"><ol><li>  input_1 - lapisan input, menerima tensor 2 dimensi (diwakili oleh matriks); </li><li>  lambda_1 - lapisan pengguna, dalam kasus kami, membuat pengisi dalam TF dari tensor nilai numerik yang sama; </li><li>  embedding_1 - builds Embedding (representasi vektor) untuk urutan input data teks (mengkonversi tensor 2-D menjadi 3-D); </li><li>  conv1d_1 - lapisan konvolusional 1-D; </li><li>  lstm_2 - lapisan LSTM (setelah lapisan embedding_1 (No. 3)); </li><li>  lstm_1 - lapisan LSTM (berjalan setelah lapisan conv1d (No. 4)); </li><li>  lambda_2 adalah lapisan pengguna di mana tensor dipotong setelah lapisan lstm_2 (No. 5) (operasi yang berlawanan dengan padding pada lapisan lambda_1 (No. 2)); </li><li>  lambda_3 adalah lapisan pengguna di mana tensor dipotong setelah lstm_1 (No. 6) dan lapisan conv1d_1 (No. 4) (operasi yang berseberangan dengan lapisan pada lapisan lambda_1 (No. 2)); </li><li>  concatenate_1 - ikatan lapisan terpotong (No. 7) dan (No. 8); </li><li>  dense_1 - lapisan 8 neuron yang terhubung penuh dan fungsi aktivasi linier eksponensial "elu"; </li><li>  batch_normalization_1 - lapisan normalisasi; </li><li>  dense_2 - sepenuhnya terhubung lapisan 1 neuron dan fungsi aktivasi sigmoid "sigmoid"; </li><li>  lambda_4 - lapisan pengguna di mana kompresi lapisan sebelumnya (memeras dalam TF) dilakukan. </li></ol></div></div><br>  <b>4.</b> Kehilangan fungsi - binary_crossentropy <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>&amp;#x2212;</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>N</mi></mrow><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>N</mi></mrow></msubsup><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo>&amp;#x2212;</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo>&amp;#x2212;</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="72.962ex" height="2.901ex" viewBox="0 -883.9 31413.9 1249" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6F" x="298" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-73" x="784" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-73" x="1253" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-3D" x="2000" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-2212" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-66" x="4085" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="4636" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-61" x="5087" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-63" x="5617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-31" x="6050" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-4E" x="6551" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-73" x="7689" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-75" x="8159" y="0"></use><g transform="translate(8731,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-4E" x="1242" y="488"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-31" x="1242" y="-435"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-28" x="10338" y="0"></use><g transform="translate(10727,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-75" x="812" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="1385" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="12877" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6F" x="13176" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-67" x="13661" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="14142" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6F" x="14440" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-67" x="14926" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-28" x="15406" y="0"></use><g transform="translate(15796,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-70" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-64" x="1421" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-29" x="17762" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-2B" x="18373" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-28" x="19374" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-31" x="19764" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-2212" x="20486" y="0"></use><g transform="translate(21487,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-75" x="812" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="1385" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-29" x="23387" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="24027" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6F" x="24325" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-67" x="24811" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="25291" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6F" x="25590" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-67" x="26075" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-28" x="26556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-31" x="26945" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-2212" x="27668" y="0"></use><g transform="translate(28669,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-70" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-64" x="1421" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-29" x="30634" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-29" x="31024" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>‚àí</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow></msubsup><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mtext>&nbsp;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> loss = - \ frac {1} {N} \ sum_ {1} ^ {N} (y_ {true} \ log log (y_ {pred}) + (1-y_ {true}) \ log log (1- y_ {pred})) </script></p><br><br>  <b>5.</b> Metrik kualitas model - rata-rata harmonik (F-ukur) <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>F</mi><mo>=</mo><mn>2</mn><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="53.569ex" height="2.419ex" viewBox="0 -780.1 23064.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-46" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-3D" x="1027" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-32" x="2083" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-66" x="2834" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="3384" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-61" x="3836" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-63" x="4365" y="0"></use><g transform="translate(4799,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="1203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-63" x="1669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-69" x="2103" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-73" x="2448" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-69" x="2918" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6F" x="3263" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6E" x="3749" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-74" x="4599" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-69" x="4961" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6D" x="5306" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="6185" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-73" x="6651" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-52" x="7121" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="7880" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-63" x="8347" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-61" x="8780" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="9310" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="9608" y="0"></use></g><g transform="translate(14706,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-72" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="1203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-63" x="1669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-69" x="2103" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-73" x="2448" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-69" x="2918" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6F" x="3263" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6E" x="3749" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMAIN-2B" x="4571" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-52" x="5572" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-65" x="6331" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-63" x="6798" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-61" x="7231" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="7761" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhhWaUwXfgcklnvjsaj-I8b1NNW0rg#MJMATHI-6C" x="8059" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>F</mi><mo>=</mo><mn>2</mn><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> F = 2 \ frac {Precision \ times Recall} {Precision + Recall} </script></p><br>  Dalam kasus kami, masalah metrik kualitas tidak sepenting kebenaran impor.  Kebenaran impor ditentukan oleh kebetulan hasil dalam model Python dan Java NN yang bekerja dalam mode Inference. <br><br><h1>  Impor model Keras di DL4J: </h1><br>  Versi yang digunakan: Tensorflow 1.5.0 dan Keras 2.2.5.  Dalam kasus kami, model dari Python diunggah secara keseluruhan oleh file HDF5. <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># saving model model1.save('model1_functional.h5')</span></span></code> </pre> <br>  Saat mengimpor model ke DL4J, modul impor tidak menyediakan metode API untuk melewatkan parameter tambahan: nama modul tensorflow (dari mana fungsi diimpor saat membangun model). <br><br>  Secara umum, DL4J hanya bekerja dengan fungsi Keras, daftar lengkap diberikan di bagian Keras Impor [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">6</a> ], jadi jika model dibuat pada Keras menggunakan metode dari TF (seperti dalam kasus kami), modul impor tidak akan dapat mengidentifikasi mereka. <br><br><h3>  Pedoman umum untuk mengimpor model </h3><br>  Jelas, bekerja dengan model Keras menyiratkan pelatihan berulangnya.  Untuk tujuan ini, untuk menghemat waktu, parameter pelatihan ditetapkan (1 zaman) dan 1 langkah per zaman (steps_per_epoch). <br><br>  Saat Anda pertama kali mengimpor model, khususnya dengan lapisan khusus dan kombinasi lapisan langka, keberhasilan tidak mungkin.  Oleh karena itu, disarankan untuk melakukan proses impor secara iteratif: kurangi jumlah lapisan model Keras hingga Anda dapat mengimpor dan menjalankan model di Jawa tanpa kesalahan.  Selanjutnya, tambahkan satu lapis pada satu waktu ke model Keras dan impor model yang dihasilkan ke Jawa, menyelesaikan kesalahan yang terjadi. <br><br><h3>  Menggunakan Fungsi Kehilangan TF </h3><br>  Untuk membuktikan bahwa, ketika mengimpor ke Jawa, fungsi kerugian dari model yang dilatih harus dari Keras, kami menggunakan log_loss dari tensorflow (sebagai yang paling mirip dengan fungsi custom_loss).  Kami mendapatkan kesalahan berikut di konsol: <br><br><pre> <code class="java hljs">Exception in thread <span class="hljs-string"><span class="hljs-string">"main"</span></span> org.deeplearning4j.nn.modelimport.keras.exceptions.UnsupportedKerasConfigurationException: Unknown Keras loss function log_loss.</code> </pre> <br><h3>  Mengganti Metode TF dengan Keras </h3><br>  Dalam kasus kami, fungsi-fungsi dari modul TF digunakan 2 kali dan dalam semua kasus mereka hanya ditemukan di lapisan lambda. <br><br>  Lapisan Lambda adalah lapisan khusus yang digunakan untuk menambahkan fungsi sewenang-wenang. <br><br>  Model kami hanya memiliki 4 lapisan lambda.  Faktanya adalah bahwa di Jawa perlu mendaftarkan lapisan lambda ini secara manual melalui KerasLayer.registerLambdaLayer (jika tidak kita akan mendapatkan kesalahan [ <a href="">12</a> ]).  Dalam hal ini, fungsi yang didefinisikan di dalam lapisan lambda harus merupakan fungsi dari pustaka Java yang sesuai.  Di Jawa tidak ada contoh mendaftar lapisan ini, serta dokumentasi yang komprehensif untuk ini;  contohnya ada di sini [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">13</a> ].  Pertimbangan umum dipinjam dari contoh [ <a href="">14</a> , <a href="">15</a> ]. <br><br>  Secara berurutan pertimbangkan untuk mendaftarkan semua lapisan lambda dari model di Jawa: <br><br>  1) Lapisan Lambda untuk menambahkan konstanta ke tensor (matriks) beberapa kali sepanjang arah yang diberikan (dalam kasus kami, kiri dan kanan): <br><br>  Input dari lapisan ini terhubung ke input model. <br><br>  1.1) Lapisan Python: <br><br><pre> <code class="python hljs">padding = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: tf.pad(x, paddings=[[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>], [<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]], constant_values=<span class="hljs-number"><span class="hljs-number">1</span></span>))(embedding)</code> </pre> <br>  Untuk kejelasan, fungsi lapisan ini berfungsi, kami secara eksplisit mengganti nilai numerik dalam lapisan python. <br><br><div class="spoiler">  <b class="spoiler_title">Tabel dengan contoh tensor 2x2 yang berubah-ubah</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  Itu 2x2 </td><td>  Sudah menjadi 2x22 </td></tr><tr><td>  [[ <strong>1</strong> , <strong>2</strong> ], <br>  [ <strong>3</strong> , <strong>4</strong> ]] </td><td>  [[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, <strong>1</strong> , <strong>2</strong> , 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37], <br>  [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, <strong>3</strong> , <strong>4</strong> , 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]] </td></tr></tbody></table></div><br></div></div><br>  1.2) Lapisan Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_1"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.nn().pad(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][]{ { <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span> }, { <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }}, <span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.feedForward(<span class="hljs-number"><span class="hljs-number">20</span></span>); } });</code> </pre> <br>  Di semua lapisan lambda terdaftar di Jawa, 2 fungsi didefinisikan ulang: <br>  Fungsi pertama "definelayer" bertanggung jawab untuk metode yang digunakan (sama sekali bukan fakta yang jelas: metode ini hanya dapat digunakan dari bawah nn () backend);  getOutputType bertanggung jawab atas output dari layer terdaftar, argumennya adalah parameter numerik (di sini 20, tetapi secara umum setiap nilai integer diizinkan).  Ini terlihat tidak konsisten, tetapi berfungsi seperti ini. <br><br>  2) Lapisan Lambda untuk memotong tensor (matriks) sepanjang arah yang diberikan (dalam kasus kami, kiri dan kanan): <br><br>  Dalam hal ini, lapisan LSTM memasukkan input dari lapisan lambda. <br><br>  2.1) Lapisan Python: <br><br><pre> <code class="python hljs">slicing_lstm = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:, <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">-10</span></span>])(lstm)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Tabel dengan contoh tensor 2x22x5 sewenang-wenang</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  Itu 2x22x5 </td><td>  Sudah menjadi 2x2x5 </td></tr><tr><td>  [[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1 , 2,3,4,5], [1,2,3,4,5], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [1,2 , 3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3 , 4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4] , 5], [1,2,3,4,5]], <br><br>  [[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [ 1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1, 2,3,4,5], [1,2,3,4,5], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [1,2, 3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3, 4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4, 5], [1,2,3,4,5]]] </td><td>  [[[ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ]], <br>  [[ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ]]]] </td></tr></tbody></table></div><br></div></div><br>  2.2) layer Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_2"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.stridedSlice(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">0</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">1</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">2</span></span>]-<span class="hljs-number"><span class="hljs-number">10</span></span>}, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> }); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.recurrent(<span class="hljs-number"><span class="hljs-number">60</span></span>); } });</code> </pre> <br>  Dalam hal lapisan ini, parameter InputType berubah dari feedforward (20) menjadi berulang (60).  Dalam argumen berulang, jumlahnya bisa berupa bilangan bulat apa saja (bukan nol), tetapi jumlahnya dengan argumen berulang dari lapisan lambda berikutnya harus memberikan 160 (mis., Pada lapisan berikutnya, argumen harus 100).  Angka 160 disebabkan oleh fakta bahwa tensor dengan dimensi (Tidak, Tidak, 160) harus diterima pada input concatenate_1 dari layer. <br><br>  2 argumen pertama adalah variabel, tergantung pada ukuran string input. <br><br>  3) Lapisan Lambda untuk memotong tensor (matriks) sepanjang arah yang diberikan (dalam kasus kami, kiri dan kanan): <br><br>  Input dari layer ini adalah layer LSTM, sebelum layer conv1_d berada <br><br>  3.1) Lapisan Python: <br><br><pre> <code class="python hljs">slicing_convolution = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,<span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">-10</span></span>])(lstm_conv)</code> </pre> <br>  Operasi ini sepenuhnya identik dengan operasi dalam paragraf 2.1. <br><br>  3.2) Lapisan Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_3"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.stridedSlice(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">0</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">1</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">2</span></span>]-<span class="hljs-number"><span class="hljs-number">10</span></span>}, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> }); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.recurrent(<span class="hljs-number"><span class="hljs-number">100</span></span>); } });</code> </pre> <br>  Lapisan lambda ini mengulangi lapisan lambda sebelumnya dengan pengecualian parameter berulang (100).  Mengapa "100" diambil dicatat dalam deskripsi lapisan sebelumnya. <br><br>  Dalam poin 2 dan 3, lapisan lambda terletak setelah lapisan LSTM, sehingga jenis berulang digunakan.  Tetapi jika sebelum lambda-layer tidak ada LSTM, tetapi conv1d_1, maka Anda masih perlu mengatur berulang (terlihat tidak konsisten, tetapi berfungsi seperti itu). <br><br>  4) Lapisan Lambda untuk mengompres lapisan sebelumnya: <br><br>  Input dari lapisan ini adalah lapisan yang terhubung sepenuhnya. <br><br>  4.1) Lapisan Python: <br><br><pre> <code class="python hljs"> squeeze = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: tf.squeeze( x, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>))(dense)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Tabel dengan contoh tensor 2x4x1 sewenang-wenang</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  Itu 2x4x1 </td><td>  Menjadi 2x4 </td></tr><tr><td>  [[[ <strong>[1], [2], [3], [4]]</strong> , <br><br>  [ <strong>[1], [2], [3], [4]</strong> ]] </td><td>  [[ <strong>1, 2, 3, 4</strong> ], <br>  [ <strong>1, 2, 3, 4</strong> ]] </td></tr></tbody></table></div><br></div></div><br>  4.2) Lapisan Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_4"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.squeeze(sdVariable, -<span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.feedForward(<span class="hljs-number"><span class="hljs-number">15</span></span>); } });</code> </pre> <br>  Input dari lapisan ini menerima lapisan yang sepenuhnya terhubung, InputType untuk layer ini feedForward (15), parameter 15 tidak mempengaruhi model (nilai integer apa pun diperbolehkan). <br><br><h3>  Unduh Model Impor </h3><br>  Model dimuat melalui modul ComputationGraph: <br><br><pre> <code class="java hljs">ComputationGraph model = org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasModelAndWeights(<span class="hljs-string"><span class="hljs-string">"/home/user/Models/model1_functional.h5"</span></span>);</code> </pre> <br><h3>  Mengeluarkan data ke konsol Java </h3><br>  Di Jawa, khususnya di DL4J, tensor ditulis sebagai array dari perpustakaan Nd4j berkinerja tinggi, yang dapat dianggap sebagai analog dari perpustakaan Numpy dengan Python. <br><br>  Katakanlah string input kami terdiri dari 4 karakter.  Simbol direpresentasikan sebagai bilangan bulat (sebagai indeks), misalnya, menurut beberapa penomoran.  Array dimensi yang sesuai (4) dibuat untuk mereka. <br><br>  Misalnya, kami memiliki 4 karakter indeks-disandikan: 1, 3, 4, 8. <br><br>  Kode di Jawa: <br><br><pre> <code class="java hljs">INDArray myArray = Nd4j.zeros(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">4</span></span>); <span class="hljs-comment"><span class="hljs-comment">// one row 4 column array myArray.putScalar(0,0,1); myArray.putScalar(0,1,3); myArray.putScalar(0,2,4); myArray.putScalar(0,3,8); INDArray output = model.outputSingle(myArray); System.out.println(output);</span></span></code> </pre> <br>  Konsol akan menampilkan probabilitas untuk setiap elemen input. <br><br><h3>  Model yang Diimpor </h3><br>  Arsitektur jaringan saraf dan bobot asli diimpor tanpa kesalahan.  Baik model jaringan saraf Keras dan Java dalam mode Inferensi menyetujui hasil. <br><br>  Model python: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/om/sk/oe/omskoecug43s_gop5osadysm21m.png" alt="alt gambar"></div><br>  Model Java: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/es/qc/px/esqcpxwnhjdgrhqapedjukmvfec.png" alt="alt gambar"></div><br>  Pada kenyataannya, mengimpor model tidak sesederhana itu.  Di bawah ini kami akan menyoroti secara singkat beberapa poin yang mungkin dalam beberapa kasus kritis. <br><br>  1) Lapisan normalisasi tambalan tidak berfungsi setelah lapisan rekursif.  Masalah telah terbuka di GitHub selama hampir setahun [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">16</a> ].  Misalnya, jika Anda menambahkan lapisan ini ke model (setelah lapisan kontak), kami mendapatkan kesalahan berikut: <br><br><pre> <code class="java hljs">Exception in thread <span class="hljs-string"><span class="hljs-string">"main"</span></span> java.lang.IllegalStateException: Invalid input type: Batch norm layer expected input of type CNN, CNN Flat or FF, <span class="hljs-function"><span class="hljs-function">got </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">InputTypeRecurrent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">160</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">for</span></span></span><span class="hljs-function"> layer index -1, layer name </span></span>= batch_normalization_1</code> </pre> <br>  Dalam praktiknya, model menolak untuk bekerja, mengutip kesalahan yang sama ketika lapisan normalisasi ditambahkan setelah conv1d.  Setelah lapisan sepenuhnya terhubung, penambahan bekerja dengan sempurna. <br><br>  2) Setelah lapisan sepenuhnya terhubung, pengaturan hasil Ratakan lapisan dalam kesalahan.  Kesalahan serupa disebutkan pada Stackoverflow [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://stackoverflow.com/questions/55753493/problem-opening-a-keras-model-in-java-with-deeplearning4j-">17</a> ].  Selama enam bulan, tidak ada umpan balik. <br><br>  Jelas ini tidak semua batasan yang dapat Anda temui ketika bekerja dengan DL4J. <br>  Waktu operasi akhir untuk model ada di sini [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">18</a> ]. <br><br><h1>  Kesimpulan </h1><br>  Sebagai kesimpulan, dapat dicatat bahwa Keras-model yang diimpor tanpa kesulitan diimpor ke DL4J hanya mungkin untuk kasus-kasus sederhana (tentu saja, jika Anda tidak memiliki pengalaman seperti itu, dan memang pengetahuan yang baik tentang Jawa). <br><br>  Semakin sedikit lapisan pengguna, semakin tidak menyakitkan model yang akan diimpor, tetapi jika arsitektur jaringan rumit, Anda harus menghabiskan banyak waktu untuk mentransfernya ke DL4J. <br><br>  Dukungan dokumenter dari modul impor yang dikembangkan, jumlah contoh terkait, tampak agak lembab.  Pada setiap tahap, muncul pertanyaan baru - bagaimana cara mendaftar lapisan Lambda, kebermaknaan parameter, dll. <br><br>  Mengingat kecepatan kompleksitas arsitektur jaringan saraf dan interaksi antara lapisan, kompleksitas lapisan, DL4J belum berkembang secara aktif untuk mencapai tingkat kerangka kerja top-end untuk bekerja dengan jaringan saraf tiruan. <br><br>  Bagaimanapun, para pria layak untuk menghargai pekerjaan mereka dan ingin melihat kelanjutan pengembangan arah ini. <br><br>  <strong>Referensi</strong> <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">5 Bahasa Pemrograman terbaik untuk bidang Kecerdasan Buatan</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kerangka Pembelajaran Mendalam Skor Daya 2018</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Perbandingan perangkat lunak pembelajaran dalam</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">9 Kerangka Teratas di Dunia Kecerdasan Buatan</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DeepLearning4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Model yang tersedia</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DeepLearning4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Impor model keras.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Fitur yang didukung.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Deeplearning4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Mulai cepat</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kuliah 0: Memulai dengan DeepLearning4j</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Deeplearing4j: Impor model keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kuliah 7 |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Impor model keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Instal TensorFlow untuk Java</a> </li><li>  <a href="">Menggunakan Lapisan Keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DeepLearning4j: Kelas KerasLayer</a> </li><li>  <a href="">DeepLearning4j: SameDiffLambdaLayer.java</a> </li><li>  <a href="">DeepLearning4j: KerasLambdaTest.java</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DeepLearning4j: BatchNorm dengan RecurrentInputType</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://stackoverflow.com/questions/55753493/problem-opening-a-keras-model-in-java-with-deeplearning4j-">StackOverFlow: Masalah membuka model keras di java dengan deeplearning4j (https://deeplearning4j.org/)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GitHub: Kode lengkap untuk model yang dimaksud</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Skymind: Perbandingan Kerangka AI</a> </li></ol><br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id475338/">https://habr.com/ru/post/id475338/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id475326/index.html">Bagaimana scammers melakukan ini. Alat curang</a></li>
<li><a href="../id475328/index.html">Operasi TA505, bagian empat. Kembar</a></li>
<li><a href="../id475330/index.html">Kontes Plugin Platform Miro dengan Kelompok Hadiah $ 21.000</a></li>
<li><a href="../id475332/index.html">3. Desain Jaringan Perusahaan pada Sakelar Ekstrim</a></li>
<li><a href="../id475336/index.html">Cara berhenti dengan benar (instruksi)</a></li>
<li><a href="../id475340/index.html">AMD memperkenalkan prosesor Threadripper - CPU desktop tercepat</a></li>
<li><a href="../id475342/index.html">Andrey Sebrant (Yandex): Bisnis di Zaman Kecerdasan Buatan</a></li>
<li><a href="../id475346/index.html">Ketika militer AS mencoba membaca pikiran</a></li>
<li><a href="../id475354/index.html">Selamat Hari Spesialis Keamanan</a></li>
<li><a href="../id475358/index.html">Analisis gaji di sektor TI Armenia plus lowongan terbuka di perusahaan-perusahaan TI TOP10</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📉 👨🏻‍🔧 🔬 RESTinio est un serveur HTTP asynchrone. Asynchrone 🚵🏾 💤 💆🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a quelques années, nous avons publié RESTinio , notre petit framework OpenSource C ++ pour intégrer un serveur HTTP dans des applications C ++. R...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RESTinio est un serveur HTTP asynchrone. Asynchrone</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451728/"><p>  Il y a quelques années, nous avons publié <a href="">RESTinio</a> , notre petit framework OpenSource C ++ pour intégrer un serveur HTTP dans des applications C ++.  RESTinio n'est pas devenu très populaire pendant cette période, mais il n'a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pas</a> été <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">perdu</a> .  Quelqu'un le choisit pour la prise en charge «native» de Windows, quelqu'un pour certaines fonctionnalités individuelles (comme la prise en charge de sendfile), quelqu'un pour le rapport des fonctionnalités, la facilité d'utilisation et la personnalisation.  Mais je pense qu'au départ, de nombreux RESTinio sont attirés par ce laconique "Hello, World": </p><br><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;restinio/all.hpp&gt; int main() { restinio::run( restinio::on_this_thread() .port(8080) .address("localhost") .request_handler([](auto req) { return req-&gt;create_response().set_body("Hello, World!").done(); })); return 0; }</span></span></span></span></code> </pre> <br><p>  C'est vraiment tout ce qui est nécessaire pour exécuter le serveur HTTP dans une application C ++. </p><br><p>  Et bien que nous essayions toujours de dire que la fonctionnalité clé pour laquelle nous nous sommes généralement engagés dans RESTinio était le traitement asynchrone des demandes entrantes, nous rencontrons toujours occasionnellement des questions sur ce qu'il faut faire si à l'intérieur de request_handler vous devez effectuer de longues opérations. </p><br><p>  Et comme une telle question est pertinente, vous pouvez en reparler et donner quelques petits exemples. </p><a name="habracut"></a><br><h1 id="nebolshaya-otsylka-k-istokam">  Une petite référence aux origines </h1><br><p>  Nous avons décidé de rendre notre serveur HTTP intégrable après plusieurs fois d'affilée face à des tâches très similaires: il fallait organiser une entrée HTTP pour une application C ++ existante ou il fallait écrire un microservice dans lequel il fallait réutiliser le C ++ "lourd" déjà existant ny code.  Une caractéristique commune de ces tâches était que le traitement de la demande par l'application pouvait s'étendre sur des dizaines de secondes. </p><br><p>  En gros, pendant une milliseconde, le serveur HTTP a trié une nouvelle requête HTTP, mais pour émettre une réponse HTTP, il a fallu se tourner vers d'autres services ou effectuer de longs calculs.  Si vous traitez les requêtes HTTP en mode synchrone, le serveur HTTP aura besoin d'un pool de milliers de threads de travail, ce qui peut difficilement être considéré comme une bonne idée même dans des conditions modernes. </p><br><p>  C'est beaucoup plus pratique lorsque le serveur HTTP ne peut travailler que sur un seul thread de travail, sur lequel des E / S sont effectuées et des gestionnaires de requêtes sont appelés.  Le gestionnaire de demandes délègue simplement le traitement réel d'un autre thread de travail et renvoie le contrôle au serveur HTTP.  Lorsque, bien plus tard, quelque part sur un autre thread de travail, les informations sont prêtes à répondre à la demande, une réponse HTTP est simplement générée qui récupère automatiquement le serveur HTTP et envoie cette réponse au client approprié. </p><br><p>  Comme nous n'avons jamais trouvé de version prête à l'emploi qui soit simple et pratique à utiliser, elle était multiplateforme et supportait Windows en tant que plate-forme «native», fournirait des performances plus ou moins décentes et, plus important encore, serait affinée spécifiquement pour les applications asynchrones. travail, puis début 2017 nous avons commencé à développer RESTinio. </p><br><p>  Nous voulions créer un serveur HTTP intégrable asynchrone, facile à utiliser, libérant l'utilisateur de certains soucis de routine, tout en étant plus ou moins productif, multiplateforme et permettant une configuration flexible pour différentes conditions.  Cela semble fonctionner, mais laissons aux utilisateurs le soin de juger ... </p><br><h1 id="itak-est-vhodyaschiy-zapros-trebuyuschiy-mnogo-vremeni-na-obrabotku-chto-delat">  Il y a donc une demande entrante qui nécessite beaucoup de temps de traitement.  Que faire </h1><br><h2 id="rabochie-niti-restinioasio">  Fils de travail RESTinio / Asio </h2><br><p>  Parfois, les utilisateurs de RESTinio ne réfléchissent pas aux threads de travail et à la façon exacte d'utiliser RESTinio.  Par exemple, quelqu'un pourrait considérer que lorsque RESTinio est lancé sur un thread de travail (en utilisant <code>run(on_this_thread(...))</code> , comme dans l'exemple ci-dessus), alors sur ce thread de travail, RESTinio n'appelle que les gestionnaires de demandes.  Alors que pour les E / S, RESTinio crée un filetage séparé sous le capot.  Et ce thread séparé continue de servir de nouvelles connexions lorsque le thread de travail principal est occupé par request_handler. </p><br><p>  En fait, tous les threads que l'utilisateur alloue à RESTinio sont utilisés à la fois pour effectuer des opérations d'E / S et pour appeler des gestionnaires de requêtes.  Par conséquent, si vous avez démarré le serveur RESTinio via <code>run(on_this_thread(...))</code> , puis à l'intérieur de <code>run()</code> sur le thread actuel, les E / S et les gestionnaires de requêtes seront exécutés. </p><br><p>  En gros, RESTinio lance une boucle d'événements Asio, à l'intérieur de laquelle il traite les nouvelles connexions, lit et analyse les données des connexions existantes, écrit les données prêtes pour l'envoi, gère la fermeture des connexions, etc.  Entre autres choses, après que la requête entrante a été lue et complètement analysée à partir de la connexion suivante, le gestionnaire de requêtes spécifié par l'utilisateur est appelé pour traiter cette requête. </p><br><p>  Par conséquent, si request_handler bloque le fonctionnement du thread actuel, la boucle d'événements Asio-action travaillant sur le même thread est également bloquée.  Tout est simple. </p><br><p>  Si RESTinio est démarré sur un pool de threads de travail (c'est-à-dire au moyen de <code>run(on_thread_pool(...))</code> , comme <a href="">dans cet exemple</a> ), alors presque la même chose se produit: une boucle d'événement Asio-event est lancée sur chaque thread du pool.  Par conséquent, si certains request_handler commencent à multiplier les grandes matrices, cela bloquera le thread de travail dans le pool et les opérations d'E / S ne seront plus servies sur ce thread. </p><br><p>  Par conséquent, lorsque vous utilisez RESTinio, la tâche du développeur est de terminer ses gestionnaires de requêtes dans un délai raisonnable et, de préférence, pas très long. </p><br><h2 id="nuzhen-li-vam-pul-rabochih-potokov-dlya-restinioasio">  Avez-vous besoin d'un pool de workflows pour RESTinio / Asio? </h2><br><p>  Ainsi, lorsque le request_handler spécifié par l'utilisateur bloque le thread de travail sur lequel il est appelé pendant une longue période, ce thread perd la capacité de traiter les opérations d'E / S.  Mais que se passe-t-il si request_handler a besoin de beaucoup de temps pour former une réponse?  Supposons qu'il effectue une sorte d'opération informatique lourde, dont le temps, en principe, ne peut pas être raccourci à quelques millisecondes? </p><br><p>  L'un des utilisateurs pourrait penser que, puisque RESTinio peut fonctionner sur un pool de threads de travail, il suffit de spécifier la plus grande taille de pool et c'est tout. </p><br><p>  Malheureusement, cela ne fonctionnera que dans des cas simples lorsque vous avez peu de connexions parallèles.  Et l'intensité des requêtes est faible.  Si le nombre de requêtes parallèles atteint des milliers (au moins quelques centaines), il est facile d'obtenir une situation où tous les threads de travail du pool seront occupés à traiter des demandes déjà acceptées.  Et il ne restera plus de threads pour effectuer des opérations d'E / S.  En conséquence, le serveur perdra sa réactivité.  L'inclusion de RESTinio perdra la capacité de traiter les délais d'attente que RESTinio compte automatiquement lorsqu'il reçoit de nouvelles connexions et lors du traitement des demandes. </p><br><p>  Par conséquent, si vous devez effectuer de longues opérations de blocage pour traiter les demandes entrantes, il est préférable d'allouer un seul thread de travail pour RESTinio, mais d'affecter un grand pool de flux de travail pour effectuer ces mêmes opérations.  Le gestionnaire de demande mettra simplement la demande suivante dans une file d'attente, d'où la demande sera récupérée et soumise pour traitement. </p><br><p>  Nous avons examiné un exemple de ce schéma en détail lorsque nous avons parlé de notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet de démonstration Shrimp</a> dans cet article: " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shrimp: redimensionner et partager des images HTTP en C ++ moderne en utilisant ImageMagic ++, SObjectizer et RESTinio</a> ." </p><br><h2 id="primery-delegirovaniya-obrabotki-zaprosov-na-otdelnye-rabochie-niti">  Exemples de délégation du traitement des demandes à des threads de travail individuels </h2><br><p>  Ci-dessus, j'ai essayé d'expliquer pourquoi il n'est pas nécessaire d'effectuer un traitement long directement dans le request_handler.  D'où vient le résultat évident: le long traitement des demandes doit être délégué à un autre fil de travail.  Voyons à quoi cela pourrait ressembler. </p><br><p>  Dans les deux exemples ci-dessous, nous avons besoin d'un seul thread de travail pour exécuter RESTinio et d'un autre thread de travail pour simuler un long traitement des demandes.  Et nous avons également besoin d'une sorte de file d'attente de messages pour transférer les demandes du thread RESTinio vers un thread de travail distinct. </p><br><p>  Il n'a pas été facile pour moi de créer une nouvelle implémentation de file d'attente de messages thread-safe sur mes genoux pour ces deux exemples, j'ai donc utilisé mon SObjectizer natif et ses mchains, qui sont des canaux CSP.  Vous pouvez en savoir plus sur mchain ici: " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Échange d'informations entre les threads de travail sans douleur? Canaux CSP pour nous aider</a> ." </p><br><h3 id="sohranenie-obekta-request_handle">  Enregistrement de l'objet request_handle </h3><br><p>  La technique de base sur laquelle repose la délégation du traitement des demandes est le transfert de l'objet <code>request_handle_t</code> quelque part. </p><br><p>  Lorsque RESTinio appelle le request_handler spécifié par l'utilisateur pour traiter une demande entrante, un objet de type <code>request_handle_t</code> est passé à ce <code>request_handle_t</code> .  Ce type n'est rien de plus qu'un pointeur intelligent vers les paramètres de la demande reçue.  Donc, s'il est pratique pour quelqu'un de penser que <code>request_handle_t</code> est <code>shared_ptr</code> , vous pouvez le penser en toute sécurité.  Ce <code>shared_ptr</code> est. </p><br><p>  Et puisque <code>request_handle_t</code> est <code>shared_ptr</code> , nous pouvons passer ce pointeur intelligent quelque part en toute sécurité.  Ce que nous ferons dans les exemples ci-dessous. </p><br><p>  Nous avons donc besoin d'un thread de travail et d'un canal distincts pour communiquer avec lui.  Créons tout cela: </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//  SObjectizer. so_5::wrapped_env_t sobj; //  std::thread    . std::thread processing_thread; //    main      join. //    RAII. auto processing_thread_joiner = so_5::auto_join(processing_thread); //      . auto req_ch = so_5::create_mchain(sobj); //       main. //    RAII. auto ch_closer = so_5::auto_close_drop_content(req_ch); //     . //      main()  - , //     ,      join(). processing_thread = std::thread{ processing_thread_func, req_ch };</span></span></code> </pre> <br><p>  Le corps du thread de travail lui-même est situé à l'intérieur de la fonction <code>processing_thread_func()</code> , dont nous parlerons un peu plus tard. </p><br><p>  Maintenant, nous avons déjà un thread de travail séparé et un canal de communication avec lui.  Vous pouvez démarrer le serveur RESTinio: </p><br><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">// ,     . struct traits_t : public restinio::default_traits_t { using logger_t = restinio::shared_ostream_logger_t; }; restinio::run( restinio::on_this_thread&lt;traits_t&gt;() .port(8080) .address("localhost") .request_handler([req_ch](auto req) { //   GET-   . if(restinio::http_method_t::http_get == req-&gt;header().method() &amp;&amp; "/" == req-&gt;header().path()) { //    . so_5::send&lt;handle_request&gt;(req_ch, req); return restinio::request_accepted(); } else return restinio::request_rejected(); }) .cleanup_func([&amp;] { //      . //    , ..  req_ch //          //     . so_5::close_drop_content(req_ch); }));</span></span></code> </pre> <br><p>  La logique de ce serveur est très simple.  Si une demande GET est arrivée pour '/', nous déléguons le traitement de la demande d'un seul thread.  Pour ce faire, nous effectuons deux opérations importantes: </p><br><ul><li>  envoyer l'objet <code>request_handle_t</code> au canal CSP.  Bien que cet objet soit stocké à l'intérieur du canal CSP ou ailleurs, RESTinio sait que la demande est toujours en vie; </li><li>  nous <code>restinio::request_accepted()</code> la valeur <code>restinio::request_accepted()</code> du gestionnaire de requêtes.  Cela permet à RESTinio de comprendre que la demande a été acceptée pour traitement et que la connexion avec le client ne peut pas être fermée. </li></ul><br><p>  Le fait que request_handler n'ait pas généré immédiatement une réponse RESTinio ne dérange pas.  Une fois <code>restinio::request_accepted()</code> retourné, l'utilisateur a pris la responsabilité de traiter la demande et un jour la réponse à la demande sera générée. </p><br><p>  Si le gestionnaire de demande a renvoyé <code>restinio::request_rejected()</code> , alors RESTinio comprend que la demande ne sera pas traitée et renverra une erreur 501 au client. </p><br><p>  Donc, nous fixons le résultat préliminaire: l'instance <code>request_handle_t</code> peut être passée quelque part, car il s'agit en fait de <code>std::shared_ptr</code> .  Tant que cette instance est vivante, RESTinio considère que la demande est en cours de traitement.  Si le gestionnaire de demande a renvoyé <code>restinio::request_accepted()</code> , alors RESTinio ne s'inquiétera pas que la réponse à la demande n'ait pas été générée pour l'instant. </p><br><p>  Maintenant, nous pouvons regarder la mise en œuvre de ce fil très distinct: </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">processing_thread_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(so_5::</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">mchain_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> req_ch)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//       //    . std::random_device rd; std::mt19937 generator{rd()}; std::uniform_int_distribution&lt;&gt; pause_generator{350, 3500}; //      timeout_elapsed. auto delayed_ch = so_5::create_mchain(req_ch-&gt;environment()); //     -  . bool stop = false; select( so_5::from_all() //      . .on_close([&amp;stop](const auto &amp;) { stop = true; }) //     select(). //  select()     . .stop_on([&amp;stop]{ return stop; }), //   handle_request     RESTinio. case_(req_ch, [&amp;](handle_request cmd) { //     . const std::chrono::milliseconds pause{pause_generator(generator)}; //     . so_5::send_delayed&lt;timeout_elapsed&gt;(delayed_ch, //    timeout_elapsed. pause, //      timeout_elapsed. cmd.m_req, pause); }), //   timeout_elapsed. case_(delayed_ch, [](timeout_elapsed cmd) { //     . cmd.m_req-&gt;create_response() .set_body("Hello, World! (pause:" + std::to_string(cmd.m_pause.count()) + "ms)") .done(); }) ); }</span></span></code> </pre> <br><p>  La logique ici est très simple: nous obtenons la demande initiale sous la forme d'un message <code>handle_request</code> et nous la transmettons sous la forme d'un message <code>timeout_elapsed</code> retardé pendant un certain temps aléatoire.  Nous n'effectuons le traitement réel de la demande qu'à réception de <code>timeout_elapsed</code> . </p><br><p>  <strong>Upd.</strong>  Lorsque la méthode <code>done()</code> est appelée sur un thread de travail distinct, RESTinio est averti qu'une réponse toute prête est apparue et doit être écrite sur la connexion TCP.  RESTinio lance l'opération d'écriture, mais l'opération d'E / S elle-même ne sera pas exécutée lorsque <code>done()</code> appelée, mais lorsque RESTinio effectue les E / S et appelle request_handlers.  C'est-à-dire  dans cet exemple, <code>done()</code> est appelée sur un thread de travail séparé et l'opération d'écriture sera effectuée sur le thread principal, où <code>restinio::run()</code> fonctionne. </p><br><p>  Les messages eux-mêmes sont les suivants: </p><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">handle_request</span></span></span><span class="hljs-class"> {</span></span> restinio::<span class="hljs-keyword"><span class="hljs-keyword">request_handle_t</span></span> m_req; }; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">timeout_elapsed</span></span></span><span class="hljs-class"> {</span></span> restinio::<span class="hljs-keyword"><span class="hljs-keyword">request_handle_t</span></span> m_req; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::chrono::milliseconds m_pause; };</code> </pre> <br><p>  C'est-à-dire  un thread de travail séparé prend <code>request_handle_t</code> et l'enregistre jusqu'à ce que l'occasion se présente de former une réponse complète.  Et lorsque cette opportunité se présente, <code>create_response()</code> est appelée sur l'objet de demande enregistré et la réponse est renvoyée à RESTinio.  Ensuite, RESTinio déjà dans son contexte de travail écrit la réponse en relation avec le client correspondant. </p><br><p>  Ici, l'instance <code>timeout_elapsed</code> est stockée dans un message différé <code>timeout_elapsed</code> , car il n'y a pas de traitement réel dans cet exemple primitif.  Dans une application réelle, <code>request_handle_t</code> peut être stocké dans une sorte de file d'attente ou à l'intérieur d'un objet créé pour traiter la demande. </p><br><p>  Le code complet de cet exemple se trouve <a href="">parmi les exemples réguliers de RESTinio</a> . </p><br><h4 id="neskolko-nebolshih-poyasneniy-po-kodu">  Quelques petites notes de code </h4><br><p>  Cette construction définit les propriétés RESTinio qu'un serveur RESTinio devrait avoir: </p><br><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">// ,     . struct traits_t : public restinio::default_traits_t { using logger_t = restinio::shared_ostream_logger_t; }; restinio::run( restinio::on_this_thread&lt;traits_t&gt;()</span></span></code> </pre> <br><p>  Pour cet exemple, j'ai besoin de RESTinio pour enregistrer ses actions de traitement des demandes.  Par conséquent, j'ai défini <code>logger_t</code> être différent du <code>null_logger_t</code> par défaut.  Mais depuis  RESTinio fonctionnera, en fait, sur plusieurs threads (RESTinio traite les demandes entrantes sur le thread principal, mais les réponses viennent d'un thread de travail séparé), alors vous avez besoin d'un enregistreur thread-safe, qui est <code>shared_ostream_logger_t</code> . </p><br><p>  À l'intérieur de <code>processing_thread_func()</code> , la fonction SObjectizer <code>select()</code> , ce qui est quelque peu similaire à la construction de sélection Go-shn: vous pouvez lire et traiter les messages de plusieurs canaux à la fois.  La fonction <code>select()</code> fonctionne jusqu'à ce que tous les canaux qui lui sont passés soient fermés.  Ou jusqu'à ce qu'on lui dise de force qu'il est temps de mettre fin. </p><br><p>  Dans le même temps, si le canal de communication avec le serveur RESTinio est fermé, il est inutile de poursuivre le travail.  Par conséquent, dans <code>select()</code> , la réponse à la fermeture de l'un des canaux est déterminée: dès qu'un canal est fermé, le drapeau d'arrêt est levé.  Et cela conduira à l'achèvement de <code>select()</code> et à la sortie de <code>processing_thread_func()</code> . </p><br><h3 id="sohranenie-obekta-response_builder">  Enregistrement de l'objet response_builder </h3><br><p>  Dans l'exemple précédent, nous avons considéré un cas simple où il est possible d'enregistrer <code>request_handle_t</code> jusqu'à ce que nous puissions immédiatement donner la réponse entière à la demande. </p><br><p>  Mais il peut y avoir des scénarios plus complexes lorsque, par exemple, vous devez donner une réponse en plusieurs parties.  Autrement dit, nous recevons une demande, nous ne pouvons immédiatement former que la première partie de la réponse.  Nous le formons.  Ensuite, après un certain temps, nous avons la possibilité de former la deuxième partie de la réponse.  Ensuite, après un peu plus de temps, nous pouvons former la partie suivante, etc. </p><br><p>  De plus, il peut être souhaitable pour nous que toutes ces parties disparaissent au fur et à mesure que nous les formons.  C'est-à-dire  Tout d'abord, la première partie de la réponse pour que le client puisse la soustraire, puis la deuxième, puis la troisième, etc. </p><br><p>  RESTinio vous permet de le faire en raison de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">différents types de responce_builders</a> .  En particulier, des types tels que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">user_controlled_output</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chunked_output</a> . </p><br><p>  Dans ce cas, il ne suffit pas d'enregistrer <code>request_handle_t</code> , car <code>request_handle_t</code> ne sera utile que jusqu'au premier appel à <code>create_reponse()</code> .  Ensuite, nous devons travailler avec response_builder.  Et bien ... </p><br><p>  Eh bien, ça va.  Response_builder est un type mobile, quelque peu similaire à unique_ptr.  Nous pouvons donc le conserver aussi longtemps que nous en avons besoin.  Et pour montrer à quoi ça ressemble, on refait légèrement l'exemple ci-dessus.  Laissez la fonction <code>processing_thread_func()</code> former la réponse en plusieurs parties. </p><br><p>  Ce n'est pas du tout difficile. </p><br><p>  Nous devons d'abord décider des types dont le nouveau <code>processing_thread_func()</code> aura besoin: </p><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">handle_request</span></span></span><span class="hljs-class"> {</span></span> restinio::<span class="hljs-keyword"><span class="hljs-keyword">request_handle_t</span></span> m_req; }; <span class="hljs-comment"><span class="hljs-comment">//     . using output_t = restinio::chunked_output_t; //   reponse_builder-   . using response_t = restinio::response_builder_t&lt;output_t&gt;; //     . struct timeout_elapsed { response_t m_resp; int m_counter; };</span></span></code> </pre> <br><p>  Le message <code>handle_request</code> reste inchangé.  Mais dans le message <code>timeout_elapsed</code> nous stockons maintenant non <code>request_handle_t</code> , mais response_builder du type dont nous avons besoin.  Plus un compteur des pièces restantes.  Dès que ce compteur est réinitialisé, le service de demande se termine. </p><br><p>  Maintenant, nous pouvons regarder une nouvelle version de la fonction <code>processing_thread_func()</code> : </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">processing_thread_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(so_5::</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">mchain_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> req_ch)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::random_device rd; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::mt19937 generator{rd()}; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::uniform_int_distribution&lt;&gt; pause_generator{<span class="hljs-number"><span class="hljs-number">350</span></span>, <span class="hljs-number"><span class="hljs-number">3500</span></span>}; <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> delayed_ch = so_5::create_mchain(req_ch-&gt;environment()); <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> stop = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; select( so_5::from_all() .on_close([&amp;stop](<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> &amp;) { stop = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; }) .stop_on([&amp;stop]{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> stop; }), case_(req_ch, [&amp;](handle_request cmd) { <span class="hljs-comment"><span class="hljs-comment">//    ,    . auto resp = cmd.m_req-&gt;create_response&lt;output_t&gt;(); resp.append_header( restinio::http_field::server, "RESTinio" ) .append_header_date_field() .append_header( restinio::http_field::content_type, "text/plain; charset=utf-8" ); //    ,  RESTinio //   . resp.flush(); //       . so_5::send_delayed&lt;so_5::mutable_msg&lt;timeout_elapsed&gt;&gt;(delayed_ch, //     . std::chrono::milliseconds{pause_generator(generator)}, //    timeout_elapsed. //     response_builder-  . std::move(resp), 3); }), case_(delayed_ch, [&amp;](so_5::mutable_mhood_t&lt;timeout_elapsed&gt; cmd) { //      . cmd-&gt;m_resp.append_chunk( "this is the next part of the response\n" ); //  RESTinio   . cmd-&gt;m_resp.flush(); cmd-&gt;m_counter -= 1; if( 0 != cmd-&gt;m_counter ) { //        . so_5::send_delayed( delayed_ch, std::chrono::milliseconds{pause_generator(generator)}, std::move(cmd)); } else // ,   . cmd-&gt;m_resp.done(); }) ); }</span></span></code> </pre> <br><p>  C'est-à-dire     ,        .       .         . </p><br><p> <strong>Upd.</strong>   <code>flush()</code>   ,     <code>done()</code> : RESTinio   ,   I/O-    ,   <code>flush()</code> ,  ,  RESTinio  -   request_handler-.  C'est-à-dire    <code>flush()</code>     ,        , ,   <code>restinio::run()</code> . </p><br><p>       ,    RESTinio    : </p><br><pre> <code class="plaintext hljs">[2019-05-13 15:02:35.106] TRACE: starting server on 127.0.0.1:8080 [2019-05-13 15:02:35.106] INFO: init accept #0 [2019-05-13 15:02:35.106] INFO: server started on 127.0.0.1:8080 [2019-05-13 15:02:39.050] TRACE: accept connection from 127.0.0.1:49280 on socket #0 [2019-05-13 15:02:39.050] TRACE: [connection:1] start connection with 127.0.0.1:49280 [2019-05-13 15:02:39.050] TRACE: [connection:1] start waiting for request [2019-05-13 15:02:39.050] TRACE: [connection:1] continue reading request [2019-05-13 15:02:39.050] TRACE: [connection:1] received 78 bytes [2019-05-13 15:02:39.050] TRACE: [connection:1] request received (#0): GET / [2019-05-13 15:02:39.050] TRACE: [connection:1] append response (#0), flags: { not_final_parts, connection_keepalive }, write group size: 1 [2019-05-13 15:02:39.050] TRACE: [connection:1] start next write group for response (#0), size: 1 [2019-05-13 15:02:39.050] TRACE: [connection:1] start response (#0): HTTP/1.1 200 OK [2019-05-13 15:02:39.050] TRACE: [connection:1] sending resp data, buf count: 1, total size: 167 [2019-05-13 15:02:39.050] TRACE: [connection:1] outgoing data was sent: 167 bytes [2019-05-13 15:02:39.050] TRACE: [connection:1] finishing current write group [2019-05-13 15:02:39.050] TRACE: [connection:1] should keep alive [2019-05-13 15:02:40.190] TRACE: [connection:1] append response (#0), flags: { not_final_parts, connection_keepalive }, write group size: 3 [2019-05-13 15:02:40.190] TRACE: [connection:1] start next write group for response (#0), size: 3 [2019-05-13 15:02:40.190] TRACE: [connection:1] sending resp data, buf count: 3, total size: 42 [2019-05-13 15:02:40.190] TRACE: [connection:1] outgoing data was sent: 42 bytes [2019-05-13 15:02:40.190] TRACE: [connection:1] finishing current write group [2019-05-13 15:02:40.190] TRACE: [connection:1] should keep alive [2019-05-13 15:02:43.542] TRACE: [connection:1] append response (#0), flags: { not_final_parts, connection_keepalive }, write group size: 3 [2019-05-13 15:02:43.542] TRACE: [connection:1] start next write group for response (#0), size: 3 [2019-05-13 15:02:43.542] TRACE: [connection:1] sending resp data, buf count: 3, total size: 42 [2019-05-13 15:02:43.542] TRACE: [connection:1] outgoing data was sent: 42 bytes [2019-05-13 15:02:43.542] TRACE: [connection:1] finishing current write group [2019-05-13 15:02:43.542] TRACE: [connection:1] should keep alive [2019-05-13 15:02:46.297] TRACE: [connection:1] append response (#0), flags: { not_final_parts, connection_keepalive }, write group size: 3 [2019-05-13 15:02:46.297] TRACE: [connection:1] start next write group for response (#0), size: 3 [2019-05-13 15:02:46.297] TRACE: [connection:1] sending resp data, buf count: 3, total size: 42 [2019-05-13 15:02:46.297] TRACE: [connection:1] append response (#0), flags: { final_parts, connection_keepalive }, write group size: 1 [2019-05-13 15:02:46.297] TRACE: [connection:1] outgoing data was sent: 42 bytes [2019-05-13 15:02:46.298] TRACE: [connection:1] finishing current write group [2019-05-13 15:02:46.298] TRACE: [connection:1] should keep alive [2019-05-13 15:02:46.298] TRACE: [connection:1] start next write group for response (#0), size: 1 [2019-05-13 15:02:46.298] TRACE: [connection:1] sending resp data, buf count: 1, total size: 5 [2019-05-13 15:02:46.298] TRACE: [connection:1] outgoing data was sent: 5 bytes [2019-05-13 15:02:46.298] TRACE: [connection:1] finishing current write group [2019-05-13 15:02:46.298] TRACE: [connection:1] should keep alive [2019-05-13 15:02:46.298] TRACE: [connection:1] start waiting for request [2019-05-13 15:02:46.298] TRACE: [connection:1] continue reading request [2019-05-13 15:02:46.298] TRACE: [connection:1] EOF and no request, close connection [2019-05-13 15:02:46.298] TRACE: [connection:1] close [2019-05-13 15:02:46.298] TRACE: [connection:1] close: close socket [2019-05-13 15:02:46.298] TRACE: [connection:1] close: timer canceled [2019-05-13 15:02:46.298] TRACE: [connection:1] close: reset responses data [2019-05-13 15:02:46.298] TRACE: [connection:1] destructor called</code> </pre> <br><p>   ,  RESTinio           167 .          ,           , RESTinio          . </p><br><p>   ,    RESTinio   -     response_builder     ,        . </p><br><p>      .        , ,     .       response_builder   .     ,   responce_builder       ,          .. </p><br><p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> . </p><br><h2 id="chto-budet-esli-obrabotka-zaprosa-zaymet-slishkom-mnogo-vremeni">  ,       ? </h2><br><p> ,   request_handler-     -   .  ,      ,           ? </p><br><p>  RESTinio    ,   -  request_handler-.    - ,     , RESTinio       . ,         . , : </p><br><pre> <code class="plaintext hljs">[2019-05-13 15:32:23.618] TRACE: starting server on 127.0.0.1:8080 [2019-05-13 15:32:23.618] INFO: init accept #0 [2019-05-13 15:32:23.618] INFO: server started on 127.0.0.1:8080 [2019-05-13 15:32:26.768] TRACE: accept connection from 127.0.0.1:49502 on socket #0 [2019-05-13 15:32:26.768] TRACE: [connection:1] start connection with 127.0.0.1:49502 [2019-05-13 15:32:26.768] TRACE: [connection:1] start waiting for request [2019-05-13 15:32:26.768] TRACE: [connection:1] continue reading request [2019-05-13 15:32:26.768] TRACE: [connection:1] received 78 bytes [2019-05-13 15:32:26.768] TRACE: [connection:1] request received (#0): GET / [2019-05-13 15:32:30.768] TRACE: [connection:1] handle request timed out [2019-05-13 15:32:30.768] TRACE: [connection:1] close [2019-05-13 15:32:30.768] TRACE: [connection:1] close: close socket [2019-05-13 15:32:30.768] TRACE: [connection:1] close: timer canceled [2019-05-13 15:32:30.768] TRACE: [connection:1] close: reset responses data [2019-05-13 15:32:31.768] WARN: [connection:1] try to write response, while socket is closed [2019-05-13 15:32:31.768] TRACE: [connection:1] destructor called</code> </pre> <br><p>   -       . ,      ,  RESTinio   , ..     . </p><br><p>   -    <code>handle_request_timeout</code> ,     RESTinio- ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ). </p><br><h1 id="zaklyuchenie">  Conclusion </h1><br><p> ,   ,      RESTinio —   ,   .  ,     RESTinio,    ,        RESTinio,     . </p><br><p>      RESTinio        ,  , ,  :  ? -  ? -  ? - -  ? </p><br><p>  PS.    RESTinio     ,   SObjectizer,    .  ,  -   RESTinio ,     : " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> C++      HTTP-   </a> ", " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> HTTP-  C++:   RESTinio,   libcurl.  1</a> ", " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Shrimp:     HTTP    C++  ImageMagic++, SObjectizer  RESTinio</a> " </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451728/">https://habr.com/ru/post/fr451728/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451718/index.html">Créer un assistant vocal</a></li>
<li><a href="../fr451720/index.html">Chargement de FIAS dans la base de données sur MSSQLSERVER par des moyens improvisés (SQLXMLBULKLOAD). Comment cela (probablement) n'a pas besoin d'être fait</a></li>
<li><a href="../fr451722/index.html">Bibliothèque de widgets asynchrones Qt-async</a></li>
<li><a href="../fr451724/index.html">Skyrmion à skyrmion discord: skyrmions polaires tridimensionnels dans les ferroélastiques</a></li>
<li><a href="../fr451726/index.html">Vous cherchez du travail à l'étranger: 7 conseils simples pour les professionnels de l'informatique</a></li>
<li><a href="../fr451738/index.html">Brève revue de l'article "DeViSE: un modèle d'intégration visuelle et sémantique profonde"</a></li>
<li><a href="../fr451742/index.html">Un jour avant DotNext 2019 Piter. Annonce de diffusion gratuite</a></li>
<li><a href="../fr451746/index.html">MegaSlerm pour les ingénieurs et architectes Kubernetes</a></li>
<li><a href="../fr451748/index.html">Surveillance de l'état du SSD dans les baies Qsan</a></li>
<li><a href="../fr451750/index.html">Livre "Elasticsearch, Kibana, Logstash et Next Generation Search Engine"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
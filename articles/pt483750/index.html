<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚åöÔ∏è üë©üèª‚Äçüíº üöµüèΩ Tradu√ß√£o do livro de Andrew Un, Passion for Machine Learning, Cap√≠tulos 30 - 32 üñêüèº üåï ‚≠êÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="cap√≠tulos anteriores 
 30. Interpreta√ß√£o da curva de aprendizado: grande vi√©s 


 Suponha que sua curva de erro em uma amostra de valida√ß√£o tenha a se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tradu√ß√£o do livro de Andrew Un, Passion for Machine Learning, Cap√≠tulos 30 - 32</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483750/"><p>  <a href="https://habr.com/ru/post/429832/">cap√≠tulos anteriores</a> </p><br><h1 id="30-interpretaciya-krivoy-obucheniya-bolshoe-smeschenie">  30. Interpreta√ß√£o da curva de aprendizado: grande vi√©s </h1><br><p>  Suponha que sua curva de erro em uma amostra de valida√ß√£o tenha a seguinte apar√™ncia: <br><img src="https://habrastorage.org/webt/fi/oy/fz/fioyfz5q4qb98cjga-aesqkuxea.png" alt="imagem"></p><br><p>  J√° dissemos que, se um erro de algoritmo na amostra de valida√ß√£o atingir um plat√¥, √© improv√°vel que voc√™ atinja o n√≠vel de qualidade desejado simplesmente adicionando dados. </p><br><p>  Mas √© dif√≠cil imaginar como ser√° a extrapola√ß√£o da curva da depend√™ncia da qualidade do algoritmo na amostra de valida√ß√£o (erro de desenvolvimento) ao adicionar dados.  E se a amostra de valida√ß√£o for pequena, responder a essa pergunta √© ainda mais dif√≠cil devido ao fato de a curva ser barulhenta (com uma grande variedade de pontos). </p><br><p>  Suponha que adicionamos ao nosso gr√°fico uma curva da depend√™ncia da magnitude do erro na quantidade de dados da amostra de teste e obtivemos a seguinte imagem: </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/webt/gf/3e/m-/gf3em-wuh6vtvru1w-pyd2lypog.png" alt="imagem"></p><br><p>  Observando essas duas curvas, voc√™ pode ter certeza absoluta de que a adi√ß√£o de novos dados por si s√≥ n√£o produzir√° o efeito desejado (n√£o permitir√° aumentar a qualidade do algoritmo).  Onde essa conclus√£o pode ser tirada? <br>  Vamos lembrar os dois pontos a seguir: </p><br><ul><li>  Se adicionarmos mais dados ao conjunto de treinamento, o erro do algoritmo no conjunto de treinamento poder√° aumentar apenas.  Assim, a linha azul do nosso gr√°fico n√£o muda ou aumenta rapidamente e se afasta do n√≠vel de qualidade desejado do nosso algoritmo (linha verde). </li><li>  A linha de erro vermelha na amostra de valida√ß√£o geralmente √© maior que a linha de erro azul do algoritmo na amostra de treinamento.  Assim, sob quaisquer circunst√¢ncias conceb√≠veis, a adi√ß√£o de dados n√£o levar√° a uma diminui√ß√£o adicional na linha vermelha, nem a aproximar√° do n√≠vel de erro desejado.  Isso √© quase imposs√≠vel, pois mesmo o erro na amostra de treinamento √© maior que o desejado. </li></ul><br><p>  A considera√ß√£o de ambas as curvas da depend√™ncia do erro do algoritmo na quantidade de dados nas amostras de valida√ß√£o e treinamento no mesmo gr√°fico permite extrapolar com mais confian√ßa a curva de erro do algoritmo de aprendizado da quantidade de dados na amostra de valida√ß√£o. </p><cut></cut><br><p>  Suponha que tenhamos uma estimativa da qualidade desejada do algoritmo na forma de um n√≠vel √≥timo de erros em nosso sistema.  Nesse caso, os gr√°ficos acima s√£o uma ilustra√ß√£o de um caso "manual" padr√£o de como a curva de aprendizado se parece com um alto n√≠vel de vi√©s remov√≠vel.  No maior tamanho de amostra de treinamento, presumivelmente correspondendo a todos os dados que temos √† nossa disposi√ß√£o, existe uma grande lacuna entre o erro do algoritmo na amostra de treinamento e a qualidade desejada do algoritmo, o que indica um alto n√≠vel de vi√©s evitado.  Al√©m disso, a diferen√ßa entre o erro na amostra de treinamento e o erro na amostra de valida√ß√£o √© pequena, o que indica uma pequena dispers√£o. </p><br><p>  Anteriormente, discutimos os erros de algoritmos treinados em amostras de treinamento e valida√ß√£o apenas no ponto mais √† direita acima do gr√°fico que corresponde ao uso de todos os dados de treinamento dispon√≠veis.  A curva das depend√™ncias do erro na quantidade de dados da amostra de treinamento, constru√≠da para diferentes tamanhos da amostra usada para treinamento, fornece uma imagem mais completa da qualidade do algoritmo treinado em diferentes tamanhos da amostra de treinamento. </p><cut></cut><br><h1 id="31-interpretaciya-krivoy-obucheniya-ostalnye-sluchai">  31. Interpreta√ß√£o da curva de aprendizado: outros casos </h1><br><p>  Considere a curva de aprendizado: <br><img src="https://habrastorage.org/webt/mh/q1/ws/mhq1wskh19gbk_pu7hifvuhodg4.png" alt="imagem"></p><br><p>  Existe um vi√©s alto, uma an√°lise alta ou os dois ao mesmo tempo? </p><br><p>  A curva de erro azul nos dados de treinamento √© relativamente baixa, a curva de erro vermelha nos dados de valida√ß√£o √© significativamente maior que o erro azul nos dados de treinamento.  Portanto, neste caso, o vi√©s √© pequeno, mas a propaga√ß√£o √© grande.  Adicionar mais dados de treinamento pode ajudar a fechar a lacuna entre o erro na amostra de valida√ß√£o e o erro na amostra de treinamento. </p><cut></cut><br><p>  Agora considere este gr√°fico: </p><br><p><img src="https://habrastorage.org/webt/oy/uv/dg/oyuvdgzaf9bj_fvz8ywfpjn4zgq.png" alt="imagem"></p><br><p>  Nesse caso, o erro na amostra de treinamento √© grande, √© significativamente maior que o algoritmo correspondente ao n√≠vel de qualidade desejado.  O erro na amostra de valida√ß√£o tamb√©m √© significativamente maior que o erro na amostra de treinamento.  Assim, estamos lidando com vi√©s e dispers√£o simultaneamente grandes.  Voc√™ deve procurar maneiras de reduzir, compensar e dispersar seu algoritmo. </p><br><h1 id="32-postroenie-krivyh-obucheniya">  32. Construindo curvas de aprendizado </h1><br><p>  Suponha que voc√™ tenha uma amostra de treinamento muito pequena, consistindo em apenas 100 exemplos.  Voc√™ treina seu algoritmo usando um subconjunto selecionado aleatoriamente de 10 exemplos, depois de 20 exemplos, depois de 30 e assim por diante para 100, aumentando o n√∫mero de exemplos com um intervalo de dez exemplos.  Ent√£o, usando esses 10 pontos, voc√™ constr√≥i sua curva de aprendizado.  Voc√™ pode achar que a curva parece barulhenta (valores maiores ou menores que o esperado) para amostras de treinamento menores. </p><br><p>  Quando voc√™ treina o algoritmo com apenas 10 exemplos selecionados aleatoriamente, pode n√£o ter sorte e isso se tornar√° uma subamostra de treinamento particularmente "ruim", com uma parcela maior de exemplos amb√≠guos / marcados incorretamente.  Ou, inversamente, voc√™ pode encontrar uma subamostra de treinamento particularmente ‚Äúboa‚Äù.  A presen√ßa de uma pequena amostra de treinamento implica que o valor dos erros nas amostras de valida√ß√£o e treinamento pode estar sujeito a flutua√ß√µes aleat√≥rias. </p><cut></cut><br><p>  Se os dados usados ‚Äã‚Äãpara o seu aplicativo usando o aprendizado de m√°quina forem fortemente direcionados a uma classe (como no problema de classifica√ß√£o de gatos, em que a propor√ß√£o de exemplos negativos √© muito maior que a propor√ß√£o de positivo), ou se estamos lidando com um grande n√∫mero de classes (como reconhecimento de 100 esp√©cies diferentes de animais), ent√£o a chance de obter uma amostra de treinamento particularmente ‚Äún√£o representativa‚Äù ou ruim tamb√©m aumenta.  Por exemplo, se 80% dos seus exemplos s√£o negativos (y = 0) e apenas 20% s√£o positivos (y = 1), h√° uma boa chance de que um subconjunto de treinamento de 10 exemplos contenha apenas exemplos negativos, neste caso muito √© dif√≠cil obter algo razo√°vel do algoritmo treinado. </p><br><p>  Se, devido ao ru√≠do da curva de aprendizado na amostra de treinamento, for dif√≠cil fazer uma avalia√ß√£o das tend√™ncias, √© poss√≠vel propor as duas solu√ß√µes a seguir: </p><br><ul><li><p>  Em vez de treinar apenas um modelo para 10 exemplos de treinamento, selecione com substitui√ß√£o v√°rias (por exemplo, 3 a 10) subamostras de treinamento aleat√≥rio diferentes da amostra inicial, composta por 100 exemplos.  Treine o modelo em cada um deles e calcule para cada um desses modelos o erro na amostra de valida√ß√£o e treinamento.  Conte e plote o erro m√©dio nas amostras de treinamento e valida√ß√£o. </p><cut></cut><br><p>  <u><em>Observa√ß√£o do autor:</em></u> <em>uma amostra com uma substitui√ß√£o significa o seguinte: selecione aleatoriamente os 10 primeiros exemplos diferentes de 100 para formar a primeira subamostra de treinamento.</em>  <em>Ent√£o, para formar a segunda subamostra de treinamento, mais uma vez tomamos 10 exemplos, mas sem levar em conta aqueles selecionados na primeira subamostra (novamente entre as centenas de exemplos completos).</em>  <em>Assim, um exemplo espec√≠fico pode aparecer nas duas subamostras.</em>  <em>Isso distingue uma amostra com uma substitui√ß√£o de uma amostra sem substitui√ß√£o; no caso de uma amostra sem substitui√ß√£o, a segunda subamostra de treinamento seria selecionada de apenas 90 exemplos que n√£o se enquadravam na primeira subamostra.</em>  <em>Na pr√°tica, o m√©todo de sele√ß√£o de exemplos com ou sem substitui√ß√£o n√£o deve ser de grande import√¢ncia, mas a sele√ß√£o de exemplos com substitui√ß√£o √© pr√°tica comum.</em> </p><br></li><li><p>  Se sua amostra de treinamento for direcionada para uma das classes, ou se incluir muitas, selecione uma subamostra "equilibrada" que consiste em 10 exemplos de treinamento, selecionados aleatoriamente de 100 amostras.  Por exemplo, voc√™ pode ter certeza de que 2/10 exemplos s√£o positivos e 8/10 negativos.  Para resumir, voc√™ pode ter certeza de que a propor√ß√£o de exemplos de cada classe no conjunto de dados observado √© o mais pr√≥xima poss√≠vel de sua participa√ß√£o na amostra de treinamento inicial. </p><cut></cut><br><p>  Eu n√£o me incomodaria com nenhum desses m√©todos at√© que o gr√°fico das curvas de erro leve √† conclus√£o de que essas curvas s√£o excessivamente barulhentas, o que n√£o nos permite ver tend√™ncias compreens√≠veis.  Se voc√™ tem uma grande amostra de treinamento - digamos cerca de 10.000 exemplos e a distribui√ß√£o de suas aulas n√£o √© muito tendenciosa, talvez voc√™ n√£o precise desses m√©todos. </p><br></li></ul><br><p>  Finalmente, a constru√ß√£o de uma curva de aprendizado pode ser cara do ponto de vista computacional: por exemplo, voc√™ precisa treinar dez modelos, nos primeiros 1000 exemplos, no segundo 2000 e assim por diante at√© o √∫ltimo contendo 10.000 exemplos.  O treinamento do modelo em pequenas quantidades de dados √© muito mais r√°pido que o treinamento do modelo em amostras grandes.  Portanto, em vez de distribuir uniformemente os tamanhos das subamostras de treinamento em uma escala linear, conforme descrito acima (1000, 2000, 3000, ..., 10000), voc√™ pode treinar modelos com um aumento n√£o linear no n√∫mero de exemplos, por exemplo, 1000, 2000, 4000, 6000 e 10.000 exemplos.  Mesmo assim, deve fornecer uma compreens√£o clara da tend√™ncia da depend√™ncia da qualidade do modelo no n√∫mero de exemplos de treinamento nas curvas de aprendizado.  Obviamente, essa t√©cnica √© relevante apenas se o custo computacional do treinamento de modelos adicionais for alto. </p><cut></cut><br><p>  <a href="https://habr.com/ru/post/484680/"><em>continua√ß√£o</em></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt483750/">https://habr.com/ru/post/pt483750/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt483740/index.html">Configurando o roteamento din√¢mico (em particular o BGP) sobre o t√∫nel OpenVPN no Linux (e provavelmente * BSD)</a></li>
<li><a href="../pt483742/index.html">Procure bugs como um modo de vida</a></li>
<li><a href="../pt483744/index.html">Venda de Ano Novo</a></li>
<li><a href="../pt483746/index.html">Esta√ß√£o de entrada: passagem para a linha lunar, acesso √† esta√ß√£o marciana</a></li>
<li><a href="../pt483748/index.html">O descuido dos usu√°rios do PayPal, permitindo que eles roubem sua conta e dinheiro [Fixo]</a></li>
<li><a href="../pt483752/index.html">Onde ir: os pr√≥ximos eventos gratuitos para especialistas em TI em Moscou (14 a 18 de janeiro)</a></li>
<li><a href="../pt483754/index.html">Como medir a melhoria da equipe?</a></li>
<li><a href="../pt483756/index.html">Fazemos solicita√ß√µes HTTP, degradamos normalmente (e n√£o uma √∫nica lacuna)</a></li>
<li><a href="../pt483758/index.html">As 10 principais empresas iniciantes de desenvolvimento de aplicativos m√≥veis podem se associar em 2020</a></li>
<li><a href="../pt483762/index.html">Lan√ßamento do GitLab 12.6 com classifica√ß√µes de seguran√ßa do projeto e materiais de lan√ßamento</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
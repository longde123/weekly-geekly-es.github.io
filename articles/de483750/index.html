<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö® üßï üêô √úbersetzung des Buches von Andrew Un, Leidenschaft f√ºr maschinelles Lernen, Kapitel 30 - 32 üë©‚Äç‚öñÔ∏è ‚òØÔ∏è üë®üèæ‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="vorherige Kapitel 
 30. Lernkurveninterpretation: Gro√üe Abweichung 


 Angenommen, Ihre Fehlerkurve f√ºr ein Validierungsmuster sieht folgenderma√üen au...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√úbersetzung des Buches von Andrew Un, Leidenschaft f√ºr maschinelles Lernen, Kapitel 30 - 32</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483750/"><p>  <a href="https://habr.com/ru/post/429832/">vorherige Kapitel</a> </p><br><h1 id="30-interpretaciya-krivoy-obucheniya-bolshoe-smeschenie">  30. Lernkurveninterpretation: Gro√üe Abweichung </h1><br><p>  Angenommen, Ihre Fehlerkurve f√ºr ein Validierungsmuster sieht folgenderma√üen aus: <br><img src="https://habrastorage.org/webt/fi/oy/fz/fioyfz5q4qb98cjga-aesqkuxea.png" alt="Bild"></p><br><p>  Wir haben bereits gesagt, dass es unwahrscheinlich ist, dass Sie das gew√ºnschte Qualit√§tsniveau durch einfaches Hinzuf√ºgen von Daten erreichen, wenn ein Algorithmusfehler im Validierungsmuster ein Plateau erreicht. </p><br><p>  Es ist jedoch schwer vorstellbar, wie die Extrapolation der Kurve der Abh√§ngigkeit der Qualit√§t des Algorithmus von der Validierungsstichprobe (Dev error) beim Hinzuf√ºgen von Daten aussehen wird.  Und wenn die Validierungsstichprobe klein ist, ist die Beantwortung dieser Frage noch schwieriger, da die Kurve verrauscht sein kann (gro√üe Punktespreizung). </p><br><p>  Angenommen, wir haben unserem Diagramm eine Kurve der Abh√§ngigkeit der Gr√∂√üe des Fehlers von der Datenmenge der Testprobe hinzugef√ºgt und das folgende Bild erhalten: </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/webt/gf/3e/m-/gf3em-wuh6vtvru1w-pyd2lypog.png" alt="Bild"></p><br><p>  Wenn Sie sich diese beiden Kurven ansehen, k√∂nnen Sie absolut sicher sein, dass das Hinzuf√ºgen neuer Daten allein nicht den gew√ºnschten Effekt erzielt (wodurch die Qualit√§t des Algorithmus nicht erh√∂ht werden kann).  Wo kann diese Schlussfolgerung gezogen werden? <br>  Erinnern wir uns an die folgenden zwei Punkte: </p><br><ul><li>  Wenn wir dem Trainingssatz weitere Daten hinzuf√ºgen, kann der Algorithmusfehler im Trainingssatz nur zunehmen.  Daher √§ndert sich die blaue Linie in unserem Diagramm entweder nicht oder schleicht sich nach oben und entfernt sich von der gew√ºnschten Qualit√§tsstufe unseres Algorithmus (gr√ºne Linie). </li><li>  Die rote Fehlerzeile im Validierungsmuster ist normalerweise h√∂her als die blaue Fehlerzeile des Algorithmus im Trainingsmuster.  Daher f√ºhrt das Hinzuf√ºgen von Daten unter allen denkbaren Umst√§nden nicht zu einer weiteren Verringerung der roten Linie und bringt sie nicht n√§her an die gew√ºnschte Fehlerstufe.  Dies ist nahezu unm√∂glich, da selbst der Fehler im Trainingsmuster h√∂her ist als gew√ºnscht. </li></ul><br><p>  Durch die Ber√ºcksichtigung beider Kurven der Abh√§ngigkeit des Fehlers des Algorithmus von der Datenmenge in den Validierungs- und Trainingsstichproben in demselben Diagramm k√∂nnen Sie die Fehlerkurve des Lernalgorithmus sicherer aus der Datenmenge in der Validierungsstichprobe extrapolieren. </p><cut></cut><br><p>  Angenommen, wir haben eine Sch√§tzung der gew√ºnschten Qualit√§t des Algorithmus in Form einer optimalen Fehlerquote in unserem System.  In diesem Fall sind die obigen Grafiken ein Beispiel f√ºr einen Standard- "Lehrbuch" -Fall, wie die Lernkurve mit einem hohen Grad an entfernbarer Verzerrung aussieht.  Bei der gr√∂√üten Trainingsstichprobengr√∂√üe, die vermutlich allen uns zur Verf√ºgung stehenden Daten entspricht, besteht eine gro√üe L√ºcke zwischen dem Algorithmusfehler in der Trainingsstichprobe und der gew√ºnschten Qualit√§t des Algorithmus, was auf ein hohes Ma√ü an vermiedener Verzerrung hinweist.  Au√üerdem ist die L√ºcke zwischen dem Fehler in der Trainingsstichprobe und dem Fehler in der Validierungsstichprobe klein, was auf eine kleine Streuung hinweist. </p><br><p>  Zuvor haben wir die Fehler von Algorithmen, die an Trainings- und Validierungsmustern trainiert wurden, nur ganz rechts √ºber dem Diagramm diskutiert, was der Verwendung aller verf√ºgbaren Trainingsdaten entspricht.  Die Kurve der Abh√§ngigkeiten des Fehlers von der Datenmenge aus der Trainingsstichprobe, die f√ºr verschiedene Gr√∂√üen der f√ºr das Training verwendeten Stichprobe konstruiert wurde, gibt uns ein vollst√§ndigeres Bild der Qualit√§t des Algorithmus, der auf verschiedenen Gr√∂√üen der Trainingsstichprobe trainiert wurde. </p><cut></cut><br><h1 id="31-interpretaciya-krivoy-obucheniya-ostalnye-sluchai">  31. Lernkurveninterpretation: Andere F√§lle </h1><br><p>  Betrachten Sie die Lernkurve: <br><img src="https://habrastorage.org/webt/mh/q1/ws/mhq1wskh19gbk_pu7hifvuhodg4.png" alt="Bild"></p><br><p>  Gibt es eine hohe Verzerrung, eine hohe Analyse oder beides gleichzeitig? </p><br><p>  Die blaue Fehlerkurve in den Trainingsdaten ist relativ niedrig, die rote Fehlerkurve in den Validierungsdaten ist signifikant h√∂her als der blaue Fehler in den Trainingsdaten.  Somit ist in diesem Fall die Vorspannung gering, aber die Spreizung ist gro√ü.  Das Hinzuf√ºgen weiterer Trainingsdaten kann dazu beitragen, die L√ºcke zwischen dem Fehler im Validierungsmuster und dem Fehler im Trainingsmuster zu schlie√üen. </p><cut></cut><br><p>  Betrachten Sie nun diese Tabelle: </p><br><p><img src="https://habrastorage.org/webt/oy/uv/dg/oyuvdgzaf9bj_fvz8ywfpjn4zgq.png" alt="Bild"></p><br><p>  In diesem Fall ist der Fehler in der Trainingsstichprobe gro√ü und deutlich h√∂her als der Algorithmus, der dem gew√ºnschten Qualit√§tsniveau entspricht.  Der Fehler in der Validierungsstichprobe ist ebenfalls signifikant h√∂her als der Fehler in der Trainingsstichprobe.  Wir haben es also gleichzeitig mit gro√üer Vorspannung und Streuung zu tun.  Sie sollten nach M√∂glichkeiten suchen, Ihren Algorithmus zu reduzieren, zu versetzen und zu dispergieren. </p><br><h1 id="32-postroenie-krivyh-obucheniya">  32. Lernkurven aufbauen </h1><br><p>  Angenommen, Sie haben eine sehr kleine Stichprobe, bestehend aus nur 100 Beispielen.  Sie trainieren Ihren Algorithmus mit einer zuf√§llig ausgew√§hlten Teilmenge von 10 Beispielen, dann von 20 Beispielen, dann von 30 usw. auf 100, wobei Sie die Anzahl der Beispiele mit einem Intervall von zehn Beispielen erh√∂hen.  Mit diesen 10 Punkten erstellen Sie dann Ihre Lernkurve.  M√∂glicherweise ist die Kurve bei kleineren Trainingsmustern verrauscht (Werte h√∂her oder niedriger als erwartet). </p><br><p>  Wenn Sie den Algorithmus mit nur 10 zuf√§llig ausgew√§hlten Beispielen trainieren, haben Sie m√∂glicherweise kein Gl√ºck und dies ist ein besonders ‚Äûschlechtes‚Äú Trainingssubample mit einem gr√∂√üeren Anteil an mehrdeutigen / falsch markierten Beispielen.  Umgekehrt k√∂nnen Sie auch auf ein besonders ‚Äûgutes‚Äú Trainingssubample sto√üen.  Das Vorhandensein eines kleinen Trainingsmusters impliziert, dass der Wert von Fehlern in den Validierungs- und Trainingsmustern zuf√§lligen Schwankungen unterliegen kann. </p><cut></cut><br><p>  Wenn die Daten, die f√ºr Ihre Anwendung mit maschinellem Lernen verwendet werden, stark auf eine Klasse ausgerichtet sind (wie beim Problem der Katzenklassifizierung, bei dem der Anteil der negativen Beispiele viel gr√∂√üer ist als der Anteil der positiven), oder wenn es sich um eine gro√üe Anzahl von Klassen handelt (z. B. Erkennung von 100 verschiedenen Tierarten), dann steigt auch die Chance, eine besonders ‚Äûnicht repr√§sentative‚Äú oder schlechte Trainingsstichprobe zu erhalten.  Wenn beispielsweise 80% Ihrer Beispiele negative Beispiele sind (y = 0) und nur 20% positive Beispiele sind (y = 1), besteht eine gute Chance, dass eine Trainingsuntermenge von 10 Beispielen nur negative Beispiele enth√§lt, in diesem Fall sehr Es ist schwierig, mit dem trainierten Algorithmus etwas Vern√ºnftiges zu erreichen. </p><br><p>  Wenn es aufgrund des Rauschens der Lernkurve in der Trainingsstichprobe schwierig ist, eine Bewertung der Trends vorzunehmen, kann man die folgenden zwei L√∂sungen vorschlagen: </p><br><ul><li><p>  Anstatt nur ein Modell f√ºr 10 Trainingsbeispiele zu trainieren, w√§hlen Sie durch Ersetzen mehrere (z. B. 3 bis 10) verschiedene zuf√§llige Trainingsunterproben aus der anf√§nglichen Stichprobe aus 100 Beispielen aus.  Trainieren Sie das Modell an jedem von ihnen und berechnen Sie f√ºr jedes dieser Modelle den Fehler in der Validierungs- und Trainingsprobe.  Z√§hlen Sie den durchschnittlichen Fehler in den Trainings- und Validierungsmustern und zeichnen Sie ihn auf. </p><cut></cut><br><p>  <u><em>Anmerkung des Autors:</em></u> <em>Eine Stichprobe mit einem Ersatz bedeutet Folgendes: W√§hlen Sie zuf√§llig die ersten 10 verschiedenen Beispiele aus 100 aus, um die erste Teilstichprobe f√ºr das Training zu bilden.</em>  <em>Um das zweite Trainings-Teilmuster zu bilden, nehmen wir wiederum 10 Beispiele, jedoch ohne Ber√ºcksichtigung der im ersten Teilmuster ausgew√§hlten (wiederum aus den gesamten hundert Beispielen).</em>  <em>Daher kann in beiden Teilbeispielen ein bestimmtes Beispiel vorkommen.</em>  <em>Dies unterscheidet eine Probe mit einer Ersetzung von einer Probe ohne Ersetzung, im Fall einer Probe ohne Ersetzung w√ºrde die zweite Trainingsunterprobe aus nur 90 Beispielen ausgew√§hlt, die nicht in die erste Unterprobe fallen.</em>  <em>In der Praxis sollte die Methode der Auswahl von Beispielen mit oder ohne Substitution nicht von gro√üer Bedeutung sein, aber die Auswahl von Beispielen mit Substitution ist g√§ngige Praxis.</em> </p><br></li><li><p>  Wenn Ihre Trainingsstichprobe auf eine der Klassen ausgerichtet ist oder viele Klassen enth√§lt, w√§hlen Sie eine ‚Äûausgewogene‚Äú Unterstichprobe aus 10 Trainingsbeispielen, die zuf√§llig aus 100 Stichproben ausgew√§hlt wurden.  Sie k√∂nnen beispielsweise sicher sein, dass 2/10 Beispiele positiv und 8/10 negativ sind.  Zusammenfassend k√∂nnen Sie sicher sein, dass der Anteil der Beispiele jeder Klasse im beobachteten Datensatz so nahe wie m√∂glich an ihrem Anteil an der anf√§nglichen Trainingsstichprobe liegt. </p><cut></cut><br><p>  Ich w√ºrde mich mit keiner dieser Methoden besch√§ftigen, bis die grafische Darstellung von Fehlerkurven zu dem Schluss f√ºhrt, dass diese Kurven √ºberm√§√üig verrauscht sind, was es uns nicht erlaubt, verst√§ndliche Trends zu erkennen.  Wenn Sie eine gro√üe Stichprobe von Schulungen haben - sagen wir etwa 10.000 Beispiele - und die Verteilung Ihrer Klassen nicht sehr voreingenommen ist, ben√∂tigen Sie diese Methoden m√∂glicherweise nicht. </p><br></li></ul><br><p>  Schlie√ülich kann das Erstellen einer Lernkurve aus rechnerischer Sicht teuer sein: Sie m√ºssen beispielsweise zehn Modelle in den ersten 1000 Beispielen, im zweiten 2000 usw. trainieren, bis das letzte 10.000 Beispiele enth√§lt.  Das Modelltraining f√ºr kleine Datenmengen ist viel schneller als das Modelltraining f√ºr gro√üe Stichproben.  Anstatt die Gr√∂√üen der Trainingsteilproben wie oben beschrieben auf einer linearen Skala (1000, 2000, 3000, ..., 10000) gleichm√§√üig zu verteilen, k√∂nnen Sie Modelle mit einer nichtlinearen Zunahme der Anzahl der Beispiele trainieren, z. B. 1000, 2000, 4000, 6000 und 10.000 Beispiele.  Trotzdem sollte es Ihnen ein klares Verst√§ndnis f√ºr den Trend der Abh√§ngigkeit der Qualit√§t des Modells von der Anzahl der Trainingsbeispiele in den Lernkurven geben.  Nat√ºrlich ist diese Technik nur relevant, wenn der Rechenaufwand f√ºr das Training zus√§tzlicher Modelle hoch ist. </p><cut></cut><br><p>  <a href="https://habr.com/ru/post/484680/"><em>Fortsetzung</em></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de483750/">https://habr.com/ru/post/de483750/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de483736/index.html">Reverse Image Search: Ein Leitfaden von Bellingcat Detective Agency</a></li>
<li><a href="../de483740/index.html">Dynamisches Routing (insbesondere BGP) √ºber den OpenVPN-Tunnel unter Linux (und wahrscheinlich * BSD) einrichten</a></li>
<li><a href="../de483744/index.html">Old New Year Sale</a></li>
<li><a href="../de483746/index.html">Gateway Station: Durchgang zur Mondlinie, Zugang zur Marsstation</a></li>
<li><a href="../de483748/index.html">Die Nachl√§ssigkeit von PayPal-Nutzern, die es ihnen erlaubten, ihr Konto und Geld zu stehlen [Behoben]</a></li>
<li><a href="../de483752/index.html">Wohin: Die n√§chsten kostenlosen Veranstaltungen f√ºr IT-Spezialisten in Moskau (14.-18. Januar)</a></li>
<li><a href="../de483754/index.html">Wie kann man die Teamverbesserung messen?</a></li>
<li><a href="../de483756/index.html">Wir stellen HTTP-Anfragen, verschlechtern die Qualit√§t (und nicht eine einzige L√ºcke)</a></li>
<li><a href="../de483758/index.html">Top 10 Startups von Mobile Application Development-Unternehmen k√∂nnen 2020 eine Partnerschaft eingehen</a></li>
<li><a href="../de483762/index.html">GitLab 12.6 mit Project Safety Ratings und Release Materials ver√∂ffentlicht</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤥 🧑🏿 🚬 Klasifikasi tutupan lahan menggunakan eo-learning. Bagian 3 ⚽️ 🙅🏽 👩🏽‍🏫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Saat Anda membutuhkan hasil yang lebih baik daripada memuaskan 


 Bagian 1 
 Bagian 2 





 Transisi zona dari musim dingin ke musim panas terdiri d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Klasifikasi tutupan lahan menggunakan eo-learning. Bagian 3</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/453354/"><p>  Saat Anda membutuhkan hasil yang lebih baik daripada memuaskan </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 1</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 2</a> </p><br><p><img src="https://habrastorage.org/webt/c0/ls/b2/c0lsb2it_c9qwggm74kdk3uglw4.png"></p><br><p> <em>Transisi zona dari musim dingin ke musim panas terdiri dari gambar Sentinel-2.</em>  <em>Anda dapat melihat beberapa perbedaan dalam jenis penutup di salju, yang telah dijelaskan dalam artikel sebelumnya.</em> </p><a name="habracut"></a><br><h2 id="predislovie">  Kata Pengantar </h2><br><p> Beberapa minggu terakhir sangat sulit.  Kami menerbitkan bagian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertama</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kedua</a> dari artikel kami tentang klasifikasi tutupan di seluruh negara menggunakan kerangka <code>eo-learn</code> .  <code>eo-learn</code> learning adalah pustaka sumber terbuka untuk membuat lapisan antara menerima dan memproses gambar satelit dan pembelajaran mesin.  Dalam artikel sebelumnya dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">contoh,</a> kami menunjukkan hanya sebagian kecil dari data dan menunjukkan hasilnya hanya pada persentase kecil dari seluruh area yang diminati (AOI - area of ​​interest).  Saya tahu bahwa ini terlihat setidaknya tidak terlalu mengesankan, dan mungkin sangat kasar di pihak kami.  Selama ini Anda telah tersiksa oleh pertanyaan tentang bagaimana Anda dapat menggunakan pengetahuan ini dan mentransfernya ke tingkat <em>berikutnya</em> . </p><br><p>  Jangan khawatir, ini untuk apa artikel ketiga dalam seri ini!  Ambil secangkir kopi dan duduk ... </p><br><h2 id="all-our-data-are-belong-to-you">  Semua Data kami Milik Anda! </h2><br><p>  Apakah kamu sudah duduk?  Mungkin tinggalkan kopi di atas meja sebentar, karena sekarang Anda akan mendengar berita terbaik untuk hari ini ... <br>  Kami di Sinergise memutuskan untuk menerbitkan set data lengkap untuk Slovenia untuk 2017.  Gratis.  Anda dapat dengan bebas mengakses 200GB data dalam bentuk ~ 300 fragmen EOPatch, masing-masing berukuran sekitar 1000x1000, dalam resolusi 10m!  Anda dapat membaca lebih lanjut tentang format EOPatch di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">posting terakhir</a> tentang <code>eo-learn</code> learning, tetapi sebenarnya itu adalah wadah untuk <em>geo-temporal</em> EO (Pengamatan Bumi) dan data non-EO: misalnya, gambar satelit, topeng, peta, dll. </p><br><p><img src="https://habrastorage.org/webt/dc/nt/gy/dcntgywsu4la7pdpwegv5m6eskc.png"><br>  <em>Struktur EOPatch</em> ) </p><br><p>  Kami tidak meretas ketika kami mengunduh data ini.  Setiap EOPatch berisi gambar Sentinel-2 L1C, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">s2cloudless</a> mask yang sesuai, dan peta tutupan lahan resmi dalam format raster! </p><br><p>  Data disimpan di AWS S3 di: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">http://eo-learn.sentinel-hub.com/</a> </p><br><p>  Deserializing objek EOPatch cukup sederhana: </p><br><pre> <code class="python hljs">EOPatch.load(<span class="hljs-string"><span class="hljs-string">'path_to_eopatches/eopatch-0x6/'</span></span>)</code> </pre> <br><p>  Sebagai hasilnya, Anda mendapatkan objek dari struktur berikut: </p><br><pre> <code class="python hljs">EOPatch( data: { BANDS: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>), dtype=float32) } mask: { CLM: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) IS_DATA: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) IS_VALID: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=bool) } mask_timeless: { LULC: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) VALID_COUNT: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=int64) } meta_info: { maxcc: <span class="hljs-number"><span class="hljs-number">0.8</span></span> service_type: <span class="hljs-string"><span class="hljs-string">'wcs'</span></span> size_x: <span class="hljs-string"><span class="hljs-string">'10m'</span></span> size_y: <span class="hljs-string"><span class="hljs-string">'10m'</span></span> time_difference: datetime.timedelta(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">86399</span></span>) time_interval: (datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>), datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">31</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)) } bbox: BBox(((<span class="hljs-number"><span class="hljs-number">370230.5261411405</span></span>, <span class="hljs-number"><span class="hljs-number">5085303.344972428</span></span>), (<span class="hljs-number"><span class="hljs-number">380225.31836121203</span></span>, <span class="hljs-number"><span class="hljs-number">5095400.767924464</span></span>)), crs=EPSG:<span class="hljs-number"><span class="hljs-number">32633</span></span>) timestamp: [datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>), ..., datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">25</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)], length=<span class="hljs-number"><span class="hljs-number">80</span></span> )</code> </pre> <br><p>  Akses ke berbagai atribut EOPatch adalah sebagai berikut: </p><br><pre> <code class="python hljs">eopatch.timestamp eopatch.mask[<span class="hljs-string"><span class="hljs-string">'LULC'</span></span>] eopatch.data[<span class="hljs-string"><span class="hljs-string">'CLM'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] eopatch.data[<span class="hljs-string"><span class="hljs-string">'BANDS'</span></span>][<span class="hljs-number"><span class="hljs-number">5</span></span>][..., [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]]</code> </pre> <br><h3 id="eoexecute-order-66">  Pesanan EOExecute 66 </h3><br><p>  Hebat, datanya dimuat.  Sementara kami menunggu selesainya proses ini, mari kita lihat kemampuan kelas yang belum dibahas dalam artikel ini - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><code>EOExecutor</code></a> .  Modul ini terlibat dalam pelaksanaan dan pemantauan pipa dan memungkinkan multi-threading untuk digunakan tanpa upaya yang tidak perlu.  Tidak ada lagi pencarian di Stack Overflow tentang cara memparalelkan pipa dengan benar atau bagaimana membuat progress bar bekerja dalam mode ini - kami telah melakukan segalanya untuk Anda! </p><br><p>  Selain itu, ia menangani kesalahan yang terjadi dan dapat menghasilkan ringkasan singkat dari proses eksekusi.  Yang terakhir adalah momen yang paling penting untuk memastikan pengulangan hasil Anda di masa depan, sehingga pengguna tidak harus menghabiskan waktu kerja yang berharga untuk mencari parameter yang ia gunakan Kamis lalu jam 9 pagi setelah semalaman pesta pora (jangan campur alkohol dan pemrograman layak!).  Kelas ini juga dapat menghasilkan grafik ketergantungan yang bagus untuk pipa, yang dapat Anda tunjukkan kepada bos Anda! </p><br><p><img src="https://habrastorage.org/webt/_o/x7/0q/_ox70q41_uiebqp7opyqbeu0nx0.png"><br>  <em>Grafik ketergantungan pipa yang dihasilkan oleh <code>eo-learn</code></em> </p><br><h3 id="eksperimenty-s-mashinnym-obucheniem">  Eksperimen Pembelajaran Mesin </h3><br><p>  Seperti yang dijanjikan, artikel ini terutama dimaksudkan untuk mempelajari berbagai model dengan <code>eo-learn</code> menggunakan data yang kami berikan.  Di bawah ini kami telah menyiapkan dua percobaan di mana kami mempelajari efek cloud dan algoritma resampling berbeda selama interpolasi temporal pada hasil akhir.  Setelah semua ini, kami akan mulai bekerja dengan jaringan konvolusi (CNN), dan membandingkan hasil dari dua pendekatan - analisis pixel-by-pixel dari pohon keputusan dan pembelajaran mendalam menggunakan jaringan saraf convolutional. </p><br><p>  Sayangnya, orang tidak dapat memberikan jawaban yang jelas tentang keputusan apa yang harus diambil selama percobaan.  Anda dapat mempelajari area subjek lebih dalam dan membuat asumsi untuk memutuskan apakah game tersebut layak untuk ditiru, tetapi pada akhirnya pekerjaan tersebut masih akan sampai pada coba-coba. </p><br><h3 id="igraem-s-oblakami">  Bermainlah dengan awan </h3><br><p>  Awan adalah rasa sakit yang sangat besar di dunia EO, terutama ketika datang ke algoritma pembelajaran mesin, di mana Anda ingin menentukan mereka dan menghapusnya dari kumpulan data untuk interpolasi berdasarkan nilai-nilai yang hilang.  Tetapi seberapa besar manfaat dari prosedur ini?  Apakah itu sepadan?  Rußwurm dan Körner, dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Klasifikasi Penutupan Lahan Multi-Temporal dengan artikel Sequential Recurrent Encoders,</a> bahkan menunjukkan bahwa untuk pembelajaran yang mendalam, proses penyaringan awan mungkin sama sekali tidak penting, karena pengklasifikasi itu sendiri mampu mendeteksi awan dan mengabaikannya. </p><br><p><img src="https://habrastorage.org/webt/gz/c8/zs/gzc8zsp0nrdjtgbewqqysxulaiu.png"><br>  Aktivasi lapisan input (atas) dan lapisan modulasi (bawah) dalam urutan gambar dari fragmen tertentu untuk jaringan saraf.  Anda mungkin memperhatikan bahwa fragmen jaringan ini belajar membuat topeng cloud dan memfilter hasil yang diperoleh.  (Halaman 9 di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://www.researchgate.net/publication/322975904_Multi-Temporal_Land_Cover_Classification_with_Sequential_Recurrent_Encoders</a> ) </p><br><p>  Kami mengingat secara singkat struktur langkah penyaringan data (untuk detail, lihat [artikel sebelumnya] ()).  Setelah mengambil snapshot Sentinel-2, kami mulai memfilter snapshot cloud.  Semua gambar yang jumlah pikselnya tidak berawan tidak melebihi 80% dapat disaring (nilai ambang mungkin berbeda untuk bidang minat yang berbeda).  Setelah itu, untuk mendapatkan nilai piksel pada hari yang sewenang-wenang, masker cloud digunakan agar tidak mempertimbangkan data tersebut. </p><br><p>  Secara total, empat perilaku dimungkinkan: </p><br><ol><li>  <strong>dengan</strong> filter gambar, <strong>diberi</strong> topeng cloud </li><li>  <strong>tidak ada</strong> filter snapshot, masker cloud yang <strong>diberikan</strong> </li><li>  <strong>dengan</strong> filter gambar, tidak termasuk masker cloud </li><li>  <strong>tanpa</strong> filter gambar, <strong>tidak termasuk</strong> cloud mask </li></ol><br><p><img src="https://habrastorage.org/webt/rd/3i/ne/rd3ineypd8f0akhs41yve8mtgso.png"><br>  <em>Tampilan visual dari tumpukan gambar dari satelit Sentinel-2.</em>  <em>Piksel transparan di sebelah kiri berarti piksel yang hilang karena tutupan awan.</em>  <em>Tumpukan tengah menunjukkan nilai piksel setelah memfilter gambar dan menyisipkannya dengan cloud mask (Kasus 4), dan tumpukan di sebelah kanan menunjukkan hasil interpolasi dalam case tanpa memfilter gambar dan tanpa cloud mask (1).</em>  <em>(Catatan jalur - tampaknya, artikel berisi kesalahan ketik, dan itu berarti sebaliknya - kasus 1 di tengah, dan 4 di sebelah kanan).</em> </p><br><p>  Pada artikel terakhir, kami sudah melakukan variasi kasus 1 dan menunjukkan hasilnya, jadi kami akan menggunakannya untuk perbandingan.  Mempersiapkan conveyor lain dan melatih modelnya terdengar seperti tugas sederhana - Anda hanya perlu memastikan bahwa kami membandingkan nilai yang benar.  Untuk melakukan ini, ambil set piksel yang sama untuk melatih dan memvalidasi model. </p><br><p>  Hasilnya ditunjukkan pada tabel di bawah ini.  Anda dapat melihat bahwa secara umum, pengaruh awan pada hasil model cukup rendah!  Ini mungkin disebabkan oleh fakta bahwa kartu referensi memiliki kualitas yang sangat baik dan modelnya dapat mengabaikan sebagian besar gambar.  Bagaimanapun, perilaku ini tidak dapat dijamin untuk AOI mana pun, jadi luangkan waktu Anda untuk membuang langkah ini dari model Anda! </p><br><div class="scrollable-table"><table><thead><tr><th>  Model </th><th>  Akurasi [%] </th><th>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">F_1</a> [%] </th></tr></thead><tbody><tr><td>  Tanpa filter, tanpa topeng </td><td>  92.8 </td><td>  92.6 </td></tr><tr><td>  Tanpa filter, dengan mask </td><td>  94.2 </td><td>  93.9 </td></tr><tr><td>  Dengan filter, tanpa topeng </td><td>  94.0 </td><td>  93.8 </td></tr><tr><td>  Dengan filter, dengan mask </td><td>  94.4 </td><td>  94.1 </td></tr></tbody></table></div><br><h3 id="vliyanie-raznyh-podhodov-k-resemplingu">  Dampak Berbagai Pendekatan Resampling </h3><br><p>  Pilihan opsi penempatan sementara tidak jelas.  Di satu sisi, kita membutuhkan susunan gambar yang detail yang menunjukkan detail gambar sumber dengan baik - kami ingin menyertakan jumlah gambar terdekat dengan data sumber.  Di sisi lain, kita dibatasi oleh sumber daya komputasi.  Mengurangi langkah resampling menggandakan jumlah frame setelah interpolasi, dan dengan demikian meningkatkan jumlah atribut yang digunakan dalam pelatihan.  Apakah peningkatan seperti itu sepadan dengan biaya sumber daya?  Inilah yang harus kita cari tahu. </p><br><p>  Untuk percobaan ini, kami akan menggunakan variasi 1 dari langkah sebelumnya.  Setelah interpolasi, kami melakukan pengujian ulang dengan variasi berikut: </p><br><ol><li>  Resampling seragam dengan interval 16 hari </li><li>  Resampling seragam dengan interval 8 hari </li><li>  Pilihan tanggal "terbaik", nomornya bertepatan dengan kasus 2. </li></ol><br><p>  Sampel dalam kasus 3 didasarkan pada jumlah terbesar dari tanggal umum untuk semua EOPatch di AOI yang dipilih <br><img src="https://habrastorage.org/webt/xg/qa/9w/xgqa9w17-oe4dbtxca22yejwhzo.png"><br>  <em>Grafik menunjukkan jumlah fragmen EOPatch yang berisi data untuk setiap hari 2017 (biru).</em>  <em>Garis merah menunjukkan tanggal optimal untuk resampling, yang didasarkan pada tanggal gambar Sentinel-2 untuk AOI 2017 yang diberikan.</em> </p><br><p>  Melihat tabel di bawah ini, Anda dapat melihat bahwa hasilnya tidak terlalu mengesankan, seperti dalam pengalaman masa lalu.  Untuk kasus 2 dan 3, jumlah waktu yang dihabiskan berlipat ganda, tetapi perbedaan dengan pendekatan awal kurang dari 1%.  Peningkatan semacam itu terlalu mencolok untuk penggunaan praktis, sehingga kami dapat mempertimbangkan interval 16 hari yang cocok untuk tugas tersebut. </p><br><div class="scrollable-table"><table><thead><tr><th>  Model </th><th>  Akurasi [%] </th><th>  F_1 [%] </th></tr></thead><tbody><tr><td>  Merata setiap 16 hari </td><td>  94.4 </td><td>  94.1 </td></tr><tr><td>  Merata setiap 8 hari </td><td>  94.5 </td><td>  94.3 </td></tr><tr><td>  Memilih tanggal terbaik </td><td>  94.6 </td><td>  94.4 </td></tr></tbody></table></div><br><p>  <em>Hasil akurasi keseluruhan dan F1 berbobot untuk saluran pipa yang berbeda dengan perubahan dalam pendekatan resampling.</em> </p><br><h2 id="glubokoe-obuchenie-ispolzuem-svyortochnuyu-neyronnuyu-set-cnn">  Deep Learning: Menggunakan Jaringan Neural Konvolusional (CNN) </h2><br><p>  Pembelajaran mendalam telah menjadi pendekatan standar untuk banyak tugas, seperti visi komputer, pemrosesan kata bahasa alami, dan pemrosesan sinyal.  Ini karena kemampuan mereka untuk mengekstraksi pola dari input multidimensi yang kompleks.  Pendekatan pembelajaran mesin klasik (seperti pohon keputusan) telah digunakan dalam banyak tugas geodata temporal.  Jaringan konvolusional, di sisi lain, digunakan untuk menganalisis korelasi spasial antara gambar yang berdekatan.  Pada dasarnya, penggunaannya terbatas untuk bekerja dengan gambar tunggal. </p><br><p>  Kami ingin mempelajari arsitektur model-model pembelajaran dalam, dan mencoba memilih salah satu yang mampu menganalisis aspek spasial dan temporal dari data satelit secara bersamaan. </p><br><p>  Untuk melakukan ini, kami menggunakan Netvork Sepenuhnya-Konvolusional Temporal, TFCN, atau lebih tepatnya, ekstensi temporal ke U-Net, diimplementasikan di TensorFlow.  Lebih khusus, arsitektur menggunakan korelasi spatio-temporal untuk meningkatkan hasilnya.  Keuntungan tambahan adalah bahwa struktur jaringan memungkinkan Anda untuk lebih mewakili hubungan spasial pada skala yang berbeda berkat proses encoding / decoding di U-net.  Seperti pada model klasik, pada output kita mendapatkan matriks label dua dimensi, yang akan kita bandingkan dengan kebenaran. </p><br><p><img src="https://habrastorage.org/webt/p0/jl/mg/p0jlmgxi9euwvodwonx4zrmezsw.png"></p><br><p>  Kami menggunakan model yang terlatih untuk memprediksi nilai pada set tes, dan nilai yang diperoleh diperiksa dengan kebenaran.  Secara keseluruhan, akurasi 84,4% dan F1 85,4%. </p><br><p><img src="https://habrastorage.org/webt/ol/z2/zj/olz2zjp3waghaak9hnirzcwa258.png"></p><br><p>  <em>Perbandingan berbagai prediksi untuk tugas kami.</em>  <em>Gambar visual (kiri atas), peta referensi sebenarnya (kanan atas), prediksi model LightGBM (kiri bawah) dan prediksi U-net (kanan bawah)</em> </p><br><p>  Hasil ini hanya menunjukkan pekerjaan awal pada prototipe ini, yang tidak sangat dioptimalkan untuk tugas saat ini.  Meskipun demikian, hasilnya setuju dengan beberapa statistik yang diperoleh di wilayah tersebut.  Untuk melepaskan potensi jaringan saraf, perlu mengoptimalkan arsitektur (set fitur, kedalaman jaringan, jumlah konvolusi), serta pengaturan parameter hiper (kecepatan belajar, jumlah era, bobot kelas).  Kami berharap untuk menggali lebih dalam topik ini (ha ha) bahkan lebih, dan berencana untuk mendistribusikan kode kami ketika itu dalam bentuk yang dapat diterima. </p><br><h3 id="drugie-eksperimenty">  Eksperimen lain </h3><br><p>  Anda dapat menemukan <em>banyak</em> cara untuk meningkatkan hasil Anda saat ini, tetapi kami tidak dapat memilah atau mencoba semuanya.  Pada saat itulah Anda muncul di tempat kejadian!  Tunjukkan apa yang dapat Anda lakukan dengan kumpulan data ini dan bantu kami meningkatkan hasilnya! </p><br><p>  Misalnya, dalam waktu dekat, salah satu kolega kami akan terlibat dalam klasifikasi tutupan berdasarkan tumpukan temporal gambar <em>individu</em> menggunakan jaringan konvolusi.  Idenya adalah bahwa beberapa permukaan, misalnya, yang buatan, dapat dibedakan tanpa fitur temporal - cukup spasial.  Kami akan dengan senang hati menulis artikel terpisah ketika karya ini membuahkan hasil! </p><br><h3 id="ot-perevodchika">  Dari penerjemah </h3><br><p>  Sayangnya, bagian selanjutnya dari seri artikel ini tidak keluar, yang berarti bahwa penulis tidak menunjukkan contoh kode sumber dengan membangun U-Net.  Sebagai alternatif, saya dapat menawarkan sumber-sumber berikut: </p><br><ol><li>  <em>U-Net: Jaringan Konvolusional untuk Segmentasi Gambar Biomedis - Olaf Ronneberger, Philipp Fischer, Thomas Brox</em> adalah salah satu artikel dasar tentang arsitektur U-Net yang tidak melibatkan data sementara. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://eo-learn.readthedocs.io/en/latest/examples/land-cover-map/SI_LULC_pipeline.html</a> - Halaman dokumentasi eo-learning, di mana (mungkin) versi terbaru dari jaringan pipa 1,2 bagian berada. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://github.com/divamgupta/image-segmentation-keras</a> - Repositori dengan beberapa jaringan yang diimplementasikan menggunakan keras.  Saya memiliki beberapa pertanyaan tentang implementasi (mereka sedikit berbeda dari yang dijelaskan dalam artikel asli), tetapi secara umum, solusi mudah diadaptasi untuk keperluan pribadi dan cukup berfungsi. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id453354/">https://habr.com/ru/post/id453354/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id453342/index.html">Mitos tentang karyawan jarak jauh yang kami hancurkan sendiri</a></li>
<li><a href="../id453346/index.html">Teknologi penyimpanan dan perlindungan data - hari ketiga di VMware EMPOWER 2019</a></li>
<li><a href="../id453348/index.html">Apa yang ada di dalam asyncio</a></li>
<li><a href="../id453350/index.html">Buka siaran aula utama RIT ++ 2019</a></li>
<li><a href="../id453352/index.html">Bagaimana drone mengirimkan obat-obatan penting di Ghana</a></li>
<li><a href="../id453356/index.html">Tren dan rekomendasi terkini tentang aglomerasi lembaga keuangan besar</a></li>
<li><a href="../id453360/index.html">Kota tanpa kemacetan lalu lintas</a></li>
<li><a href="../id453362/index.html">HabraConf # 1 - Mundur untuk Backend</a></li>
<li><a href="../id453364/index.html">Sebuah kisah peluncuran yang memengaruhi segalanya</a></li>
<li><a href="../id453366/index.html">Cara menggunakan koma dalam bahasa Inggris: 15 aturan dan contoh kesalahan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
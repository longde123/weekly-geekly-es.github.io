<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï∂Ô∏è ‚§¥Ô∏è ü§∞üèø Interpretiertes Modell des maschinellen Lernens. Teil 1 ‚ÄºÔ∏è üï£ üéÑ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo an alle. Vor Beginn des Kurses f√ºr maschinelles Lernen verbleibt etwas mehr als eine Woche. Im Vorgriff auf den Beginn des Unterrichts haben wir...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Interpretiertes Modell des maschinellen Lernens. Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/464695/">  <i>Hallo an alle.</i>  <i>Vor Beginn des Kurses f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">maschinelles Lernen</a> verbleibt etwas mehr als eine Woche.</i>  <i>Im Vorgriff auf den Beginn des Unterrichts haben wir eine n√ºtzliche √úbersetzung vorbereitet, die sowohl f√ºr unsere Sch√ºler als auch f√ºr alle Blog-Leser von Interesse sein wird.</i>  <i>Fangen wir an.</i> <i><br></i> <br><img src="https://habrastorage.org/webt/tl/i0/vp/tli0vprttxvthhlrnbdtrzwrguw.png"><br><hr><br>  <i>Es ist Zeit, die Black Boxes loszuwerden und Vertrauen in maschinelles Lernen aufzubauen!</i> <br><br>  In seinem Buch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûInterpretierbares maschinelles Lernen‚Äú</a> hebt Christoph Molnar die Essenz der Interpretierbarkeit des maschinellen Lernens anhand des folgenden Beispiels perfekt hervor: Stellen Sie sich vor, Sie sind ein Data Science-Experte und versuchen in Ihrer Freizeit anhand ihrer Daten von Facebook und vorherzusagen, wohin Ihre Freunde in den Sommerferien fahren werden Twitter.  Wenn die Prognose korrekt ist, werden Ihre Freunde Sie als Assistenten betrachten, der die Zukunft sehen kann.  Wenn die Vorhersagen falsch sind, schadet dies nichts anderem als Ihrem Ruf als Analyst.  Stellen Sie sich nun vor, es war nicht nur ein lustiges Projekt, sondern es wurden auch Investitionen angezogen.  Angenommen, Sie wollten in Immobilien investieren, in denen sich Ihre Freunde wahrscheinlich entspannen.  Was passiert, wenn Modellvorhersagen fehlschlagen?  Sie werden Geld verlieren.  Solange das Modell keine signifikanten Auswirkungen hat, spielt seine Interpretierbarkeit keine gro√üe Rolle. Wenn jedoch finanzielle oder soziale Konsequenzen mit den Vorhersagen des Modells verbunden sind, erh√§lt seine Interpretierbarkeit eine v√∂llig andere Bedeutung. <a name="habracut"></a><br><br><h3>  Erkl√§rtes maschinelles Lernen </h3><br>  Interpretieren hei√üt verst√§ndlich erkl√§ren oder zeigen.  Interpretierbarkeit ist im Kontext eines ML-Systems die F√§higkeit, seine Wirkung zu erkl√§ren oder in einer f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Menschen lesbaren Form</a> darzustellen. <br><br>  Viele Menschen haben Modelle des maschinellen Lernens als ‚ÄûBlack Boxes‚Äú bezeichnet.  Dies bedeutet, dass wir trotz der Tatsache, dass wir eine genaue Prognose von ihnen erhalten k√∂nnen, die Logik ihrer Zusammenstellung nicht klar erkl√§ren oder verstehen k√∂nnen.  Aber wie k√∂nnen Sie Erkenntnisse aus dem Modell gewinnen?  Welche Dinge sollten beachtet werden und welche Werkzeuge ben√∂tigen wir, um dies zu tun?  Dies sind wichtige Fragen, die sich bei der Interpretierbarkeit von Modellen stellen. <br><br><h3>  Bedeutung der Interpretierbarkeit </h3><br>  Die Frage, die sich einige Leute stellen, ist, <i>warum nicht einfach froh sein, dass wir ein konkretes Ergebnis der Modellarbeit erhalten. Warum ist es so wichtig zu wissen, wie diese oder jene Entscheidung getroffen wurde?</i>  Die Antwort liegt in der Tatsache, dass das Modell einen gewissen Einfluss auf nachfolgende Ereignisse in der realen Welt haben kann.  Die Interpretierbarkeit ist f√ºr Modelle, die Filme empfehlen sollen, viel weniger wichtig als f√ºr Modelle, die zur Vorhersage der Wirkung eines Arzneimittels verwendet werden. <br><br>  "Das Problem ist, dass nur eine Metrik, wie z. B. die Klassifizierungsgenauigkeit, eine unzureichende Beschreibung der meisten realen Aufgaben darstellt."  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Doshi Veles und Kim 2017</a> ) <br><br>  Hier ist ein gro√ües Bild √ºber erkl√§rbares maschinelles Lernen.  In gewisser Weise erfassen wir die Welt (oder vielmehr Informationen daraus), sammeln Rohdaten und verwenden sie f√ºr weitere Prognosen.  Im Wesentlichen ist die Interpretierbarkeit nur eine weitere Ebene des Modells, die den Menschen hilft, den gesamten Prozess zu verstehen. <br><br><img src="https://habrastorage.org/webt/dt/_4/qs/dt_4qs0cekctsww88fzeqtowdtw.png"><br>  <i>Der Text im Bild von unten nach oben: Welt -&gt; Informationen abrufen -&gt; Daten -&gt; Training -&gt; Black-Box-Modell -&gt; Extrahieren -&gt; Interpretationsmethoden -&gt; Personen</i> <br><br>  Einige der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vorteile</a> , die Interpretierbarkeit mit sich bringt, sind: <br><br><ul><li>  Zuverl√§ssigkeit </li><li>  Bequemes Debuggen; </li><li>  Informationen zu technischen Merkmalen; </li><li>  Verwalten der Datenerfassung f√ºr Merkmale </li><li>  Informationen zur Entscheidungsfindung; </li><li>  Vertrauen aufbauen. </li></ul><br><br><h3>  Modellinterpretationsmethoden </h3><br>  Eine Theorie macht nur Sinn, solange wir sie in die Praxis umsetzen k√∂nnen.  Wenn Sie sich wirklich mit diesem Thema befassen m√∂chten, k√∂nnen Sie versuchen, den Kurs zur Erkl√§rung des maschinellen Lernens von Kaggle zu belegen.  Darin finden Sie die richtige Korrelation von Theorie und Code, um Konzepte zu verstehen und die Konzepte der Interpretierbarkeit (Erkl√§rbarkeit) von Modellen mit realen F√§llen in die Praxis umzusetzen. <br><br>  Klicken Sie auf den Screenshot unten, um direkt zur Kursseite zu gelangen.  Wenn Sie sich zuerst einen √úberblick √ºber das Thema verschaffen m√∂chten, lesen Sie weiter. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/jf/mp/ek/jfmpekkvn5aut5szzywmkxuxzrs.png"></a> <br><br><h3>  Erkenntnisse, die aus Modellen extrahiert werden k√∂nnen </h3><br>  Um das Modell zu verstehen, ben√∂tigen wir folgende Erkenntnisse: <br><br><ul><li>  Die wichtigsten Merkmale des Modells; </li><li>  F√ºr jede spezifische Prognose des Modells die Auswirkung jedes einzelnen Attributs auf eine bestimmte Prognose. </li><li>  Der Einfluss jedes Features auf eine Vielzahl m√∂glicher Prognosen. </li></ul><br><br>  Lassen Sie uns einige Methoden diskutieren, die helfen, die obigen Erkenntnisse aus dem Modell zu extrahieren: <br><br><h3>  Permutationsbedeutung </h3><br>  Welche Funktionen h√§lt das Modell f√ºr wichtig?  Welche Symptome haben den gr√∂√üten Einfluss?  Dieses Konzept wird als Merkmalsbedeutung bezeichnet, und die Permutationsbedeutung ist eine weit verbreitete Methode zur Berechnung der Wichtigkeit von Merkmalen.  Es hilft uns zu sehen, an welchem ‚Äã‚ÄãPunkt das Modell unerwartete Ergebnisse liefert, und es hilft uns, anderen zu zeigen, dass unser Modell genau so funktioniert, wie es sollte. <br><br>  Permutationsbedeutung funktioniert f√ºr viele Scikit-Lernbewertungen.  Die Idee ist einfach: Ordnen Sie eine Spalte im Validierungsdatensatz willk√ºrlich neu an oder mischen Sie sie, wobei alle anderen Spalten intakt bleiben.  Ein Vorzeichen wird als ‚Äûwichtig‚Äú angesehen, wenn die Genauigkeit des Modells abnimmt und seine √Ñnderung zu einer Zunahme von Fehlern f√ºhrt.  Andererseits wird ein Feature als ‚Äûunwichtig‚Äú angesehen, wenn das Mischen seiner Werte die Genauigkeit des Modells nicht beeintr√§chtigt. <br><br><h3>  Wie funktioniert es </h3><br>  Stellen Sie sich ein Modell vor, das anhand bestimmter Parameter vorhersagt, ob eine Fu√üballmannschaft die Auszeichnung ‚ÄûMann des Spiels‚Äú erh√§lt oder nicht.  Diese Auszeichnung wird an den Spieler vergeben, der die besten F√§higkeiten des Spiels demonstriert. <br>  Permutation Die Wichtigkeit wird nach dem Training des Modells berechnet.  Lassen Sie uns also das <code>RandomForestClassifier</code> Modell, das als <code>my_model</code> , anhand der Trainingsdaten trainieren und vorbereiten. <br><br>  Die Permutationsbedeutung wird mithilfe der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ELI5-</a> Bibliothek berechnet.  ELI5 ist eine Bibliothek in Python, mit der Sie verschiedene Modelle des maschinellen Lernens mithilfe einer einheitlichen API visualisieren und debuggen k√∂nnen.  Es unterst√ºtzt mehrere ML-Frameworks und bietet M√∂glichkeiten zur Interpretation des Black-Box-Modells. <br><br>  Berechnung und Visualisierung der Wichtigkeit mit der ELI5-Bibliothek: <br>  (Hier bezeichnen <code>val_X</code> , <code>val_y</code> Validierungss√§tze) <br><br><img src="https://habrastorage.org/webt/f5/wi/fd/f5wifdqfixprjdvrbnzjsubqygg.png"><br><br><h3>  Interpretation </h3><br><ul><li>  Die Zeichen oben sind die wichtigsten, unten die geringsten.  In diesem Beispiel war das wichtigste Zeichen das erzielte Tor. </li><li>  Die Zahl nach ¬± ‚Äã‚Äãgibt an, wie sich die Produktivit√§t von einer Permutation zur anderen ge√§ndert hat. </li><li>  Einige Gewichte sind negativ.  Dies liegt an der Tatsache, dass sich in diesen F√§llen die Prognosen f√ºr die gemischten Daten als genauer als die tats√§chlichen Daten herausstellten. </li></ul><br><h4>  √úbe </h4><br>  Um das vollst√§ndige Beispiel anzusehen und zu √ºberpr√ºfen, ob Sie alles richtig verstanden haben, rufen Sie die Kaggle-Seite √ºber den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link auf</a> . <br><br>  Damit ging der erste Teil der √úbersetzung zu Ende.  Schreiben Sie Ihre Kommentare und treffen Sie sich auf dem Kurs! <br><br>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lesen Sie den zweiten Teil</a> .</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de464695/">https://habr.com/ru/post/de464695/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de464679/index.html">Voxgun - ein Service zum Erstellen professioneller Videoinhalte ohne zus√§tzlichen Aufwand</a></li>
<li><a href="../de464685/index.html">Optischer Telegraph, Mikrowellennetz und Tesla-Turm: ungew√∂hnliche Kommunikationst√ºrme</a></li>
<li><a href="../de464687/index.html">Wenn Sie die Welt retten wollen, ist Veganismus keine Option</a></li>
<li><a href="../de464689/index.html">Panda Frontend Meetup # 22 Inhalt: Plugins, anspruchsvolle Daten, Tests, deklarative Angular</a></li>
<li><a href="../de464691/index.html">Die Ergebnisse des Standoff-Cyberkampfs oder Wie das PT Expert Security Center Angreifer im Auge behalten hat</a></li>
<li><a href="../de464701/index.html">Effektive Startup-Site: Wie Kunden, Partner und Investoren eine Site m√∂gen</a></li>
<li><a href="../de464705/index.html">Schreiben einer API in Python (mit Flask und RapidAPI)</a></li>
<li><a href="../de464709/index.html">Lebendig und lebendig: Ransomware-Viren im Jahr 2019</a></li>
<li><a href="../de464711/index.html">Die Zahnfee funktioniert hier nicht: die Schmelzstruktur der Z√§hne von Krokodilen und ihren pr√§historischen Vorfahren</a></li>
<li><a href="../de464713/index.html">Algoreve: Wie Programmierer Partys veranstalten</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
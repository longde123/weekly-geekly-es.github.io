<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🀄️ 👊🏽 🤔 Kami mempercepat pemrosesan acara menjadi 1,6 juta per detik 👶🏻 🧘🏾 🕉️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ketika HighLoad ++ peserta datang ke laporan Alexander Krasheninnikov , mereka berharap untuk mendengar tentang pemrosesan 1.600.000 peristiwa per det...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kami mempercepat pemrosesan acara menjadi 1,6 juta per detik</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/badoo/blog/442616/">  Ketika <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++</a> peserta datang ke laporan <b>Alexander Krasheninnikov</b> , mereka berharap untuk mendengar tentang pemrosesan 1.600.000 peristiwa per detik.  Ekspektasi tidak menjadi kenyataan ... Karena selama persiapan untuk kinerja, angka ini terbang hingga <b>1.800.000</b> - jadi, di HighLoad ++, kenyataan melebihi harapan. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3 tahun yang lalu, Alexander memberi tahu</a> bagaimana mereka membangun sistem pemrosesan acara dekat waktu nyata di Badoo.  Sejak itu, ia telah berevolusi, volume telah tumbuh dalam proses, perlu untuk memecahkan masalah penskalaan dan toleransi kesalahan, dan pada saat-saat tertentu diperlukan tindakan radikal - <b>perubahan dalam tumpukan teknologi</b> . <br><br><img src="https://habrastorage.org/webt/q8/s-/cq/q8s-cqlxfrv8abkdotnudzeq1u8.jpeg"><br><br>  Dari dekripsi, Anda akan belajar bagaimana di Badoo Anda mengganti bundel Spark + Hadoop dengan ClickHouse, <b>menyimpan perangkat keras 3 kali dan menambah beban 6 kali</b> , mengapa dan dengan cara apa mengumpulkan statistik di proyek, dan kemudian apa yang harus dilakukan dengan data ini. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/5KQsNmRTQmg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  <b>Tentang pembicara:</b> Alexander Krasheninnikov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">alexkrash</a> ) - Kepala Teknik Data di Badoo.  Dia terlibat dalam infrastruktur BI, penskalaan untuk beban kerja, dan mengelola tim yang membangun infrastruktur pemrosesan data.  Dia menyukai semua yang didistribusikan: Hadoop, Spark, ClickHouse.  Saya yakin bahwa sistem terdistribusi keren dapat disiapkan dari OpenSource. <a name="habracut"></a><br><br><h2>  Koleksi statistik </h2><br>  Jika kami tidak memiliki data, kami buta dan tidak dapat mengelola proyek kami.  Itu sebabnya kami membutuhkan statistik - untuk <strong>memantau kelangsungan proyek.</strong>  Kami, sebagai insinyur, harus berusaha untuk meningkatkan produk kami, dan jika <strong>Anda ingin meningkatkan, mengukurnya.</strong>  Ini adalah moto saya dalam pekerjaan.  Pertama-tama, tujuan kami adalah keuntungan bisnis.  Statistik <strong>memberikan jawaban untuk pertanyaan bisnis</strong> .  Metrik teknis adalah metrik teknis, tetapi bisnis juga tertarik pada indikator, dan mereka juga perlu dipertimbangkan. <br><br><h2>  Statistik Siklus Hidup </h2><br>  Saya mendefinisikan siklus hidup statistik dengan 4 poin, yang masing-masing akan kita bahas secara terpisah. <br><br><img src="https://habrastorage.org/webt/pp/kb/p5/ppkbp5uw_stwtzdgmakh9z_ffbw.jpeg"><br><br><h2>  Tentukan Fase - Formalisasi </h2><br>  Dalam aplikasi, kami mengumpulkan beberapa metrik.  Pertama-tama, ini adalah <strong>metrik bisnis</strong> .  Jika Anda memiliki layanan foto, misalnya, Anda bertanya-tanya berapa banyak foto yang diunggah per hari, per jam, per detik.  Metrik berikut adalah <strong>"semi-teknis"</strong> : responsif terhadap aplikasi atau situs seluler, kerja API, seberapa cepat pengguna berinteraksi dengan situs, instalasi aplikasi, UX.  <strong>Melacak perilaku pengguna</strong> adalah metrik penting ketiga.  Ini adalah sistem seperti Google Analytics dan Yandex.Metrics.  Kami memiliki sistem pelacakan keren kami sendiri, di mana kami banyak berinvestasi. <br><br>  Dalam proses bekerja dengan statistik, banyak pengguna terlibat - ini adalah pengembang dan analitik bisnis.  Penting bagi setiap orang untuk berbicara dalam bahasa yang sama, jadi Anda harus setuju. <br><br><blockquote>  Dimungkinkan untuk bernegosiasi secara verbal, tetapi jauh lebih baik bila ini terjadi secara formal - dalam struktur peristiwa yang jelas. </blockquote><br>  <strong>Formalisasi struktur acara bisnis</strong> adalah ketika pengembang mengatakan berapa banyak pendaftaran yang kami miliki, analis memahami bahwa ia diberikan informasi tidak hanya tentang jumlah total pendaftaran, tetapi juga menurut negara, jenis kelamin, dan parameter lainnya.  Dan semua informasi ini diformalkan dan berada <strong>dalam domain publik untuk semua pengguna perusahaan</strong> .  Acara ini memiliki struktur yang diketik dan deskripsi formal.  Misalnya, kami menyimpan informasi ini dalam format <strong>Protokol Buffer</strong> . <br><br>  Deskripsi acara "Registrasi": <br><br><pre><code class="plaintext hljs">enum Gender { FEMALE = 1; MALE = 2; } message Registration { required int32 userid =1; required Gender usergender = 2; required int32 time =3; required int32 countryid =4; }</code> </pre> <br>  Acara pendaftaran berisi informasi tentang <strong>pengguna, bidang, waktu</strong> acara, dan <strong>negara</strong> pendaftaran pengguna.  Informasi ini tersedia untuk analis, dan, di masa depan, bisnis memahami apa yang kami kumpulkan. <br><br><h3>  Mengapa saya perlu deskripsi formal? </h3><br>  Deskripsi formal adalah <strong>keseragaman untuk pengembang, analis, dan departemen produk.</strong>  Maka informasi ini menembus uraian logika bisnis aplikasi.  Sebagai contoh, kami memiliki sistem internal untuk menggambarkan proses bisnis dan di dalamnya ada layar yang kami miliki fitur baru. <br><br><img src="https://habrastorage.org/webt/qf/cv/hg/qfcvhgvo39rtidli5fxdq65hx2q.jpeg"><br><br>  Dalam <strong>dokumen persyaratan produk</strong> terdapat bagian dengan instruksi bahwa ketika pengguna berinteraksi dengan aplikasi dengan cara ini, kita harus mengirim acara dengan parameter yang persis sama.  Selanjutnya, kami akan dapat memvalidasi seberapa baik fitur kami bekerja, dan kami mengukurnya dengan benar.  Deskripsi formal memungkinkan kami untuk lebih memahami cara menyimpan data ini dalam database: NoSQL, SQL, atau lainnya.  Kami memiliki <strong>skema data</strong> , dan itu keren. <br><br>  Dalam beberapa sistem analitik yang disediakan sebagai layanan, hanya ada 10-15 peristiwa dalam penyimpanan rahasia.  Di negara kami, jumlah ini telah bertambah lebih dari 1000 dan tidak akan berhenti - <strong>tidak mungkin untuk hidup tanpa satu registri</strong> . <br><br><h3>  Tentukan Ringkasan Fase </h3><br>  Kami memutuskan bahwa <strong>statistik - ini penting</strong> dan <strong>menggambarkan bidang subjek tertentu</strong> - ini bagus, Anda dapat hidup terus. <br><br><h2>  Kumpulkan fase - pengumpulan data </h2><br>  Kami memutuskan untuk membangun sistem sehingga ketika peristiwa bisnis terjadi - pendaftaran, mengirim pesan, seperti - pada saat yang sama dengan menyimpan informasi ini, kami secara terpisah mengirim peristiwa statistik tertentu. <br><br><blockquote>  Dalam kode, statistik dikirim bersamaan dengan acara bisnis. </blockquote><br>  Ini diproses sepenuhnya secara independen dari penyimpanan data di mana aplikasi berjalan, karena <strong>aliran data melewati pipa pemrosesan yang terpisah.</strong> <br><br>  Deskripsi melalui EDL: <br><br><pre> <code class="plaintext hljs">enum Gender { FEMALE = 1; MALE = 2; } message Registration { required int32 user_id =1; required Gender user_gender = 2; required int32 time =3; required int32 country_id =4; }</code> </pre> <br>  Kami memiliki deskripsi acara pendaftaran.  API dihasilkan secara otomatis, dapat diakses oleh pengembang dari kode, yang dalam 4 baris memungkinkan Anda mengirim statistik. <br><br>  API berbasis EDL: <br><br><pre> <code class="plaintext hljs">\EDL\Event\Regist ration::create() -&gt;setUserId(100500) -&gt;setGender(Gender: :MALE) -&gt;setTime(time()) -&gt;send();</code> </pre> <br><h3>  Pengiriman Acara </h3><br>  Ini adalah sistem eksternal kita.  Kami melakukan ini karena kami memiliki layanan luar biasa yang menyediakan API untuk bekerja dengan data foto, tentang hal lain.  Mereka semua menyimpan data dalam database bermodel baru yang keren, seperti Aerospike dan CockroachDB. <br><br>  Ketika Anda perlu membuat semacam pelaporan, Anda tidak perlu pergi dan bertarung: "Kawan, berapa banyak yang Anda miliki dan berapa banyak?"  - Semua data dikirim dalam aliran terpisah.  Memproses conveyor - sistem eksternal.  Dari konteks aplikasi, kami membuka semua data dari repositori logika bisnis, dan mengirimkannya lebih jauh ke saluran pipa terpisah. <br><br>  Fase Kumpulkan mengasumsikan ketersediaan server aplikasi.  Kami punya PHP ini. <br><br><img src="https://habrastorage.org/webt/az/vo/va/azvova-esx681etff8drvvkigeq.gif"><br><br><h3>  Transportasi </h3><br>  Ini adalah subsistem yang memungkinkan kami mengirim ke saluran lain apa yang kami lakukan dari konteks aplikasi.  Transportasi dipilih semata-mata dari kebutuhan Anda, tergantung pada situasi di proyek. <br><br>  Transportasi memiliki karakteristik, dan yang pertama adalah <strong>jaminan pengiriman.</strong>  Karakteristik transportasi: setidaknya-sekali, tepat-sekali, Anda memilih statistik untuk tugas Anda, berdasarkan seberapa penting data ini.  Misalnya, untuk sistem penagihan tidak dapat diterima bahwa statistik menunjukkan lebih banyak transaksi daripada yang ada - ini adalah uang, itu tidak mungkin. <br><br>  Parameter kedua adalah <strong>binding untuk bahasa pemrograman.</strong>  Kita harus entah bagaimana berinteraksi dengan transportasi, jadi itu dipilih sesuai dengan bahasa di mana proyek ditulis. <br><br>  Parameter ketiga adalah <strong>skalabilitas.</strong>  Karena kita berbicara tentang jutaan peristiwa per detik, alangkah baiknya mengingat skalabilitas di masa depan. <br><br>  Ada banyak opsi transportasi: aplikasi RDBMS, Flume, Kafka atau LSD.  Kami menggunakan <strong>LSD</strong> - ini adalah cara khusus kami. <br><br><h3>  Daemon streaming langsung </h3><br>  LSD tidak ada hubungannya dengan zat terlarang.  Ini adalah <strong>daemon streaming yang hidup dan sangat cepat</strong> yang tidak menyediakan agen apa pun untuk menulisnya.  Kita dapat menyetelnya, kami memiliki <strong>integrasi dengan sistem lain</strong> : HDFS, Kafka - kami dapat mengatur ulang data yang dikirim.  LSD tidak memiliki panggilan jaringan pada INSERT, dan Anda dapat mengontrol topologi jaringan di dalamnya. <br><br>  Yang paling penting, ini adalah <strong>OpenSource Badoo</strong> - tidak ada alasan untuk tidak mempercayai perangkat lunak ini. <br><br>  Jika itu adalah iblis yang sempurna, maka alih-alih Kafka kita akan membahas LSD di setiap konferensi, tetapi setiap LSD memiliki lalat di salep.  Kami memiliki batasan kami sendiri yang membuat kami nyaman: kami <strong>tidak memiliki dukungan replikasi di LSD</strong> dan memiliki <strong>setidaknya satu kali</strong> jaminan pengiriman.  Juga, untuk transaksi uang, ini bukan transportasi yang paling cocok, tetapi Anda umumnya perlu berkomunikasi dengan uang secara eksklusif melalui database "asam" - mendukung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ACID</a> . <br><br><h3>  Kumpulkan Ringkasan Fase </h3><br>  Berdasarkan hasil dari seri sebelumnya, kami menerima <strong>deskripsi formal dari</strong> data, menghasilkan <strong>API yang</strong> sangat baik dan nyaman <strong>untuk pengirim acara</strong> dari mereka, dan menemukan cara <strong>untuk mentransfer</strong> data ini <strong>dari konteks aplikasi ke pipa yang terpisah</strong> .  Sudah tidak buruk, dan kami sedang mendekati fase berikutnya. <br><br><h2>  Proses Fase - Pemrosesan Data </h2><br>  Kami mengumpulkan data dari pendaftaran, foto yang diunggah, jajak pendapat - apa yang harus dilakukan dengan semua ini?  Dari data ini kami ingin mendapatkan <strong>bagan</strong> dengan riwayat panjang dan <strong>data mentah</strong> .  Grafik memahami segalanya - Anda tidak perlu menjadi pengembang untuk memahami dari kurva bahwa pendapatan perusahaan tumbuh.  Kami menggunakan data mentah untuk pelaporan online dan ad-hoc.  Untuk kasus yang lebih kompleks, analis kami ingin melakukan kueri analitik pada data ini.  Baik itu maupun fungsionalitas itu penting bagi kita. <br><br><h3>  Grafik </h3><br>  Grafik tersedia dalam berbagai bentuk. <br><br><img src="https://habrastorage.org/webt/hu/c7/ap/huc7apcxpcajxhc5k3an8ken4wk.jpeg"><br><br>  Atau, misalnya, grafik dengan riwayat yang menunjukkan data selama 10 tahun. <br><br><img src="https://habrastorage.org/webt/cq/_z/pc/cq_zpcmcbe2b_nipvwhbtnkme94.jpeg"><br><br>  Grafik bahkan seperti itu. <br><br><img src="https://habrastorage.org/webt/rs/76/eg/rs76eg23gglv8m1xlaby2gr8vzg.jpeg"><br><br>  Ini adalah hasil dari beberapa tes AB, dan secara mengejutkan mirip dengan gedung Chrysler di New York. <br><br>  Ada dua cara untuk menggambar grafik: <strong>kueri untuk data mentah</strong> dan <strong>seri waktu</strong> .  Kedua pendekatan memiliki kekurangan dan kelebihan, yang tidak akan kita bahas secara terperinci.  Kami menggunakan <strong>pendekatan hibrid</strong> : kami menjaga ekor pendek dari data mentah untuk pelaporan operasional, dan seri waktu untuk penyimpanan jangka panjang.  Yang kedua dihitung dari yang pertama. <br><br><h3>  Bagaimana kami telah berkembang menjadi 1,8 juta acara per detik </h3><br>  Ceritanya panjang - jutaan RPS tidak terjadi dalam sehari.  Badoo adalah perusahaan dengan sejarah sepuluh tahun, dan kita dapat mengatakan bahwa sistem pemrosesan data tumbuh bersama perusahaan. <br><br><img src="https://habrastorage.org/webt/av/o3/04/avo304ko07jkl4szc5dnz2x7zc8.jpeg"><br><br>  Awalnya kami tidak punya apa-apa.  Kami mulai mengumpulkan data - ternyata <strong>5.000 acara per detik.</strong>  Satu host MySQL dan tidak ada yang lain!  Setiap DBMS relasional akan mengatasi tugas ini, dan akan nyaman dengan itu: Anda akan memiliki transaksionalitas - memasukkan data, menerima permintaan padanya - semuanya bekerja dengan baik dan baik.  Jadi kami hidup sebentar. <br><br>  Di beberapa titik, terjadi sharding fungsional: data pendaftaran - di sini, dan tentang foto - di sana.  Jadi kami hidup hingga <strong>200.000 peristiwa per detik</strong> dan mulai menggunakan berbagai pendekatan gabungan: untuk menyimpan bukan data mentah, tetapi <strong>dikumpulkan</strong> , tetapi sejauh ini dalam database relasional.  Kami menyimpan penghitung, tetapi esensi dari sebagian besar basis data relasional adalah sedemikian rupa sehingga tidak mungkin untuk menjalankan <strong>kueri DISTINCT</strong> pada data ini - model aljabar penghitung tidak memungkinkan menghitung DISTINCT. <br><br>  Kami di Badoo memiliki motto <strong>"Kekuatan tak terbendung"</strong> .  Kami tidak akan berhenti dan tumbuh lebih jauh.  Pada saat kami melewati ambang <strong>200.000 peristiwa per detik</strong> , kami memutuskan untuk membuat deskripsi formal, yang saya bicarakan di atas.  Sebelum itu, ada beberapa kekacauan, dan sekarang kami telah mendapatkan daftar acara yang terstruktur: kami mulai mengukur sistem, <strong>menghubungkan Hadoop</strong> , semua data masuk ke <strong>tabel Hive.</strong> <br><br>  Hadoop adalah paket perangkat lunak besar, sistem file.  Untuk komputasi terdistribusi, Hadoop mengatakan, "Letakkan data di sini, saya akan membiarkan Anda melakukan pertanyaan analitik pada mereka."  Jadi kami melakukan - menulis <strong>perhitungan teratur untuk semua grafik</strong> - ternyata baik-baik saja.  Tetapi bagan sangat berharga ketika mereka diperbarui dengan cepat - sekali sehari, menonton pembaruan bagan tidak begitu menyenangkan.  Jika kami meluncurkan sesuatu yang mengarah ke kesalahan fatal pada produksi, kami ingin melihat grafik langsung turun, dan tidak setiap hari.  Oleh karena itu, seluruh sistem mulai menurun setelah beberapa waktu.  Namun, kami menyadari bahwa pada tahap ini Anda dapat menempel pada tumpukan teknologi yang dipilih. <br><br><blockquote>  Bagi kami, Jawa itu baru, kami menyukainya, dan kami mengerti apa yang bisa dilakukan secara berbeda. </blockquote><br>  Pada tahap dari 400.000 hingga <strong>800.000 acara per detik</strong> , kami mengganti Hadoop dalam bentuk yang paling murni dan Hive, sebagai pelaksana kueri analitis, dengan <strong>Spark Streaming</strong> , menulis <strong>peta umum / pengurangan</strong> dan penghitungan metrik tambahan.  3 tahun yang lalu saya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memberi tahu</a> bagaimana kami melakukannya.  Kemudian tampak bagi kami bahwa Spark akan hidup selamanya, tetapi hidup menentukan sebaliknya - kami bertemu dengan keterbatasan Hadoop.  Mungkin jika kami memiliki kondisi lain, kami akan terus hidup dengan Hadoop. <br><br>  Masalah lain, selain menghitung grafik pada Hadoop, adalah pertanyaan SQL empat lantai yang luar biasa yang didorong oleh analis, dan grafik tidak diperbarui dengan cepat.  Faktanya adalah bahwa ada pekerjaan yang agak rumit dengan pemrosesan data operasional, sehingga real-time, cepat dan keren. <br><br>  Badoo dilayani oleh dua pusat data yang terletak di dua sisi Samudra Atlantik - di Eropa dan Amerika Utara.  Untuk membuat laporan terpadu, Anda harus mengirim data dari Amerika ke Eropa.  Di pusat data Eropa kami menyimpan semua statistik statistik, karena ada lebih banyak kekuatan komputasi.  <strong>Bolak</strong> -balik antara pusat data sekitar <strong>200 ms</strong> - jaringannya cukup rumit - membuat permintaan ke DC lain tidak sama dengan pergi ke rak berikutnya. <br><br>  Ketika kami mulai meresmikan acara dan pengembang, dan manajer produk terlibat, semua orang menyukai segalanya - hanya ada <strong>ledakan pertumbuhan yang pesat</strong> .  Saat ini, sudah waktunya untuk membeli besi di kluster, tetapi kami tidak benar-benar ingin melakukan ini. <br><br>  Ketika kami melewati puncak <strong>800.000 acara per detik</strong> , kami menemukan apa yang Yandex unggah ke OpenSource <strong>ClickHouse</strong> , dan memutuskan untuk mencobanya.  <strong>Mereka mengisi kerucut kerucut</strong> ketika mereka mencoba melakukan sesuatu, dan sebagai hasilnya, ketika semuanya bekerja, mereka membuat resepsi prasmanan kecil tentang sejuta acara pertama.  Mungkin, ClickHouse bisa menyelesaikan laporan. <br><br><blockquote>  Ambil saja ClickHouse dan jalani saja. </blockquote><br>  Tapi ini tidak menarik, jadi kami akan terus berbicara tentang pemrosesan data. <br><br><h3>  Clickhouse </h3><br>  ClickHouse adalah hype dari dua tahun terakhir dan tidak perlu diperkenalkan: hanya di HighLoad ++ pada tahun 2018 saya ingat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tentang lima laporan</a> tentang hal itu, serta seminar dan pertemuan. <br><br>  Alat ini dirancang untuk menyelesaikan tugas-tugas yang kita tentukan sendiri.  Ada <strong>pembaruan</strong> dan chip waktu nyata yang kami terima pada satu waktu dari Hadoop: replikasi, sharding.  Tidak ada alasan untuk tidak mencoba ClickHouse, karena mereka mengerti bahwa dengan implementasi pada Hadoop kami telah melanggar bagian bawah.  Alatnya keren, dan dokumentasinya pada umumnya menyala - saya menulis di sana sendiri, saya sangat suka semuanya, dan semuanya hebat.  Tetapi kami harus menyelesaikan sejumlah masalah. <br><br>  <strong>Bagaimana cara mengubah seluruh aliran acara di ClickHouse?</strong>  <strong>Bagaimana cara menggabungkan data dari dua pusat data?</strong>  Dari kenyataan bahwa kami datang ke admin dan berkata: "Guys, mari kita instal ClickHouse", mereka tidak akan membuat jaringan dua kali lebih tebal, dan penundaannya setengahnya.  Tidak, jaringan masih setipis dan sekecil gaji pertama. <br><br>  <strong>Bagaimana cara menyimpan hasilnya</strong> ?  Di Hadoop, kami mengerti cara menggambar grafik - tetapi bagaimana melakukannya di ClickHouse ajaib?  Tongkat sihir tidak termasuk.  <strong>Bagaimana cara mengirimkan hasil</strong> ke penyimpanan seri waktu? <br><br>  Seperti yang dikatakan dosen saya di institut, pertimbangkan 3 skema data: strategis, logis, dan fisik. <br><br><h4>  Skema penyimpanan strategis </h4><br>  Kami memiliki <strong>2 pusat data</strong> .  Kami mengetahui bahwa ClickHouse tidak tahu apa-apa tentang DC, dan kami baru saja membuka gugus di setiap DC.  Sekarang <strong>data tidak bergerak melalui kabel lintas-Atlantik</strong> - semua data yang terjadi di DC disimpan secara lokal di cluster-nya.  Ketika kami ingin mengajukan permintaan atas data gabungan, misalnya, untuk mengetahui berapa banyak pendaftaran di kedua DC, ClickHouse memberi kami kesempatan ini.  Latensi dan ketersediaan rendah untuk permintaan - hanya sebuah mahakarya! <br><br><img src="https://habrastorage.org/webt/mr/dc/-2/mrdc-205rzloz1c2oemavnikcxu.jpeg"><br><br><h4>  Skema penyimpanan fisik </h4><br>  Sekali lagi, pertanyaan: bagaimana data kita akan jatuh ke dalam model relasional ClickHouse, apa yang harus dilakukan agar tidak kehilangan replikasi dan sharding?  Semuanya dijelaskan secara luas dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi ClickHouse</a> , dan jika Anda memiliki lebih dari satu server, Anda akan menemukan artikel ini.  Oleh karena itu, kami tidak akan menyelidiki apa yang ada di manual: replikasi, sharding, dan pertanyaan untuk semua data pada pecahan. <br><br><h4>  Logika penyimpanan </h4><br>  Diagram logika adalah yang paling menarik.  Dalam satu jalur pipa kami memproses acara yang heterogen.  Ini berarti bahwa kami memiliki <strong>aliran acara yang heterogen</strong> : pendaftaran, suara, unggah foto, metrik teknis, pelacakan perilaku pengguna - semua acara ini memiliki <strong>atribut yang sangat berbeda</strong> .  Misalnya, saya melihat layar pada ponsel - saya perlu id layar, saya memilih seseorang - Anda perlu memahami apakah suara itu mendukung atau tidak.  Semua peristiwa ini memiliki atribut yang berbeda, grafik yang berbeda digambar di atasnya, tetapi semua ini harus diproses dalam satu saluran pipa.  Bagaimana cara memasukkannya ke dalam model ClickHouse? <br><br>  <strong>Pendekatan No. 1 - per tabel acara.</strong>  Pendekatan pertama ini, kami memperkirakan dari pengalaman yang diperoleh dengan MySQL - kami menciptakan <strong>tablet untuk setiap acara</strong> di ClickHouse.  Kedengarannya cukup logis, tetapi kami menemukan sejumlah kesulitan. <br><br>  Kami tidak memiliki batasan bahwa acara tersebut akan mengubah strukturnya ketika build hari ini dirilis.  Tambalan ini dapat dilakukan oleh pengembang mana pun.  Skema ini umumnya bisa berubah ke segala arah.  Satu-satunya <strong>bidang yang diperlukan</strong> adalah <strong>acara cap waktu</strong> dan apa acara itu.  Segala sesuatu yang lain berubah dengan cepat, dan, karenanya, pelat-pelat ini perlu dimodifikasi.  ClickHouse memiliki kemampuan untuk melakukan <strong>ALTER pada sebuah cluster</strong> , tetapi ini adalah prosedur rumit yang sulit untuk diotomatisasi untuk membuatnya bekerja dengan lancar.  Karena itu, ini adalah minus. <br><br>  Kami memiliki lebih dari seribu peristiwa berbeda, yang memberi kami <strong>tingkat INSERT tinggi per mesin</strong> - kami terus-menerus merekam semua data dalam seribu tabel.  Untuk ClickHouse, ini adalah anti-pola.  Jika Pepsi memiliki slogan - "Live in big teguk", maka ClickHouse - <strong>"Live in big batch</strong> . <strong>"</strong>  Jika ini tidak dilakukan, maka replikasi tersendat, ClickHouse menolak untuk menerima sisipan baru - skema yang tidak menyenangkan. <br><br>  <strong>Pendekatan No. 2 - tabel lebar</strong> .  Orang-orang Siberia mencoba menyelipkan gergaji ke atas rel dan menerapkan model data yang berbeda.  Kami membuat tabel dengan <strong>seribu kolom</strong> , di mana setiap acara memiliki kolom yang disediakan untuk datanya.  Kami mendapatkan <strong>meja yang sangat kecil</strong> - untungnya, ini tidak melampaui lingkungan pengembangan, karena dari sisipan pertama menjadi jelas bahwa skema ini benar-benar buruk, dan kami tidak akan melakukannya. <br><br>  Tapi saya masih ingin menggunakan produk perangkat lunak yang keren, sedikit lebih banyak untuk menyelesaikan - dan itu akan menjadi apa yang Anda butuhkan. <br><br>  <strong>Pendekatan No. 3 - tabel umum.</strong>  Kami memiliki satu tabel besar di mana kami menyimpan data dalam array, karena ClickHouse mendukung <strong>tipe data non-skalar</strong> .  Yaitu, kita mulai kolom di mana nama atribut disimpan, dan kolom terpisah dengan array di mana nilai atribut disimpan. <br><br><img src="https://habrastorage.org/webt/ot/s3/ro/ots3ronbcjh69ssxujqvbuxeghc.jpeg"><br><br>  ClickHouse di sini melakukan tugasnya dengan sangat baik.  Jika kita hanya perlu memasukkan data, kita mungkin akan memeras 10 kali lebih banyak dalam instalasi saat ini. <br><br>  Namun, lalat di salep adalah bahwa itu juga merupakan anti-pola untuk ClickHouse - <strong>untuk menyimpan array string</strong> .  Ini buruk karena array baris <strong>membutuhkan lebih banyak ruang disk</strong> - mereka menyusut lebih buruk daripada kolom sederhana dan lebih <strong>sulit untuk diproses</strong> .  Tetapi untuk tugas kita, kita menutup mata kita terhadap hal ini, karena kelebihannya lebih besar. <br><br>  Bagaimana cara membuat SELECT dari tabel seperti itu?  Tugas kami adalah menghitung pendaftaran yang dikelompokkan berdasarkan gender.  Pertama, Anda perlu menemukan dalam satu array yang posisinya sesuai dengan kolom gender, lalu naik ke kolom lain dengan indeks ini dan dapatkan datanya. <br><br><img src="https://habrastorage.org/webt/gh/pw/ek/ghpwekgjjrr0eisi8_zjmoi48tk.jpeg"><br><br><h4>  Cara menggambar grafik pada data ini </h4><br>  Karena semua peristiwa dijelaskan, mereka memiliki struktur yang ketat, kami membentuk kueri SQL empat lantai untuk setiap jenis acara, jalankan dan simpan hasilnya ke tabel lain. <br><br>  Masalahnya adalah bahwa untuk menggambar dua titik yang berdekatan pada grafik, Anda perlu <strong>memindai seluruh tabel</strong> .  Contoh: kita melihat registrasi per hari.  Acara ini dari baris atas ke yang kedua dari belakang.  Dipindai satu kali - sangat baik.  Setelah 5 menit, kami ingin menggambar titik baru pada bagan - lagi, kami memindai rentang data yang bersinggungan dengan pemindaian sebelumnya, dan seterusnya untuk setiap peristiwa.  Kedengarannya masuk akal, tetapi tidak terlihat bagus. <br><br>  Selain itu, ketika kita mengambil beberapa baris, kita juga perlu <strong>membaca hasil di bawah agregasi</strong> .  Sebagai contoh, ada fakta bahwa hamba Tuhan terdaftar di Skandinavia dan seorang laki-laki, dan kita perlu menghitung statistik ringkasan: berapa banyak pendaftaran, berapa banyak pria, berapa banyak dari mereka adalah manusia, dan berapa banyak dari Norwegia.  Ini disebut dalam hal basis data analitis <strong>ROLLUP, CUBE,</strong> dan <strong>GROUPING SETS</strong> - <strong>ubah</strong> satu baris menjadi beberapa. <br><br><h4>  Bagaimana cara mengobati </h4><br>  Untungnya, ClickHouse memiliki alat untuk memecahkan masalah ini, yaitu, <strong>keadaan agregat fungsi serial</strong> .  Ini berarti Anda dapat memindai sepotong data satu kali dan menyimpan hasil ini.  Ini adalah <strong>fitur pembunuh</strong> .  3 tahun yang lalu kami melakukan ini pada Spark dan Hadoop, dan itu keren bahwa secara paralel dengan kami, pikiran Yandex terbaik mengimplementasikan analog di ClickHouse. <br><br><h4>  Permintaan lambat </h4><br>  Kami memiliki permintaan lambat - untuk menghitung pengguna unik untuk hari ini dan kemarin. <br><br><pre> <code class="plaintext hljs">SELECT uniq(user_id) FROM table WHERE dt IN (today(), yesterday())</code> </pre> <br>  Dalam bidang fisik, kita dapat membuat SELECT untuk state untuk kemarin, mendapatkan representasi binernya, menyimpannya di suatu tempat. <br><br><pre> <code class="plaintext hljs">SELECT uniq(user_id), 'xxx' AS ts, uniqState(user id) AS state FROM table WHERE dt IN (today(), yesterday())</code> </pre> <br>  Untuk hari ini, kita hanya mengubah syaratnya menjadi hari ini: <code>'yyy' AS ts</code> dan <code>WHERE dt = today()</code> dan timestamp kita sebut "xxx" dan "yyy".            ,        ,    2 . <br><br><pre> <code class="plaintext hljs">SELECT uniqMerge(state) FROM ageagate_table WHERE ts IN ('xxx', 'yyy')</code> </pre> <br><h4>   </h4><br>  : <br><br><ul><li>    ,       ; </li><li>       ; </li><li>  . </li></ul><br>         ,   -      .     <strong>    </strong> .    ,     ,  ,   ,       ClickHouse,  : «,      ! ,    !» <br><br><h4>     </h4><br>   ,      ,    .      <strong>  ,</strong>          .    .    —     SQL-,       . ,        ,      . <br><br><img src="https://habrastorage.org/webt/df/0b/o6/df0bo6pb7l6t94sxnrwtpctfcxk.jpeg"><br><br>     ,   -  time series.      :      ,  ,      ,    time series. <br><br>   time series    :   ,    ,    timestamp       .        ,    ,    .              .   ,        ,       ,      —  ,    . ,     ,   ClickHouse  -,     ,     . <br><br>      ,       ,      ClickHouse: <br><br><blockquote> —    « »,    —      . </blockquote><br>     time series  2 ,     20   20-80 .   .  ClickHouse   <strong>GraphiteMergeTree</strong> ,    time series,      . <br><br><h4>    </h4><br> <strong>8  ClickHouse</strong> ,   6  -  ,  2  :    2 —     ,    . <strong>  1.8 .   </strong>  ,     <strong>500</strong> <strong>   </strong> . ,   1,8 ,       500 !       . <br><br><h3>    Hadoop </h3><br> <strong>   2 </strong> .          .     <strong>3 </strong> ,   CPU —  <strong>4</strong> .  ,        . <br><br><h3>   Process </h3><br>     <strong>   </strong> , ,   ,        .   ,    ,    ClickHouse    3 000   . ,  ,   ,      overkill. <br><br>   ,   ,     .   ClickHouse,   <strong>   </strong> . ,  ,   ,    .   ,  8      3–4     .  —     . <br><br><h2>  Present —    </h2><br>      ,     ?   time series,     <strong>  time series</strong> ,           ,   ,   . <br><br><img src="https://habrastorage.org/webt/82/uo/qq/82uoqq4jw6amtxph_jgcjpjnwkm.jpeg"><br><br> <strong>Drop Detect —    SQL</strong> :  SQL-    ,     ,      . <br><br><img src="https://habrastorage.org/webt/ru/1v/up/ru1vuporiqj-suncjyc-sh06xrk.jpeg"><br><br>     <strong>Anomaly Detection</strong> —      .    ,  ,       2%   ,    —   40,    ,     ,        ,    . <br><br>    —   ,  ,   - ,    Anomaly Detection. <br><br><h3> Anomaly Detection </h3><br>  ,   time series .    : ,  ,    .   time series     <strong></strong> .  ,       ,  .    ,   <strong>drop detection</strong> —       ,  . <br><br>     UI. <br><br><img src="https://habrastorage.org/webt/sk/mg/hn/skmghn7mirsubwu-vpm2dq5tols.jpeg"><br><br>    .  -  ,       —  .    -,  . <br><br><h3>   Present </h3><br>    ,      ,     <strong> </strong> .     <strong> </strong>    ,   :     1000 — alarm,     0 — alarm.    . <br><br>   <strong>Anomaly Detection</strong>    ,    .    Anomaly Detection     <strong>Exasol</strong> ,        ClickHouse.        Anomaly Detection  2 ,   . <br><br><h2>   </h2><br>  ,  ,  4    . <br><br>  , <strong>  </strong>  ,     ,     .  , <strong>    </strong> ,      . ,  <strong>    </strong> <strong> </strong> . <br><br><blockquote>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad++</a>  ,    HighLoad++    -       .        ,        , <strong>    </strong> :) <br><br>  ,    <u><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PHP Russia</a></u> ,  ,       .  , ,   ,      1,8 /,     ,      1 . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id442616/">https://habr.com/ru/post/id442616/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id442606/index.html">Objek Domain dengan Lombok: Battle Classic</a></li>
<li><a href="../id442608/index.html">Dompet dingin pertukaran cryptocurrency QuadrigaCX, pendiri yang meninggal, ternyata kosong</a></li>
<li><a href="../id442610/index.html">Telegram-bot + Google Analytics</a></li>
<li><a href="../id442612/index.html">Mesin kardus untuk permainan papan listrik. Bagaimana kami membawanya lebih dekat dengan kenyataan</a></li>
<li><a href="../id442614/index.html">CI / CD menggunakan Jenkins di Kubernetes</a></li>
<li><a href="../id442618/index.html">Tidak untuk selfie: uji immunosorbent terkait-enzim digital menggunakan chip baru yang tertanam dalam smartphone</a></li>
<li><a href="../id442620/index.html">Pembelajaran mesin dalam pemantauan TI</a></li>
<li><a href="../id442622/index.html">Cara membuat coroutine di Unity sedikit lebih nyaman</a></li>
<li><a href="../id442624/index.html">Buku “Algoritma Sempurna. Dasar-Dasar</a></li>
<li><a href="../id442626/index.html">Habraiting: membangun awan kata-kata berbahasa Rusia pada contoh header Habra</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
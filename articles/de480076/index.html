<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üó®Ô∏è üëÄ üë®üèø‚Äç‚öïÔ∏è Multiprocessing und Abgleich von Daten aus verschiedenen Quellen üßùüèº üêì üçõ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo habr 

 Angesichts der Vielfalt der verteilten Systeme ist die Verf√ºgbarkeit verifizierter Informationen im Zielspeicher ein wichtiges Kriterium...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Multiprocessing und Abgleich von Daten aus verschiedenen Quellen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/480076/">  Hallo habr <br><br>  Angesichts der Vielfalt der verteilten Systeme ist die Verf√ºgbarkeit verifizierter Informationen im Zielspeicher ein wichtiges Kriterium f√ºr die Datenkonsistenz. <br><br>  Zu diesem Zweck gibt es viele Ans√§tze und Methoden, und wir werden uns auf die Vers√∂hnung konzentrieren, deren theoretische Aspekte <a href="https://habr.com/ru/post/428443/">hier in diesem Artikel</a> er√∂rtert <a href="https://habr.com/ru/post/428443/">wurden.</a>  Ich schlage vor, die praktische Implementierung dieses Systems in Betracht zu ziehen, das skalierbar und an eine gro√üe Datenmenge angepasst ist. <br><br>  Wie Sie diesen Fall auf dem guten alten Python implementieren - lesen Sie es unter dem Schnitt!  Lass uns gehen! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ic/zx/hg/iczxhgu9zvlumwggetuoblxm1ra.jpeg"></div><br>  <a href="https://www.megapixl.com/alexdobysh-stock-images-videos-portfolio" rel="nofollow">(Bildquelle)</a> <br><a name="habracut"></a><br><h2>  Einleitung </h2><br>  Stellen wir uns vor, ein Finanzinstitut verf√ºgt √ºber mehrere verteilte Systeme und wir stehen vor der Aufgabe, Transaktionen in diesen Systemen zu √ºberpr√ºfen und die abgeglichenen Daten in den Zielspeicher hochzuladen. <br><br>  Nehmen Sie als Datenquelle eine gro√üe Textdatei und eine Tabelle in eine PostgreSQL-Datenbank.  Angenommen, die Daten in diesen Quellen haben dieselben Transaktionen, k√∂nnen jedoch Unterschiede aufweisen. Daher m√ºssen sie √ºberpr√ºft und zur Analyse in die √ºberpr√ºften Daten im endg√ºltigen Speicher geschrieben werden. <br><br>  Dar√ºber hinaus ist es erforderlich, mehrere Abstimmungen in derselben Datenbank parallel zu starten und das System mithilfe von Multiprocessing an ein gro√ües Volumen anzupassen. <br><br>  Das <a href="https://docs.python.org/dev/library/multiprocessing.html" rel="nofollow">Multiprocessing-</a> Modul eignet sich hervorragend zum Parallelisieren von Operationen in Python und umgeht gewisserma√üen bestimmte GIL-Fehler.  Wir werden die Funktionen dieser Bibliothek weiter unten nutzen. <br><br><h2>  Architektur des in Entwicklung befindlichen Systems </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/je/dm/hu/jedmhumxsx9d-mxu-bbfbzqbulq.png"></div><br>  Verwendete Komponenten: <br><br><ul><li>  <b>Zufallsdatengenerator</b> - Ein Python-Skript, das eine CSV-Datei generiert und auf dieser Basis eine Tabelle in einer Datenbank f√ºllt. </li><li>  <b>Datenquellen</b> - CSV-Datei und Tabelle in der PostgreSQL-Datenbank; </li><li>  <b>Adapter</b> - In diesem Fall verwenden wir zwei Adapter, die Daten aus ihren Quellen (CSV oder Datenbank) extrahieren und Informationen in die Zwischendatenbank eingeben. </li><li>  <b>Datenbanken</b> - in der Gr√∂√üe von drei Teilen: Rohdaten, eine Zwischendatenbank, in der die von den Adaptern erfassten Informationen gespeichert werden, und eine "saubere" Datenbank, die abgeglichene Transaktionen aus beiden Quellen enth√§lt. </li></ul><br><h2>  Erstausbildung </h2><br>  Als Datenspeichertool verwenden wir die <a href="https://hub.docker.com/_/postgres" rel="nofollow">PostgreSQL-Datenbank im Docker-Container</a> und interagieren mit unserer Datenbank √ºber <a href="https://hub.docker.com/r/dpage/pgadmin4/" rel="nofollow">pgAdmin, das im Container ausgef√ºhrt wird</a> : <br><br><pre><code class="bash hljs">docker run --name pg -d -e <span class="hljs-string"><span class="hljs-string">"POSTGRES_USER=my_user"</span></span> -e <span class="hljs-string"><span class="hljs-string">"POSTGRES_PASSWORD=my_password"</span></span> postgres</code> </pre> <br>  PgAdmin ausf√ºhren: <br><br><pre> <code class="bash hljs">docker run -p 80:80 -e <span class="hljs-string"><span class="hljs-string">"PGADMIN_DEFAULT_EMAIL=user@domain.com"</span></span> -e <span class="hljs-string"><span class="hljs-string">"PGADMIN_DEFAULT_PASSWORD=12345"</span></span> -d dpage/pgadmin4</code> </pre> <br>  Vergessen Sie nach dem Start nicht, in der Konfigurationsdatei (conf / db.ini) die Verbindungszeichenfolge zur Datenbank anzugeben (f√ºr ein Trainingsbeispiel k√∂nnen Sie das!): <br><br><pre> <code class="bash hljs">[POSTGRESQL] db_url=postgresql://my_user:my_password@172.17.0.2:5432/my_user</code> </pre><br>  Grunds√§tzlich ist die Verwendung eines Containers optional und Sie k√∂nnen Ihren Datenbankserver verwenden. <br><br><h2>  Eingabeerzeugung </h2><br>  Das Python-Skript <b>generate_test_data</b> ist f√ºr die Generierung von Testdaten verantwortlich, die die gew√ºnschte Anzahl von zu generierenden Eintr√§gen ben√∂tigen.  Die Operationssequenz kann leicht durch die Hauptfunktion der <b>GenerateTestData-</b> Klasse verfolgt werden: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @m.timing def run(self, num_rows): """ Run the process """ m.info('START!') self.create_db_schema() self.create_folder('data') self.create_csv_file(num_rows) self.bulk_copy_to_db() self.random_delete_rows() self.random_update_rows() m.info('END!')</span></span></code> </pre> <br>  Die Funktion f√ºhrt also die folgenden Schritte aus: <br><br><ul><li>  Erstellen von Schemata in der Datenbank (wir erstellen alle grundlegenden Schemata und Tabellen); </li><li>  Erstellen eines Ordners zum Speichern einer Testdatei; </li><li>  Generieren einer Testdatei mit einer bestimmten Anzahl von Zeilen; </li><li>  Bulk-Insert-Daten in die Zieltabelle transaction_db_raw.transaction_log; </li><li>  Versehentliches L√∂schen mehrerer Zeilen in dieser Tabelle; </li><li>  Zuf√§llige Aktualisierung mehrerer Zeilen in dieser Tabelle. </li></ul><br>  Das L√∂schen und √Ñndern ist erforderlich, damit die verglichenen Objekte zumindest eine gewisse Diskrepanz aufweisen.  Es ist wichtig, diese Diskrepanzen suchen zu k√∂nnen! <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing @m.wrapper(m.entering, m.exiting) def random_delete_rows(self): """ Random deleting some rows from the table """ sql_command = sql.SQL(""" delete from {0}.{1} where ctid = any(array( select ctid from {0}.{1} tablesample bernoulli (1) ))""").format(sql.Identifier(self.schema_raw), sql.Identifier(self.raw_table_name)) try: rows = self.database.execute(sql_command) m.info('Has been deleted [%s rows] from table %s' % (rows, self.raw_table_name)) except psycopg2.Error as err: m.error('Oops! Delete random rows has been FAILED. Reason: %s' % err.pgerror) @m.timing @m.wrapper(m.entering, m.exiting) def random_update_rows(self): """ Random update some rows from the table """ sql_command = sql.SQL(""" update {0}.{1} set transaction_amount = round(random()::numeric, 2) where ctid = any(array( select ctid from {0}.{1} tablesample bernoulli (1) ))""").format(sql.Identifier(self.schema_raw), sql.Identifier(self.raw_table_name)) try: rows = self.database.execute(sql_command) m.info('Has been updated [%s rows] from table %s' % (rows, self.raw_table_name)) except psycopg2.Error as err: m.error('Oops! Delete random rows has been FAILED. Reason: %s' % err.pgerror)</span></span></code> </pre> <br>  Die Generierung eines Testdatensatzes und die anschlie√üende Aufzeichnung in eine Textdatei im CSV-Format sieht wie folgt aus: <br><br><ul><li>  Eine zuf√§llige Transaktions-UID wird erstellt. </li><li>  Es wird eine zuf√§llige UID-Kontonummer erstellt (standardm√§√üig werden zehn eindeutige Konten verwendet, dieser Wert kann jedoch mithilfe der Konfigurationsdatei durch √Ñndern des Parameters "random_accounts" ge√§ndert werden). </li><li>  Transaktionsdatum - ein zuf√§lliges Datum aus dem in der Konfigurationsdatei angegebenen Datum (initial_date); </li><li>  Art der Transaktion (Transaktion / Provision); </li><li>  Transaktionsbetrag; </li><li>  Die Hauptarbeit bei der Datengenerierung wird von der <i>generate_test_data_by_chunk-</i> Methode der <b>TestDataCreator-</b> Klasse ausgef√ºhrt: </li></ul><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing def generate_test_data_by_chunk(self, chunk_start, chunk_end): """ Generating and saving to the file """ num_rows_mp = chunk_end - chunk_start new_rows = [] for _ in range(num_rows_mp): transaction_uid = uuid.uuid4() account_uid = choice(self.list_acc) transaction_date = (self.get_random_date(self.date_in, 0) .__next__() .strftime('%Y-%m-%d %H:%M:%S')) type_deal = choice(self.list_type_deal) transaction_amount = randint(-1000, 1000) new_rows.append([transaction_uid, account_uid, transaction_date, type_deal, transaction_amount]) self.write_in_file(new_rows, chunk_start, chunk_end)</span></span></code> </pre> <br><blockquote>  Ein Merkmal dieser Funktion ist der Start in mehreren parallelisierten asynchronen Prozessen, von denen jeder seinen eigenen Teil von 50.000 Datens√§tzen generiert.  Mit diesem "Chip" k√∂nnen Sie schnell genug eine Datei in mehreren Millionen Zeilen erstellen </blockquote><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run_csv_writing</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Writing the test data into csv file """</span></span> pool = mp.Pool(mp.cpu_count()) jobs = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chunk_start, chunk_end <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.divide_into_chunks(<span class="hljs-number"><span class="hljs-number">0</span></span>, self.num_rows): jobs.append(pool.apply_async(self.generate_test_data_by_chunk, (chunk_start, chunk_end))) <span class="hljs-comment"><span class="hljs-comment"># wait for all jobs to finish for job in jobs: job.get() # clean up pool.close() pool.join()</span></span></code> </pre> <br>  Nach Abschluss der Textdatei wird der Befehl bulk_insert verarbeitet und alle Daten aus dieser Datei werden in die Tabelle <b>transaction_db_raw.transaction_log geschrieben.</b> <br><br>  Au√üerdem enthalten die beiden Quellen genau dieselben Daten, und der Abgleich findet nichts Interessantes. Daher l√∂schen und √§ndern wir mehrere zuf√§llige Zeilen in der Datenbank. <br><br>  F√ºhren Sie das Skript aus und generieren Sie eine Test-CSV-Datei mit Transaktionen in 10-KB-Zeilen: <br><br><pre> <code class="bash hljs">./generate_test_data.py 10000</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4c/cp/hm/4ccphmc5dcjcgxuy54p_9limlz4.png"></div><br>  Der Screenshot zeigt, dass eine Datei mit 10 KByte Zeilen empfangen wurde, 10 KByte in die Datenbank geladen wurden, dann jedoch 112 Zeilen aus der Datenbank gel√∂scht und weitere 108 ge√§ndert wurden Ergebnis: Die Datei und die Tabelle in der Datenbank unterscheiden sich um 220 Eintr√§ge. <br><br>  ‚ÄûNun, wo ist Multiprocessing?‚Äú, Fragen Sie. <br>  Und seine Arbeit kann gesehen werden, wenn Sie eine gr√∂√üere Datei erzeugen, nicht durch 10K-Datens√§tze, sondern zum Beispiel durch 1M.  Versuchen wir es? <br><br><pre> <code class="bash hljs">./generate_test_data.py 1000000</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rw/_a/ne/rw_aneqnairixqk-wglpqxgjvkc.png"></div><br>  Nach dem Laden der Daten, L√∂schen und √Ñndern von zuf√§lligen Datens√§tzen sehen wir die Unterschiede der Textdatei aus der Tabelle: 19.939 Zeilen (von denen 10.022 zuf√§llig gel√∂scht und 9.917 ge√§ndert wurden). <br><br><blockquote>  Das Bild zeigt, dass die Generierung von Datens√§tzen asynchron und inkonsistent war.  Dies bedeutet, dass der n√§chste Prozess beginnen kann, ohne die Startreihenfolge zu ber√ºcksichtigen, sobald der vorherige abgeschlossen ist.  Es kann nicht garantiert werden, dass das Ergebnis in der gleichen Reihenfolge wie die Eingabe vorliegt. </blockquote><br><div class="spoiler">  <b class="spoiler_title">Ist es definitiv schneller?</b> <div class="spoiler_text">  Eine Million Leitungen, die sich nicht auf der schnellsten virtuellen Maschine befinden, wurden in 15,5 Sekunden ‚Äûerfunden‚Äú - und das ist eine Option, die es wert ist.  Nachdem ich die gleiche Generation nacheinander gestartet hatte, ohne Multiprocessing zu verwenden, erhielt ich das Ergebnis: Die Dateierzeugung war mehr als dreimal langsamer (√ºber 52 Sekunden statt 15,5): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sb/kb/ck/sbkbckylzluoyyslyflwak5udrq.png"></div><br></div></div><br><h2>  Adapter f√ºr CSV </h2><br>  Dieser Adapter durchsucht die Zeile, wobei nur die erste Spalte, die Transaktionskennung, unver√§ndert bleibt, und speichert die empfangenen Daten in der Datei <i>data / transaction_hashed.csv</i> .  Der letzte Schritt seiner Arbeit besteht darin, diese Datei mit dem Befehl COPY in die tempor√§re Tabelle des Schemas <b>reconciliation_db</b> zu laden <b>.</b> <br><br>  Das optimale Lesen der Dateien erfolgt durch mehrere parallele Prozesse.  Wir lesen Zeile f√ºr Zeile in St√ºcken von jeweils 5 Megabyte.  Die Zahl "5 Megabyte" wurde durch die empirische Methode erhalten.  Mit dieser Gr√∂√üe von einem Textst√ºck konnten wir die k√ºrzeste Zeit zum Lesen gro√üer Dateien auf unserer virtuellen Maschine erhalten.  Sie k√∂nnen mit diesem Parameter in Ihrer Umgebung experimentieren und sehen, wie sich die Betriebszeit √§ndert: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing def process_wrapper(self, chunk_start, chunk_size): """ Read a particular chunk """ with open(self.file_name_raw, newline='\n') as file: file.seek(chunk_start) lines = file.read(chunk_size).splitlines() for line in lines: self.process(line) def chunkify(self, size=1024*1024*5): """ Return a new chunk """ with open(self.file_name_raw, 'rb') as file: chunk_end = file.tell() while True: chunk_start = chunk_end file.seek(size, 1) file.readline() chunk_end = file.tell() if chunk_end &gt; self.file_end: chunk_end = self.file_end yield chunk_start, chunk_end - chunk_start break else: yield chunk_start, chunk_end - chunk_start @m.timing def run_reading(self): """ The main method for the reading """ # init objects pool = mp.Pool(mp.cpu_count()) jobs = [] m.info('Run csv reading...') # create jobs for chunk_start, chunk_size in self.chunkify(): jobs.append(pool.apply_async(self.process_wrapper, (chunk_start, chunk_size))) # wait for all jobs to finish for job in jobs: job.get() # clean up pool.close() pool.join() m.info('CSV file reading has been completed')</span></span></code> </pre> <br>  Beispiel f√ºr das Lesen einer zuvor erstellten Datei in 1M-Datens√§tzen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9p/z1/zr/9pz1zrkzeelnep_r8oppk0sxhok.png"></div><br>  Der Screenshot zeigt die Erstellung einer tempor√§ren Tabelle mit einem eindeutigen Namen f√ºr den aktuellen Abstimmungslauf.  Als n√§chstes erfolgt das asynchrone Lesen der Datei in Teilen und das Aufnehmen des Hash jeder Zeile.  Das Einf√ºgen von Daten vom Adapter in die Zieltabelle vervollst√§ndigt die Arbeit mit diesem Adapter. <br><blockquote>  Durch die Verwendung einer tempor√§ren Tabelle mit einem eindeutigen Namen f√ºr jeden Abstimmungsprozess k√∂nnen Sie den Abstimmungsprozess zus√§tzlich in einer Datenbank parallelisieren. </blockquote><br><h2>  Adapter f√ºr PostgreSQL </h2><br>  Der Adapter zum Verarbeiten der in der Tabelle gespeicherten Daten funktioniert ungef√§hr so ‚Äã‚Äãwie der Adapter f√ºr die Datei: <br><br><ul><li>  Einlesen von Teilen der Tabelle (wenn sie gro√ü ist, √ºber 100 KB Eintr√§ge) und Aufnehmen eines Hashs f√ºr alle Spalten mit Ausnahme der Transaktionskennung; </li><li>  Dann werden die verarbeiteten Daten in die Tabelle <b>reconciliation_db</b> eingef√ºgt <b>.</b>  <b>Speicher _ $ (int (time.time ())</b> . </li></ul><br>  Ein interessantes Merkmal dieses Adapters besteht darin, dass er einen Pool von Verbindungen zur Datenbank verwendet, der anhand des Index nach den erforderlichen Daten in der Tabelle sucht und diese verarbeitet. <br><br>  Basierend auf der Gr√∂√üe der Tabelle wird die Anzahl der f√ºr die Verarbeitung erforderlichen Prozesse berechnet und innerhalb jedes Prozesses in 10 Aufgaben unterteilt. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">read_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Read the data from the postgres and shared those records with each processor to perform their operation using threads """</span></span> threads_array = self.get_threads(<span class="hljs-number"><span class="hljs-number">0</span></span>, self.max_id_num_row, self.pid_max) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(threads_array) + <span class="hljs-number"><span class="hljs-number">1</span></span>): m.info(<span class="hljs-string"><span class="hljs-string">'Process %s'</span></span> % pid) <span class="hljs-comment"><span class="hljs-comment"># Getting connection from the connection pool select_conn = self._select_conn_pool.getconn() select_conn.autocommit = 1 # Creating 10 process to perform the operation process = Process(target=self.process_data, args=(self.data_queque, pid, threads_array[pid-1][0], threads_array[pid-1][1], select_conn)) process.daemon = True process.start() process.join() select_conn.close()</span></span></code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pw/kt/kk/pwktkkisxg3sud4dyss_gtyi4gy.png"></div><br><h2>  Suchen Sie nach Unstimmigkeiten </h2><br>  Wir fahren mit der √úberpr√ºfung der von zwei Adaptern empfangenen Daten fort. <br><br>  Der Abgleich (oder das Empfangen eines Diskrepanzberichts) erfolgt auf der Serverseite der Datenbank unter Verwendung der gesamten Leistungsf√§higkeit der SQL-Sprache. <br><br>  Die SQL-Abfrage ist recht unkompliziert - es handelt sich lediglich um eine Tabellenverkn√ºpfung mit Daten von den Adaptern zu sich selbst nach Transaktions-ID: <br><br><pre> <code class="python hljs">sql_command = sql.SQL(<span class="hljs-string"><span class="hljs-string">""" select s1.adapter_name, count(s1.transaction_uid) as tran_count from {0}.{1} s1 full join {0}.{1} s2 on s2.transaction_uid = s1.transaction_uid and s2.adapter_name != s1.adapter_name and s2.hash = s1.hash where s2.transaction_uid is null group by s1.adapter_name;"""</span></span>).format(sql.Identifier(self.schema_target), sql.Identifier(self.storage_table))</code> </pre><br>  Die Ausgabe ist ein Bericht: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5c/ou/gy/5cougys1gkflsplq2hvkoleooto.png"></div><br>  √úberpr√ºfen Sie, ob im obigen Bild alles korrekt ist.  Wir erinnern uns, dass 9917 aus der Tabelle in der Datenbank gel√∂scht und 10.022 Zeilen ge√§ndert wurden.  Insgesamt 19939 Zeilen, wie aus dem Bericht hervorgeht. <br><br><h2>  √úbersichtstabelle </h2><br>  Es bleibt nur, "saubere" Transaktionen in die Speichertabelle einzuf√ºgen, die in jeder Hinsicht (nach Hash) in verschiedenen Adaptern √ºbereinstimmen.  Dieser Vorgang wird von der folgenden SQL-Abfrage ausgef√ºhrt: <br><br><pre> <code class="python hljs">sql_command = sql.SQL(<span class="hljs-string"><span class="hljs-string">""" with reconcil_data as ( select s1.transaction_uid from {0}.{1} s1 join {0}.{1} s2 on s2.transaction_uid = s1.transaction_uid and s2.adapter_name != s1.adapter_name where s2.hash = s1.hash and s1.adapter_name = 'postresql_adapter' ) insert into {2}.transaction_log select t.transaction_uid, t.account_uid, t.transaction_date, t.type_deal, t.transaction_amount from {3}.transaction_log t join reconcil_data r on t.transaction_uid = r.transaction_uid where not exists ( select 1 from {2}.transaction_log tl where tl.transaction_uid = t.transaction_uid ) """</span></span>).format(sql.Identifier(self.schema_target), sql.Identifier(self.storage_table), sql.Identifier(self.schema_db_clean), sql.Identifier(self.schema_raw))</code> </pre><br>  Die tempor√§re Tabelle, die wir als Zwischenspeicher f√ºr Daten von den Adaptern verwendet haben, kann gel√∂scht werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uq/sr/te/uqsrte2g0thu2woasaxqojdbc88.png"></div><br><h2>  Fazit </h2><br>  Im Laufe der Arbeit wurde ein System zum Abgleich von Daten aus verschiedenen Quellen entwickelt: eine Textdatei und eine Tabelle in der Datenbank.  Benutzte ein Minimum an zus√§tzlichen Werkzeugen. <br><br>  Vielleicht kann ein erfahrener Leser feststellen, dass die Verwendung von Frameworks wie Apache Spark in Verbindung mit der Konvertierung von Rohdaten in ein Parkettformat diesen Prozess erheblich beschleunigen kann, insbesondere bei gro√üen Volumina.  Das Hauptziel dieser Arbeit ist es jedoch, ein System in Bare-Python zu schreiben und die Multiprozessor-Datenverarbeitung zu untersuchen.  Womit wir uns meiner Meinung nach befasst haben. <br><br>  Der Quellcode des gesamten Projekts befindet sich <a href="https://github.com/igorgorbenko/transact_reconciliation" rel="nofollow">in meinem Repository auf GitHub</a> . Ich empfehle Ihnen, sich damit vertraut zu machen. <br><br>  Gerne beantworte ich alle Fragen und informiere mich √ºber Ihre Kommentare. <br><br>  Ich w√ºnsche Ihnen viel Erfolg! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de480076/">https://habr.com/ru/post/de480076/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de480062/index.html">10 Steuersysteme. Wo ist es bequemer, √ºber Aufgaben zu kommunizieren und Dateien zu teilen?</a></li>
<li><a href="../de480064/index.html">W√∂rter thematisch gruppiert lernen</a></li>
<li><a href="../de480068/index.html">[Update] Unsere Leute sind geschlagen, und wir werden schweigen?</a></li>
<li><a href="../de480070/index.html">Vorteile reagieren: Ein Segen f√ºr Unternehmen?</a></li>
<li><a href="../de480072/index.html">Kubernetes: Warum ist es so wichtig, ein Systemressourcenmanagement einzurichten?</a></li>
<li><a href="../de480078/index.html">Neue Front-End-Bibliotheken bei React Peripherals</a></li>
<li><a href="../de480080/index.html">Was ben√∂tigen Sie f√ºr Notizen?</a></li>
<li><a href="../de480082/index.html">Verwenden der Partitionierung in MySQL f√ºr Zabbix mit einer gro√üen Anzahl von √úberwachungsobjekten</a></li>
<li><a href="../de480086/index.html">Wie Sie die Anforderungen von 152-FZ erf√ºllen, die pers√∂nlichen Daten unserer Kunden sch√ºtzen und nicht auf unseren Rechen treten</a></li>
<li><a href="../de480088/index.html">DevOps - OK, aber was tun? So reduzieren Sie die Handarbeit und erzielen das gew√ºnschte Ergebnis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
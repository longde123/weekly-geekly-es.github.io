<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèΩ üè© ‚≠êÔ∏è NewSQL = NoSQL + ACID üë©üèæ‚Äçüè≠ üöí ü§ûüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hasta hace poco, en Odnoklassniki, se almacenaban alrededor de 50 TB de datos en tiempo real en SQL Server. Para tal volumen, es casi imposible propor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NewSQL = NoSQL + ACID</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/417593/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t5/hc/h2/t5hch2mr-lw9ffeahr_9gaxizlg.jpeg" width="600"></div><br>  Hasta hace poco, en Odnoklassniki, se almacenaban alrededor de 50 TB de datos en tiempo real en SQL Server.  Para tal volumen, es casi imposible proporcionar acceso al centro de datos r√°pido, confiable e incluso a prueba de fallas utilizando SQL DBMS.  Por lo general, en tales casos utilizan uno de los repositorios NoSQL, pero no todo se puede transferir a NoSQL: algunas entidades requieren garant√≠as de transacciones ACID. <br><br>  Esto nos llev√≥ a usar el almacenamiento NewSQL, es decir, un DBMS que proporciona tolerancia a fallas, escalabilidad y rendimiento de los sistemas NoSQL, pero al mismo tiempo conserva las garant√≠as ACID familiares para los sistemas cl√°sicos.  Hay pocos sistemas industriales en funcionamiento en esta nueva clase, por lo que implementamos dicho sistema nosotros mismos y lo pusimos en funcionamiento comercial. <br><br>  C√≥mo funciona y qu√© sucedi√≥: lea debajo del corte. <br><a name="habracut"></a><br>  Hoy, la audiencia mensual de Odnoklassniki es de m√°s de 70 millones de visitantes √∫nicos.  Estamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">entre las cinco</a> redes sociales m√°s grandes del mundo y los veinte sitios en los que los usuarios pasan la mayor parte del tiempo.  La infraestructura "OK" maneja cargas muy altas: m√°s de un mill√≥n de solicitudes HTTP / segundo para los frentes.  Partes de la flota de servidores en la cantidad de m√°s de 8000 piezas se encuentran cerca unas de otras, en cuatro centros de datos de Mosc√∫, lo que permite una latencia de red de menos de 1 ms entre ellas. <br><br>  Hemos estado usando Cassandra desde 2010, comenzando con la versi√≥n 0.6.  Hoy, varias docenas de grupos est√°n en funcionamiento.  El cl√∫ster m√°s r√°pido procesa m√°s de 4 millones de operaciones por segundo, y el m√°s grande almacena 260 TB. <br><br>  Sin embargo, todos estos son cl√∫steres NoSQL ordinarios utilizados para almacenar datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">d√©bilmente consistentes</a> .  Pero quer√≠amos reemplazar el almacenamiento consistente principal, Microsoft SQL Server, que se ha utilizado desde la fundaci√≥n de Odnoklassniki.  El almacenamiento consisti√≥ en m√°s de 300 m√°quinas SQL Server Standard Edition, que conten√≠an 50 TB de datos: entidades comerciales.  Estos datos se modifican como parte de las transacciones ACID y requieren una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gran coherencia</a> . <br><br>  Para distribuir datos entre los nodos de SQL Server, utilizamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">particiones</a> verticales y horizontales (fragmentaci√≥n).  Hist√≥ricamente, utilizamos un esquema simple de fragmentaci√≥n de datos: cada entidad estaba asociada a un token, una funci√≥n de la ID de la entidad.  Las entidades con el mismo token se colocaron en el mismo servidor SQL.  La relaci√≥n de tipo maestro-detalle se implement√≥ para que los tokens de los registros principales y generados siempre coincidieran y estuvieran en el mismo servidor.  En una red social, casi todos los registros se generan en nombre de un usuario, lo que significa que todos los datos del usuario dentro de un subsistema funcional se almacenan en un servidor.  Es decir, las tablas de un servidor SQL casi siempre participaban en una transacci√≥n comercial, lo que hac√≠a posible garantizar la consistencia de los datos utilizando transacciones ACID locales, sin la necesidad de transacciones ACID distribuidas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lentas y poco confiables</a> . <br><br>  Gracias a sharding y a acelerar SQL: <br><br><ul><li>  No utilizamos restricciones de clave externa, ya que al fragmentar, la ID de entidad puede estar en otro servidor. </li><li>  No utilizamos procedimientos almacenados y disparadores debido a la carga adicional en la CPU DBMS. </li><li>  No utilizamos JOIN debido a todo lo anterior y a muchas lecturas aleatorias del disco. </li><li>  Fuera de una transacci√≥n, para reducir los puntos muertos, utilizamos el nivel de aislamiento Leer no comprometido. </li><li>  Realizamos solo transacciones cortas (en promedio, m√°s cortas que 100 ms). </li><li>  No utilizamos UPDATE y DELETE de varias filas debido a la gran cantidad de puntos muertos; solo actualizamos un registro. </li><li>  Siempre ejecutamos consultas solo por √≠ndices: una consulta con un plan para un an√°lisis completo de la tabla para nosotros significa una sobrecarga de la base de datos y su falla. </li></ul><br>  Estos pasos permitieron exprimir el rendimiento casi m√°ximo de los servidores SQL.  Sin embargo, los problemas se hicieron cada vez m√°s.  Miremos a ellos. <br><br><h2>  Problemas de SQL </h2><br><ul><li>  Como utilizamos fragmentos de propiedad, los administradores agregaron manualmente nuevos fragmentos.  Todo este tiempo, las r√©plicas de datos escalables no respondieron a las solicitudes. </li><li>  A medida que aumenta el n√∫mero de registros en la tabla, la velocidad de inserci√≥n y modificaci√≥n disminuye, al agregar √≠ndices a una tabla existente, la velocidad cae varias veces, la creaci√≥n y recreaci√≥n de √≠ndices se produce con el tiempo de inactividad. </li><li>  Tener pocos Windows para SQL Server en producci√≥n dificulta la administraci√≥n de su infraestructura </li></ul><br>  Pero el problema principal es <br><br><h2>  Tolerancia a fallos </h2><br>  El SQL Server cl√°sico tiene poca tolerancia a fallas.  Supongamos que solo tiene un servidor de base de datos y falla una vez cada tres a√±os.  En este momento, el sitio no funciona durante 20 minutos, esto es aceptable.  Si tiene 64 servidores, entonces el sitio no funciona una vez cada tres semanas.  Y si tiene 200 servidores, entonces el sitio no funciona todas las semanas.  Esto es un problema <br><br>  ¬øQu√© se puede hacer para mejorar la resistencia de SQL Server?  Wikipedia nos ofrece construir un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cl√∫ster altamente accesible</a> : en caso de falla de cualquiera de los componentes, hay uno duplicado. <br><br>  Esto requiere una flota de equipos caros: redundancia m√∫ltiple, fibra, almacenamiento compartido y la inclusi√≥n de una reserva no funciona de manera confiable: aproximadamente el 10% de las inclusiones fallan con un nodo de respaldo por el motor detr√°s del nodo principal. <br><br>  Pero el principal inconveniente de un cl√∫ster tan accesible es la disponibilidad cero en caso de falla del centro de datos en el que se encuentra.  Odnoklassniki tiene cuatro centros de datos, y necesitamos proporcionar trabajo en caso de un accidente completo en uno de ellos. <br><br>  Para hacer esto, puede usar la replicaci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Multi-Master</a> integrada en SQL Server.  Esta soluci√≥n es mucho m√°s costosa debido al costo del software y adolece de problemas bien conocidos con la replicaci√≥n: demoras impredecibles en las transacciones durante la replicaci√≥n s√≠ncrona y demoras en la aplicaci√≥n de replicaciones (y, como resultado, modificaciones perdidas) durante la asincr√≥nica.  La <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">resoluci√≥n manual</a> impl√≠cita <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de conflictos</a> hace que esta opci√≥n sea completamente inaplicable para nosotros. <br><br>  Todos estos problemas requer√≠an una soluci√≥n radical y procedimos a un an√°lisis detallado de ellos.  Aqu√≠ debemos familiarizarnos con lo que b√°sicamente hace SQL Server: las transacciones. <br><br><h2>  Transacci√≥n simple </h2><br>  Considere la transacci√≥n m√°s simple, desde el punto de vista de un programador SQL aplicado: agregar una foto a un √°lbum.  Los √°lbumes y las fotos se almacenan en diferentes platos.  El √°lbum tiene un contador p√∫blico de fotos.  Luego, dicha transacci√≥n se divide en los siguientes pasos: <br><br><ol><li>  Bloqueamos el √°lbum por clave. </li><li>  Crea una entrada en la tabla de fotos. </li><li>  Si la foto tiene un estado p√∫blico, entonces cerramos el contador p√∫blico de fotos en el √°lbum, actualizamos el registro y confirmamos la transacci√≥n. </li></ol><br>  O en forma de pseudoc√≥digo: <br><br><pre><code class="hljs pgsql">TX.<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>("Albums", id); Album album = albums.<span class="hljs-keyword"><span class="hljs-keyword">lock</span></span>(id); Photo photo = photos.<span class="hljs-keyword"><span class="hljs-keyword">create</span></span>(‚Ä¶); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (photo.status == <span class="hljs-built_in"><span class="hljs-built_in">PUBLIC</span></span> ) { album.incPublicPhotosCount(); } album.<span class="hljs-keyword"><span class="hljs-keyword">update</span></span>(); TX.<span class="hljs-keyword"><span class="hljs-keyword">commit</span></span>();</code> </pre> <br>  Vemos que el escenario de transacci√≥n comercial m√°s com√∫n es leer datos de la base de datos en la memoria del servidor de aplicaciones, cambiar algo y guardar los nuevos valores nuevamente en la base de datos.  Por lo general, en dicha transacci√≥n actualizamos varias entidades, varias tablas. <br><br>  Al ejecutar una transacci√≥n, puede ocurrir una modificaci√≥n competitiva de los mismos datos de otro sistema.  Por ejemplo, Antispam puede decidir que el usuario es sospechoso y, por lo tanto, todas las fotos del usuario ya no deber√≠an ser p√∫blicas, deber√≠an enviarse con moderaci√≥n, lo que significa cambiar photo.status a otro valor y desenroscar los contadores correspondientes.  Obviamente, si esta operaci√≥n ocurre sin garant√≠as de atomicidad de aplicaci√≥n y aislamiento de modificaciones de la competencia, como en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ACID</a> , el resultado no ser√° lo que se necesita: el contador de fotos mostrar√° el valor incorrecto o no se enviar√°n todas las fotos para moderaci√≥n. <br><br>  Existe una gran cantidad de c√≥digo similar que manipula varias entidades comerciales dentro del marco de una transacci√≥n durante toda la existencia de Odnoklassniki.  Por la experiencia de migrar a NoSQL con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">coherencia eventual,</a> sabemos que las mayores dificultades (y costos de tiempo) son la necesidad de desarrollar c√≥digo destinado a mantener la coherencia de los datos.  Por lo tanto, consideramos el requisito principal para un nuevo repositorio para proporcionar transacciones ACID de l√≥gica real para la l√≥gica de la aplicaci√≥n. <br><br>  Otros requisitos igualmente importantes fueron: <br><br><ul><li>  Si el centro de datos falla, tanto la lectura como la escritura en el nuevo almacenamiento deber√≠an estar disponibles. </li><li>  Mantener la velocidad de desarrollo actual.  Es decir, cuando se trabaja con un nuevo repositorio, la cantidad de c√≥digo deber√≠a ser aproximadamente la misma, no deber√≠a ser necesario agregar algo al repositorio, desarrollar algoritmos para resolver conflictos, mantener √≠ndices secundarios, etc. </li><li>  La velocidad del nuevo almacenamiento debe ser lo suficientemente alta tanto al leer datos como al procesar transacciones, lo que efectivamente significa la inaplicabilidad de soluciones acad√©micamente rigurosas, universales pero lentas, como, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los compromisos de dos fases</a> . </li><li>  Autoescalado sobre la marcha. </li><li>  Usar servidores ordinarios y baratos, sin la necesidad de comprar piezas ex√≥ticas de hierro. </li><li>  Oportunidad de desarrollar almacenamiento por parte de los desarrolladores de la compa√±√≠a.  En otras palabras, se dio prioridad a sus propias soluciones basadas en c√≥digo abierto, preferiblemente en Java. </li></ul><br><h2>  Decisiones, Decisiones </h2><br>  Analizando posibles soluciones, llegamos a dos posibles opciones de arquitectura: <br><br>  El primero es tomar cualquier servidor SQL e implementar la tolerancia a fallas necesaria, el mecanismo de escala, el cl√∫ster de conmutaci√≥n por error, la resoluci√≥n de conflictos y las transacciones ACID distribuidas, confiables y r√°pidas.  Calificamos esta opci√≥n como altamente no trivial y consume mucho tiempo. <br><br>  La segunda opci√≥n es tomar un repositorio NoSQL listo para usar con escalamiento implementado, un cl√∫ster de conmutaci√≥n por error, resoluci√≥n de conflictos e implementar transacciones y SQL nosotros mismos.  A primera vista, incluso la tarea de implementar SQL, sin mencionar las transacciones ACID, parece una tarea durante a√±os.  Pero luego nos dimos cuenta de que el conjunto de caracter√≠sticas de SQL que usamos en la pr√°ctica est√° tan lejos de ANSI SQL como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cassandra CQL est√°</a> lejos de ANSI SQL.  Echando un vistazo m√°s de cerca a CQL, nos dimos cuenta de que estaba lo suficientemente cerca de lo que necesit√°bamos. <br><br><h2>  Cassandra y CQL </h2><br>  Entonces, ¬øqu√© es lo interesante de Cassandra, qu√© capacidades tiene? <br><br>  En primer lugar, aqu√≠ puede crear tablas con soporte para varios tipos de datos, puede hacer SELECCIONAR o ACTUALIZAR en la clave primaria. <br><br><pre> <code class="hljs sql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> photos (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span> <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span> <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, owner <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span>,‚Ä¶); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> photos <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">id</span></span>=?; <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> photos <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> ‚Ä¶ <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">id</span></span>=?;</code> </pre> <br>  Para garantizar datos de r√©plica consistentes, Cassandra utiliza un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enfoque de qu√≥rum</a> .  En el caso m√°s simple, esto significa que cuando se colocan tres r√©plicas de la misma fila en diferentes nodos del cl√∫ster, el registro se considera exitoso si la mayor√≠a de los nodos (es decir, dos de cada tres) confirman el √©xito de esta operaci√≥n de escritura.  Los datos de una serie se consideran consistentes si, al leer, la mayor√≠a de los nodos fueron interrogados y confirmados.  Por lo tanto, con la presencia de tres r√©plicas, se garantiza la consistencia de datos completa e instant√°nea en caso de falla de un nodo.  Este enfoque nos permiti√≥ implementar un esquema a√∫n m√°s confiable: siempre enviar solicitudes a las tres r√©plicas, esperando la respuesta de las dos m√°s r√°pidas.  La respuesta tard√≠a de la tercera r√©plica se descarta.  Un nodo que llega tarde con una respuesta puede tener serios problemas: frenos, recolecci√≥n de basura en la JVM, recuperaci√≥n directa de memoria en el kernel de Linux, falla de hardware, desconexi√≥n de la red.  Sin embargo, esto no afecta las operaciones o los datos del cliente. <br><br>  El enfoque cuando recurrimos a tres nodos y obtenemos una respuesta de dos se llama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">especulaci√≥n</a> : se env√≠a una solicitud de comentarios adicionales incluso antes de que "se caiga". <br><br>  Otra ventaja de Cassandra es Batchlog, un mecanismo que garantiza la aplicaci√≥n completa o la no aplicaci√≥n completa del paquete de cambios que realice.  Esto nos permite resolver A en ACID - atomicidad fuera de la caja. <br><br>  Lo m√°s cercano a las transacciones en Cassandra son las llamadas " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transacciones ligeras</a> ".  Pero est√°n lejos de ser transacciones "reales" de ACID: de hecho, es una oportunidad para hacer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CAS</a> con datos de un solo registro, utilizando el consenso sobre el protocolo pesado de Paxos.  Por lo tanto, la velocidad de tales transacciones es baja. <br><br><h2>  Lo que extra√±amos en Cassandra </h2><br>  Entonces, tuvimos que implementar transacciones reales de ACID en Cassandra.  Con lo cual podr√≠amos implementar f√°cilmente otras dos caracter√≠sticas convenientes del DBMS cl√°sico: √≠ndices r√°pidos consistentes, lo que nos permitir√≠a realizar un muestreo de datos no solo en la clave primaria y el generador habitual de ID mon√≥tonas de incremento autom√°tico. <br><br><h4>  C * uno </h4><br>  As√≠ naci√≥ el nuevo DBMS <b>C * One</b> , que consta de tres tipos de nodos de servidor: <br><br><ul><li>  Almacenamiento: los servidores Cassandra (casi) est√°ndar responsables del almacenamiento de datos en unidades locales.  A medida que aumenta la carga y la cantidad de datos, su n√∫mero puede escalarse f√°cilmente a decenas o cientos. </li><li>  Coordinadores de transacciones: permite la ejecuci√≥n de transacciones. </li><li>  Los clientes son servidores de aplicaciones que implementan operaciones comerciales e inician transacciones.  Puede haber miles de tales clientes. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/eb6/f4f/498/eb6f4f4983f44dcbe63cd545e87f8d1a.png"><br><br>  Todos los tipos de servidores est√°n en un cl√∫ster com√∫n, use el protocolo de mensaje interno de Cassandra para comunicarse entre s√≠ y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cotillee</a> para intercambiar informaci√≥n del cl√∫ster.  Con la ayuda de Heartbeat, los servidores aprenden sobre fallas mutuas, admiten un √∫nico esquema de datos: tablas, su estructura y replicaci√≥n;  esquema de partici√≥n, topolog√≠a de cl√∫ster, etc. <br><br><h4>  Los clientes </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/b83/9ff/971/b839ff971b0049d56d55bd309f44ae4e.png"><br><br>  En lugar de los controladores est√°ndar, se utiliza el modo Fat Client.  Dicho nodo no almacena datos, pero puede actuar como coordinador de la ejecuci√≥n de la consulta, es decir, el Cliente mismo realiza la funci√≥n de coordinador de sus solicitudes: sondea los repositorios de r√©plica y resuelve los conflictos.  Esto no solo es m√°s confiable y m√°s r√°pido que un controlador est√°ndar que requiere comunicaci√≥n con un coordinador remoto, sino que tambi√©n le permite controlar la transferencia de solicitudes.  Fuera de una transacci√≥n abierta en el cliente, las solicitudes se env√≠an al almacenamiento.  Si el cliente abri√≥ la transacci√≥n, todas las solicitudes dentro de la transacci√≥n se env√≠an al coordinador de transacciones. <br><img src="https://habrastorage.org/getpro/habr/post_images/d39/d43/483/d39d43483590319f4d49e41a25316058.png"><br><br><h2>  C * Un coordinador de transacciones </h2><br>  El coordinador es lo que implementamos para C * One desde cero.  Es responsable de administrar transacciones, bloqueos y el orden en que se aplican las transacciones. <br><br>  Para cada transacci√≥n que se atiende, el coordinador genera una marca de tiempo: cada una posterior es mayor que la transacci√≥n anterior.  Dado que el sistema de resoluci√≥n de conflictos en Cassandra se basa en marcas de tiempo (de dos registros en conflicto, el actual con la √∫ltima marca de tiempo se considera relevante), el conflicto siempre se resolver√° a favor de la transacci√≥n posterior.  Por lo tanto, implementamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">relojes Lamport</a> , una forma econ√≥mica de resolver conflictos en un sistema distribuido. <br><br><h2>  Cerraduras </h2><br>  Para garantizar el aislamiento, decidimos utilizar el m√©todo m√°s simple: bloqueos pesimistas en la clave principal del registro.  En otras palabras, en una transacci√≥n, el registro primero debe bloquearse, solo luego leerse, modificarse y guardarse.  Solo despu√©s de una confirmaci√≥n exitosa se puede desbloquear un registro para que las transacciones de la competencia puedan usarlo. <br><br>  La implementaci√≥n de este bloqueo es simple en un entorno no asignado.  Hay dos formas principales en un sistema distribuido: implementar bloqueo distribuido en el cl√∫ster o distribuir transacciones para que las transacciones que involucran un solo registro sean atendidas siempre por el mismo coordinador. <br><br>  Como en nuestro caso los datos ya est√°n distribuidos por grupos de transacciones locales en SQL, se decidi√≥ asignar grupos de transacciones locales a los coordinadores: un coordinador realiza todas las transacciones con un token de 0 a 9, el segundo con un token de 10 a 19, y as√≠ sucesivamente.  Como resultado, cada una de las instancias del coordinador se convierte en un maestro de grupo de transacciones. <br><br>  Luego, los bloqueos se pueden implementar como un HashMap banal en la memoria del coordinador. <br><br><h2>  Fallas del coordinador </h2><br>  Dado que un coordinador atiende exclusivamente a un grupo de transacciones, es muy importante determinar r√°pidamente el hecho de su falla, de modo que se agote el tiempo de un intento repetido de ejecutar la transacci√≥n.  Para hacerlo m√°s r√°pido y confiable, aplicamos un protocolo de audici√≥n de qu√≥rum totalmente conectado: <br><br>  Cada centro de datos tiene al menos dos nodos coordinadores.  Peri√≥dicamente, cada coordinador env√≠a un mensaje de latido a los otros coordinadores y les informa sobre su funcionamiento, as√≠ como los mensajes de latidos de los coordinadores en el grupo por √∫ltima vez. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cde/1e4/ccd/cde1e4ccd6d23620eda08adc231aeec7.jpg"><br><br>  Despu√©s de recibir informaci√≥n similar de los dem√°s en la composici√≥n de sus mensajes de latido, cada coordinador decide por s√≠ mismo qu√© nodos del cl√∫ster funcionan y cu√°les no, guiados por el principio del qu√≥rum: si el nodo X recibe informaci√≥n de la mayor√≠a de los nodos del cl√∫ster sobre la recepci√≥n normal de mensajes del nodo Y, entonces , Y funciona.  Por el contrario, tan pronto como la mayor√≠a informa la p√©rdida de mensajes del nodo Y, Y ha fallado.  Es curioso que si un qu√≥rum le dice al nodo X que no recibe m√°s mensajes de √©l, entonces el propio nodo X considerar√° que ha fallado. <br><br>  Los mensajes de latido se env√≠an a una frecuencia alta, aproximadamente 20 veces por segundo, con un per√≠odo de 50 ms.  En Java, es dif√≠cil garantizar una respuesta de la aplicaci√≥n de 50 ms debido a la duraci√≥n comparable de las pausas causadas por el recolector de basura.  Pudimos lograr dicho tiempo de respuesta utilizando el recolector de basura G1, que nos permite especificar el objetivo durante la duraci√≥n de las pausas del GC.  Sin embargo, a veces, muy raramente, la pausa del colector va m√°s all√° de 50 ms, lo que puede conducir a una falsa detecci√≥n de falla.  Para evitar esto, el coordinador no informa la falla del nodo remoto cuando el primer mensaje de latido desaparece de √©l, solo si varios desaparecen consecutivamente, por lo que logramos detectar la falla del nodo del coordinador en 200 ms. <br><br>  Pero no es suficiente entender r√°pidamente qu√© nodo ha dejado de funcionar.  Necesitas hacer algo al respecto. <br><br><h2>  Reserva </h2><br>  El esquema cl√°sico supone que, en caso de que un maestro se niegue a lanzar una nueva elecci√≥n utilizando uno de los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modernos</a> algoritmos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">universales</a> .  Sin embargo, tales algoritmos tienen problemas bien conocidos con la convergencia del tiempo y la duraci√≥n del proceso electoral en s√≠.  Logramos evitar tales demoras adicionales utilizando el circuito equivalente de coordinadores en una red totalmente conectada: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e90/45e/007/e9045e00777362a5846eb78ef15bedea.png"><br><br>  Supongamos que queremos ejecutar una transacci√≥n en el grupo 50. Determinaremos de antemano un esquema de sustituci√≥n, es decir, qu√© nodos ejecutar√°n transacciones del grupo 50 en caso de falla del coordinador principal.  Nuestro objetivo es mantener el sistema operativo en caso de falla del centro de datos.  Determinamos que la primera reserva ser√° un nodo de otro centro de datos, y la segunda reserva ser√° un nodo del tercero.  Este esquema se selecciona una vez y no cambia hasta que la topolog√≠a del cl√∫ster cambia, es decir, hasta que ingresan nuevos nodos (lo que ocurre muy raramente).  El procedimiento para elegir un nuevo maestro activo en caso de falla del antiguo siempre ser√° el siguiente: la primera reserva se convertir√° en el maestro activo, y si ha dejado de funcionar, la segunda reserva se convertir√°. <br><br>  Tal esquema es m√°s confiable que el algoritmo universal, ya que para activar un nuevo maestro es suficiente determinar el hecho del fracaso del antiguo. <br><br>  Pero, ¬øc√≥mo entender√°n los clientes cu√°l de los maestros est√° trabajando ahora?  Durante 50 ms, no es posible enviar informaci√≥n a miles de clientes.  Una situaci√≥n es posible cuando un cliente env√≠a una solicitud para abrir una transacci√≥n, a√∫n sin saber que este asistente ya no funciona, y la solicitud se bloquear√° en un tiempo de espera.  Para evitar que esto suceda, los clientes env√≠an una solicitud especulativa para abrir una transacci√≥n inmediatamente al maestro del grupo y sus dos reservas, pero solo el que es el maestro activo en este momento responder√° a esta solicitud.  El cliente llevar√° a cabo toda la comunicaci√≥n posterior dentro de la transacci√≥n solo con el maestro activo. <br><br>  Los maestros de respaldo reciben solicitudes de transacciones no propias en la cola de transacciones no nacidas, donde se almacenan durante alg√∫n tiempo.  Si el maestro activo muere, el nuevo maestro procesa las solicitudes para abrir transacciones desde su cola y responde al cliente.  Si el cliente ya ha logrado abrir una transacci√≥n con el maestro anterior, se ignora la segunda respuesta (y, obviamente, dicha transacci√≥n no se completar√° y el cliente la repetir√°). <br><br><h2>  C√≥mo funciona una transacci√≥n </h2><br>  Supongamos que un cliente le env√≠a al coordinador una solicitud para abrir una transacci√≥n para dicha entidad con una clave primaria.  El coordinador bloquea esta entidad y la coloca en la tabla de bloqueo en la memoria.  Si es necesario, el coordinador lee esta entidad de la tienda y almacena los datos recibidos en un estado de transacci√≥n en la memoria del coordinador. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4d1/dfb/dcd/4d1dfbdcd92e4b05ca49ef5168177eb8.png"><br><br>  Cuando el cliente quiere cambiar los datos en la transacci√≥n, env√≠a al coordinador una solicitud para actualizar la entidad, y coloca los nuevos datos en la tabla de estado de la transacci√≥n en la memoria.  Esto completa la grabaci√≥n: la grabaci√≥n no se realiza en el repositorio. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/00e/803/570/00e803570a0fbe19cb76786cbc6f0142.png"><br><br>  Cuando un cliente solicita, en el marco de una transacci√≥n activa, sus propios datos modificados, el coordinador act√∫a as√≠: <br><br><ul><li>  si la ID ya est√° en la transacci√≥n, los datos se toman de la memoria; </li><li>  Si no hay ID en la memoria, los datos que faltan se leen desde los nodos de almacenamiento, combinados con los que ya est√°n en la memoria, y el resultado se devuelve al cliente. </li></ul><br>  Por lo tanto, el cliente puede leer sus propios cambios, mientras que otros clientes no ven estos cambios, ya que se almacenan solo en la memoria del coordinador, todav√≠a no est√°n en los nodos de Cassandra. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d8e/140/5f7/d8e1405f7995228ec3d061af59f1f685.png"><br><br>  Cuando el cliente env√≠a una confirmaci√≥n, el coordinador guarda el estado en la memoria del servicio en el lote registrado, y ya en forma de lote registrado se env√≠a a los repositorios de Cassandra.  Los repositorios hacen todo lo necesario para que este paquete se aplique at√≥micamente (completamente) y devuelven una respuesta al coordinador, quien libera los bloqueos y confirma el √©xito de la transacci√≥n al cliente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/090/739/9fc/0907399fc025879f16174ff26163a937.png"><br><br>  Y para volver al coordinador, es suficiente para liberar la memoria ocupada por el estado de la transacci√≥n. <br><br>  Como resultado de las mejoras anteriores, implementamos los principios de ACID: <br><br><ul><li>  <b>Atomicidad</b>  Esta es una garant√≠a de que ninguna transacci√≥n se comprometer√° parcialmente con el sistema, se completar√°n todas sus operaciones secundarias o no se ejecutar√° ninguna.  Cumplimos con este principio debido al lote registrado en Cassandra. </li><li>  <b>Coherencia</b>  Cada transacci√≥n exitosa, por definici√≥n, captura solo resultados aceptables.  Si, despu√©s de abrir una transacci√≥n y realizar parte de las operaciones, se descubre que el resultado no es v√°lido, se realiza una reversi√≥n. </li><li>  <b>Aislamiento</b>  Cuando se ejecuta una transacci√≥n, las transacciones paralelas no deber√≠an afectar su resultado.  Las transacciones competidoras se a√≠slan utilizando bloqueos pesimistas en el coordinador.  Para las lecturas fuera de la transacci√≥n, se respeta el principio de aislamiento en el nivel Compromiso de lectura. </li><li>  <b>Sostenibilidad</b>  Independientemente de los problemas en los niveles inferiores (desenergizaci√≥n del sistema, falla del hardware,) los cambios realizados por una transacci√≥n completada con √©xito deben permanecer guardados despu√©s de reanudar la operaci√≥n. </li></ul><br><h2>  Lectura de √≠ndice </h2><br>  Toma una tabla simple: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> photos ( id <span class="hljs-type"><span class="hljs-type">bigint</span></span> <span class="hljs-keyword"><span class="hljs-keyword">primary key</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">owner</span></span> <span class="hljs-type"><span class="hljs-type">bigint</span></span>, modified <span class="hljs-type"><span class="hljs-type">timestamp</span></span>, ‚Ä¶)</code> </pre> <br>  Ella tiene una identificaci√≥n (clave principal), propietario y fecha de cambio.  Debe realizar una solicitud muy simple: seleccione los datos del propietario con la fecha de cambio "para el √∫ltimo d√≠a". <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> owner=? <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> modified&gt;?</code> </pre> <br>  Para que una consulta de este tipo funcione r√°pidamente, en SQL DBMS cl√°sico, debe crear un √≠ndice por columnas (propietario, modificado).  ¬°Podemos hacer esto de manera simple, ya que ahora tenemos garant√≠as de ACID! <br><br><h2>  √çndices en C * One </h2><br>  Hay una tabla fuente con fotos, en la que la identificaci√≥n del registro es la clave principal. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/039/5b3/a78/0395b3a784329992b88ba0618a94a7f1.jpg"><br><br>  Para el √≠ndice C *, One crea una nueva tabla, que es una copia del original.  La clave coincide con la expresi√≥n de √≠ndice, y tambi√©n incluye la clave primaria del registro de la tabla de origen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/92a/8c2/93e/92a8c293e8c145dc37f49a5126e68095.jpg"><br><br>  Ahora la solicitud de "propietario durante el √∫ltimo d√≠a" se puede volver a escribir como seleccionar de otra tabla: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> i1_test <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> owner=? <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> modified&gt;?</code> </pre> <br>  El coordinador mantiene autom√°ticamente la coherencia de los datos de la tabla de fotos originales y el √≠ndice i1.  Bas√°ndose √∫nicamente en el esquema de datos, cuando se recibe el cambio, el coordinador genera y recuerda el cambio no solo en la tabla principal, sino tambi√©n en los cambios de la copia.  No se realizan acciones adicionales con la tabla de √≠ndice, los registros no se leen, los bloqueos no se utilizan.  Es decir, agregar √≠ndices casi no consume recursos y pr√°cticamente no afecta la velocidad de aplicaci√≥n de modificaciones. <br><br>  Usando ACID, pudimos implementar √≠ndices "como en SQL".  Tienen consistencia, se pueden escalar, funcionan r√°pidamente, pueden ser compuestos e incorporados en el lenguaje de consulta CQL.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para admitir √≠ndices, no es necesario realizar cambios en el c√≥digo de la aplicaci√≥n. </font><font style="vertical-align: inherit;">Todo es simple, como en SQL. </font><font style="vertical-align: inherit;">Y lo m√°s importante, los √≠ndices no afectan la velocidad de ejecuci√≥n de las modificaciones a la tabla de transacciones original.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Que paso </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desarrollamos C * One hace tres a√±os y lo pusimos en operaci√≥n comercial. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øQu√© obtuvimos al final? Vamos a evaluar esto usando el ejemplo de un subsistema para procesar y almacenar fotos, uno de los tipos de datos m√°s importantes en una red social. No se trata de los cuerpos de las fotos en s√≠, sino de todo tipo de metainformaci√≥n. Ahora en Odnoklassniki hay alrededor de 20 mil millones de tales registros, el sistema procesa 80 mil solicitudes de lectura por segundo, hasta 8 mil transacciones ACID por segundo asociadas con la modificaci√≥n de datos. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuando utilizamos SQL con factor de replicaci√≥n = 1 (pero en RAID 10), la metainformaci√≥n de la foto se almacen√≥ en un cl√∫ster altamente accesible de 32 m√°quinas con Microsoft SQL Server (m√°s 11 copias de seguridad). Tambi√©n asign√≥ 10 servidores para almacenar copias de seguridad. Un total de 50 autos caros. Al mismo tiempo, el sistema funcionaba a carga nominal, sin reserva.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Despu√©s de migrar al nuevo sistema, obtuvimos un factor de replicaci√≥n = 3: una copia en cada centro de datos. El sistema consta de 63 nodos de almacenamiento Cassandra y 6 m√°quinas coordinadoras, con un total de 69 servidores. Pero estas m√°quinas son mucho m√°s baratas, su costo total es aproximadamente el 30% del costo del sistema en SQL. En este caso, la carga se mantiene al 30%. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Con la introducci√≥n de C * One, los retrasos tambi√©n disminuyeron: en SQL, la operaci√≥n de escritura tom√≥ aproximadamente 4.5 ms. En C * One: aproximadamente 1,6 ms. La duraci√≥n de la transacci√≥n es en promedio inferior a 40 ms, la confirmaci√≥n se realiza en 2 ms, la duraci√≥n de lectura y escritura es en promedio 2 ms. El percentil 99, solo 3-3,1 ms, el n√∫mero de tiempos de espera disminuy√≥ 100 veces, todo debido al uso generalizado de la especulaci√≥n.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hasta la fecha, la mayor√≠a de los nodos de SQL Server se han dado de baja; los nuevos productos se desarrollan solo con C * One. </font><font style="vertical-align: inherit;">Adaptamos C * One para trabajar en nuestra </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nube √∫nica</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , lo que nos permiti√≥ acelerar la implementaci√≥n de nuevos cl√∫steres, simplificar la configuraci√≥n y automatizar la operaci√≥n. </font><font style="vertical-align: inherit;">Sin el c√≥digo fuente, ser√≠a mucho m√°s dif√≠cil y hacer muletas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora estamos trabajando para transferir nuestras otras instalaciones de almacenamiento a la nube, pero esta es una historia completamente diferente.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417593/">https://habr.com/ru/post/es417593/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417583/index.html">Ma√±ana ICFP Contest 2018, ¬°salud! (+ √∫til para participar por primera vez)</a></li>
<li><a href="../es417585/index.html">C√≥mo ingresar al comit√© de programa de una conferencia de clase y por qu√© lo necesita</a></li>
<li><a href="../es417587/index.html">Medios de comunicaci√≥n: los ataques cibern√©ticos a gran escala aceleraron el crecimiento de la capitalizaci√≥n de las empresas de la industria de seguridad de la informaci√≥n</a></li>
<li><a href="../es417589/index.html">Siete reglas simples para hacer que Internet sea accesible para todos</a></li>
<li><a href="../es417591/index.html">C√≥mo "aprender" ingl√©s en un a√±o por su cuenta o un art√≠culo para aquellos que no trabajaron con ingl√©s</a></li>
<li><a href="../es417595/index.html">Antig√ºedades: Palm OS, c√≥digo eficiente y fotos repugnantes</a></li>
<li><a href="../es417597/index.html">Almacenamiento confiable con DRBD9 y Proxmox (Parte 2: iSCSI + LVM)</a></li>
<li><a href="../es417599/index.html">Fintech digest: los reguladores financieros necesitan IA para trabajar en condiciones modernas</a></li>
<li><a href="../es417601/index.html">Elige un servidor. ¬øQu√© buscar? Lista de verificaci√≥n</a></li>
<li><a href="../es417603/index.html">Anuncio de un mitap m√≥vil: ¬øQu√© hacer cuando la aplicaci√≥n se ha vuelto grande?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
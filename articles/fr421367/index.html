<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ°Ô∏è üöç üç£ AI, cours pratique. Configuration du mod√®le et des hyperparam√®tres pour reconna√Ætre les √©motions dans les images üíµ ü§õüèª üëû</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans les articles pr√©c√©dents de cette s√©rie de didacticiels, les options possibles pour la pr√©paration des donn√©es ont √©t√© d√©crites. Pr√©-traitement et...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, cours pratique. Configuration du mod√®le et des hyperparam√®tres pour reconna√Ætre les √©motions dans les images</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/421367/"><img src="https://habrastorage.org/webt/zq/7s/el/zq7selxswjsrmplg_pxw2xilqi4.jpeg"><br><br>  Dans les articles pr√©c√©dents de cette s√©rie de didacticiels, les options possibles pour la pr√©paration des donn√©es ont √©t√© d√©crites. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©-traitement et ajout de donn√©es avec des images</a> ; dans ces articles, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®le de base pour reconna√Ætre les √©motions √†</a> partir des images d'un r√©seau de neurones convolutionnels a √©galement √©t√© construit. <br>  Dans cet article, nous allons construire un mod√®le de r√©seau de neurones convolutionnel am√©lior√© pour reconna√Ætre les √©motions dans les images en utilisant une technique appel√©e <i>apprentissage inductif</i> . <br><a name="habracut"></a><br>  Vous devez d'abord vous familiariser avec l'article sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®le de base pour la reconnaissance des √©motions dans les images</a> , et vous pouvez √©galement vous y r√©f√©rer pendant la lecture, car certaines sections, y compris l'√©tude des donn√©es sources et la description des indicateurs de r√©seau, ne seront pas d√©taill√©es ici. <br><br><h2>  <font color="#0071c5">Les donn√©es</font> </h2><br>  L'ensemble de donn√©es contient 1630 images avec des √©motions de deux classes: <i>n√©gatives</i> (classe 0) et <i>positives</i> (classe 1).  Quelques exemples de ces images sont donn√©s ci-dessous. <br><br>  <b>N√©gatif</b> <br><img src="https://habrastorage.org/webt/zr/pf/ki/zrpfkiqvgcxw6kpsv777v9d1t6w.jpeg"><br><br><img src="https://habrastorage.org/webt/52/8x/s6/528xs6k7jnimfgvhagwolru8mi4.jpeg"><br><br><img src="https://habrastorage.org/webt/no/p0/vb/nop0vbapr4ep7o5dps1wvpkncoa.jpeg"><br><br>  <b>Positif</b> <br><img src="https://habrastorage.org/webt/uc/ua/oh/ucuaohklcwcgotqf4uryopnt_qg.jpeg"><br><br><img src="https://habrastorage.org/webt/u5/hp/rb/u5hprb1cjig28b4xk8urdljb8lm.jpeg"><br><br><img src="https://habrastorage.org/webt/ru/_a/xo/ru_axoahw4h4xytx_-yphxk56ii.jpeg"><br><br>  Certains exemples contiennent une √©motion positive ou n√©gative √©vidente, tandis que d'autres peuvent ne pas √™tre class√©s - m√™me avec une implication humaine.  Sur la base d'une inspection visuelle de ces cas, nous estimons que la pr√©cision maximale possible devrait √™tre d'environ 80%.  Notez qu'un classificateur al√©atoire fournit une pr√©cision d'environ 53% en raison d'un petit d√©s√©quilibre dans les classes. <br><br>  Pour former le mod√®le, nous utilisons la technique de <i>conservation d'une partie des √©chantillons</i> et divisons l'ensemble de donn√©es initial en deux parties, dont l'une (20 pour cent de l'ensemble initial) sera utilis√©e par nous pour v√©rification.  Le partitionnement est effectu√© par <i>stratification</i> : cela signifie que l'√©quilibre entre les classes est maintenu dans les ensembles de formation et de test. <br><br><h2>  <font color="#0071c5">R√©soudre l'insuffisance des donn√©es</font> </h2><br>  Le mod√®le de base a montr√© des r√©sultats, l√©g√®rement meilleurs que les pr√©dictions al√©atoires de la classe d'images.  Il peut y avoir plusieurs raisons possibles √† ce comportement.  Nous pensons que la raison principale est que la quantit√© de donn√©es disponibles est d√©cid√©ment insuffisante pour une telle formation de la partie convolutionnelle du r√©seau qui permettrait d'obtenir des caract√©ristiques sur la base de l'image d'entr√©e. <br>  Il existe de nombreuses fa√ßons de r√©soudre le probl√®me de l'insuffisance des donn√©es.  En voici quelques uns: <br><br><ul><li>  <b>R√©cup√©rer</b> .  L'id√©e de la m√©thode est d'√©valuer la distribution des donn√©es et de s√©lectionner de <i>nouveaux exemples √†</i> partir de cette distribution. </li><li>  <b>Apprendre sans professeur</b> .  Tout le monde peut trouver de grandes quantit√©s de donn√©es de m√™me nature que des exemples marqu√©s dans un ensemble de donn√©es donn√©.  Par exemple, il peut s'agir de films pour la reconnaissance vid√©o ou de livres audio pour la reconnaissance vocale.  L'√©tape suivante en cours de route consiste √† utiliser ces donn√©es pour la pr√©-formation du mod√®le (par exemple, en utilisant des auto-encodeurs). </li><li>  <b>Augmentation des donn√©es</b> .  Au cours de ce processus, les √©chantillons de donn√©es sont modifi√©s de mani√®re al√©atoire √† l'aide d'un ensemble donn√© de transformations. </li><li>  <b>Apprentissage inductif</b> .  Ce sujet nous int√©resse beaucoup, alors apprenons-le plus en d√©tail. </li></ul><br><h2>  <font color="#0071c5">Apprentissage inductif</font> </h2><br>  Le terme <i>entra√Ænement inductif</i> fait r√©f√©rence √† un ensemble de techniques utilisant des mod√®les (souvent tr√®s volumineux) form√©s sur diff√©rents ensembles de donn√©es approximativement de m√™me nature. <br><br><img src="https://habrastorage.org/webt/wl/jb/qi/wljbqidbfmpj1yfddtvjlkqt9ma.png"><br><br><img src="https://habrastorage.org/webt/bq/ji/ah/bqjiahabshkakrv2jcilp5pa1y8.png"><br><br>  Comparaison des m√©thodes traditionnelles d'apprentissage automatique et d'apprentissage inductif.  Image tir√©e de l'entr√©e de blog de S. Ruder <i>¬´Qu'est-ce que l'apprentissage inductif?¬ª</i>  . <br>  Il existe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">trois</a> principaux sc√©narios d'utilisation de l'apprentissage inductif: <br><br><ul><li>  <b>Mod√®les pr√©-form√©s</b> .  Tout utilisateur peut simplement prendre un mod√®le form√© par quelqu'un d'autre et l'utiliser pour ses t√¢ches.  Un tel sc√©nario est possible si les t√¢ches sont tr√®s similaires. </li><li>  <b>Bloquer la s√©lection des signes</b> .  √Ä ce stade, nous savons que l'architecture du mod√®le peut √™tre divis√©e en deux parties principales: l' <i>unit√©</i> d'extraction d'entit√©s, qui est charg√©e d'extraire les entit√©s des donn√©es d'entr√©e, et le <i>module de classification</i> , qui classe les exemples en fonction des entit√©s re√ßues.  En r√®gle g√©n√©rale, le bloc d'extraction d'entit√©s est la partie principale du mod√®le.  L'id√©e de la m√©thode est de prendre un bloc pour distinguer les caract√©ristiques d'un mod√®le form√© √† un autre probl√®me, de fixer ses coefficients de pond√©ration (les rendre non form√©s), puis de construire sur sa base de nouveaux modules de classification pour le probl√®me consid√©r√©.  Le module de classification n'est g√©n√©ralement pas tr√®s profond et se compose de plusieurs couches enti√®rement connect√©es, ce mod√®le est donc beaucoup plus facile √† former. </li><li>  <b>Accord pr√©cis et profond</b> .  Cette m√©thode est comme un sc√©nario utilisant un bloc d'extraction d'entit√©s.  Les m√™mes actions sont effectu√©es √† l'exception de ¬´geler¬ª le bloc d'extraction de fonctionnalit√©s.  Par exemple, vous pouvez prendre le r√©seau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VGG</a> comme un bloc d'extraction de fonctionnalit√©s et y ¬´geler¬ª uniquement les trois premiers (sur quatre) blocs convolutifs.  Dans ce cas, l'unit√© d'extraction de fonctionnalit√©s peut mieux s'adapter √† la t√¢che en cours.  Pour plus d'informations, consultez l'article de blog de F. Chollet. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cr√©ez des mod√®les de classification d'images puissants en utilisant une tr√®s petite quantit√© de donn√©es</a> . </li></ul><br>  Une description d√©taill√©e des sc√©narios d'utilisation de l'apprentissage inductif se trouve dans le cours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CS231n sur les r√©seaux de neurones convolutionnels de</a> l'Universit√© de Stanford <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pour la reconnaissance visuelle</a> par Fei-Fei Li et les articles de blog de S. Ruder L' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprentissage inductif est la prochaine fronti√®re du d√©veloppement apprentissage automatique</a> (sujets abord√©s de mani√®re plus approfondie). <br><br>  Vous pouvez avoir des questions: pourquoi toutes ces m√©thodes sont-elles n√©cessaires et pourquoi peuvent-elles fonctionner?  Nous essaierons d'y r√©pondre. <br><br><ul><li>  Avantages de l'utilisation de grands ensembles de donn√©es.  Par exemple, nous pouvons prendre le bloc d'extraction d'entit√©s √† partir d'un mod√®le form√© sur 14 millions d'images contenues dans le jeu de donn√©es du concours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ImageNet</a> .  Ces mod√®les sont suffisamment complexes pour permettre l' <i>extraction de fonctionnalit√©s de tr√®s haute qualit√© √†</i> partir des donn√©es d'entr√©e. </li><li>  Consid√©rations li√©es au temps.  La formation de grands mod√®les peut prendre des semaines, voire des mois.  Dans ce cas, tout le monde peut <i>√©conomiser √©norm√©ment de temps et de ressources informatiques</i> . </li><li>  Une hypoth√®se de poids sous-jacente √† la raison pour laquelle tout cela peut fonctionner est la suivante: Les attributs obtenus de la formation dans une t√¢che peuvent √™tre utiles et adapt√©s √† une autre t√¢che.  En d'autres termes, les caract√©ristiques ont la propri√©t√© de l'invariance par rapport au probl√®me.  Notez que le <i>domaine de la</i> nouvelle t√¢che doit √™tre similaire au domaine de la t√¢che d'origine.  Sinon, l'unit√© d'extraction de fonctionnalit√©s peut m√™me aggraver les r√©sultats. </li></ul><br><h2>  <font color="#0071c5">Architecture de mod√®le am√©lior√©e</font> </h2><br>  Nous connaissons maintenant le concept d'apprentissage inductif.  Nous savons √©galement qu'ImageNet est un √©v√©nement majeur, dans lequel presque toutes les architectures modernes de r√©seaux de neurones convolutionnels avanc√©s ont √©t√© test√©es.  Essayons de prendre le bloc d'extraction de fonctionnalit√©s de l'un de ces r√©seaux. <br><br>  Heureusement, la biblioth√®que Keras nous fournit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plusieurs</a> mod√®les pr√©-form√©s (via ImageNet) qui ont √©t√© cr√©√©s √† l'int√©rieur de cette plate-forme.  Nous importons et utilisons l'un de ces mod√®les. <br><br><img src="https://habrastorage.org/webt/jz/3t/ry/jz3trysk11d88hbmbxvlnoungxy.png"><br><br>  Dans ce cas, nous utiliserons un r√©seau avec une architecture VGG.  Pour s√©lectionner uniquement l'unit√© d'extraction d'entit√©s, nous supprimons le module de classification (les trois premi√®res couches enti√®rement connect√©es) du r√©seau en d√©finissant le param√®tre <i>include_top</i> sur <i>False</i> .  Nous voulons √©galement initialiser notre r√©seau en utilisant les poids du r√©seau form√© √† ImageNet.  Le dernier param√®tre est la taille de l'entr√©e. <br><br>  Veuillez noter que la taille des images originales du concours ImageNet est de (224, 224, 3), tandis que nos images sont de (400, 500, 3).  Cependant, nous utilisons des couches convolutives - cela signifie que les poids du r√©seau sont les poids des noyaux en mouvement dans l'op√©ration de convolution.  Avec la propri√©t√© de la s√©paration des param√®tres (une discussion √† ce sujet se trouve dans notre article th√©orique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Aper√ßu des r√©seaux de neurones convolutionnels pour la classification des images</a> ), cela conduit au fait que la taille des donn√©es d'entr√©e peut √™tre presque arbitraire, car la convolution est effectu√©e au moyen d'une fen√™tre coulissante, et cette fen√™tre peut glisser le long image de toute taille.  La seule limitation est que la taille des donn√©es d'entr√©e doit √™tre suffisamment grande pour ne pas s'effondrer √† un point (mesures spatiales) dans une couche interm√©diaire, car sinon il sera impossible de faire d'autres calculs. <br><br>  Une autre astuce que nous utilisons est la <i>mise en cache</i> .  VGG est un tr√®s grand r√©seau.  Un passage direct pour toutes les images (1630 exemples) √† travers l'unit√© d'extraction de fonctionnalit√©s prend environ 50 secondes.  Cependant, il faut se rappeler que les poids de l'unit√© d'extraction d'entit√©s sont fixes, et un passage direct donne toujours le m√™me r√©sultat pour la m√™me image.  Nous pouvons utiliser ce fait pour effectuer un passage direct √† travers l'unit√© d'extraction de fonctionnalit√©s <i>une</i> seule <i>fois</i> , puis mettre en cache les r√©sultats dans un tableau interm√©diaire.  Pour impl√©menter ce sc√©nario, nous cr√©ons d'abord une instance de la classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ImageDataGenerator</a> pour charger directement les fichiers depuis le disque dur (pour plus d'informations, consultez l'article de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">base Mod√®le de base pour reconna√Ætre les √©motions dans les images</a> ). <br><br><img src="https://habrastorage.org/webt/o-/wo/7h/o-wo7hel-_kgurcvwcs2v2smecc.png"><br><br>  √Ä l'√©tape suivante, nous utilisons en mode pr√©diction le bloc d'extraction d'entit√©s cr√©√© pr√©c√©demment dans le cadre du mod√®le pour obtenir des entit√©s d'image. <br><br><img src="https://habrastorage.org/webt/gl/no/p7/glnop717aagtytzitgpdtbl_11c.png"><br><br>  Cela prend environ 50 secondes.  Nous pouvons maintenant utiliser les r√©sultats pour un entra√Ænement tr√®s rapide de la partie de classification sup√©rieure du mod√®le - une √®re dure environ 1 seconde pour nous.  Imaginez maintenant que chaque √®re dure 50 secondes de plus.  Ainsi, cette simple technique de mise en cache nous a permis d'acc√©l√©rer le processus de formation r√©seau de 50 fois!  Dans ce sc√©nario, nous enregistrons tous les signes pour tous les exemples en RAM, car son volume est suffisant pour cela.  Lorsque vous utilisez un ensemble de donn√©es plus grand, vous pouvez calculer les propri√©t√©s, les √©crire sur le disque dur, puis les lire en utilisant la m√™me approche associ√©e √† la classe du g√©n√©rateur. <br><br>  Enfin, consid√©rons l'architecture de la partie classification du mod√®le: <br><br><img src="https://habrastorage.org/webt/6x/hq/qb/6xhqqbgjol6dfxyn47rufbuc_ag.png"><br><br><img src="https://habrastorage.org/webt/ss/4v/3t/ss4v3to-rinafik2lthu5ecszt8.png"><br><br>  N'oubliez pas qu'√† la sortie du bloc d'extraction de caract√©ristiques du r√©seau neuronal convolutionnel, un tenseur √† quatre dimensions (exemples, hauteur, largeur et canaux) est √©mis, et une couche enti√®rement connect√©e pour la classification prend un tenseur √† deux dimensions (exemples, caract√©ristiques).  Une fa√ßon de transformer un tenseur √† quatre dimensions avec des caract√©ristiques consiste simplement √† l'aligner autour des trois derniers axes (nous avons utilis√© une technique similaire dans le mod√®le de base).  Dans ce sc√©nario, nous utilisons une approche diff√©rente, appel√©e <i>sous</i> - <i>√©chantillonnage de la valeur moyenne mondiale</i> (BPA).  Au lieu d'aligner les vecteurs √† quatre dimensions, nous prendrons la valeur moyenne bas√©e sur deux dimensions spatiales.  En fait, nous prenons une carte d'attributs et faisons simplement la moyenne de toutes les valeurs qu'il contient.  La m√©thode GAP a √©t√© introduite pour la premi√®re fois dans l'excellent travail du r√©seau Min Lin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le Net</a> (ce livre vaut vraiment la peine de le conna√Ætre car il traite de certains concepts importants - par exemple, les convolutions 1 √ó 1).  Un avantage √©vident de l'approche GAP est une r√©duction significative du nombre de param√®tres.  En utilisant GAP, nous n'obtenons que 512 fonctionnalit√©s pour chaque exemple, tout en alignant les donn√©es brutes, le nombre de fonctionnalit√©s sera de 15 √ó 12 √ó 512 = 92 160. Cela peut entra√Æner des frais g√©n√©raux importants, car dans ce cas, la partie classification du mod√®le aura environ 50 millions de param√®tres!  D'autres √©l√©ments de la partie classification du mod√®le, tels que les couches enti√®rement connect√©es et les couches qui impl√©mentent la m√©thode d'exclusion, sont discut√©s en d√©tail dans l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®le de base pour reconna√Ætre les √©motions dans les images</a> . <br><br><h2>  <font color="#0071c5">Param√®tres et options de formation</font> </h2><br>  Apr√®s avoir pr√©par√© l'architecture de notre mod√®le √† l'aide de Keras, vous devez configurer l'ensemble du mod√®le pour la formation √† l'aide de la m√©thode de compilation. <br><br><img src="https://habrastorage.org/webt/dl/x5/by/dlx5byabpmih_ocdviw_8ngvatw.png"><br><br>  Dans ce cas, nous utilisons des param√®tres qui sont presque similaires aux param√®tres du mod√®le de base, √† l'exception du choix de l'optimiseur.  Pour optimiser l'apprentissage, l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">entropie crois√©e binaire</a> sera utilis√©e comme fonction de perte et une m√©trique de pr√©cision sera √©galement suivie.  Nous utilisons la m√©thode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Adam</a> comme optimiseur.  Adam est un type d'algorithme de descente de gradient stochastique avec un moment et une <i>vitesse d'apprentissage</i> adaptative (pour plus d'informations, voir l'entr√©e de blog de S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©sentation des algorithmes d'optimisation de la descente de gradient</a> ). <br><br>  La vitesse d'apprentissage est un hyperparam√®tre optimiseur qui doit √™tre configur√© pour garantir que le mod√®le est op√©rationnel.  N'oubliez pas que la formule pour la descente du gradient ¬´vanille¬ª ne contient pas de fonctionnalit√©s suppl√©mentaires: <br><br><img src="https://habrastorage.org/webt/qy/iu/ny/qyiunyjwn2bjmvzkkd_jg5050ay.png"><br><br>  Œò est le vecteur des param√®tres du mod√®le (dans notre cas, ce sont les coefficients de pond√©ration du r√©seau de neurones), - est la fonction objective, ‚àá est l'op√©rateur de gradient (calcul√© √† l'aide de l'algorithme de propagation d'erreur de retour), et Œ± est la vitesse d'apprentissage.  Ainsi, le gradient de la fonction objectif repr√©sente la direction de l'√©tape d'optimisation dans l'espace des param√®tres, et la vitesse d'apprentissage est sa taille.  Lorsque vous utilisez une vitesse d'apprentissage d√©raisonnablement √©lev√©e, il y a la possibilit√© d'un glissement constant du point optimal en raison de la taille de pas trop grande.  D'un autre c√¥t√©, si la vitesse d'apprentissage est trop faible, l'optimisation prendra trop de temps et ne pourra assurer la convergence que vers des minima locaux de faible qualit√© au lieu d'un extremum global.  Par cons√©quent, dans chaque situation sp√©cifique, il est n√©cessaire de rechercher un compromis appropri√©.  L'utilisation des param√®tres par d√©faut de l'algorithme Adam est un bon point de d√©part pour commencer. <br><br>  Cependant, dans cette t√¢che, les param√®tres Adam par d√©faut affichent des r√©sultats m√©diocres.  Nous devons r√©duire le taux d'apprentissage initial √† 0,0001.  Sinon, la formation ne pourra pas assurer la convergence. <br><br>  En fin de compte, nous pouvons commencer √† apprendre plus de 100 √©poques, puis enregistrer le mod√®le lui-m√™me et l'historique de l'apprentissage.  La commande <i>% time</i> est une commande magique Ipython * qui vous permet de mesurer le temps d'ex√©cution du code. <br><br><img src="https://habrastorage.org/webt/tp/qr/h3/tpqrh3zk0u7oxnxg77cbsmigxc8.png"><br><br><h2>  <font color="#0071c5">√âvaluation</font> </h2><br><br><img src="https://habrastorage.org/webt/ij/w6/a-/ijw6a-rdyl9fd5rhlsuybmu24vm.png"><br><br>  √âvaluons l'efficacit√© du mod√®le pendant la formation.  Dans notre cas, la pr√©cision de v√©rification est de 73% (contre 55% avec le mod√®le de base).  Ce r√©sultat est bien meilleur que le r√©sultat du mod√®le de base. <br><br>  Examinons √©galement la distribution des erreurs √† l'aide de la matrice des inexactitudes.  Les erreurs sont r√©parties presque √©galement entre les classes avec un l√©ger biais vers des exemples n√©gatifs mal class√©s (cellule sup√©rieure gauche de la matrice des inexactitudes).  Cela peut s'expliquer par un <i>petit d√©s√©quilibre dans l'ensemble de donn√©es</i> vers la classe positive. <br><br>  Une autre mesure que nous suivons est la courbe de performance du r√©cepteur (courbe ROC) et la zone sous cette courbe (AUC).  Pour une description d√©taill√©e de ces mesures, consultez l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®le de base pour reconna√Ætre les √©motions dans les images</a> . <br><br><img src="https://habrastorage.org/webt/if/lx/cf/iflxcf-2pxzdcuicg8im4us-9yg.png"><br><br>  Plus la courbe ROC est proche du point sup√©rieur gauche du graphique et plus la zone sous-jacente (m√©trique AUC) est grande, mieux le classificateur fonctionne.  Cette figure montre clairement qu'un mod√®le am√©lior√© et pr√©-form√© montre de meilleurs r√©sultats par rapport au mod√®le de base cr√©√© √† partir de z√©ro.  La valeur AUC pour le mod√®le pr√©-form√© est de 0,82, ce qui est un bon r√©sultat. <br><br><img src="https://habrastorage.org/webt/7o/dy/hu/7odyhuvi5j09ajzquknecv_ch2s.png"><br><br><h2>  <font color="#0071c5">Conclusion</font> </h2><br>  Dans cet article, nous avons rencontr√© une technique puissante - l'apprentissage inductif.  Nous avons √©galement construit un classificateur de r√©seau neuronal convolutionnel √† l'aide d'une unit√© d'extraction de fonctions pr√©-form√©e bas√©e sur l'architecture VGG.  Ce classificateur a surpass√© dans ses caract√©ristiques de performance le mod√®le convolutionnel de base, form√© √† partir de z√©ro.  L'augmentation de la pr√©cision √©tait de 18 pour cent, et l'augmentation de la m√©trique AUC √©tait de 0,25, ce qui d√©montre une augmentation tr√®s significative de la qualit√© du syst√®me. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr421367/">https://habr.com/ru/post/fr421367/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr421355/index.html">Go 1.11 est lanc√© - WebAssembly et modules natifs</a></li>
<li><a href="../fr421357/index.html">√Ä la question de l'impossible. 3e partie</a></li>
<li><a href="../fr421359/index.html">Le festival est comme un jeu. Taxonomie des informaticiens</a></li>
<li><a href="../fr421361/index.html">AMD a ouvert le code source de V-EZ, une API Vulkan shell multiplateforme de bas niveau</a></li>
<li><a href="../fr421365/index.html">L'√©volution d'une startup. Agile de Yaytselov aux envahisseurs de Chiken</a></li>
<li><a href="../fr421369/index.html">Ce que les stagiaires d'ABBYY font r√©ellement</a></li>
<li><a href="../fr421371/index.html">Aiguilles invisibles: les scientifiques ont d√©velopp√© un moyen de masquer les nanocapteurs pour l'optique et la biom√©decine</a></li>
<li><a href="../fr421373/index.html">Python met la programmation √† la disposition d'un large public</a></li>
<li><a href="../fr421375/index.html">Comment l'incertitude tue le commerce</a></li>
<li><a href="../fr421377/index.html">7 id√©es fausses d'un chef de projet novice √† Gamedev</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
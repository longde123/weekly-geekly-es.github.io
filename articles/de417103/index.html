<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçã üëñ üëáüèΩ Spark SQL. Ein bisschen √ºber das Abfrageoptimierungsprogramm üë©üèª‚Äçüé§ üìì üöå</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo an alle. Als Einf√ºhrung m√∂chte ich Ihnen erz√§hlen, wie ich zu einem solchen Leben gekommen bin. 



 Insbesondere vor dem Treffen mit Big Data u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark SQL. Ein bisschen √ºber das Abfrageoptimierungsprogramm</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neoflex/blog/417103/"><p>  Hallo an alle.  Als Einf√ºhrung m√∂chte ich Ihnen erz√§hlen, wie ich zu einem solchen Leben gekommen bin. <br></p><br><p>  Insbesondere vor dem Treffen mit Big Data und Spark musste ich h√§ufig SQL-Abfragen optimieren, zuerst f√ºr MSSQL, dann f√ºr Oracle, und jetzt bin ich auf SparkSQL gesto√üen. <br></p><br><p>  Und wenn es bereits viele gute B√ºcher f√ºr das DBMS gibt, die die Methodik und die ‚ÄûStifte‚Äú beschreiben, die Sie drehen k√∂nnen, um den optimalen Abfrageplan zu erhalten, habe ich solche B√ºcher f√ºr Spark nicht gesehen.  Ich bin auf mehr Artikel und Vorgehensweisen gesto√üen, die sich eher auf die Arbeit mit der RDD / Dataset-API als auf reines SQL beziehen.  F√ºr mich ist eines der Nachschlagewerke zur SQL-Optimierung das Buch Oracle von J. Lewis.  Grundlagen der Kostenoptimierung. "  Ich suchte nach etwas √Ñhnlichem in der Tiefe des Studiums.  Warum war das Forschungsgebiet speziell SparkSQL und nicht die zugrunde liegende API?  Dann wurde das Interesse durch die Funktionen des Projekts verursacht, an dem ich arbeite. <br></p><br><img src="https://habrastorage.org/webt/po/1f/un/po1fun6vgbktou6lykepwmrncci.jpeg"><br><a name="habracut"></a><br><p>  F√ºr einen unserer Kunden entwickelt unser Unternehmen ein Data Warehouse, von dem sich eine detaillierte Schicht und ein Teil der Vitrinen im Hadoop-Cluster und die endg√ºltigen Vitrinen in Oracle befinden.  Dieses Projekt umfasst eine umfangreiche Datenkonvertierungsschicht, die auf Spark implementiert ist.  Um die Entwicklung und Konnektivit√§t von ETL-Entwicklern zu beschleunigen, die nicht mit den Feinheiten der Big Data-Technologien vertraut sind, aber mit SQL- und ETL-Tools vertraut sind, wurde ein Tool entwickelt, das andere ETL-Tools, z. B. Informatica, ideologisch erinnert und es Ihnen erm√∂glicht, ETL-Prozesse mit nachfolgender Generation visuell zu entwerfen Code f√ºr Spark.  Aufgrund der Komplexit√§t der Algorithmen und der gro√üen Anzahl von Transformationen verwenden Entwickler haupts√§chlich SparkSQL-Abfragen. <br></p><br><p> Und hier beginnt die Geschichte, da ich eine gro√üe Anzahl von Fragen des Formulars ‚ÄûWarum funktioniert die Anfrage nicht / arbeitet langsam / funktioniert sie anders als Oracle?‚Äú Beantworten musste.  Dieser erwies sich f√ºr mich als der interessanteste Teil: ‚ÄûWarum funktioniert er langsam?‚Äú.  Im Gegensatz zu dem DBMS, mit dem ich zuvor gearbeitet habe, k√∂nnen Sie au√üerdem in den Quellcode gelangen und die Antwort auf Ihre Fragen erhalten. <br></p><cut text="    "></cut><br><h2>  Einschr√§nkungen und Annahmen </h2><br><p>  Mit Spark 2.3.0 werden Beispiele ausgef√ºhrt und der Quellcode analysiert. <br>  Es wird davon ausgegangen, dass der Leser mit der Spark-Architektur und den allgemeinen Prinzipien des Abfrageoptimierers f√ºr eines der DBMS vertraut ist.  Zumindest sollte der Ausdruck "Abfrageplan" sicherlich nicht √ºberraschend sein. <br></p><br><p>  Au√üerdem versucht dieser Artikel, keine √úbersetzung des Spark-Optimierungscodes ins Russische zu werden. F√ºr Dinge, die aus Sicht des Optimierers sehr interessant sind, aber im Quellcode gelesen werden k√∂nnen, werden sie hier einfach kurz mit Links zu den entsprechenden Klassen erw√§hnt. <br></p><br><h2>  Mach weiter mit dem Lernen </h2><br><p>  Beginnen wir mit einer kleinen Abfrage, um die grundlegenden Phasen zu untersuchen, die vom Parsen bis zur Ausf√ºhrung durchlaufen werden. <br></p><br><pre><code class="scala hljs">scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/balance"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"bal"</span></span>) scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/customer"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"cust"</span></span>) scala&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> df = spark.sql(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">" | select bal.account_rk, cust.full_name | from bal | join cust | on bal.party_rk = cust.party_rk | and bal.actual_date = cust.actual_date | where bal.actual_date = cast('2017-12-31' as date) | "</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>) df: org.apache.spark.sql.<span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = [account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: string] scala&gt; df.explain(<span class="hljs-literal"><span class="hljs-literal">true</span></span>)</code> </pre> <br><p>  Das Hauptmodul, das f√ºr das Parsen von SQL und die Optimierung des Abfrageausf√ºhrungsplans verantwortlich ist, ist Spark Catalyst. <br></p><br><p>  Mit der erweiterten Ausgabe in der Beschreibung des Anforderungsplans (df.explain (true)) k√∂nnen Sie alle Phasen verfolgen, die die Anforderung durchl√§uft: <br></p><br><ul><li>  Analysierter logischer Plan - Nach dem Parsen von SQL abrufen.  In dieser Phase wird nur die syntaktische Richtigkeit der Anforderung √ºberpr√ºft. </li></ul><br><pre> <code class="hljs rust">== Parsed Logical Plan == <span class="hljs-symbol"><span class="hljs-symbol">'Project</span></span> [<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.account_rk, <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.full_name] +- <span class="hljs-symbol"><span class="hljs-symbol">'Filter</span></span> (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- <span class="hljs-symbol"><span class="hljs-symbol">'Join</span></span> Inner, ((<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.party_rk = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.party_rk) &amp;&amp; (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.actual_date)) :- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `bal` +- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `cust`</code> </pre><br><ul><li>  Analysierter logischer Plan - In dieser Phase werden Informationen zur Struktur der verwendeten Entit√§ten hinzugef√ºgt, die √úbereinstimmung der Struktur und der angeforderten Attribute √ºberpr√ºft. </li></ul><br><pre> <code class="hljs delphi">== Analyzed Logical Plan == account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Filter (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- SubqueryAlias bal : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- SubqueryAlias cust +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Der optimierte logische Plan ist f√ºr uns am interessantesten.  In dieser Phase wird der resultierende Abfragebaum basierend auf den verf√ºgbaren Optimierungsregeln konvertiert. </li></ul><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Physischer Plan - Funktionen f√ºr den Zugriff auf Quelldaten werden zunehmend ber√ºcksichtigt, einschlie√ülich Optimierungen zum Filtern von Partitionen und Daten, um den resultierenden Datensatz zu minimieren.  Die Join-Ausf√ºhrungsstrategie ist ausgew√§hlt (mehr zu den unten verf√ºgbaren Optionen). </li></ul><br><pre> <code class="hljs pgsql">== Physical Plan == *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [account_rk#<span class="hljs-number"><span class="hljs-number">1</span></span>, full_name#<span class="hljs-number"><span class="hljs-number">59</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) BroadcastHashJoin [party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">27</span></span>], [party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">88</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">Inner</span></span>, BuildRight :- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>, PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>) : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) FileScan orc [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>,PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/balance], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;ACCOUNT_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>)&gt; +- BroadcastExchange HashedRelationBroadcastMode(List(<span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>])) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) Project [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>, FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) FileScan orc [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>,FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/customer], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),FULL_NAME:string&gt;</code> </pre><br><p>  Die folgenden Phasen der Optimierung und Ausf√ºhrung (z. B. WholeStageCodegen) gehen √ºber den Rahmen dieses Artikels hinaus, werden jedoch (sowie die oben beschriebenen Phasen) in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mastering Spark Sql ausf√ºhrlich beschrieben</a> . <br></p><br><p>  Das Lesen des Abfrageausf√ºhrungsplans erfolgt normalerweise ‚Äûvon innen‚Äú und ‚Äûvon unten nach oben‚Äú, dh die am meisten verschachtelten Teile werden zuerst ausgef√ºhrt und gelangen schrittweise zur endg√ºltigen Projektion ganz oben. <br></p><br><h2>  Arten von Abfrageoptimierern </h2><br><p>  Es k√∂nnen zwei Arten von Abfrageoptimierern unterschieden werden: </p><br><ul><li>  Regelbasierte Optimierer (RBOs). </li><li>  Optimierer basierend auf einer Sch√§tzung der Kosten f√ºr die Ausf√ºhrung von Abfragen (Kostenbasierter Optimierer, CBO). </li></ul><br><p>  Die ersten konzentrieren sich auf die Verwendung eines Satzes fester Regeln, zum Beispiel die Anwendung von Filterbedingungen, aus denen in fr√ºheren Stadien, wenn m√∂glich, die Berechnung von Konstanten usw. <br></p><br><p>  Um die Qualit√§t des resultierenden Plans zu bewerten, verwendet der CBO-Optimierer eine Kostenfunktion, die normalerweise von der Menge der verarbeiteten Daten, der Anzahl der Zeilen, die unter die Filter fallen, und den Kosten f√ºr die Ausf√ºhrung bestimmter Vorg√§nge abh√§ngt. <br></p><br><p>  Um mehr √ºber die CBO-Designspezifikation f√ºr Apache Spark zu erfahren, folgen Sie bitte den Links: der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spezifikation</a> und der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hauptaufgabe von JIRA f√ºr die Implementierung</a> . <br></p><br><p>  Der Ausgangspunkt f√ºr die Erkundung aller vorhandenen Optimierungen ist der Code Optimizer.scala. <br></p><br><p>  Hier ist ein kurzer Auszug aus einer langen Liste verf√ºgbarer Optimierungen: <br></p><br><pre> <code class="hljs perl">def batches: Se<span class="hljs-string"><span class="hljs-string">q[Batch]</span></span> = { val operatorOptimizationRuleSet = Se<span class="hljs-string"><span class="hljs-string">q( // Operator push down PushProjectionThroughUnion, ReorderJoin, EliminateOuterJoin, PushPredicateThroughJoin, PushDownPredicate, LimitPushDown, ColumnPruning, InferFiltersFromConstraints, // Operator combine CollapseRepartition, CollapseProject, CollapseWindow, CombineFilters, CombineLimits, CombineUnions, // Constant folding and strength reduction NullPropagation, ConstantPropagation, ........</span></span></code> </pre><br><p>  Es ist zu beachten, dass die Liste dieser Optimierungen sowohl regelbasierte Optimierungen als auch Optimierungen basierend auf Abfragekostensch√§tzungen enth√§lt, die nachstehend erl√§utert werden. <br></p><br><p>  Ein Merkmal von CBO ist, dass es f√ºr einen korrekten Betrieb Informationen √ºber die Statistiken der in der Abfrage verwendeten Daten kennen und speichern muss - Anzahl der Datens√§tze, Datensatzgr√∂√üe, Histogramme der Datenverteilung in den Tabellenspalten. <br></p><br><p>  Zum Sammeln von Statistiken wird eine Reihe von SQL-Befehlen ANALYZE TABLE ... COMPUTE STATISTICS verwendet. Au√üerdem wird eine Reihe von Tabellen zum Speichern von Informationen ben√∂tigt. Die API wird √ºber ExternalCatalog bereitgestellt, genauer gesagt √ºber HiveExternalCatalog. <br></p><br><p>  Da CBO derzeit standardm√§√üig deaktiviert ist, liegt der Schwerpunkt auf der Untersuchung der verf√ºgbaren Optimierung und Nuancen von RBO. <br></p><br><h2>  Typen und Auswahl der Join-Strategie </h2><br><p>  In der Phase der Erstellung des physischen Plans zur Ausf√ºhrung der Anforderung wird die Verbindungsstrategie ausgew√§hlt.  Die folgenden Optionen sind derzeit in Spark verf√ºgbar (Sie k√∂nnen Code aus dem Code in SparkStrategies.scala lernen). <br></p><br><h3>  Broadcast-Hash-Join </h3><br><p>  Die beste Option ist, wenn eine der Join-Parteien klein genug ist (das Suffizienzkriterium wird durch den Parameter spark.sql.autoBroadcastJoinThreshold in SQLConf festgelegt).  In diesem Fall wird diese Seite vollst√§ndig auf alle Executoren kopiert, bei denen ein Hash-Join mit der Haupttabelle vorhanden ist.  Zus√§tzlich zur Gr√∂√üe sollte beachtet werden, dass im Fall einer √§u√üeren Verkn√ºpfung nur die Au√üenseite kopiert werden kann. Wenn m√∂glich, m√ºssen Sie als f√ºhrende Tabelle im Fall einer √§u√üeren Verkn√ºpfung die Tabelle mit der gr√∂√üten Datenmenge verwenden. <br></p><br><pre> <code class="hljs pgsql">  ,    ,     <span class="hljs-keyword"><span class="hljs-keyword">SQL</span></span>      Oracle,   <span class="hljs-comment"><span class="hljs-comment">/*+ broadcast(t1, t2) */</span></span></code> </pre><br><h3>  Sort Merge Join </h3><br><p>  <em>Wenn spark.sql.join.preferSortMergeJoin</em> standardm√§√üig aktiviert ist, wird diese Methode standardm√§√üig angewendet, wenn die Schl√ºssel f√ºr den Join sortiert werden k√∂nnen. <br>  Von den Merkmalen kann angemerkt werden, dass im Gegensatz zum vorherigen Verfahren die Codegenerierungsoptimierung zum Ausf√ºhren der Operation nur f√ºr die innere Verkn√ºpfung verf√ºgbar ist. <br></p><br><h3>  Shuffle Hash Join </h3><br><p>  Wenn die Schl√ºssel nicht sortiert werden k√∂nnen oder die Standardauswahloption f√ºr Sortierzusammenf√ºhrungsverkn√ºpfungen deaktiviert ist, versucht Catalyst, einen Shuffle-Hash-Join anzuwenden.  Zus√§tzlich zur √úberpr√ºfung der Einstellungen wird auch √ºberpr√ºft, ob Spark √ºber gen√ºgend Speicher verf√ºgt, um eine lokale Hash-Map f√ºr eine Partition zu erstellen (die Gesamtzahl der Partitionen wird durch Festlegen von <em>spark.sql.shuffle.partitions festgelegt</em> ). </p><br><h3>  BroadcastNestedLoopJoin und CartesianProduct </h3><br><p>  In dem Fall, in dem keine M√∂glichkeit eines direkten Vergleichs nach Schl√ºsseln besteht (z. B. eine Bedingung wie) oder keine Schl√ºssel zum Verkn√ºpfen von Tabellen vorhanden sind, wird abh√§ngig von der Gr√∂√üe der Tabellen entweder dieser Typ oder CartesianProduct ausgew√§hlt. <br></p><br><h3>  Die Reihenfolge der Angabe von Tabellen in join'ah </h3><br><p>  In jedem Fall erfordert der Join das Mischen von Tabellen nach Schl√ºssel.  Daher ist derzeit die Reihenfolge der Angabe von Tabellen wichtig, insbesondere bei der Ausf√ºhrung mehrerer Verkn√ºpfungen in einer Reihe (wenn Sie eine Bohrung sind, ist CBO nicht aktiviert und die Einstellung JOIN_REORDER_ENABLED ist nicht aktiviert). <br></p><br><p>  Wenn m√∂glich, sollte die Reihenfolge der Verkn√ºpfungstabellen die Anzahl der Mischvorg√§nge f√ºr gro√üe Tabellen minimieren, f√ºr die Verkn√ºpfungen mit demselben Schl√ºssel nacheinander ausgef√ºhrt werden sollten.  Vergessen Sie auch nicht, die Daten f√ºr die Verkn√ºpfung zu minimieren, um die Broadcast-Hash-Verkn√ºpfung zu aktivieren. <br></p><br><h2>  Transitive Anwendung von Filterbedingungen </h2><br><p>  Betrachten Sie die folgende Abfrage: <br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> bal.account_rk, cust.full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> balance bal <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> customer cust <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> bal.party_rk = cust.party_rk <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> bal.actual_date = cust.actual_date <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> bal.actual_date = <span class="hljs-keyword"><span class="hljs-keyword">cast</span></span>(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-built_in"><span class="hljs-built_in">date</span></span>)</code> </pre><br><p>  Hier verbinden wir zwei Tabellen, die gem√§√ü dem Feld actual_date auf dieselbe Weise partitioniert sind, und wenden einen expliziten Filter nur auf die Partition gem√§√ü der Balance-Tabelle an. <br></p><br><p>  Wie aus dem optimierten Abfrageplan hervorgeht, wird der Filter nach Datum auch auf den Kunden angewendet, und zum Zeitpunkt des Lesens von Daten von der Festplatte wird festgestellt, dass genau eine Partition ben√∂tigt wird. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter (((actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>) &amp;&amp; isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><p>  Sie m√ºssen jedoch nur den inneren Join durch den linken √§u√üeren in der Abfrage ersetzen, da das Push-Pr√§dikat f√ºr die Kundentabelle sofort abf√§llt und ein vollst√§ndiger Scan erfolgt, was ein unerw√ºnschter Effekt ist. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join LeftOuter, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter (isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><h2>  Typkonvertierung </h2><br><p>  Betrachten Sie ein einfaches Beispiel f√ºr die Auswahl aus einer Tabelle mit Filterung nach Clienttyp. Im Schema ist der Typ des Felds party_type string. <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> party_rk, full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> cust <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> actual_date = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> party_type = <span class="hljs-number"><span class="hljs-number">101</span></span> <span class="hljs-comment"><span class="hljs-comment">--   -- and party_type = '101' --    </span></span></code> </pre><br><p>  Und vergleichen Sie die beiden resultierenden Pl√§ne, den ersten - wenn wir uns auf den falschen Typ beziehen (es wird eine implizite Umwandlung in int geben), den zweiten - wenn der Typ dem Schema entspricht. <br></p><br><pre> <code class="hljs powershell">PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>)] //            . PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>), <span class="hljs-type"><span class="hljs-type">EqualTo</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>,<span class="hljs-number"><span class="hljs-number">101</span></span>)] //             .</code> </pre><br><p>  Ein √§hnliches Problem wird beim Vergleichen von Datumsangaben mit einer Zeichenfolge beobachtet. Es gibt einen Filter zum Vergleichen von Zeichenfolgen.  Ein Beispiel: <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = <span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> (isnotnull(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span>) &amp;&amp; (cast(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> string) = <span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>) PushedFilters: [IsNotNull(OPER_DATE)] <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) PushedFilters: [IsNotNull(OPER_DATE), EqualTo(OPER_DATE,<span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>)]</code> </pre><br><p>  F√ºr den Fall, dass eine implizite Typkonvertierung m√∂glich ist, z. B. int -&gt; decimal, f√ºhrt der Optimierer dies selbst aus. <br></p><br><h2>  Weitere Forschung </h2><br><p>  Viele interessante Informationen zu den ‚ÄûReglern‚Äú, mit denen Catalyst fein eingestellt werden kann, sowie zu den M√∂glichkeiten (Gegenwart und Zukunft) des Optimierers erhalten Sie bei SQLConf.scala. <br></p><br><p>  Wie Sie standardm√§√üig sehen k√∂nnen, ist das Kostenoptimierungsprogramm derzeit noch deaktiviert. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">CBO_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables CBO for estimation of plan statistics when set true."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  Sowie seine abh√§ngigen Optimierungen im Zusammenhang mit der Neuordnung von join'ov. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">JOIN_REORDER_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.joinReorder.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables join reorder in CBO."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  oder </p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">STARSCHEMA_DETECTION</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.starSchemaDetection"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"When true, it enables join reordering based on star schema detection. "</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><h2>  Kurze Zusammenfassung </h2><br><p>  Nur ein kleiner Teil der vorhandenen Optimierungen wurde ber√ºhrt. Experimente zur Kostenoptimierung, die viel mehr Raum f√ºr die Abfragekonvertierung bieten k√∂nnen, stehen an.  Eine weitere interessante Frage ist der Vergleich einer Reihe von Optimierungen beim Lesen von Dateien aus Parkett und Ork. Nach dem Jira des Projekts geht es um Parit√§t, aber ist es wirklich so? <br></p><br><p>  Au√üerdem: </p><br><ul><li>  Die Analyse und Optimierung von Anfragen ist interessant und aufregend, insbesondere angesichts der Verf√ºgbarkeit von Quellcodes. </li><li>  Die Einbeziehung von CBO bietet Raum f√ºr weitere Optimierungen und Forschungsarbeiten. </li><li>  Es ist notwendig, die Anwendbarkeit der Grundregeln zu √ºberwachen, die es Ihnen erm√∂glichen, so viele "zus√§tzliche" Daten wie m√∂glich zum fr√ºhestm√∂glichen Zeitpunkt herauszufiltern. </li><li>  Join ist ein notwendiges √úbel, aber wenn m√∂glich, lohnt es sich, sie zu minimieren und zu verfolgen, welche Implementierung unter der Haube verwendet wird. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de417103/">https://habr.com/ru/post/de417103/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de417091/index.html">Erstellen Sie einen Cartoon-Water-Shader f√ºr das Web. Teil 3</a></li>
<li><a href="../de417093/index.html">Touch-Schalter mit Modbus: Warum werden sie ben√∂tigt und wie werden sie in einer intelligenten Wohnung angewendet?</a></li>
<li><a href="../de417097/index.html">JavaScript-Metaprogrammierung</a></li>
<li><a href="../de417099/index.html">Wie habe ich die Standard-C ++ 11-Bibliothek geschrieben oder warum ist Boost so be√§ngstigend? Kapitel 2</a></li>
<li><a href="../de417101/index.html">Definition von Ready - Was wir vergessen haben zu erz√§hlen</a></li>
<li><a href="../de417105/index.html">Drucken auf einem 3D-Drucker. Die geheimen Erfahrungen von 3Dtool</a></li>
<li><a href="../de417107/index.html">Entwickler des Spiels w√§hrend True: Erfahren Sie () mehr √ºber Gamedev-Programmierung, VR-Probleme und ML-Simulationen</a></li>
<li><a href="../de417109/index.html">Richard Hamming: Kapitel 10. Codierungstheorie - I.</a></li>
<li><a href="../de417111/index.html">Online-Konferenzen: Streaming vs Webinar</a></li>
<li><a href="../de417113/index.html">Italienischer 3D-Drucker in Russland: Raise3D N1 Dual - Modellierung und Prototyping</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôèüèø ‚≠ïÔ∏è üÜé CUDA e GPU remota ü§π üë©üèº‚Äçüíª üåè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O CUDA √© bom para todos, desde que haja uma placa de v√≠deo da Nvidia em m√£os. Mas o que fazer quando n√£o h√° placa de v√≠deo Nvidia no seu laptop favori...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>CUDA e GPU remota</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416127/"><p>  O CUDA √© bom para todos, desde que haja uma placa de v√≠deo da Nvidia em m√£os.  Mas o que fazer quando n√£o h√° placa de v√≠deo Nvidia no seu laptop favorito?  Ou voc√™ precisa realizar o desenvolvimento em uma m√°quina virtual? </p><br><p>  Tentarei considerar neste artigo uma solu√ß√£o como a estrutura rCUDA (Remote CUDA), que ajudar√° quando houver uma placa de v√≠deo Nvidia, mas ela n√£o est√° instalada na m√°quina em que os aplicativos CUDA devem ser lan√ßados.  Para aqueles que est√£o interessados, bem-vindo ao gato. </p><br><div class="spoiler">  <b class="spoiler_title">TLDR</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rCUDA</a> (CUDA remoto) - uma estrutura que implementa a API CUDA, permitindo o uso de uma placa de v√≠deo remota.  Est√° em uma vers√£o beta funcional, dispon√≠vel apenas no Linux.  O principal objetivo do rCUDA √© a total compatibilidade com a API CUDA, voc√™ n√£o precisa modificar seu c√≥digo de nenhuma maneira, basta definir vari√°veis ‚Äã‚Äãde ambiente especiais. </p></div></div><a name="habracut"></a><br><h2 id="chto-takoe-rcuda">  O que √© rCUDA </h2><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O rCUDA</a> (CUDA remoto) √© uma estrutura que implementa a API CUDA, permitindo que voc√™ use uma placa de v√≠deo localizada na m√°quina remota para a computa√ß√£o CUDA sem fazer altera√ß√µes no seu c√≥digo.  Desenvolvido na Universidade Polit√©cnica de Val√™ncia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rcuda-team</a> ). </p><br><h2 id="ogranicheniya">  Limita√ß√µes </h2><br><p>  Atualmente, apenas os sistemas GNU / Linux s√£o suportados, no entanto, os desenvolvedores prometem suporte ao Windows no futuro.  A vers√£o atual do rCUDA, 18.03beta, √© compat√≠vel com o CUDA 5-8, ou seja, o CUDA 9 n√£o √© suportado.  Os desenvolvedores declararam total compatibilidade com a API CUDA, com exce√ß√£o dos gr√°ficos. </p><br><h2 id="vozmozhnye-scenarii-ispolzovaniya">  Poss√≠veis casos de uso </h2><br><ol><li>  A execu√ß√£o de aplicativos CUDA em uma m√°quina virtual ao encaminhar uma placa de v√≠deo √© inconveniente ou imposs√≠vel, por exemplo, quando a placa de v√≠deo est√° ocupada por um host ou quando h√° mais de uma m√°quina virtual. </li><li>  Laptop sem placa gr√°fica discreta. </li><li>  O desejo de usar v√°rias placas de v√≠deo (clustering).  Teoricamente, voc√™ pode usar todas as placas de v√≠deo dispon√≠veis na equipe, inclusive em conjunto. </li></ol><br><h2 id="kratkaya-instrukciya">  Breve instru√ß√£o </h2><br><h4 id="testovaya-konfiguraciya">  Configura√ß√£o de teste </h4><br><p>  O teste foi realizado na seguinte configura√ß√£o: </p><br><p>  <strong>Servidor:</strong> <br>  Ubuntu 16.04, GeForce GTX 660 </p><br><p>  <strong>Cliente:</strong> <br>  Uma m√°quina virtual com Ubuntu 16.04 em um laptop sem uma placa gr√°fica discreta. </p><br><h4 id="poluchenie-rcuda">  Obtendo o rCUDA </h4><br><p>  A fase mais dif√≠cil.  Infelizmente, no momento, a √∫nica maneira de obter sua c√≥pia dessa estrutura √© preencher o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">formul√°rio de solicita√ß√£o</a> apropriado no site oficial.  No entanto, os desenvolvedores prometem responder dentro de 1-2 dias.  No meu caso, eles me enviaram uma distribui√ß√£o no mesmo dia. </p><br><h4 id="ustanovka-cuda">  Instalar CUDA </h4><br><p>  Primeiro, voc√™ precisa instalar o CUDA Toolkit no servidor e no cliente (mesmo se o cliente n√£o tiver uma placa de v√≠deo nvidia).  Para fazer isso, voc√™ pode baix√°-lo do site oficial ou usar o reposit√≥rio.  O principal √© usar a vers√£o n√£o superior a 8. Neste exemplo, o instalador .run do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site oficial √© usado</a> . </p><br><pre><code class="bash hljs">chmod +x cuda_8.0.61_375.26_linux.run ./cuda_8.0.61_375.26_linux.run</code> </pre> <br><p>  <strong>Importante!</strong>  No cliente, voc√™ deve recusar a instala√ß√£o do driver da nvidia.  Por padr√£o, o CUDA Toolkit estar√° dispon√≠vel em / usr / local / cuda /.  Instale as amostras CUDA, voc√™ precisar√° delas. </p><br><h4 id="ustanovka-rcuda">  Instale o rCUDA </h4><br><p>  Descompactaremos o arquivo recebido dos desenvolvedores em nosso diret√≥rio pessoal no servidor e no cliente. </p><br><pre> <code class="bash hljs">tar -xvf rCUDA*.tgz -C ~/ mv ~/rCUDA* ~/rCUDA</code> </pre> <br><p>  Voc√™ precisa executar essas a√ß√µes no servidor e no cliente. </p><br><h4 id="zapusk-demona-rcuda-na-servere">  Iniciando o daemon rCUDA no servidor </h4><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span>:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/lib64:/home/&lt;XXX&gt;/rCUDA/lib/cudnn <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rCUDA/bin ./rCUDAd</code> </pre> <br><p>  Substitua &lt;XXX&gt; pelo seu nome de usu√°rio.  Use ./rCUDAd -iv se desejar ver uma sa√≠da detalhada. </p><br><h4 id="nastroyka-klienta">  Configura√ß√£o do cliente </h4><br><p>  Vamos abrir o terminal no cliente, no qual executaremos o c√≥digo CUDA no futuro.  No lado do cliente, precisamos "substituir" as bibliotecas CUDA padr√£o pelas bibliotecas rCUDA, para as quais adicionamos os caminhos apropriados √† vari√°vel de ambiente LD_LIBRARY_PATH.  Tamb√©m precisamos especificar o n√∫mero de servidores e seus endere√ßos (no meu exemplo, ser√° um). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=/home/&lt;XXX&gt;/rCUDA/lib/:<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> RCUDA_DEVICE_COUNT=1 <span class="hljs-comment"><span class="hljs-comment">#    (),     export RCUDA_DEVICE_0=&lt;IP  &gt;:0 #    </span></span></code> </pre> <br><h4 id="sborka-i-zapusk">  Montagem e lan√ßamento </h4><br><p>  Vamos tentar criar e executar alguns exemplos. </p><br><p>  <strong>Exemplo 1</strong> </p><br><p>  Vamos come√ßar com um exemplo simples de deviceQuery que simplesmente exibe as configura√ß√µes CUDA para um dispositivo compat√≠vel, ou seja, no nosso caso, o GTX660 remoto. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt;YYY&gt;/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery make EXTRA_NVCCFLAGS=--cudart=shared</code> </pre> <br><p>  <strong>Importante!</strong>  Sem EXTRA_NVCCFLAGS = - cudart = compartilhado, o milagre n√£o funcionar√° <br>  Substitua &lt;YYY&gt; pelo caminho especificado para amostras CUDA ao instalar o CUDA. </p><br><p>  Execute o exemplo montado: </p><br><pre> <code class="bash hljs">./deviceQuery</code> </pre> <br><p>  Se voc√™ fez tudo corretamente, o resultado ser√° algo como isto: </p><br><div class="spoiler">  <b class="spoiler_title">Resultado</b> <div class="spoiler_text"><pre> <code class="bash hljs">./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: <span class="hljs-string"><span class="hljs-string">"GeForce GTX 660"</span></span> CUDA Driver Version / Runtime Version 9.0 / 8.0 CUDA Capability Major/Minor version number: 3.0 Total amount of global memory: 1994 MBytes (2090991616 bytes) ( 5) Multiprocessors, (192) CUDA Cores/MP: 960 CUDA Cores GPU Max Clock rate: 1072 MHz (1.07 GHz) Memory Clock rate: 3004 Mhz Memory Bus Width: 192-bit L2 Cache Size: 393216 bytes Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096) Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time <span class="hljs-built_in"><span class="hljs-built_in">limit</span></span> on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 660 Result = PASS</code> </pre> </div></div><br><p>  A coisa mais importante que devemos ver: </p><br><blockquote>  Device0 = GeForce GTX 660 <br>  Resultado = PASS </blockquote><p>  √ìtimo!  Conseguimos criar e executar o aplicativo CUDA em uma m√°quina sem uma placa gr√°fica discreta, usando para isso uma placa de v√≠deo instalada em um servidor remoto. </p><br><p>  <strong>Importante!</strong>  Se a sa√≠da do aplicativo come√ßar com linhas do formul√°rio: </p><br><pre> <code class="bash hljs">mlock error: Cannot allocate memory rCUDA warning: 1007.461 mlock error: Cannot allocate memory</code> </pre> <br><p>  significa que √© necess√°rio adicionar as seguintes linhas ao arquivo "/etc/security/limits.conf" no servidor e no cliente: </p><br><pre> <code class="bash hljs">* hard memlock unlimited * soft memlock unlimited</code> </pre> <br><p>  Assim, voc√™ permitir√° a todos os usu√°rios (*) mem√≥ria de bloqueio ilimitada (ilimitada) (memlock).  Seria ainda melhor substituir * pelo usu√°rio desejado e, em vez de ilimitado, escolher direitos com menos gordura. </p><br><p>  <strong>Exemplo 2</strong> </p><br><p>  Agora vamos tentar algo mais interessante.  Testaremos a implementa√ß√£o do produto escalar de vetores usando mem√≥ria compartilhada e sincroniza√ß√£o ("CUDA Technology in Examples" Sanders J. Kendrot E. 5.3.1). </p><br><p>  Neste exemplo, calculamos o produto escalar de dois vetores da dimens√£o 33 * 1024, comparando a resposta com o resultado obtido na CPU. </p><br><div class="spoiler">  <b class="spoiler_title">dotProd.cu</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #define imin(a,b) (a&lt;b?a:b) const int N = 33 * 1024; const int threadsPerBlock = 256; const int blocksPerGrid = imin(32, (N+threadsPerBlock-1) / threadsPerBlock); __global__ void dot(float* a, float* b, float* c) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x; int cacheIndex = threadIdx.x; float temp = 0; while (tid &lt; N){ temp += a[tid] * b[tid]; tid += blockDim.x * gridDim.x; } // set the cache values cache[cacheIndex] = temp; // synchronize threads in this block __syncthreads(); // for reductions, threadsPerBlock must be a power of 2 // because of the following code int i = blockDim.x/2; while (i != 0){ if (cacheIndex &lt; i) cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); i /= 2; } if (cacheIndex == 0) c[blockIdx.x] = cache[0]; } int main (void) { float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; // allocate memory on the cpu side a = (float*)malloc(N*sizeof(float)); b = (float*)malloc(N*sizeof(float)); partial_c = (float*)malloc(blocksPerGrid*sizeof(float)); // allocate the memory on the gpu cudaMalloc((void**)&amp;dev_a, N*sizeof(float)); cudaMalloc((void**)&amp;dev_b, N*sizeof(float)); cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid*sizeof(float)); // fill in the host memory with data for(int i=0; i&lt;N; i++) { a[i] = i; b[i] = i*2; } // copy the arrays 'a' and 'b' to the gpu cudaMemcpy(dev_a, a, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(float), cudaMemcpyHostToDevice); dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_partial_c); // copy the array 'c' back from the gpu to the cpu cudaMemcpy(partial_c,dev_partial_c, blocksPerGrid*sizeof(float), cudaMemcpyDeviceToHost); // finish up on the cpu side c = 0; for(int i=0; i&lt;blocksPerGrid; i++) { c += partial_c[i]; } #define sum_squares(x) (x*(x+1)*(2*x+1)/6) printf("GPU - %.6g \nCPU - %.6g\n", c, 2*sum_squares((float)(N-1))); // free memory on the gpu side cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_partial_c); // free memory on the cpu side free(a); free(b); free(partial_c); }</span></span></span></span></code> </pre></div></div><br><p>  Crie e execute: </p><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin/nvcc --cudart=shared dotProd.cu -o dotProd ./dotProd</code> </pre> <br><p>  Esse resultado nos diz que est√° tudo bem conosco: </p><br><blockquote>  GPU - 2.57236e + 13 <br>  CPU - 2.57236e + 13 </blockquote><p>  <strong>Exemplo 3</strong> </p><br><p>  Execute outro teste padr√£o CUDA-matrixMulCUBLAS (multiplica√ß√£o de matriz). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt; YYY&gt;/NVIDIA_CUDA-8.0_Samples/0_Simple/matrixMulCUBLAS make EXTRA_NVCCFLAGS=--cudart=shared ./matrixMulCUBLAS</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Resultado</b> <div class="spoiler_text"><p>  [Matrix Multiply CUBLAS] - Iniciando ... <br>  Dispositivo GPU 0: "GeForce GTX 660" com capacidade de computa√ß√£o 3.0 </p><br><p>  Matriz A (640.480), Matriz B (480.320), Matriz C (640.320) <br>  Resultado da computa√ß√£o usando CUBLAS ... feito. <br>  Desempenho = 436,24 GFlop / s, Tempo = 0,451 ms, Tamanho = 196608000 Ops <br>  Resultado da computa√ß√£o usando CPU host ... pronto. <br>  Comparando os resultados da matriz CUBLAS Multiply com CPU: PASS </p><br><p>  NOTA: As amostras CUDA n√£o se destinam a medi√ß√µes de desempenho.  Os resultados podem variar quando o GPU Boost est√° ativado. </p></div></div><br><p>  Interessante para n√≥s: </p><br><blockquote>  Desempenho = 436,24 GFlop / s, <br>  Comparando os resultados da matriz CUBLAS Multiply com CPU: PASS </blockquote><br><h4 id="bezopasnost">  Seguran√ßa </h4><br><p>  N√£o encontrei men√ß√£o de nenhum m√©todo de autoriza√ß√£o na documenta√ß√£o do rCUDA.  Acho que, no momento, a coisa mais simples que pode ser feita √© abrir o acesso √† porta desejada (8308) apenas a partir de um endere√ßo espec√≠fico. </p><br><p>  Usando o iptables, ficar√° assim: </p><br><pre> <code class="bash hljs">iptables -A INPUT -m state --state NEW -p tcp -s &lt; &gt; --dport 8308 -j ACCEPT</code> </pre> <br><p>  De resto, deixo a quest√£o de seguran√ßa al√©m do escopo deste post. </p><br><div class="spoiler">  <b class="spoiler_title">Fontes e links</b> <div class="spoiler_text"><p>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://www.rcuda.net/pub/rCUDA_guide.pdf</a> <br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://www.rcuda.net/pub/rCUDA_QSG.pdf</a> <br>  [3] C. Rea√±o, F. Silla, G. Shainer e S. Schultz, ‚ÄúGPUs locais e remotas executam de forma semelhante com o EDR 100G InfiniBand‚Äù, em anais da International Middleware Conference, Vancouver, BC, Canad√°, dezembro de 2015. <br>  [4] C. Rea√±o e F. Silla, ‚ÄúUma compara√ß√£o de desempenho das estruturas de virtualiza√ß√£o de GPU remotas CUDA‚Äù, em um processo da Confer√™ncia Internacional sobre Computa√ß√£o de Cluster, Chicago, IL, EUA, setembro de 2015. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt416127/">https://habr.com/ru/post/pt416127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt416115/index.html">10 pequenos erros de design que ainda cometemos</a></li>
<li><a href="../pt416119/index.html">Postagem na sexta-feira: top dos pacotes NPM mais "essenciais"</a></li>
<li><a href="../pt416121/index.html">Fujitsu Artificial Intelligence calcula a geometria dos materiais magn√©ticos</a></li>
<li><a href="../pt416123/index.html">Reconhecimento de mercadorias nas prateleiras usando redes neurais usando as tecnologias Keras e Tensorflow Object Detection API</a></li>
<li><a href="../pt416125/index.html">Instala√ß√£o, configura√ß√£o do sistema e controle para c√¢meras</a></li>
<li><a href="../pt416129/index.html">Como a IA aprende a gerar imagens de gatos</a></li>
<li><a href="../pt416131/index.html">Como lidar com a DP na Federa√ß√£o Russa e n√£o violar a lei</a></li>
<li><a href="../pt416133/index.html">Data Center no exterior: Equinix LD8</a></li>
<li><a href="../pt416135/index.html">Aplicativo GUI menor que 1 kb</a></li>
<li><a href="../pt416137/index.html">Zabbix como um scanner de seguran√ßa</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçò üìë üéπ Desde el MPP DBMS cargado - Data Lake lleno de vida con herramientas anal√≠ticas: comparta los detalles de la creaci√≥n ü•£ üéÖüèª üßúüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todas las organizaciones que tienen al menos algo que ver con los datos tarde o temprano enfrentan el problema de almacenar bases de datos relacionale...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Desde el MPP DBMS cargado - Data Lake lleno de vida con herramientas anal√≠ticas: comparta los detalles de la creaci√≥n</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/420141/">  Todas las organizaciones que tienen al menos algo que ver con los datos tarde o temprano enfrentan el problema de almacenar bases de datos relacionales y no estructuradas.  No es f√°cil encontrar un enfoque conveniente, efectivo y econ√≥mico para este problema al mismo tiempo.  Y para asegurarse de que los cient√≠ficos de datos puedan trabajar con √©xito con modelos de aprendizaje autom√°tico.  Lo hicimos, y aunque tuve que jugar con ello, el beneficio final fue incluso m√°s de lo esperado.  Discutiremos todos los detalles a continuaci√≥n. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/755/bd0/32c/755bd032c95a1b46c4f412d65c5a7bf4.png"><br><a name="habracut"></a><br>  Con el tiempo, se acumulan cantidades incre√≠bles de datos corporativos en cualquier banco.  Una cantidad comparable se almacena solo en empresas de Internet y telecomunicaciones.  Sucedi√≥ debido a los altos requisitos reglamentarios.  Estos datos no permanecen inactivos: los jefes de las instituciones financieras han descubierto durante mucho tiempo c√≥mo obtener ganancias de esto. <br><br>  Todos comenzamos con la gesti√≥n y la informaci√≥n financiera.  Con base en estos datos, aprendimos c√≥mo tomar decisiones comerciales.  A menudo era necesario obtener datos de varios sistemas de informaci√≥n del banco, para lo cual creamos bases de datos consolidadas y sistemas de informes.  A partir de esto se form√≥ gradualmente lo que ahora se llama un almac√©n de datos.  Pronto, sobre la base de este almacenamiento, nuestros otros sistemas comenzaron a funcionar: <br><br><ul><li>  CRM anal√≠tico, que permite ofrecer al cliente productos m√°s convenientes para √©l; <br></li><li>  transportadores de pr√©stamos que lo ayudan a tomar una decisi√≥n sobre un pr√©stamo de manera r√°pida y precisa; <br></li><li>  Sistemas de fidelizaci√≥n que calculan reembolsos o puntos de bonificaci√≥n seg√∫n mecanismos de diversa complejidad. <br></li></ul><br>  Todas estas tareas se resuelven mediante aplicaciones anal√≠ticas que utilizan modelos de aprendizaje autom√°tico.  Cuanta m√°s informaci√≥n puedan obtener los modelos del repositorio, m√°s exactamente funcionar√°n.  Su necesidad de datos est√° creciendo exponencialmente. <br><br>  Sobre esta situaci√≥n llegamos hace dos o tres a√±os.  En ese momento, ten√≠amos un almacenamiento basado en el MPP Teradata DBMS usando la herramienta SAS Data Integration Studio ELT.  Construimos este almac√©n desde 2011 junto con Glowbyte Consulting.  En √©l se integraron m√°s de 15 grandes sistemas bancarios y, al mismo tiempo, se acumularon datos suficientes para la implementaci√≥n y el desarrollo de aplicaciones anal√≠ticas.  Por cierto, justo en ese momento, la cantidad de datos en las capas principales de la tienda, debido a muchas tareas diferentes, comenz√≥ a crecer de forma no lineal, y el an√°lisis avanzado de clientes se convirti√≥ en una de las principales direcciones del desarrollo del banco.  S√≠, y nuestros cient√≠ficos de datos estaban ansiosos por apoyarla.  En general, para construir la Plataforma de Investigaci√≥n de Datos, las estrellas se formaron como deber√≠an. <br><br><h2>  Planificando una soluci√≥n </h2><br>  Aqu√≠ es necesario explicar: el software industrial y los servidores son un placer costoso incluso para un banco grande.  No todas las organizaciones pueden permitirse almacenar una gran cantidad de datos en los principales MPP DBMS.  Siempre debe elegir entre precio y velocidad, confiabilidad y volumen. <br><br>  Para aprovechar al m√°ximo las oportunidades disponibles, decidimos hacer esto: <br><br><ul><li> La carga ELT y la parte m√°s solicitada de los datos hist√≥ricos del CD deben dejarse en el DBMS de Teradata; <br></li><li>  env√≠e la historia completa a Hadoop, que le permite almacenar informaci√≥n mucho m√°s barata. <br></li></ul><br>  Alrededor de ese tiempo, el ecosistema de Hadoop no solo se puso de moda, sino tambi√©n lo suficientemente confiable y conveniente para el uso empresarial.  Era necesario elegir un kit de distribuci√≥n.  Puede construir el suyo propio o usar el Apache Hadoop abierto.  Pero entre las soluciones empresariales basadas en Hadoop, las distribuciones listas para usar de otros proveedores, Cloudera y Hortonworks, han demostrado ser m√°s.  Por lo tanto, tambi√©n decidimos usar una distribuci√≥n preparada. <br><br>  Dado que nuestra tarea principal todav√≠a era almacenar grandes datos estructurados, en la pila de Hadoop est√°bamos interesados ‚Äã‚Äãen soluciones que estuvieran lo m√°s cerca posible de los DBMS SQL cl√°sicos.  Los l√≠deres aqu√≠ son Impala y Hive.  Cloudera desarrolla e integra las soluciones Impala, Hortonworks - Hive. <br><br>  Para un estudio en profundidad, organizamos pruebas de carga para ambos DBMS, teniendo en cuenta la carga de perfil para nosotros.  Debo decir que los motores de procesamiento de datos en Impala y Hive son significativamente diferentes: Hive generalmente presenta varias opciones diferentes.  Sin embargo, la elecci√≥n recay√≥ en Impala y, en consecuencia, la distribuci√≥n de Cloudera. <br><br><h2>  Lo que me gust√≥ de Impala </h2><br><ul><li>  <i>Alta velocidad de ejecuci√≥n de consultas anal√≠ticas</i> debido a un enfoque alternativo en relaci√≥n con MapReduce.  Los resultados intermedios de los c√°lculos no se pliegan en HDFS, lo que acelera significativamente el procesamiento de datos. <br></li><li>  <i>Trabajo eficiente con almacenamiento de datos de parquet en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parquet</a> .</i>  Para tareas anal√≠ticas, a menudo se usan las llamadas tablas anchas con muchas columnas.  Raramente se usan todas las columnas: la capacidad de subir desde HDFS solo las que son necesarias para el trabajo le permite ahorrar RAM y acelerar significativamente la solicitud. <br></li><li>  <i>Una soluci√≥n elegante con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">filtros de tiempo de ejecuci√≥n</a> que incluyen filtrado de floraci√≥n.</i>  Tanto Hive como Impala est√°n significativamente limitados en su uso de √≠ndices comunes a los DBMS cl√°sicos debido a la naturaleza del sistema de almacenamiento de archivos HDFS.  Por lo tanto, para optimizar la ejecuci√≥n de la consulta SQL, el motor DBMS deber√≠a usar efectivamente la partici√≥n disponible incluso cuando no se especifique expl√≠citamente en las condiciones de la consulta.  Adem√°s, debe tratar de predecir qu√© cantidad m√≠nima de datos de HDFS debe generarse para garantizar el procesamiento de todas las filas.  En Impala, esto funciona muy bien. <br></li><li>  <i>Impala <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">utiliza LLVM</a></i> , un compilador de m√°quinas virtuales con instrucciones similares a RISC, para generar el c√≥digo √≥ptimo de ejecuci√≥n de consultas SQL. <br></li><li>  <i>Las interfaces ODBC y JDBC son compatibles.</i>  Esto le permite integrar los datos de Impala con herramientas anal√≠ticas y aplicaciones casi listas para usar. <br></li><li>  <i>Es posible usar Kudu</i> para eludir algunas de las limitaciones de HDFS y, en particular, escribir construcciones UPDATE y DELETE en consultas SQL. <br></li></ul><br><h2>  Sqoop y el resto de la arquitectura. </h2><br>  La siguiente herramienta m√°s importante en la pila de Hadoop fue Sqoop para nosotros.  Le permite transferir datos entre DBMS relacionales (por supuesto, est√°bamos interesados ‚Äã‚Äãen Teradata) y HDFS en un cl√∫ster Hadoop en varios formatos, incluido Parquet.  En las pruebas, Sqoop mostr√≥ una gran flexibilidad y rendimiento, por lo que decidimos usarlo, en lugar de desarrollar nuestras propias herramientas para capturar datos a trav√©s de ODBC / JDBC y guardarlos en HDFS. <br><br>  Para los modelos de capacitaci√≥n y tareas relacionadas de Data Science, que son m√°s convenientes para ejecutar directamente en el cl√∫ster Hadoop, utilizamos Apache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Spark</a> .  En su campo, se ha convertido en una soluci√≥n est√°ndar, y hay una raz√≥n: <br><br><ul><li>  Bibliotecas de aprendizaje autom√°tico de Spark ML <br></li><li>  soporte para cuatro lenguajes de programaci√≥n (Scala, Java, Python, R); <br></li><li>  integraci√≥n con herramientas anal√≠ticas; <br></li><li>  El procesamiento de datos en memoria proporciona un rendimiento excelente. <br></li></ul><br>  El servidor de Oracle Big Data Appliance se compr√≥ como una plataforma de hardware.  Comenzamos con seis nodos en un circuito productivo con una CPU de 2x24 n√∫cleos y 256 GB de memoria cada uno.  La configuraci√≥n actual contiene 18 de los mismos nodos con hasta 512 GB de memoria expandida. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58f/173/025/58f173025e987a85582e383fd5f4b3d9.png"><br><br>  El diagrama muestra la arquitectura de nivel superior de la plataforma de investigaci√≥n de datos y los sistemas relacionados.  El enlace central es el cl√∫ster Hadoop basado en la distribuci√≥n Cloudera (CDH).  Se utiliza tanto para recibir con Sqoop como para almacenar datos QCD en HDFS, en formato de parquet, lo que permite el uso de c√≥decs para la compresi√≥n, por ejemplo, Snappy.  El cl√∫ster tambi√©n procesa datos: Impala se usa para transformaciones similares a ELT, Spark, para tareas de Data Science.  Sentry se usa para compartir el acceso a datos. <br><br>  Impala tiene interfaces para casi todas las herramientas modernas de an√°lisis empresarial.  Adem√°s, las herramientas arbitrarias que admiten interfaces ODBC / JDBC se pueden conectar como clientes.  Para trabajar con SQL, consideramos que Hue y TOAD para Hadoop son los principales clientes. <br><br>  Un subsistema ETL que consta de herramientas SAS (Metadata Server, Data Integration Studio) y un marco ETL escrito sobre la base de SAS y scripts de shell que utilizan una base de datos para almacenar metadatos de procesos ETL se utilizan para administrar todos los flujos indicados por flechas en el diagrama. .  Guiado por las reglas especificadas en los metadatos, el subsistema ETL lanza procesos de procesamiento de datos tanto en QCD como en la Plataforma de Investigaci√≥n de Datos.  Como resultado, tenemos un sistema de extremo a extremo para monitorear y administrar los flujos de datos independientemente del entorno utilizado (Teradata, Impala, Spark, etc., si es necesario). <br><br><h2>  A trav√©s del rastrillo a las estrellas </h2><br>  Descargar QCD parece ser simple.  En la entrada y salida, el DBMS relacional, toma y desborda datos a trav√©s de Sqoop.  A juzgar por la descripci√≥n anterior, todo nos fue muy bien, pero, por supuesto, no fue sin aventuras, y esta es quiz√°s la parte m√°s interesante de todo el proyecto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c7/011/2fc/5c70112fc6dae573401cfd4a85733514.png"><br><br>  Con nuestro volumen, no podr√≠amos esperar transferir todos los datos por completo todos los d√≠as.  En consecuencia, en cada instalaci√≥n de almacenamiento era necesario aprender a distinguir un incremento confiable, lo que no siempre es f√°cil cuando los datos de las fechas comerciales hist√≥ricas pueden cambiar en la tabla.  Para resolver este problema, sistematizamos objetos seg√∫n los m√©todos de carga y mantenimiento del historial.  Luego, para cada tipo, se determin√≥ el predicado correcto para Sqoop y el m√©todo de carga en el receptor.  Y finalmente, escribieron instrucciones para desarrolladores de nuevos objetos. <br><br>  Sqoop es una herramienta de muy alta calidad, pero no en todos los casos y combinaciones de sistemas, funciona de manera absolutamente confiable.  En nuestros vol√∫menes, el conector a Teradata no funcion√≥ de manera √≥ptima.  Aprovechamos el c√≥digo fuente abierto de Sqoop e hicimos cambios en las bibliotecas de conectores.  La estabilidad de la conexi√≥n al mover datos ha aumentado. <br><br>  Por alguna raz√≥n, cuando Sqoop llama a Teradata, los predicados no se convierten correctamente a las condiciones WHERE.  Debido a esto, Sqoop a veces intenta sacar una gran mesa y filtrarla m√°s tarde.  No pudimos parchear el conector aqu√≠, pero encontramos otra forma: crear a la fuerza una tabla temporal con un predicado impuesto para cada objeto descargado y pedirle a Sqoop que lo llene en exceso. <br><br>  Todos los MPP, y Teradata en particular, tienen una caracter√≠stica relacionada con el almacenamiento de datos paralelos y la ejecuci√≥n de instrucciones.  Si esta caracter√≠stica no se tiene en cuenta, puede resultar que todo el trabajo ser√° asumido por un nodo l√≥gico del cl√∫ster, lo que har√° que la ejecuci√≥n de la consulta sea mucho m√°s lenta, una vez en 100-200.  Por supuesto, no podr√≠amos permitir esto, por lo tanto, escribimos un motor especial que utiliza metadatos ETL de tablas QCD y selecciona el grado √≥ptimo de paralelizaci√≥n de las tareas de Sqoop. <br><br>  La historicidad en el almacenamiento es un asunto delicado, especialmente si usa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SCD2</a> , mientras que Impala no admite ACTUALIZAR y ELIMINAR.  Por supuesto, queremos que las tablas hist√≥ricas en la Plataforma de investigaci√≥n de datos tengan exactamente el mismo aspecto que en Teradata.  Esto se puede lograr combinando el incremento de recepci√≥n a trav√©s de Sqoop, resaltando claves comerciales actualizadas y eliminando particiones en Impala.  Para que esta l√≥gica elaborada no tenga que ser escrita por cada desarrollador, la empaquetamos en una biblioteca especial (en nuestro "cargador" de jerga ETL). <br><br>  Finalmente, una pregunta con tipos de datos.  Impala es bastante libre de escribir conversi√≥n, por lo que encontramos algunas dificultades solo en los tipos TIMESTAMP y CHAR / VARCHAR.  Para la fecha y hora, decidimos almacenar datos en Impala en el formato de texto (STRING) AAAA-MM-DD HH: MM: SS.  Como resultado, este enfoque permite utilizar las funciones de transformaci√≥n de fecha y hora.  Para los datos de cadena de una longitud dada, result√≥ que el almacenamiento en formato STRING en Impala no es inferior a ellos, por lo tanto, tambi√©n lo usamos. <br><br>  Por lo general, para organizar Data Lake, copian datos de origen en formatos semiestructurados en un √°rea de escenario especial en Hadoop, despu√©s de lo cual Hive o Impala configuran un esquema de deserializaci√≥n para estos datos para su uso en consultas SQL.  Nosotros fuimos por el mismo camino.  Es importante tener en cuenta que no todo y que no siempre tiene sentido arrastrar al almac√©n de datos, ya que el desarrollo de procesos de copia de archivos y la instalaci√≥n del esquema es mucho m√°s barato que cargar atributos comerciales en el modelo QCD utilizando procesos ETL.  Cuando todav√≠a no est√° claro cu√°nto, por cu√°nto tiempo y con qu√© frecuencia se necesitan los datos de origen, Data Lake en el enfoque descrito es una soluci√≥n simple y barata.  Ahora cargamos regularmente a Data Lake principalmente fuentes que generan eventos de usuario: datos de an√°lisis de aplicaciones, registros y escenarios de transici√≥n para marcador autom√°tico y contestador autom√°tico Avaya, transacciones con tarjeta. <br><br><h2>  Kit de herramientas para analistas </h2><br>  No nos hemos olvidado de otro objetivo de todo el proyecto: permitir a los analistas utilizar toda esta riqueza.  Aqu√≠ est√°n los principios b√°sicos que nos guiaron aqu√≠: <br><br><ul><li>  Conveniencia de la herramienta en uso y soporte <br></li><li>  Aplicabilidad en tareas de ciencia de datos <br></li><li>  La posibilidad m√°xima de utilizar los recursos inform√°ticos del cl√∫ster Hadoop, y no los servidores de aplicaciones o la computadora del investigador <br></li></ul><br>  Y esto es lo que paramos en: <br><br><ul><li>  Python + Anaconda.  El entorno utilizado es iPython / Jupyter. <br></li><li>  R + brillante.  El investigador trabaja en la versi√≥n de escritorio o web de R Studio, Shiny se utiliza para desarrollar aplicaciones web que se agudizan mediante el uso de algoritmos desarrollados en R. <br></li><li>  Chispa  Para trabajar con datos, se utilizan las interfaces para Python (pyspark) y R, que se configuran en los entornos de desarrollo especificados en los p√°rrafos anteriores.  Ambas interfaces le permiten utilizar la biblioteca Spark ML, lo que permite entrenar modelos ML en el cl√∫ster Hadoop / Spark. <br></li><li>  Se puede acceder a los datos de Impala a trav√©s de Hue, Spark y desde entornos de desarrollo utilizando la interfaz est√°ndar ODBC y bibliotecas especiales como implyr <br></li></ul><br>  Actualmente, Data Lake contiene aproximadamente 100 TB de datos del almacenamiento minorista, adem√°s de aproximadamente 50 TB de varias fuentes OLTP.  El lago se actualiza diariamente de forma incremental.  En el futuro, vamos a aumentar la conveniencia del usuario, introducir una carga ELT en Impala, aumentar el n√∫mero de fuentes cargadas en Data Lake y ampliar las oportunidades para an√°lisis avanzados. <br><br>  En conclusi√≥n, me gustar√≠a dar algunos consejos generales a colegas que reci√©n comienzan su viaje en la creaci√≥n de grandes repositorios: <br><br><ul><li>  Utiliza las mejores pr√°cticas.  Si no tuvi√©ramos un subsistema ETL, metadatos, almacenamiento versionado y una arquitectura comprensible, no habr√≠amos dominado esta tarea.  Las mejores pr√°cticas se pagan por s√≠ mismas, aunque no de inmediato. <br></li><li>  Recuerda la cantidad de datos.  Big data puede crear dificultades t√©cnicas en lugares muy inesperados. <br></li><li>  Est√©n atentos a las nuevas tecnolog√≠as.  A menudo aparecen nuevas soluciones, no todas son √∫tiles, pero a veces se encuentran gemas reales. <br></li><li>  Experimenta m√°s.  No conf√≠e solo en las descripciones de marketing de las soluciones, pru√©belo usted mismo. <br></li></ul><br>  <i>Por cierto, puede leer sobre c√≥mo nuestros analistas utilizaron el aprendizaje autom√°tico y los datos bancarios para trabajar con los riesgos de cr√©dito en una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaci√≥n</a> separada.</i> <i><br></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es420141/">https://habr.com/ru/post/es420141/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es420129/index.html">Patrones de rutina de Asyncio: afuera aguardan</a></li>
<li><a href="../es420131/index.html">M√©todo de miner√≠a probabil√≠stico de Bitcoin</a></li>
<li><a href="../es420133/index.html">Modelado de sistemas din√°micos: ¬øc√≥mo se mueve la luna?</a></li>
<li><a href="../es420135/index.html">Esto tambi√©n es Toshiba: productos inesperados de la corporaci√≥n japonesa</a></li>
<li><a href="../es420139/index.html">Libro "Ingenier√≠a de confiabilidad del sitio. Fiabilidad y fiabilidad como en Google ¬ª</a></li>
<li><a href="../es420143/index.html">Rendimiento de Kotlin en Android</a></li>
<li><a href="../es420145/index.html">¬øC√≥mo es el d√≠a de trabajo de los miembros de PC AppsConf?</a></li>
<li><a href="../es420147/index.html">OpenSource en Clojure</a></li>
<li><a href="../es420151/index.html">M√°s f√°cil de lo que parece. Cap√≠tulo 12</a></li>
<li><a href="../es420153/index.html">Impresi√≥n 3D de piezas complejas hechas de ABS y PLA con mucho soporte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
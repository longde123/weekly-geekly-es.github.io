<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游댷 游뛇 游뛏 C칩mo crear un AI-racista sin mucho esfuerzo 游댱 丘뉦잺 游눷</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Una lecci칩n de advertencia. 

 춰Hagamos un clasificador de tonalidad! 

 El an치lisis de sentimientos (an치lisis de sentimientos) es una tarea muy com칰n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C칩mo crear un AI-racista sin mucho esfuerzo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436506/"> Una lecci칩n de advertencia. <br><br>  <b>춰Hagamos un clasificador de tonalidad!</b> <br><br>  El an치lisis de sentimientos (an치lisis de sentimientos) es una tarea muy com칰n en el procesamiento del lenguaje natural (PNL), y esto no es sorprendente.  Es importante que una empresa entienda lo que dice la gente: positiva o negativa.  Dicho an치lisis se utiliza para monitorear las redes sociales, los comentarios de los clientes e incluso en el comercio de acciones algor칤tmico (como resultado, los bots <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">compran acciones de Berkshire Hathaway despu칠s de publicar cr칤ticas positivas sobre el papel de Anne Hathaway en la 칰ltima pel칤cula</a> ). <br><br>  El m칠todo de an치lisis a veces se simplifica demasiado, pero es una de las formas m치s f치ciles de obtener resultados medibles.  Simplemente env칤e el texto, y el resultado es positivo y negativo.  No es necesario tratar con el 치rbol de an치lisis, construir un gr치fico u otra representaci칩n compleja. <br><a name="habracut"></a><br>  Esto es lo que haremos.  Seguiremos el camino de menor resistencia y crearemos el clasificador m치s simple, que probablemente parezca muy familiar para todos los involucrados en desarrollos relevantes en el campo de la PNL.  Por ejemplo, dicho modelo se puede encontrar en el art칤culo <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deep Averaging Networks</a></i> (Iyyer et al., 2015).  No estamos intentando desafiar sus resultados o criticar el modelo;  simplemente damos un m칠todo bien conocido de representaci칩n vectorial de palabras. <br><br>  Plan de trabajo: <br><br><ul><li>  Introduzca una <b>representaci칩n vectorial</b> t칤pica <b>de palabras</b> para trabajar con significados (significados). </li><li>  Presente <b>conjuntos de datos de entrenamiento y prueba</b> con listas est치ndar de palabras positivas y negativas. </li><li>  <b>Entrene</b> al <b>clasificador de</b> descenso de gradiente para reconocer otras palabras positivas y negativas basadas en su representaci칩n vectorial. </li><li>  Use este clasificador para calcular <b>clasificaciones de tonalidad</b> para oraciones de texto. </li><li>  <b>Para ver el monstruo</b> que hemos creado. </li></ul><br>  Y luego veremos, "c칩mo crear un racista AI sin esfuerzos especiales".  Por supuesto, no puedes dejar el sistema en una forma tan monstruosa, as칤 que vamos a: <br><br><ul><li>  <b>Evaluar el problema</b> estad칤sticamente, para que sea posible medir el progreso a medida que se resuelve. </li><li>  <b>Mejore los datos</b> para obtener un modelo sem치ntico m치s preciso y menos racista. </li></ul><br><h1>  Dependencias de software </h1><br>  Este tutorial est치 escrito en Python y se basa en una pila t칤pica de aprendizaje autom치tico de Python: <code>numpy</code> y <code>scipy</code> para computaci칩n num칠rica, <code>pandas</code> para administraci칩n de datos y <code>scikit-learn</code> para aprendizaje autom치tico.  Al final, tambi칠n <code>seaborn</code> <code>matplotlib</code> y <code>seaborn</code> para crear diagramas. <br><br>  En principio, <code>scikit-learn</code> se puede reemplazar con TensorFlow o Keras, o algo as칤: tambi칠n pueden entrenar al clasificador en el descenso de gradiente.  Pero no necesitamos sus abstracciones, porque aqu칤 el entrenamiento se lleva a cabo en una etapa. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.formula.api <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGDClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score <span class="hljs-comment"><span class="hljs-comment">#     %matplotlib inline seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)</span></span></code> </pre> <br><h1>  Paso 1. Representaci칩n vectorial de palabras </h1><br>  Las representaciones vectoriales a menudo se usan cuando hay entrada de texto.  Las palabras se convierten en vectores en el espacio multidimensional, donde los vectores adyacentes representan significados similares.  Usando representaciones vectoriales, puede comparar palabras por (aproximadamente) su significado, y no solo por coincidencias exactas. <br><br>  El aprendizaje exitoso requiere cientos de gigabytes de texto.  Afortunadamente, varios equipos de investigaci칩n ya han realizado este trabajo y han proporcionado modelos pre-entrenados de representaciones vectoriales disponibles para descargar. <br><br>  Los dos conjuntos de datos m치s conocidos para el idioma ingl칠s son <b>word2vec</b> (capacitado en textos de Google News) y <b>GloVe</b> (en p치ginas web de Common Crawl).  Cualquiera de ellos dar치 un resultado similar, pero tomaremos el modelo GloVe porque tiene una fuente de datos m치s transparente. <br><br>  GloVe viene en tres tama침os: 6 mil millones, 42 mil millones y 840 mil millones. El 칰ltimo modelo es el m치s poderoso, pero requiere importantes recursos de procesamiento.  La versi칩n de 42 mil millones es bastante buena, y el diccionario est치 perfectamente recortado a 1 mill칩n de palabras.  Estamos en el camino de menor resistencia, as칤 que tome la versi칩n de 42 mil millones. <br><br><blockquote>  <b>- 쯇or qu칠 es tan importante utilizar un modelo "bien conocido"?</b> <br><br>  "춰Me alegra que hayas preguntado sobre esto, hipot칠tico interlocutor!"  En cada paso tratamos de hacer algo extremadamente t칤pico, y el mejor modelo para la representaci칩n vectorial de palabras por alguna raz칩n a칰n no se ha determinado.  Espero que este art칤culo provoque el deseo de utilizar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelos modernos de alta calidad</a> , especialmente aquellos que tienen en cuenta un error algor칤tmico y tratan de corregirlo.  Sin embargo, m치s sobre eso m치s tarde. </blockquote><br>  Descargue glove.42B.300d.zip del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sitio web de GloVe</a> y extraiga el archivo <code>data/glove.42B.300d.txt</code> .  A continuaci칩n, definimos una funci칩n para leer vectores en un formato simple. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_embeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""  DataFrame      ,   word2vec, GloVe, fastText  ConceptNet Numberbatch.            . """</span></span> labels = [] rows = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(infile): items = line.rstrip().split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(items) == <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-comment"><span class="hljs-comment"># This is a header row giving the shape of the matrix continue labels.append(items[0]) values = np.array([float(x) for x in items[1:]], 'f') rows.append(values) arr = np.vstack(rows) return pd.DataFrame(arr, index=labels, dtype='f') embeddings = load_embeddings('data/glove.42B.300d.txt') embeddings.shape</span></span></code> </pre> <br> <code>(1917494, 300)</code> <br> <h1>  Paso 2. Diccionario de tonalidad est치ndar de oro </h1><br>  Ahora necesitamos informaci칩n sobre qu칠 palabras se consideran positivas y cu치les negativas.  Existen muchos diccionarios de este tipo, pero tomaremos un diccionario muy simple (Hu y Liu, 2004), que se utiliza en el art칤culo de <i>Deep Averaging Networks</i> . <br><br>  Descargue el diccionario <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">del sitio web</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bing Liu</a> y extraiga los datos en <code>data/positive-words.txt</code> y <code>data/negative-words.txt</code> . <br><br>  A continuaci칩n, determinamos c칩mo leer estos archivos y asignarlos como <code>neg_words</code> <code>pos_words</code> y <code>neg_words</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_lexicon</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""       (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)      Latin-1.      ,    - .    ,    ';'   ,   . """</span></span> lexicon = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'latin-1'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> infile: line = line.rstrip() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> line.startswith(<span class="hljs-string"><span class="hljs-string">';'</span></span>): lexicon.append(line) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lexicon pos_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/positive-words.txt'</span></span>) neg_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/negative-words.txt'</span></span>)</code> </pre> <br><h1>  Paso 3. Entrenamos el modelo para predecir la tonalidad </h1><br>  En base a los vectores de palabras positivas y negativas, utilizamos el <code>.loc[]</code> Pandas <code>.loc[]</code> para buscar representaciones vectoriales de todas las palabras. <br><br>  Faltan algunas palabras en el diccionario GloVe.  En la mayor칤a de los casos, estos son errores tipogr치ficos como "fascinante".  Aqu칤 vemos un mont칩n de <code>NaN</code> , que indica la ausencia de un vector, y los <code>.dropna()</code> con el <code>.dropna()</code> . <br><br> <code>pos_vectors = embeddings.loc[pos_words].dropna() <br> neg_vectors = embeddings.loc[neg_words].dropna()</code> <br> <br>  Ahora creamos matrices de datos en la entrada (representaciones vectoriales) y en la salida (1 para palabras positivas y -1 para negativas).  Tambi칠n verificamos que los vectores est칠n unidos a las palabras para que podamos interpretar los resultados. <br><br> <code>vectors = pd.concat([pos_vectors, neg_vectors]) <br> targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index]) <br> labels = list(pos_vectors.index) + list(neg_vectors.index)</code> <br> <br><blockquote>  <b>- Espera.</b>  <b>Algunas palabras no son positivas ni negativas, son neutrales.</b>  <b>쯅o deber칤a crearse una tercera clase para palabras neutrales?</b> <br><br>  "Creo que habr칤a sido 칰til".  M치s adelante veremos qu칠 problemas surgen debido a la asignaci칩n de tonalidad a palabras neutrales.  Si podemos identificar de manera confiable las palabras neutrales, entonces es muy posible aumentar la complejidad del clasificador a tres categor칤as.  Pero necesitas encontrar un diccionario de palabras neutrales, porque en el diccionario de Liu solo hay palabras positivas y negativas. <br><br>  As칤 que prob칠 mi versi칩n con 800 ejemplos de palabras y aument칠 el peso para predecir palabras neutrales.  Pero los resultados finales no fueron muy diferentes de lo que ver치 ahora. <br><br>  <b>- 쮺칩mo esta lista distingue palabras positivas y negativas?</b>  <b>쮼so no depende del contexto?</b> <br><br>  Buena pregunta  El an치lisis de claves generales no es tan simple como parece.  La frontera es bastante arbitraria en algunos lugares.  En esta lista, la palabra "insolente" est치 marcada como "mala" y "ambiciosa" como "buena".  "C칩mico" es malo y "divertido" es bueno.  Un "reembolso" es bueno, aunque generalmente se menciona en un mal contexto cuando le debe dinero a alguien o le debe a alguien. <br><br>  Todos entienden que la tonalidad est치 determinada por el contexto, pero en un modelo simple hay que ignorar el contexto y esperar que la tonalidad promedio se adivine correctamente. </blockquote><br>  Usando la funci칩n <code>train_test_split</code> , dividimos simult치neamente los vectores de entrada, los valores de salida y las etiquetas en datos de entrenamiento y prueba, dejando un 10% para las pruebas. <br><br><pre> <code class="python hljs">train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Ahora cree un clasificador y pase vectores a trav칠s de iteraciones a trav칠s de 칠l.  Usamos la funci칩n de p칠rdida log칤stica para que el clasificador final pueda deducir la probabilidad de que la palabra sea positiva o negativa. <br><br><pre> <code class="python hljs">model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) SGDClassifier(alpha=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>, average=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, class_weight=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, epsilon=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, eta0=<span class="hljs-number"><span class="hljs-number">0.0</span></span>, fit_intercept=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, l1_ratio=<span class="hljs-number"><span class="hljs-number">0.15</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'optimal'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">1</span></span>, penalty=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, power_t=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, warm_start=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  Evaluamos el clasificador en los vectores de prueba.  Muestra una precisi칩n del 95%.  No esta mal. <br><br> <code>accuracy_score(model.predict(test_vectors), test_targets) <br> 0.95022624434389136</code> <br> <br>  Definimos la funci칩n de predicci칩n de tonalidad para ciertas palabras, y luego la usamos para algunos ejemplos de datos de prueba. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vecs_to_sentiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vecs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># predict_log_proba  log-    predictions = model.predict_log_proba(vecs) #        #  log-    . return predictions[:, 1] - predictions[:, 0] def words_to_sentiment(words): vecs = embeddings.loc[words].dropna() log_odds = vecs_to_sentiment(vecs) return pd.DataFrame({'sentiment': log_odds}, index=vecs.index) #  20      words_to_sentiment(test_labels).ix[:20]</span></span></code> </pre> <br><table border="1" width="350"><thead><tr><th></th><th>  tonalidad </th></tr></thead><tbody><tr><th>  inquietarse </th><td>  -9.931679 </td></tr><tr><th>  interrumpir </th><td>  -9.634706 </td></tr><tr><th>  firmemente </th><td>  1.466919 </td></tr><tr><th>  imaginario </th><td>  -2.989215 </td></tr><tr><th>  impuestos </th><td>  0.468522 </td></tr><tr><th>  mundialmente famoso </th><td>  6.908561 </td></tr><tr><th>  barato </th><td>  9.237223 </td></tr><tr><th>  decepci칩n </th><td>  -8.737182 </td></tr><tr><th>  totalitario </th><td>  -10.851580 </td></tr><tr><th>  beligerante </th><td>  -8.328674 </td></tr><tr><th>  se congela </th><td>  -8.456981 </td></tr><tr><th>  pecado </th><td>  -7.839670 </td></tr><tr><th>  fr치gil </th><td>  -4.018289 </td></tr><tr><th>  enga침ado </th><td>  -4.309344 </td></tr><tr><th>  sin resolver </th><td>  -2.816172 </td></tr><tr><th>  h치bilmente </th><td>  2.339609 </td></tr><tr><th>  demoniza </th><td>  -2.102152 </td></tr><tr><th>  despreocupado </th><td>  8.747150 </td></tr><tr><th>  impopular </th><td>  -7.887475 </td></tr><tr><th>  simpatizar </th><td>  1.790899 </td></tr></tbody></table><br>  Se ve que el clasificador est치 funcionando.  Aprendi칩 a generalizar la tonalidad en palabras fuera de los datos de entrenamiento. <br><br><h1>  Paso 4. Obtenga una puntuaci칩n de tonalidad para el texto. </h1><br>  Hay muchas formas de agregar vectores a una estimaci칩n general.  Nuevamente, seguimos el camino de menor resistencia, as칤 que solo tome el valor promedio. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re TOKEN_RE = re.compile(<span class="hljs-string"><span class="hljs-string">r"\w.*?\b"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># regex  ,     (\w)   #   (.+?)    (\b).   #       . def text_to_sentiment(text): tokens = [token.casefold() for token in TOKEN_RE.findall(text)] sentiments = words_to_sentiment(tokens) return sentiments['sentiment'].mean()</span></span></code> </pre> <br>  Hay mucho que pedir para la optimizaci칩n: <br><br><ul><li>  Introducir una relaci칩n inversa entre el peso de la palabra y su frecuencia, de modo que las mismas preposiciones no afecten en gran medida la tonalidad. </li><li>  Configuraci칩n para que las oraciones cortas no terminen con valores de tonalidad extremos. </li><li>  Frases contables. </li><li>  Un algoritmo de segmentaci칩n de palabras m치s confiable que los ap칩strofes no eliminan. </li><li>  Contabilizaci칩n de negativos como "no satisfecho". </li></ul><br>  Pero todo requiere un c칩digo adicional y no cambiar치 fundamentalmente los resultados.  Al menos ahora puede comparar aproximadamente diferentes ofertas: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is pretty cool"</span></span>) <span class="hljs-number"><span class="hljs-number">3.889968926086298</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is okay"</span></span>) <span class="hljs-number"><span class="hljs-number">2.7997773492425186</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"meh, this example sucks"</span></span>) <span class="hljs-number"><span class="hljs-number">-1.1774475917460698</span></span></code> </pre> <br><h1>  Paso 5. Mira el monstruo que creamos </h1><br>  No todas las oraciones tienen una tonalidad pronunciada.  Veamos qu칠 pasa con las oraciones neutrales: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Italian food"</span></span>) <span class="hljs-number"><span class="hljs-number">2.0429166109408983</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Chinese food"</span></span>) <span class="hljs-number"><span class="hljs-number">1.4094033658140972</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Mexican food"</span></span>) <span class="hljs-number"><span class="hljs-number">0.38801985560121732</span></span></code> </pre> <br>  Ya me he encontrado con este fen칩meno al analizar las rese침as de restaurantes teniendo en cuenta las representaciones vectoriales de las palabras.  Sin raz칩n aparente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">, todos los restaurantes mexicanos tienen un puntaje general m치s bajo</a> . <br><br>  Las representaciones vectoriales capturan sutiles diferencias sem치nticas en contexto.  Por lo tanto, reflejan los prejuicios de nuestra sociedad. <br><br>  Aqu칤 hay otras sugerencias neutrales: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Emily"</span></span>) <span class="hljs-number"><span class="hljs-number">2.2286179364745311</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Heather"</span></span>) <span class="hljs-number"><span class="hljs-number">1.3976291151079159</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Yvette"</span></span>) <span class="hljs-number"><span class="hljs-number">0.98463802132985556</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Shaniqua"</span></span>) <span class="hljs-number"><span class="hljs-number">-0.47048131775890656</span></span></code> </pre> <br>  Pues maldita sea ... <br><br>  El sistema asociado con los nombres de personas completamente diferentes sentimientos.  Puede ver estos y muchos otros ejemplos y ver que la tonalidad generalmente es m치s alta para los nombres estereot칤picamente blancos y m치s baja para los nombres negros estereotipados. <br><br>  Esta prueba fue utilizada por Caliscan, Bryson y Narayanan en su trabajo de investigaci칩n publicado en la revista <i>Science</i> en abril de 2017.  Demuestra que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sem치ntica del corpus del lenguaje contiene los prejuicios de la sociedad</a> .  Usaremos este m칠todo. <br><br><h1>  Paso 6. Evaluar el problema </h1><br>  Queremos entender c칩mo evitar tales errores.  Pasemos m치s datos a trav칠s del clasificador y midamos estad칤sticamente su "sesgo". <br><br>  Aqu칤 tenemos cuatro listas de nombres que reflejan diferentes or칤genes 칠tnicos, principalmente en los Estados Unidos.  Las dos primeras son listas de nombres predominantemente "blancos" y "negros", adaptados en base a un art칤culo de Kaliskan et al. Tambi칠n agregu칠 nombres espa침oles y musulmanes del 치rabe y el urdu. <br><br>  Estos datos se utilizan para verificar el sesgo del algoritmo durante el proceso de construcci칩n de ConceptNet: se puede encontrar en el m칩dulo <code>conceptnet5.vectors.evaluation.bias</code> .  Existe la idea de ampliar el diccionario a otros grupos 칠tnicos, teniendo en cuenta no solo los nombres, sino tambi칠n los apellidos. <br><br>  Aqu칤 est치n los listados: <br><br><pre> <code class="python hljs">NAMES_BY_ETHNICITY = { <span class="hljs-comment"><span class="hljs-comment">#           . 'White': [ 'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin', 'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed', 'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda', 'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie', 'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie', 'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily', 'Megan', 'Rachel', 'Wendy' ], 'Black': [ 'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome', 'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun', 'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol', 'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle', 'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha', 'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya', 'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn', 'Tawanda', 'Yvette' ], #         . 'Hispanic': [ 'Juan', 'Jos칠', 'Miguel', 'Lu칤s', 'Jorge', 'Santiago', 'Mat칤as', 'Sebasti치n', 'Mateo', 'Nicol치s', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tom치s', 'Juana', 'Ana', 'Luisa', 'Mar칤a', 'Elena', 'Sof칤a', 'Isabella', 'Valentina', 'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina' ], #       # ,   .     . # #          # -   .    #   ,    . # #       . 'Arab/Muslim': [ 'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza', 'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam', 'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana', 'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin' ] }</span></span></code> </pre> <br>  Usando Pandas, compilaremos una tabla de nombres, su origen 칠tnico predominante y las clasificaciones de tonalidad: <br><br><pre> <code class="plaintext hljs">def name_sentiment_table(): frames = [] for group, name_list in sorted(NAMES_BY_ETHNICITY.items()): lower_names = [name.lower() for name in name_list] sentiments = words_to_sentiment(lower_names) sentiments['group'] = group frames.append(sentiments) #           return pd.concat(frames) name_sentiments = name_sentiment_table()</code> </pre> <br>  Datos de muestra: <br><br> <code>name_sentiments.ix[::25]</code> <br> <table border="1" width="350"><thead><tr><th></th><th>  tonalidad </th><th>  el grupo </th></tr></thead><tbody><tr><th>  Mahoma </th><td>  0.834974 </td><td>  츼rabe / musulm치n </td></tr><tr><th>  alya </th><td>  3.916803 </td><td>  츼rabe / musulm치n </td></tr><tr><th>  terryl </th><td>  -2.858010 </td><td>  Negro </td></tr><tr><th>  jos칠 </th><td>  0.432956 </td><td>  Hispano </td></tr><tr><th>  luciana </th><td>  1.086073 </td><td>  Hispano </td></tr><tr><th>  Hank </th><td>  0.391858 </td><td>  Blanco </td></tr><tr><th>  megan </th><td>  2.158679 </td><td>  Blanco </td></tr></tbody></table><br>  Haremos un gr치fico de la distribuci칩n de tonalidad para cada nombre. <br><br><pre> <code class="python hljs">plot = seaborn.swarmplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments) plot.set_ylim([<span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> <br> <code>(-10, 10)</code> <br> <br><img src="https://habrastorage.org/webt/qv/y7/ge/qvy7gel8rrvm5txo-nou6g0i0re.png"><br><br>  O como un histograma con intervalos de confianza para el promedio del 95%. <br><br><pre> <code class="python hljs">plot = seaborn.barplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments, capsize=<span class="hljs-number"><span class="hljs-number">.1</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/uv/ib/n6/uvibn6olthaxt6cxbd96szehq94.png"><br><br>  Finalmente, ejecute el paquete de estad칤sticas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">statsmodels</a> serias.  Mostrar치 cu치n grande es el sesgo del algoritmo (junto con muchas otras estad칤sticas). <br><br><br>  <font color="gray">Resultados de regresi칩n de OLS</font> <br><table><tbody><tr><th>  Dep.  Variable: </th><td>  sentimiento </td><th>  R cuadrado: </th><td>  0,208 </td></tr><tr><th>  Modelo: </th><td>  OLS </td><th>  Adj.  R cuadrado: </th><td>  0,192 </td></tr><tr><th>  M칠todo: </th><td>  M칤nimos cuadrados </td><th>  Estad칤stica F: </th><td>  13/04 </td></tr><tr><th>  Fecha: </th><td>  Jue, 13 jul 2017 </td><th>  Prob (estad칤stica F): </th><td>  1.31e-07 </td></tr><tr><th>  Tiempo: </th><td>  11:31:17 </td><th>  Probabilidad de registro: </th><td>  -356,78 </td></tr><tr><th>  No  Observaciones: </th><td>  153 </td><th>  AIC: </th><td>  721,6 </td></tr><tr><th>  Df Residuos: </th><td>  149 </td><th>  BIC: </th><td>  733,7 </td></tr><tr><th>  Modelo Df: </th><td>  3 </td><th></th><td></td></tr><tr><th>  Tipo de covarianza: </th><td>  no robusto </td><th></th><td></td></tr></tbody></table><br>  El estad칤stico F es la relaci칩n entre la variaci칩n entre los grupos y la variaci칩n dentro de los grupos, que se puede tomar como una evaluaci칩n general del sesgo. <br><br>  Inmediatamente debajo se indica la probabilidad de que veamos el estad칤stico F m치ximo con la hip칩tesis nula: es decir, en ausencia de una diferencia entre las opciones comparadas.  La probabilidad es muy, muy baja.  En un art칤culo cient칤fico, llamar칤amos al resultado "muy estad칤sticamente significativo". <br><br>  Necesitamos mejorar el valor F.  Cuanto m치s bajo, mejor. <br><br> <code>ols_model.fvalue <br> 13.041597745167659</code> <br> <br><h1>  Paso 7. Probar otros datos. </h1><br>  Ahora tenemos la oportunidad de medir num칠ricamente el sesgo perjudicial del modelo.  Intentemos ajustarlo.  Para hacer esto, debe repetir un mont칩n de cosas que sol칤an ser solo pasos separados en un bloc de notas de Python. <br><br>  Si escribiera un buen c칩digo compatible, no usar칤a variables globales como <code>model</code> e <code>embeddings</code> .  Pero el c칩digo actual de espagueti le permite examinar mejor cada paso y comprender lo que est치 sucediendo.  Reutilizamos parte del c칩digo y al menos definimos una funci칩n para repetir algunos pasos: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">retrain_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(new_embs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""      . """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model, embeddings, name_sentiments embeddings = new_embs pos_vectors = embeddings.loc[pos_words].dropna() neg_vectors = embeddings.loc[neg_words].dropna() vectors = pd.concat([pos_vectors, neg_vectors]) targets = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> pos_vectors.index] + [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> neg_vectors.index]) labels = list(pos_vectors.index) + list(neg_vectors.index) train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>) model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) accuracy = accuracy_score(model.predict(test_vectors), test_targets) print(<span class="hljs-string"><span class="hljs-string">"Accuracy of sentiment: {:.2%}"</span></span>.format(accuracy)) name_sentiments = name_sentiment_table() ols_model = statsmodels.formula.api.ols(<span class="hljs-string"><span class="hljs-string">'sentiment ~ group'</span></span>, data=name_sentiments).fit() print(<span class="hljs-string"><span class="hljs-string">"F-value of bias: {:.3f}"</span></span>.format(ols_model.fvalue)) print(<span class="hljs-string"><span class="hljs-string">"Probability given null hypothesis: {:.3}"</span></span>.format(ols_model.f_pvalue)) <span class="hljs-comment"><span class="hljs-comment">#        Y plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments) plot.set_ylim([-10, 10])</span></span></code> </pre> <br><h3>  Intentamos word2vec </h3><br>  Se puede suponer que solo GloVe tiene el problema.  Probablemente hay muchos sitios dudosos en la base de datos Common Crawl y al menos 20 copias del Urban Dictionary de street slang.  Quiz치s en una base diferente ser칤a mejor: 쯤u칠 pasa con el viejo y bueno word2vec capacitado en Google News? <br><br>  Parece que la fuente m치s autorizada para los datos de word2vec es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este archivo en Google Drive</a> .  Desc치rguelo y gu치rdelo como <code>data/word2vec-googlenews-300.bin.gz</code> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   ConceptNet   word2vec   Pandas     from conceptnet5.vectors.formats import load_word2vec_bin w2v = load_word2vec_bin('data/word2vec-googlenews-300.bin.gz', nrows=2000000) #  word2vec    w2v.index = [label.casefold() for label in w2v.index] #  ,    w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') retrain_model(w2v)</span></span></code> </pre> <br> <code>Accuracy of sentiment: 94.30% <br> F-value of bias: 15.573 <br> Probability given null hypothesis: 7.43e-09</code> <br> <br>  Entonces word2vec result칩 ser a칰n peor con un valor F de m치s de 15. <br><br>  En principio, era una tonter칤a esperar que las <i>noticias</i> estuvieran mejor protegidas de los prejuicios. <br><br><h3>  Intentando ConceptNet Numberbatch </h3><br>  Finalmente, puedo hablar sobre mi propio proyecto sobre la representaci칩n vectorial de palabras. <br><br>  ConceptNet con la funci칩n de presentaci칩n vectorial es el gr치fico de conocimiento en el que estoy trabajando.  Normaliza las representaciones vectoriales en la etapa de entrenamiento, identificando y eliminando algunas fuentes de racismo y sexismo algor칤tmico.  Este m칠todo de correcci칩n de sesgos se basa en un art칤culo cient칤fico de Bulukbashi et al. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Debiasing Word Embeddings"</a> y se generaliza para eliminar varios tipos de sesgos al mismo tiempo.  Que yo sepa, este es el 칰nico sistema sem치ntico en el que hay algo as칤. <br><br>  De vez en cuando, exportamos vectores precalculados desde ConceptNet; estas versiones se denominan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ConceptNet Numberbatch</a> .  En abril de 2017, se lanz칩 la primera versi칩n con correcci칩n de sesgo, por lo que cargaremos los vectores en ingl칠s y reentrenaremos nuestro modelo. <br><br>  <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> , lo <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> en el directorio <code>data/</code> y reciclamos el modelo: <br><br><pre> <code class="python hljs">retrain_model(load_embeddings(<span class="hljs-string"><span class="hljs-string">'data/numberbatch-en-17.04b.txt'</span></span>))</code> </pre> <br> <code>Accuracy of sentiment: 97.46% <br> F-value of bias: 3.805 <br> Probability given null hypothesis: 0.0118</code> <br> <br><img src="https://habrastorage.org/webt/5d/iu/uq/5diuuqrst8bca5-m7fljox--pro.png"><br><br>  Entonces, 쮺onceptNet Numberbatch ha solucionado completamente el problema?  쯅o m치s racismo algor칤tmico?  <b>No</b> <br><br>  쯉e ha vuelto mucho menos racista?  <b>Definitivamente</b> <br><br>  Los rangos clave para los grupos 칠tnicos se superponen mucho m치s que en los vectores GloVe o word2vec.  En comparaci칩n con GloVe, el valor de F disminuy칩 en m치s de tres veces, y en comparaci칩n con word2vec, m치s de cuatro veces.  Y, en general, vemos diferencias mucho menores en la tonalidad al comparar nombres diferentes: esto deber칤a ser as칤, porque los nombres realmente no deber칤an afectar el resultado del an치lisis. <br><br>  Pero se mantuvo una ligera correlaci칩n.  Quiz치s pueda recoger tales datos y par치metros de entrenamiento que el problema parece estar resuelto.  Pero esta ser치 una mala opci칩n, porque <i>de hecho el</i> problema persiste, porque en ConceptNet no identificamos ni compensamos todas las causas del racismo algor칤tmico.  Pero este es un buen comienzo. <br><br><h3>  Sin trampas </h3><br>  Tenga en cuenta que con el cambio a ConceptNet Numberbatch, la precisi칩n de la predicci칩n de la tonalidad ha mejorado. <br><br>  Alguien podr칤a haber sugerido que corregir el racismo algor칤tmico empeorar칤a los resultados de alguna otra manera.  Pero no  Es posible que tenga datos mejores y menos racistas.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los datos realmente est치n mejorando con esta correcci칩n. </font><font style="vertical-align: inherit;">El racismo word2vec y GloVe adquirido de las personas no tiene nada que ver con la precisi칩n del algoritmo.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Otros enfoques </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por supuesto, esta es solo una forma de analizar la tonalidad. Algunos detalles se pueden implementar de manera diferente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En cambio, o adem치s de cambiar la base de vectores, puede intentar solucionar este problema directamente en la salida. Por ejemplo, generalmente elimine la evaluaci칩n de la tonalidad para nombres y grupos de personas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En general, existe una opci칩n para negarse a calcular la tonalidad de todas las palabras y calcularla solo para las palabras de la lista. Esta es quiz치s la forma m치s com칰n de an치lisis de sentimientos, sin el aprendizaje autom치tico en absoluto. Los resultados no tendr치n m치s sesgos que el autor de la lista. Pero abandonar el aprendizaje autom치tico significa reducir el recuerdo, y la 칰nica forma de adaptar el modelo a un conjunto de datos es editar manualmente la lista.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como enfoque h칤brido, puede crear una gran cantidad de estimados estimados de tonalidad para las palabras e instruir a una persona para que las edite pacientemente, haga una lista de palabras de excepci칩n con tonalidad cero. </font><font style="vertical-align: inherit;">Pero este es un trabajo extra. </font><font style="vertical-align: inherit;">Por otro lado, realmente ver치s c칩mo funciona el modelo. </font><font style="vertical-align: inherit;">Creo que, en cualquier caso, esto deber칤a buscarse.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436506/">https://habr.com/ru/post/es436506/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436496/index.html">PVS-Studio para Java</a></li>
<li><a href="../es436498/index.html">Software AG: no solo ARIS</a></li>
<li><a href="../es436500/index.html">C칩mo se representa el marco de Rise of the Tomb Raider</a></li>
<li><a href="../es436502/index.html">Pampers de suscripci칩n o c칩mo vender m치s a los mismos clientes</a></li>
<li><a href="../es436504/index.html">Sistema en paquete, o 쯈u칠 hay debajo de la cubierta del paquete de chips?</a></li>
<li><a href="../es436508/index.html">$ 10 millones en inversiones y elogios de Wozniak: crear una computadora educativa para ni침os</a></li>
<li><a href="../es436510/index.html">Datos centrales en detalle</a></li>
<li><a href="../es436512/index.html">C칩mo encontramos versiones problem치ticas con Graphite y Moira. Vive Yandex.Money</a></li>
<li><a href="../es436514/index.html">Creando historias para Instagram desde PHP</a></li>
<li><a href="../es436518/index.html">Haiku 1 - make / b / OS great again</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
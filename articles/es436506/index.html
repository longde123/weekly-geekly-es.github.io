<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîΩ üö∞ üöπ C√≥mo crear un AI-racista sin mucho esfuerzo üî∑ ‚öíÔ∏è üíπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Una lecci√≥n de advertencia. 

 ¬°Hagamos un clasificador de tonalidad! 

 El an√°lisis de sentimientos (an√°lisis de sentimientos) es una tarea muy com√∫n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo crear un AI-racista sin mucho esfuerzo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436506/"> Una lecci√≥n de advertencia. <br><br>  <b>¬°Hagamos un clasificador de tonalidad!</b> <br><br>  El an√°lisis de sentimientos (an√°lisis de sentimientos) es una tarea muy com√∫n en el procesamiento del lenguaje natural (PNL), y esto no es sorprendente.  Es importante que una empresa entienda lo que dice la gente: positiva o negativa.  Dicho an√°lisis se utiliza para monitorear las redes sociales, los comentarios de los clientes e incluso en el comercio de acciones algor√≠tmico (como resultado, los bots <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">compran acciones de Berkshire Hathaway despu√©s de publicar cr√≠ticas positivas sobre el papel de Anne Hathaway en la √∫ltima pel√≠cula</a> ). <br><br>  El m√©todo de an√°lisis a veces se simplifica demasiado, pero es una de las formas m√°s f√°ciles de obtener resultados medibles.  Simplemente env√≠e el texto, y el resultado es positivo y negativo.  No es necesario tratar con el √°rbol de an√°lisis, construir un gr√°fico u otra representaci√≥n compleja. <br><a name="habracut"></a><br>  Esto es lo que haremos.  Seguiremos el camino de menor resistencia y crearemos el clasificador m√°s simple, que probablemente parezca muy familiar para todos los involucrados en desarrollos relevantes en el campo de la PNL.  Por ejemplo, dicho modelo se puede encontrar en el art√≠culo <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deep Averaging Networks</a></i> (Iyyer et al., 2015).  No estamos intentando desafiar sus resultados o criticar el modelo;  simplemente damos un m√©todo bien conocido de representaci√≥n vectorial de palabras. <br><br>  Plan de trabajo: <br><br><ul><li>  Introduzca una <b>representaci√≥n vectorial</b> t√≠pica <b>de palabras</b> para trabajar con significados (significados). </li><li>  Presente <b>conjuntos de datos de entrenamiento y prueba</b> con listas est√°ndar de palabras positivas y negativas. </li><li>  <b>Entrene</b> al <b>clasificador de</b> descenso de gradiente para reconocer otras palabras positivas y negativas basadas en su representaci√≥n vectorial. </li><li>  Use este clasificador para calcular <b>clasificaciones de tonalidad</b> para oraciones de texto. </li><li>  <b>Para ver el monstruo</b> que hemos creado. </li></ul><br>  Y luego veremos, "c√≥mo crear un racista AI sin esfuerzos especiales".  Por supuesto, no puedes dejar el sistema en una forma tan monstruosa, as√≠ que vamos a: <br><br><ul><li>  <b>Evaluar el problema</b> estad√≠sticamente, para que sea posible medir el progreso a medida que se resuelve. </li><li>  <b>Mejore los datos</b> para obtener un modelo sem√°ntico m√°s preciso y menos racista. </li></ul><br><h1>  Dependencias de software </h1><br>  Este tutorial est√° escrito en Python y se basa en una pila t√≠pica de aprendizaje autom√°tico de Python: <code>numpy</code> y <code>scipy</code> para computaci√≥n num√©rica, <code>pandas</code> para administraci√≥n de datos y <code>scikit-learn</code> para aprendizaje autom√°tico.  Al final, tambi√©n <code>seaborn</code> <code>matplotlib</code> y <code>seaborn</code> para crear diagramas. <br><br>  En principio, <code>scikit-learn</code> se puede reemplazar con TensorFlow o Keras, o algo as√≠: tambi√©n pueden entrenar al clasificador en el descenso de gradiente.  Pero no necesitamos sus abstracciones, porque aqu√≠ el entrenamiento se lleva a cabo en una etapa. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.formula.api <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGDClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score <span class="hljs-comment"><span class="hljs-comment">#     %matplotlib inline seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)</span></span></code> </pre> <br><h1>  Paso 1. Representaci√≥n vectorial de palabras </h1><br>  Las representaciones vectoriales a menudo se usan cuando hay entrada de texto.  Las palabras se convierten en vectores en el espacio multidimensional, donde los vectores adyacentes representan significados similares.  Usando representaciones vectoriales, puede comparar palabras por (aproximadamente) su significado, y no solo por coincidencias exactas. <br><br>  El aprendizaje exitoso requiere cientos de gigabytes de texto.  Afortunadamente, varios equipos de investigaci√≥n ya han realizado este trabajo y han proporcionado modelos pre-entrenados de representaciones vectoriales disponibles para descargar. <br><br>  Los dos conjuntos de datos m√°s conocidos para el idioma ingl√©s son <b>word2vec</b> (capacitado en textos de Google News) y <b>GloVe</b> (en p√°ginas web de Common Crawl).  Cualquiera de ellos dar√° un resultado similar, pero tomaremos el modelo GloVe porque tiene una fuente de datos m√°s transparente. <br><br>  GloVe viene en tres tama√±os: 6 mil millones, 42 mil millones y 840 mil millones. El √∫ltimo modelo es el m√°s poderoso, pero requiere importantes recursos de procesamiento.  La versi√≥n de 42 mil millones es bastante buena, y el diccionario est√° perfectamente recortado a 1 mill√≥n de palabras.  Estamos en el camino de menor resistencia, as√≠ que tome la versi√≥n de 42 mil millones. <br><br><blockquote>  <b>- ¬øPor qu√© es tan importante utilizar un modelo "bien conocido"?</b> <br><br>  "¬°Me alegra que hayas preguntado sobre esto, hipot√©tico interlocutor!"  En cada paso tratamos de hacer algo extremadamente t√≠pico, y el mejor modelo para la representaci√≥n vectorial de palabras por alguna raz√≥n a√∫n no se ha determinado.  Espero que este art√≠culo provoque el deseo de utilizar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelos modernos de alta calidad</a> , especialmente aquellos que tienen en cuenta un error algor√≠tmico y tratan de corregirlo.  Sin embargo, m√°s sobre eso m√°s tarde. </blockquote><br>  Descargue glove.42B.300d.zip del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sitio web de GloVe</a> y extraiga el archivo <code>data/glove.42B.300d.txt</code> .  A continuaci√≥n, definimos una funci√≥n para leer vectores en un formato simple. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_embeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""  DataFrame      ,   word2vec, GloVe, fastText  ConceptNet Numberbatch.            . """</span></span> labels = [] rows = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(infile): items = line.rstrip().split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(items) == <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-comment"><span class="hljs-comment"># This is a header row giving the shape of the matrix continue labels.append(items[0]) values = np.array([float(x) for x in items[1:]], 'f') rows.append(values) arr = np.vstack(rows) return pd.DataFrame(arr, index=labels, dtype='f') embeddings = load_embeddings('data/glove.42B.300d.txt') embeddings.shape</span></span></code> </pre> <br> <code>(1917494, 300)</code> <br> <h1>  Paso 2. Diccionario de tonalidad est√°ndar de oro </h1><br>  Ahora necesitamos informaci√≥n sobre qu√© palabras se consideran positivas y cu√°les negativas.  Existen muchos diccionarios de este tipo, pero tomaremos un diccionario muy simple (Hu y Liu, 2004), que se utiliza en el art√≠culo de <i>Deep Averaging Networks</i> . <br><br>  Descargue el diccionario <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">del sitio web</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bing Liu</a> y extraiga los datos en <code>data/positive-words.txt</code> y <code>data/negative-words.txt</code> . <br><br>  A continuaci√≥n, determinamos c√≥mo leer estos archivos y asignarlos como <code>neg_words</code> <code>pos_words</code> y <code>neg_words</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_lexicon</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""       (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)      Latin-1.      ,    - .    ,    ';'   ,   . """</span></span> lexicon = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'latin-1'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> infile: line = line.rstrip() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> line.startswith(<span class="hljs-string"><span class="hljs-string">';'</span></span>): lexicon.append(line) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lexicon pos_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/positive-words.txt'</span></span>) neg_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/negative-words.txt'</span></span>)</code> </pre> <br><h1>  Paso 3. Entrenamos el modelo para predecir la tonalidad </h1><br>  En base a los vectores de palabras positivas y negativas, utilizamos el <code>.loc[]</code> Pandas <code>.loc[]</code> para buscar representaciones vectoriales de todas las palabras. <br><br>  Faltan algunas palabras en el diccionario GloVe.  En la mayor√≠a de los casos, estos son errores tipogr√°ficos como "fascinante".  Aqu√≠ vemos un mont√≥n de <code>NaN</code> , que indica la ausencia de un vector, y los <code>.dropna()</code> con el <code>.dropna()</code> . <br><br> <code>pos_vectors = embeddings.loc[pos_words].dropna() <br> neg_vectors = embeddings.loc[neg_words].dropna()</code> <br> <br>  Ahora creamos matrices de datos en la entrada (representaciones vectoriales) y en la salida (1 para palabras positivas y -1 para negativas).  Tambi√©n verificamos que los vectores est√©n unidos a las palabras para que podamos interpretar los resultados. <br><br> <code>vectors = pd.concat([pos_vectors, neg_vectors]) <br> targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index]) <br> labels = list(pos_vectors.index) + list(neg_vectors.index)</code> <br> <br><blockquote>  <b>- Espera.</b>  <b>Algunas palabras no son positivas ni negativas, son neutrales.</b>  <b>¬øNo deber√≠a crearse una tercera clase para palabras neutrales?</b> <br><br>  "Creo que habr√≠a sido √∫til".  M√°s adelante veremos qu√© problemas surgen debido a la asignaci√≥n de tonalidad a palabras neutrales.  Si podemos identificar de manera confiable las palabras neutrales, entonces es muy posible aumentar la complejidad del clasificador a tres categor√≠as.  Pero necesitas encontrar un diccionario de palabras neutrales, porque en el diccionario de Liu solo hay palabras positivas y negativas. <br><br>  As√≠ que prob√© mi versi√≥n con 800 ejemplos de palabras y aument√© el peso para predecir palabras neutrales.  Pero los resultados finales no fueron muy diferentes de lo que ver√° ahora. <br><br>  <b>- ¬øC√≥mo esta lista distingue palabras positivas y negativas?</b>  <b>¬øEso no depende del contexto?</b> <br><br>  Buena pregunta  El an√°lisis de claves generales no es tan simple como parece.  La frontera es bastante arbitraria en algunos lugares.  En esta lista, la palabra "insolente" est√° marcada como "mala" y "ambiciosa" como "buena".  "C√≥mico" es malo y "divertido" es bueno.  Un "reembolso" es bueno, aunque generalmente se menciona en un mal contexto cuando le debe dinero a alguien o le debe a alguien. <br><br>  Todos entienden que la tonalidad est√° determinada por el contexto, pero en un modelo simple hay que ignorar el contexto y esperar que la tonalidad promedio se adivine correctamente. </blockquote><br>  Usando la funci√≥n <code>train_test_split</code> , dividimos simult√°neamente los vectores de entrada, los valores de salida y las etiquetas en datos de entrenamiento y prueba, dejando un 10% para las pruebas. <br><br><pre> <code class="python hljs">train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Ahora cree un clasificador y pase vectores a trav√©s de iteraciones a trav√©s de √©l.  Usamos la funci√≥n de p√©rdida log√≠stica para que el clasificador final pueda deducir la probabilidad de que la palabra sea positiva o negativa. <br><br><pre> <code class="python hljs">model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) SGDClassifier(alpha=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>, average=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, class_weight=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, epsilon=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, eta0=<span class="hljs-number"><span class="hljs-number">0.0</span></span>, fit_intercept=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, l1_ratio=<span class="hljs-number"><span class="hljs-number">0.15</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'optimal'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">1</span></span>, penalty=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, power_t=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, warm_start=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  Evaluamos el clasificador en los vectores de prueba.  Muestra una precisi√≥n del 95%.  No esta mal. <br><br> <code>accuracy_score(model.predict(test_vectors), test_targets) <br> 0.95022624434389136</code> <br> <br>  Definimos la funci√≥n de predicci√≥n de tonalidad para ciertas palabras, y luego la usamos para algunos ejemplos de datos de prueba. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vecs_to_sentiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vecs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># predict_log_proba  log-    predictions = model.predict_log_proba(vecs) #        #  log-    . return predictions[:, 1] - predictions[:, 0] def words_to_sentiment(words): vecs = embeddings.loc[words].dropna() log_odds = vecs_to_sentiment(vecs) return pd.DataFrame({'sentiment': log_odds}, index=vecs.index) #  20      words_to_sentiment(test_labels).ix[:20]</span></span></code> </pre> <br><table border="1" width="350"><thead><tr><th></th><th>  tonalidad </th></tr></thead><tbody><tr><th>  inquietarse </th><td>  -9.931679 </td></tr><tr><th>  interrumpir </th><td>  -9.634706 </td></tr><tr><th>  firmemente </th><td>  1.466919 </td></tr><tr><th>  imaginario </th><td>  -2.989215 </td></tr><tr><th>  impuestos </th><td>  0.468522 </td></tr><tr><th>  mundialmente famoso </th><td>  6.908561 </td></tr><tr><th>  barato </th><td>  9.237223 </td></tr><tr><th>  decepci√≥n </th><td>  -8.737182 </td></tr><tr><th>  totalitario </th><td>  -10.851580 </td></tr><tr><th>  beligerante </th><td>  -8.328674 </td></tr><tr><th>  se congela </th><td>  -8.456981 </td></tr><tr><th>  pecado </th><td>  -7.839670 </td></tr><tr><th>  fr√°gil </th><td>  -4.018289 </td></tr><tr><th>  enga√±ado </th><td>  -4.309344 </td></tr><tr><th>  sin resolver </th><td>  -2.816172 </td></tr><tr><th>  h√°bilmente </th><td>  2.339609 </td></tr><tr><th>  demoniza </th><td>  -2.102152 </td></tr><tr><th>  despreocupado </th><td>  8.747150 </td></tr><tr><th>  impopular </th><td>  -7.887475 </td></tr><tr><th>  simpatizar </th><td>  1.790899 </td></tr></tbody></table><br>  Se ve que el clasificador est√° funcionando.  Aprendi√≥ a generalizar la tonalidad en palabras fuera de los datos de entrenamiento. <br><br><h1>  Paso 4. Obtenga una puntuaci√≥n de tonalidad para el texto. </h1><br>  Hay muchas formas de agregar vectores a una estimaci√≥n general.  Nuevamente, seguimos el camino de menor resistencia, as√≠ que solo tome el valor promedio. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re TOKEN_RE = re.compile(<span class="hljs-string"><span class="hljs-string">r"\w.*?\b"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># regex  ,     (\w)   #   (.+?)    (\b).   #       . def text_to_sentiment(text): tokens = [token.casefold() for token in TOKEN_RE.findall(text)] sentiments = words_to_sentiment(tokens) return sentiments['sentiment'].mean()</span></span></code> </pre> <br>  Hay mucho que pedir para la optimizaci√≥n: <br><br><ul><li>  Introducir una relaci√≥n inversa entre el peso de la palabra y su frecuencia, de modo que las mismas preposiciones no afecten en gran medida la tonalidad. </li><li>  Configuraci√≥n para que las oraciones cortas no terminen con valores de tonalidad extremos. </li><li>  Frases contables. </li><li>  Un algoritmo de segmentaci√≥n de palabras m√°s confiable que los ap√≥strofes no eliminan. </li><li>  Contabilizaci√≥n de negativos como "no satisfecho". </li></ul><br>  Pero todo requiere un c√≥digo adicional y no cambiar√° fundamentalmente los resultados.  Al menos ahora puede comparar aproximadamente diferentes ofertas: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is pretty cool"</span></span>) <span class="hljs-number"><span class="hljs-number">3.889968926086298</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is okay"</span></span>) <span class="hljs-number"><span class="hljs-number">2.7997773492425186</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"meh, this example sucks"</span></span>) <span class="hljs-number"><span class="hljs-number">-1.1774475917460698</span></span></code> </pre> <br><h1>  Paso 5. Mira el monstruo que creamos </h1><br>  No todas las oraciones tienen una tonalidad pronunciada.  Veamos qu√© pasa con las oraciones neutrales: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Italian food"</span></span>) <span class="hljs-number"><span class="hljs-number">2.0429166109408983</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Chinese food"</span></span>) <span class="hljs-number"><span class="hljs-number">1.4094033658140972</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Mexican food"</span></span>) <span class="hljs-number"><span class="hljs-number">0.38801985560121732</span></span></code> </pre> <br>  Ya me he encontrado con este fen√≥meno al analizar las rese√±as de restaurantes teniendo en cuenta las representaciones vectoriales de las palabras.  Sin raz√≥n aparente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">, todos los restaurantes mexicanos tienen un puntaje general m√°s bajo</a> . <br><br>  Las representaciones vectoriales capturan sutiles diferencias sem√°nticas en contexto.  Por lo tanto, reflejan los prejuicios de nuestra sociedad. <br><br>  Aqu√≠ hay otras sugerencias neutrales: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Emily"</span></span>) <span class="hljs-number"><span class="hljs-number">2.2286179364745311</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Heather"</span></span>) <span class="hljs-number"><span class="hljs-number">1.3976291151079159</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Yvette"</span></span>) <span class="hljs-number"><span class="hljs-number">0.98463802132985556</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Shaniqua"</span></span>) <span class="hljs-number"><span class="hljs-number">-0.47048131775890656</span></span></code> </pre> <br>  Pues maldita sea ... <br><br>  El sistema asociado con los nombres de personas completamente diferentes sentimientos.  Puede ver estos y muchos otros ejemplos y ver que la tonalidad generalmente es m√°s alta para los nombres estereot√≠picamente blancos y m√°s baja para los nombres negros estereotipados. <br><br>  Esta prueba fue utilizada por Caliscan, Bryson y Narayanan en su trabajo de investigaci√≥n publicado en la revista <i>Science</i> en abril de 2017.  Demuestra que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sem√°ntica del corpus del lenguaje contiene los prejuicios de la sociedad</a> .  Usaremos este m√©todo. <br><br><h1>  Paso 6. Evaluar el problema </h1><br>  Queremos entender c√≥mo evitar tales errores.  Pasemos m√°s datos a trav√©s del clasificador y midamos estad√≠sticamente su "sesgo". <br><br>  Aqu√≠ tenemos cuatro listas de nombres que reflejan diferentes or√≠genes √©tnicos, principalmente en los Estados Unidos.  Las dos primeras son listas de nombres predominantemente "blancos" y "negros", adaptados en base a un art√≠culo de Kaliskan et al. Tambi√©n agregu√© nombres espa√±oles y musulmanes del √°rabe y el urdu. <br><br>  Estos datos se utilizan para verificar el sesgo del algoritmo durante el proceso de construcci√≥n de ConceptNet: se puede encontrar en el m√≥dulo <code>conceptnet5.vectors.evaluation.bias</code> .  Existe la idea de ampliar el diccionario a otros grupos √©tnicos, teniendo en cuenta no solo los nombres, sino tambi√©n los apellidos. <br><br>  Aqu√≠ est√°n los listados: <br><br><pre> <code class="python hljs">NAMES_BY_ETHNICITY = { <span class="hljs-comment"><span class="hljs-comment">#           . 'White': [ 'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin', 'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed', 'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda', 'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie', 'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie', 'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily', 'Megan', 'Rachel', 'Wendy' ], 'Black': [ 'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome', 'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun', 'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol', 'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle', 'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha', 'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya', 'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn', 'Tawanda', 'Yvette' ], #         . 'Hispanic': [ 'Juan', 'Jos√©', 'Miguel', 'Lu√≠s', 'Jorge', 'Santiago', 'Mat√≠as', 'Sebasti√°n', 'Mateo', 'Nicol√°s', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tom√°s', 'Juana', 'Ana', 'Luisa', 'Mar√≠a', 'Elena', 'Sof√≠a', 'Isabella', 'Valentina', 'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina' ], #       # ,   .     . # #          # -   .    #   ,    . # #       . 'Arab/Muslim': [ 'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza', 'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam', 'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana', 'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin' ] }</span></span></code> </pre> <br>  Usando Pandas, compilaremos una tabla de nombres, su origen √©tnico predominante y las clasificaciones de tonalidad: <br><br><pre> <code class="plaintext hljs">def name_sentiment_table(): frames = [] for group, name_list in sorted(NAMES_BY_ETHNICITY.items()): lower_names = [name.lower() for name in name_list] sentiments = words_to_sentiment(lower_names) sentiments['group'] = group frames.append(sentiments) #           return pd.concat(frames) name_sentiments = name_sentiment_table()</code> </pre> <br>  Datos de muestra: <br><br> <code>name_sentiments.ix[::25]</code> <br> <table border="1" width="350"><thead><tr><th></th><th>  tonalidad </th><th>  el grupo </th></tr></thead><tbody><tr><th>  Mahoma </th><td>  0.834974 </td><td>  √Årabe / musulm√°n </td></tr><tr><th>  alya </th><td>  3.916803 </td><td>  √Årabe / musulm√°n </td></tr><tr><th>  terryl </th><td>  -2.858010 </td><td>  Negro </td></tr><tr><th>  jos√© </th><td>  0.432956 </td><td>  Hispano </td></tr><tr><th>  luciana </th><td>  1.086073 </td><td>  Hispano </td></tr><tr><th>  Hank </th><td>  0.391858 </td><td>  Blanco </td></tr><tr><th>  megan </th><td>  2.158679 </td><td>  Blanco </td></tr></tbody></table><br>  Haremos un gr√°fico de la distribuci√≥n de tonalidad para cada nombre. <br><br><pre> <code class="python hljs">plot = seaborn.swarmplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments) plot.set_ylim([<span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> <br> <code>(-10, 10)</code> <br> <br><img src="https://habrastorage.org/webt/qv/y7/ge/qvy7gel8rrvm5txo-nou6g0i0re.png"><br><br>  O como un histograma con intervalos de confianza para el promedio del 95%. <br><br><pre> <code class="python hljs">plot = seaborn.barplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments, capsize=<span class="hljs-number"><span class="hljs-number">.1</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/uv/ib/n6/uvibn6olthaxt6cxbd96szehq94.png"><br><br>  Finalmente, ejecute el paquete de estad√≠sticas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">statsmodels</a> serias.  Mostrar√° cu√°n grande es el sesgo del algoritmo (junto con muchas otras estad√≠sticas). <br><br><br>  <font color="gray">Resultados de regresi√≥n de OLS</font> <br><table><tbody><tr><th>  Dep.  Variable: </th><td>  sentimiento </td><th>  R cuadrado: </th><td>  0,208 </td></tr><tr><th>  Modelo: </th><td>  OLS </td><th>  Adj.  R cuadrado: </th><td>  0,192 </td></tr><tr><th>  M√©todo: </th><td>  M√≠nimos cuadrados </td><th>  Estad√≠stica F: </th><td>  13/04 </td></tr><tr><th>  Fecha: </th><td>  Jue, 13 jul 2017 </td><th>  Prob (estad√≠stica F): </th><td>  1.31e-07 </td></tr><tr><th>  Tiempo: </th><td>  11:31:17 </td><th>  Probabilidad de registro: </th><td>  -356,78 </td></tr><tr><th>  No  Observaciones: </th><td>  153 </td><th>  AIC: </th><td>  721,6 </td></tr><tr><th>  Df Residuos: </th><td>  149 </td><th>  BIC: </th><td>  733,7 </td></tr><tr><th>  Modelo Df: </th><td>  3 </td><th></th><td></td></tr><tr><th>  Tipo de covarianza: </th><td>  no robusto </td><th></th><td></td></tr></tbody></table><br>  El estad√≠stico F es la relaci√≥n entre la variaci√≥n entre los grupos y la variaci√≥n dentro de los grupos, que se puede tomar como una evaluaci√≥n general del sesgo. <br><br>  Inmediatamente debajo se indica la probabilidad de que veamos el estad√≠stico F m√°ximo con la hip√≥tesis nula: es decir, en ausencia de una diferencia entre las opciones comparadas.  La probabilidad es muy, muy baja.  En un art√≠culo cient√≠fico, llamar√≠amos al resultado "muy estad√≠sticamente significativo". <br><br>  Necesitamos mejorar el valor F.  Cuanto m√°s bajo, mejor. <br><br> <code>ols_model.fvalue <br> 13.041597745167659</code> <br> <br><h1>  Paso 7. Probar otros datos. </h1><br>  Ahora tenemos la oportunidad de medir num√©ricamente el sesgo perjudicial del modelo.  Intentemos ajustarlo.  Para hacer esto, debe repetir un mont√≥n de cosas que sol√≠an ser solo pasos separados en un bloc de notas de Python. <br><br>  Si escribiera un buen c√≥digo compatible, no usar√≠a variables globales como <code>model</code> e <code>embeddings</code> .  Pero el c√≥digo actual de espagueti le permite examinar mejor cada paso y comprender lo que est√° sucediendo.  Reutilizamos parte del c√≥digo y al menos definimos una funci√≥n para repetir algunos pasos: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">retrain_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(new_embs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""      . """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model, embeddings, name_sentiments embeddings = new_embs pos_vectors = embeddings.loc[pos_words].dropna() neg_vectors = embeddings.loc[neg_words].dropna() vectors = pd.concat([pos_vectors, neg_vectors]) targets = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> pos_vectors.index] + [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> neg_vectors.index]) labels = list(pos_vectors.index) + list(neg_vectors.index) train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>) model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) accuracy = accuracy_score(model.predict(test_vectors), test_targets) print(<span class="hljs-string"><span class="hljs-string">"Accuracy of sentiment: {:.2%}"</span></span>.format(accuracy)) name_sentiments = name_sentiment_table() ols_model = statsmodels.formula.api.ols(<span class="hljs-string"><span class="hljs-string">'sentiment ~ group'</span></span>, data=name_sentiments).fit() print(<span class="hljs-string"><span class="hljs-string">"F-value of bias: {:.3f}"</span></span>.format(ols_model.fvalue)) print(<span class="hljs-string"><span class="hljs-string">"Probability given null hypothesis: {:.3}"</span></span>.format(ols_model.f_pvalue)) <span class="hljs-comment"><span class="hljs-comment">#        Y plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments) plot.set_ylim([-10, 10])</span></span></code> </pre> <br><h3>  Intentamos word2vec </h3><br>  Se puede suponer que solo GloVe tiene el problema.  Probablemente hay muchos sitios dudosos en la base de datos Common Crawl y al menos 20 copias del Urban Dictionary de street slang.  Quiz√°s en una base diferente ser√≠a mejor: ¬øqu√© pasa con el viejo y bueno word2vec capacitado en Google News? <br><br>  Parece que la fuente m√°s autorizada para los datos de word2vec es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este archivo en Google Drive</a> .  Desc√°rguelo y gu√°rdelo como <code>data/word2vec-googlenews-300.bin.gz</code> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   ConceptNet   word2vec   Pandas     from conceptnet5.vectors.formats import load_word2vec_bin w2v = load_word2vec_bin('data/word2vec-googlenews-300.bin.gz', nrows=2000000) #  word2vec    w2v.index = [label.casefold() for label in w2v.index] #  ,    w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') retrain_model(w2v)</span></span></code> </pre> <br> <code>Accuracy of sentiment: 94.30% <br> F-value of bias: 15.573 <br> Probability given null hypothesis: 7.43e-09</code> <br> <br>  Entonces word2vec result√≥ ser a√∫n peor con un valor F de m√°s de 15. <br><br>  En principio, era una tonter√≠a esperar que las <i>noticias</i> estuvieran mejor protegidas de los prejuicios. <br><br><h3>  Intentando ConceptNet Numberbatch </h3><br>  Finalmente, puedo hablar sobre mi propio proyecto sobre la representaci√≥n vectorial de palabras. <br><br>  ConceptNet con la funci√≥n de presentaci√≥n vectorial es el gr√°fico de conocimiento en el que estoy trabajando.  Normaliza las representaciones vectoriales en la etapa de entrenamiento, identificando y eliminando algunas fuentes de racismo y sexismo algor√≠tmico.  Este m√©todo de correcci√≥n de sesgos se basa en un art√≠culo cient√≠fico de Bulukbashi et al. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Debiasing Word Embeddings"</a> y se generaliza para eliminar varios tipos de sesgos al mismo tiempo.  Que yo sepa, este es el √∫nico sistema sem√°ntico en el que hay algo as√≠. <br><br>  De vez en cuando, exportamos vectores precalculados desde ConceptNet; estas versiones se denominan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ConceptNet Numberbatch</a> .  En abril de 2017, se lanz√≥ la primera versi√≥n con correcci√≥n de sesgo, por lo que cargaremos los vectores en ingl√©s y reentrenaremos nuestro modelo. <br><br>  <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> , lo <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> en el directorio <code>data/</code> y reciclamos el modelo: <br><br><pre> <code class="python hljs">retrain_model(load_embeddings(<span class="hljs-string"><span class="hljs-string">'data/numberbatch-en-17.04b.txt'</span></span>))</code> </pre> <br> <code>Accuracy of sentiment: 97.46% <br> F-value of bias: 3.805 <br> Probability given null hypothesis: 0.0118</code> <br> <br><img src="https://habrastorage.org/webt/5d/iu/uq/5diuuqrst8bca5-m7fljox--pro.png"><br><br>  Entonces, ¬øConceptNet Numberbatch ha solucionado completamente el problema?  ¬øNo m√°s racismo algor√≠tmico?  <b>No</b> <br><br>  ¬øSe ha vuelto mucho menos racista?  <b>Definitivamente</b> <br><br>  Los rangos clave para los grupos √©tnicos se superponen mucho m√°s que en los vectores GloVe o word2vec.  En comparaci√≥n con GloVe, el valor de F disminuy√≥ en m√°s de tres veces, y en comparaci√≥n con word2vec, m√°s de cuatro veces.  Y, en general, vemos diferencias mucho menores en la tonalidad al comparar nombres diferentes: esto deber√≠a ser as√≠, porque los nombres realmente no deber√≠an afectar el resultado del an√°lisis. <br><br>  Pero se mantuvo una ligera correlaci√≥n.  Quiz√°s pueda recoger tales datos y par√°metros de entrenamiento que el problema parece estar resuelto.  Pero esta ser√° una mala opci√≥n, porque <i>de hecho el</i> problema persiste, porque en ConceptNet no identificamos ni compensamos todas las causas del racismo algor√≠tmico.  Pero este es un buen comienzo. <br><br><h3>  Sin trampas </h3><br>  Tenga en cuenta que con el cambio a ConceptNet Numberbatch, la precisi√≥n de la predicci√≥n de la tonalidad ha mejorado. <br><br>  Alguien podr√≠a haber sugerido que corregir el racismo algor√≠tmico empeorar√≠a los resultados de alguna otra manera.  Pero no  Es posible que tenga datos mejores y menos racistas.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los datos realmente est√°n mejorando con esta correcci√≥n. </font><font style="vertical-align: inherit;">El racismo word2vec y GloVe adquirido de las personas no tiene nada que ver con la precisi√≥n del algoritmo.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Otros enfoques </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por supuesto, esta es solo una forma de analizar la tonalidad. Algunos detalles se pueden implementar de manera diferente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En cambio, o adem√°s de cambiar la base de vectores, puede intentar solucionar este problema directamente en la salida. Por ejemplo, generalmente elimine la evaluaci√≥n de la tonalidad para nombres y grupos de personas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En general, existe una opci√≥n para negarse a calcular la tonalidad de todas las palabras y calcularla solo para las palabras de la lista. Esta es quiz√°s la forma m√°s com√∫n de an√°lisis de sentimientos, sin el aprendizaje autom√°tico en absoluto. Los resultados no tendr√°n m√°s sesgos que el autor de la lista. Pero abandonar el aprendizaje autom√°tico significa reducir el recuerdo, y la √∫nica forma de adaptar el modelo a un conjunto de datos es editar manualmente la lista.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como enfoque h√≠brido, puede crear una gran cantidad de estimados estimados de tonalidad para las palabras e instruir a una persona para que las edite pacientemente, haga una lista de palabras de excepci√≥n con tonalidad cero. </font><font style="vertical-align: inherit;">Pero este es un trabajo extra. </font><font style="vertical-align: inherit;">Por otro lado, realmente ver√°s c√≥mo funciona el modelo. </font><font style="vertical-align: inherit;">Creo que, en cualquier caso, esto deber√≠a buscarse.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436506/">https://habr.com/ru/post/es436506/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436496/index.html">PVS-Studio para Java</a></li>
<li><a href="../es436498/index.html">Software AG: no solo ARIS</a></li>
<li><a href="../es436500/index.html">C√≥mo se representa el marco de Rise of the Tomb Raider</a></li>
<li><a href="../es436502/index.html">Pampers de suscripci√≥n o c√≥mo vender m√°s a los mismos clientes</a></li>
<li><a href="../es436504/index.html">Sistema en paquete, o ¬øQu√© hay debajo de la cubierta del paquete de chips?</a></li>
<li><a href="../es436508/index.html">$ 10 millones en inversiones y elogios de Wozniak: crear una computadora educativa para ni√±os</a></li>
<li><a href="../es436510/index.html">Datos centrales en detalle</a></li>
<li><a href="../es436512/index.html">C√≥mo encontramos versiones problem√°ticas con Graphite y Moira. Vive Yandex.Money</a></li>
<li><a href="../es436514/index.html">Creando historias para Instagram desde PHP</a></li>
<li><a href="../es436518/index.html">Haiku Œ≤1 - make / b / OS great again</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
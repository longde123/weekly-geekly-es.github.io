<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äçüíª üåÉ ‚úíÔ∏è Einfaches Zero-Copy-Rendering hardwarebeschleunigter Videos in QML üè™ üíÖ üëáüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einleitung 


 In diesem Artikel wird veranschaulicht, wie Sie sich mit Videopuffern und QML von Drittanbietern anfreunden k√∂nnen. Die Hauptidee ist, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Einfaches Zero-Copy-Rendering hardwarebeschleunigter Videos in QML</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/486062/"><h2 id="vvedenie">  Einleitung </h2><br><p> In diesem Artikel wird veranschaulicht, wie Sie sich mit Videopuffern und QML von Drittanbietern anfreunden k√∂nnen.  Die Hauptidee ist, die Standard-QML-Komponente von VideoOutput zu verwenden.  Sie k√∂nnen damit Quellen von Drittanbietern abrufen, sind gut dokumentiert und verf√ºgen √ºber ein Backend, das GL_OES_EGL_image_external unterst√ºtzt. </p><br><p>  Die Idee, dass dies pl√∂tzlich n√ºtzlich sein k√∂nnte, entstand, nachdem ich versuchte, Beispiele f√ºr die Arbeit mit der Kamera in Qt auszuf√ºhren, und auf der eingebetteten Plattform arbeiteten sie mit einer Geschwindigkeit von 3-5 Bildern pro Sekunde.  Es stellte sich heraus, dass von einer Nullkopie keine Rede war, obwohl die Plattform dies alles sehr gut unterst√ºtzt.  Fairerweise funktionieren VideoOutput und Camera auf dem Desktop wie erwartet schnell und ohne unn√∂tiges Kopieren.  Bei meiner Aufgabe war es leider unm√∂glich, mit den vorhandenen Klassen f√ºr die Videoerfassung fertig zu werden, und ich wollte ein Video von einer Quelle eines Drittanbieters erhalten, bei der es sich um eine beliebige GStreamer-Pipeline zum Decodieren von Videos handeln k√∂nnte, beispielsweise um eine Datei oder einen RTSP-Stream oder eine Drittanbieter-API, die in die Basis integriert werden kann Qts Klassen sind etwas zweifelhaft.  Nat√ºrlich k√∂nnen Sie das Rad noch einmal neu erfinden und Ihre Komponente mit OpenGL zeichnen. Dies schien jedoch sofort eine bewusste Sackgasse und ein schwieriger Weg zu sein. </p><br><p>  Alles hat dazu gef√ºhrt, dass Sie herausfinden m√ºssen, wie es wirklich funktioniert, und eine kleine Anwendung schreiben m√ºssen, die die Theorie best√§tigt. </p><a name="habracut"></a><br><h2 id="teoriya">  Theorie </h2><br><p>  VideoOutput unterst√ºtzt benutzerdefinierte Quellen, sofern diese vorhanden sind </p><br><ol><li>  Das √ºbergebene Objekt kann QAbstractVideoSurface direkt √ºber die videoSurface-Eigenschaft akzeptieren </li><li>  oder √ºber mediaObject mit QVideoRendererControl <a href="https://doc.qt.io/qt-5/qml-qtmultimedia-videooutput.html">[link]</a> . </li></ol><br><p>  Eine Suche in den Quellen und in der Dokumentation ergab, dass QtMultimedia √ºber eine QAbstractVideoBuffer-Klasse verf√ºgt, die verschiedene Arten von Handles unterst√ºtzt, von QPixmap bis GLTexture und EGLImage.  Weitere Suchanfragen f√ºhrten zum videonode_egl-Plugin, das den Frame, der zu ihm kam, mithilfe des Shaders mit samplerExternalOES wiedergibt.  Dies bedeutet, dass ich nach dem Erstellen eines QAbstractVideoBuffers mit EGLImage einen Weg finden muss, diesen Puffer an videnode_egl zu √ºbergeben. <br>  Wenn die EGLImage-Plattform nicht unterst√ºtzt wird, k√∂nnen Sie den Speicher umbrechen und zum Rendern senden, da die Shader f√ºr die meisten Pixelformate bereits implementiert sind. </p><br><h2 id="realizaciya">  Implementierung </h2><br><p>  Das Beispiel basiert fast ausschlie√ülich auf dem Tutorial <a href="https://doc.qt.io/qt-5/videooverview.html">Video√ºbersicht</a> . </p><br><p>  Damit Qt mit OpenGL ES auf dem Desktop funktioniert, m√ºssen Sie Qt mit dem entsprechenden Flag neu erstellen.  Standardm√§√üig ist es nicht f√ºr den Desktop aktiviert. </p><br><p>  Der Einfachheit halber verwenden wir die erste Methode und verwenden die einfache GStreamer-Pipeline als Videoquelle: </p><br><pre><code class="bash hljs">v4l2src ! appsink</code> </pre> <br><p>  Erstellen Sie eine V4L2Source-Klasse, die Frames an das von ihr angegebene QAbstractVideoSurface liefert. </p><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">V4L2Source</span></span></span><span class="hljs-class"> :</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> QQuickItem { <span class="hljs-function"><span class="hljs-function">Q_OBJECT </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Q_PROPERTY</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(QAbstractVideoSurface* videoSurface READ videoSurface WRITE setVideoSurface)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Q_PROPERTY</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(QString device MEMBER m_device READ device WRITE setDevice)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Q_PROPERTY</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(QString caps MEMBER m_caps)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">V4L2Source</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(QQuickItem* parent = </span></span><span class="hljs-literal"><span class="hljs-function"><span class="hljs-params"><span class="hljs-literal">nullptr</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>; <span class="hljs-keyword"><span class="hljs-keyword">virtual</span></span> ~V4L2Source(); <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setVideoSurface</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(QAbstractVideoSurface* surface)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setDevice</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(QString device)</span></span></span></span>; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> slots: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">start</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">stop</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> slots: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setWindow</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(QQuickWindow* win)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sync</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; signals: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">frameReady</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; ... }</code> </pre> <br><p>  Bis auf den Slot setWinow () ist alles trivial genug - er wird ben√∂tigt, um das Signal QQuickItem :: windowChanged () abzufangen und den R√ºckruf auf QQuickWindow :: beforeSynchronizing () zu setzen. </p><br><p>  Da das VideoOutput-Backend nicht immer wei√ü, wie mit EGLImage gearbeitet wird, m√ºssen Sie QAbstractVideoSurface fragen, welche Formate f√ºr den angegebenen QAbstractVideoBuffer :: HandleType unterst√ºtzt werden: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> V4L2Source::setVideoSurface(QAbstractVideoSurface* surface) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (m_surface != surface &amp;&amp; m_surface &amp;&amp; m_surface-&gt;isActive()) { m_surface-&gt;stop(); } m_surface = surface; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (surface -&gt;supportedPixelFormats( QAbstractVideoBuffer::HandleType::EGLImageHandle) .size() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { EGLImageSupported = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { EGLImageSupported = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (m_surface &amp;&amp; m_device.length() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { start(); } }</code> </pre> <br><p>  Lassen Sie uns unsere Pipeline erstellen und die erforderlichen R√ºckrufe einrichten: </p><br><pre> <code class="cpp hljs">GstAppSinkCallbacks V4L2Source::callbacks = {.eos = <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>, .new_preroll = <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>, .new_sample = &amp;V4L2Source::on_new_sample}; V4L2Source::V4L2Source(QQuickItem* parent) : QQuickItem(parent) { m_surface = <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>; connect(<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>, &amp;QQuickItem::windowChanged, <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>, &amp;V4L2Source::setWindow); pipeline = gst_pipeline_new(<span class="hljs-string"><span class="hljs-string">"V4L2Source::pipeline"</span></span>); v4l2src = gst_element_factory_make(<span class="hljs-string"><span class="hljs-string">"v4l2src"</span></span>, <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>); appsink = gst_element_factory_make(<span class="hljs-string"><span class="hljs-string">"appsink"</span></span>, <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>); GstPad* pad = gst_element_get_static_pad(appsink, <span class="hljs-string"><span class="hljs-string">"sink"</span></span>); gst_pad_add_probe(pad, GST_PAD_PROBE_TYPE_QUERY_BOTH, appsink_pad_probe, <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>, <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>); gst_object_unref(pad); gst_app_sink_set_callbacks(GST_APP_SINK(appsink), &amp;callbacks, <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>, <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>); gst_bin_add_many(GST_BIN(pipeline), v4l2src, appsink, <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>); gst_element_link(v4l2src, appsink); context = g_main_context_new(); loop = g_main_loop_new(context, FALSE); } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> V4L2Source::setWindow(QQuickWindow* win) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (win) { connect(win, &amp;QQuickWindow::beforeSynchronizing, <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>, &amp;V4L2Source::sync, Qt::DirectConnection); } } GstFlowReturn V4L2Source::on_new_sample(GstAppSink* sink, gpointer data) { Q_UNUSED(sink) V4L2Source* self = (V4L2Source*)data; <span class="hljs-function"><span class="hljs-function">QMutexLocker </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">locker</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(&amp;self-&gt;mutex)</span></span></span></span>; self-&gt;ready = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; self-&gt;frameReady(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> GST_FLOW_OK; } <span class="hljs-comment"><span class="hljs-comment">// Request v4l2src allocator to add GstVideoMeta to buffers static GstPadProbeReturn appsink_pad_probe(GstPad* pad, GstPadProbeInfo* info, gpointer user_data) { if (info-&gt;type &amp; GST_PAD_PROBE_TYPE_QUERY_BOTH) { GstQuery* query = gst_pad_probe_info_get_query(info); if (GST_QUERY_TYPE(query) == GST_QUERY_ALLOCATION) { gst_query_add_allocation_meta(query, GST_VIDEO_META_API_TYPE, NULL); } } return GST_PAD_PROBE_OK; }</span></span></code> </pre> <br><p>  Im Konstruktor wird der Standardcode zum Starten Ihrer Pipeline von GMainContext und GMainLoop erstellt, um eine Pipeline in einem separaten Stream zu erstellen. </p><br><p>  Es lohnt sich, auf das Qt :: DirectConnection-Flag in setWindow () zu achten - es garantiert, dass der R√ºckruf im selben Thread wie das Signal aufgerufen wird, wodurch wir auf den aktuellen OpenGL-Kontext zugreifen k√∂nnen. </p><br><p>  V4L2Source :: on_new_sample (), das aufgerufen wird, wenn ein neuer Frame von v4l2src in appsink eintrifft, setzt einfach das Ready-Flag und l√∂st das entsprechende Signal aus, um VideoOutput dar√ºber zu informieren, dass der Inhalt neu gezeichnet werden muss. </p><br><p>  Der appsink-Sink-Test wird ben√∂tigt, um den v4l2src-Allokator aufzufordern, jedem Puffer Metainformationen zum Videoformat hinzuzuf√ºgen.  Dies ist erforderlich, um Situationen zu ber√ºcksichtigen, in denen der Treiber einen Videopuffer mit einem anderen Strike / Offset als dem Standard ausgibt. </p><br><p>  Das Video-Frame-Update f√ºr VideoOutput erfolgt im Slot sync (): </p><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// Make sure this callback is invoked from rendering thread void V4L2Source::sync() { { QMutexLocker locker(&amp;mutex); if (!ready) { return; } // reset ready flag ready = false; } // pull available sample and convert GstBuffer into a QAbstractVideoBuffer GstSample* sample = gst_app_sink_pull_sample(GST_APP_SINK(appsink)); GstBuffer* buffer = gst_sample_get_buffer(sample); GstVideoMeta* videoMeta = gst_buffer_get_video_meta(buffer); // if memory is DMABUF and EGLImage is supported by the backend, // create video buffer with EGLImage handle videoFrame.reset(); if (EGLImageSupported &amp;&amp; buffer_is_dmabuf(buffer)) { videoBuffer.reset(new GstDmaVideoBuffer(buffer, videoMeta)); } else { // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> support other memory types, probably GL textures? // just map memory videoBuffer.reset(new GstVideoBuffer(buffer, videoMeta)); } QSize size = QSize(videoMeta-&gt;width, videoMeta-&gt;height); QVideoFrame::PixelFormat format = gst_video_format_to_qvideoformat(videoMeta-&gt;format); videoFrame.reset(new QVideoFrame( static_cast&lt;QAbstractVideoBuffer*&gt;(videoBuffer.get()), size, format)); if (!m_surface-&gt;isActive()) { m_format = QVideoSurfaceFormat(size, format); Q_ASSERT(m_surface-&gt;start(m_format) == true); } m_surface-&gt;present(*videoFrame); gst_sample_unref(sample); }</span></span></code> </pre> <br><p>  In dieser Funktion nehmen wir den letzten verf√ºgbaren Puffer von appsink, fordern GstVideoMeta auf, Informationen zu Offsets und Schritten f√ºr jede Wiedergabeliste herauszufinden (der Einfachheit halber gibt es keinen Fallback, falls aus irgendeinem Grund kein Meta vorhanden ist) und Erstellen Sie einen QAbstractVideoBuffer mit dem gew√ºnschten Kopftyp: EGLImage (GstDmaVideoBuffer) oder None (GstVideoBuffer).  Wickeln Sie es dann in einen QVideoFrame und stellen Sie es in die Renderwarteschlange. </p><br><p>  Die Implementierung von GstDmaVideoBuffer und GstVideoBuffer selbst ist ziemlich trivial: </p><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> GST_BUFFER_GET_DMAFD(buffer, plane) \ (((plane) </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt; gst_buffer_n_memory((buffer))) ? \ gst_dmabuf_memory_get_fd(gst_buffer_peek_memory((buffer), (plane))) : \ gst_dmabuf_memory_get_fd(gst_buffer_peek_memory((buffer), 0))) class GstDmaVideoBuffer : public QAbstractVideoBuffer { public: // This should be called from renderer thread GstDmaVideoBuffer(GstBuffer* buffer, GstVideoMeta* videoMeta) : QAbstractVideoBuffer(HandleType::EGLImageHandle), buffer(gst_buffer_ref(buffer)), m_videoMeta(videoMeta) { static PFNEGLCREATEIMAGEKHRPROC eglCreateImageKHR = reinterpret_cast&lt;PFNEGLCREATEIMAGEKHRPROC&gt;( eglGetProcAddress("eglCreateImageKHR")); int idx = 0; EGLint attribs[MAX_ATTRIBUTES_COUNT]; attribs[idx++] = EGL_WIDTH; attribs[idx++] = m_videoMeta-&gt;width; attribs[idx++] = EGL_HEIGHT; attribs[idx++] = m_videoMeta-&gt;height; attribs[idx++] = EGL_LINUX_DRM_FOURCC_EXT; attribs[idx++] = gst_video_format_to_drm_code(m_videoMeta-&gt;format); attribs[idx++] = EGL_DMA_BUF_PLANE0_FD_EXT; attribs[idx++] = GST_BUFFER_GET_DMAFD(buffer, 0); attribs[idx++] = EGL_DMA_BUF_PLANE0_OFFSET_EXT; attribs[idx++] = m_videoMeta-&gt;offset[0]; attribs[idx++] = EGL_DMA_BUF_PLANE0_PITCH_EXT; attribs[idx++] = m_videoMeta-&gt;stride[0]; if (m_videoMeta-&gt;n_planes &gt; 1) { attribs[idx++] = EGL_DMA_BUF_PLANE1_FD_EXT; attribs[idx++] = GST_BUFFER_GET_DMAFD(buffer, 1); attribs[idx++] = EGL_DMA_BUF_PLANE1_OFFSET_EXT; attribs[idx++] = m_videoMeta-&gt;offset[1]; attribs[idx++] = EGL_DMA_BUF_PLANE1_PITCH_EXT; attribs[idx++] = m_videoMeta-&gt;stride[1]; } if (m_videoMeta-&gt;n_planes &gt; 2) { attribs[idx++] = EGL_DMA_BUF_PLANE2_FD_EXT; attribs[idx++] = GST_BUFFER_GET_DMAFD(buffer, 2); attribs[idx++] = EGL_DMA_BUF_PLANE2_OFFSET_EXT; attribs[idx++] = m_videoMeta-&gt;offset[2]; attribs[idx++] = EGL_DMA_BUF_PLANE2_PITCH_EXT; attribs[idx++] = m_videoMeta-&gt;stride[2]; } attribs[idx++] = EGL_NONE; auto m_qOpenGLContext = QOpenGLContext::currentContext(); QEGLNativeContext qEglContext = qvariant_cast&lt;QEGLNativeContext&gt;(m_qOpenGLContext-&gt;nativeHandle()); EGLDisplay dpy = qEglContext.display(); Q_ASSERT(dpy != EGL_NO_DISPLAY); image = eglCreateImageKHR(dpy, EGL_NO_CONTEXT, EGL_LINUX_DMA_BUF_EXT, (EGLClientBuffer) nullptr, attribs); Q_ASSERT(image != EGL_NO_IMAGE_KHR); } ... // This should be called from renderer thread ~GstDmaVideoBuffer() override { static PFNEGLDESTROYIMAGEKHRPROC eglDestroyImageKHR = reinterpret_cast&lt;PFNEGLDESTROYIMAGEKHRPROC&gt;( eglGetProcAddress("eglDestroyImageKHR")); auto m_qOpenGLContext = QOpenGLContext::currentContext(); QEGLNativeContext qEglContext = qvariant_cast&lt;QEGLNativeContext&gt;(m_qOpenGLContext-&gt;nativeHandle()); EGLDisplay dpy = qEglContext.display(); Q_ASSERT(dpy != EGL_NO_DISPLAY); eglDestroyImageKHR(dpy, image); gst_buffer_unref(buffer); } private: EGLImage image; GstBuffer* buffer; GstVideoMeta* m_videoMeta; }; class GstVideoBuffer : public QAbstractPlanarVideoBuffer { public: GstVideoBuffer(GstBuffer* buffer, GstVideoMeta* videoMeta) : QAbstractPlanarVideoBuffer(HandleType::NoHandle), m_buffer(gst_buffer_ref(buffer)), m_videoMeta(videoMeta), m_mode(QAbstractVideoBuffer::MapMode::NotMapped) { } QVariant handle() const override { return QVariant(); } void release() override { } int map(MapMode mode, int* numBytes, int bytesPerLine[4], uchar* data[4]) override { int size = 0; const GstMapFlags flags = GstMapFlags(((mode &amp; ReadOnly) ? GST_MAP_READ : 0) | ((mode &amp; WriteOnly) ? GST_MAP_WRITE : 0)); if (mode == NotMapped || m_mode != NotMapped) { return 0; } else { for (int i = 0; i &lt; m_videoMeta-&gt;n_planes; i++) { gst_video_meta_map(m_videoMeta, i, &amp;m_mapInfo[i], (gpointer*)&amp;data[i], &amp;bytesPerLine[i], flags); size += m_mapInfo[i].size; } } m_mode = mode; *numBytes = size; return m_videoMeta-&gt;n_planes; } MapMode mapMode() const override { return m_mode; } void unmap() override { if (m_mode != NotMapped) { for (int i = 0; i &lt; m_videoMeta-&gt;n_planes; i++) { gst_video_meta_unmap(m_videoMeta, i, &amp;m_mapInfo[i]); } } m_mode = NotMapped; } ~GstVideoBuffer() override { unmap(); gst_buffer_unref(m_buffer); } private: GstBuffer* m_buffer; MapMode m_mode; GstVideoMeta* m_videoMeta; GstMapInfo m_mapInfo[4]; };</span></span></span></span></code> </pre> <br><p>  Nach alledem k√∂nnen wir eine QML-Seite der folgenden Form erstellen: </p><br><pre> <code class="json hljs">import QtQuick <span class="hljs-number"><span class="hljs-number">2.10</span></span> import QtQuick.Window <span class="hljs-number"><span class="hljs-number">2.10</span></span> import QtQuick.Layouts <span class="hljs-number"><span class="hljs-number">1.10</span></span> import QtQuick.Controls <span class="hljs-number"><span class="hljs-number">2.0</span></span> import QtMultimedia <span class="hljs-number"><span class="hljs-number">5.10</span></span> import v<span class="hljs-number"><span class="hljs-number">4</span></span>l<span class="hljs-number"><span class="hljs-number">2</span></span>source <span class="hljs-number"><span class="hljs-number">1.0</span></span> Window { visible: <span class="hljs-literal"><span class="hljs-literal">true</span></span> width: <span class="hljs-number"><span class="hljs-number">640</span></span> height: <span class="hljs-number"><span class="hljs-number">480</span></span> title: qsTr(<span class="hljs-string"><span class="hljs-string">"qml zero copy rendering"</span></span>) color: <span class="hljs-string"><span class="hljs-string">"black"</span></span> CameraSource { id: camera device: <span class="hljs-string"><span class="hljs-string">"/dev/video0"</span></span> onFrameReady: videoOutput.update() } VideoOutput { id: videoOutput source: camera anchors.fill: parent } onClosing: camera.stop() }</code> </pre> <br><h2 id="vyvody">  Schlussfolgerungen </h2><br><p>  In diesem Artikel wurde gezeigt, wie eine vorhandene API integriert wird, die hardwarebeschleunigtes Video mit QML liefert, und vorhandene Komponenten zum Rendern ohne Kopieren verwendet werden k√∂nnen (oder im schlimmsten Fall mit einer, aber ohne teure Software-Konvertierung in RGB). </p><br><p>  <a href="https://github.com/Rambden/qml-zero-copy-example/tree/master">Code Link</a> </p><br><h2 id="ssylki">  Referenzen </h2><br><ul><li>  <a href="https://habr.com/ru/post/481540/">https://habr.com/de/post/481540/</a> </li><li>  <a href="https://habr.com/ru/post/254625/">https://habr.com/de/post/254625/</a> </li><li>  <a href="https://doc.qt.io/qt-5/videooverview.html">https://doc.qt.io/qt-5/videooverview.html</a> </li><li>  <a href="https://doc.qt.io/qt-5/qml-qtmultimedia-videooutput.html">https://doc.qt.io/qt-5/qml-qtmultimedia-videooutput.html</a> </li><li>  <a href="https://doc.qt.io/qt-5/qtquick-visualcanvas-scenegraph.html">https://doc.qt.io/qt-5/qtquick-visualcanvas-scenegraph.html</a> </li><li>  <a href="https://doc.qt.io/qt-5.12/qtquick-scenegraph-openglunderqml-example.html">https://doc.qt.io/qt-5.12/qtquick-scenegraph-openglunderqml-example.html</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de486062/">https://habr.com/ru/post/de486062/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de486048/index.html">Was ist das und was frisst es?</a></li>
<li><a href="../de486050/index.html">Webix JavaScript-Bibliothek mit den Augen eines Anf√§ngers. Teil 3. Module, Diagramme, Baumtabellen</a></li>
<li><a href="../de486052/index.html">Verbrannte Erde ist die Mutter aller Spiele. Interview mit dem Sch√∂pfer</a></li>
<li><a href="../de486056/index.html">Vom Skript zur eigenen Plattform: Wie wir die Entwicklung am Cyan Institute automatisierten</a></li>
<li><a href="../de486060/index.html">Finden Sie Ordnung im Chaos der IT: Organisieren Sie Ihre eigene Entwicklung</a></li>
<li><a href="../de486064/index.html">Erstellen Sie eine animierte Diashow in reinem CSS.</a></li>
<li><a href="../de486066/index.html">Im Zugangsbereich. Finden Sie die Entfernung von einem Punkt zu einem Gebiet und reduzieren Sie Reverse Geocoding-Anforderungen</a></li>
<li><a href="../de486070/index.html">ACL-Schalter im Detail</a></li>
<li><a href="../de486080/index.html">Lassen Sie mich vorstellen: Veeam Availability Suite v10</a></li>
<li><a href="../de486084/index.html">Ersetzen kleinerer Festplatten durch gr√∂√üere Festplatten unter Linux</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
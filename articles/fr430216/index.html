<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤹🏼 🚃 🙃 Si je comprends bien, je mange beaucoup de bonbons, ou le classement des marchandises par chèque dans l'application 👩🏼‍🤝‍👩🏻 👨🏽‍🏫 ✍🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Défi 
 Dans cet article, nous voulons parler de la façon dont nous avons créé une solution pour classer les noms de produits à partir des reçus dans l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Si je comprends bien, je mange beaucoup de bonbons, ou le classement des marchandises par chèque dans l'application</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/430216/"><h2>  Défi </h2><br>  Dans cet article, nous voulons parler de la façon dont nous avons créé une solution pour classer les noms de produits à partir des reçus dans l'application d'enregistrement des dépenses pour les chèques et l'assistant d'achat.  Nous voulions donner aux utilisateurs la possibilité de consulter des statistiques sur les achats, collectées automatiquement sur la base de reçus scannés, à savoir, répartir tous les biens achetés par l'utilisateur par catégorie.  Parce que forcer l'utilisateur à regrouper ses produits de façon indépendante est déjà le siècle dernier.  Il existe plusieurs approches pour résoudre ce problème: vous pouvez essayer d'appliquer des algorithmes de clustering avec différentes façons de représentation vectorielle des mots ou des algorithmes de classification classiques.  Nous n'avons rien inventé de nouveau, et dans cet article, nous voulons seulement partager un petit guide sur une solution possible au problème, des exemples de la façon de ne pas le faire, une analyse des raisons pour lesquelles d'autres méthodes n'ont pas fonctionné et des problèmes que vous pourriez rencontrer dans le processus. <br><a name="habracut"></a><br><h2>  Regroupement </h2><br>  L'un des problèmes était que les noms des marchandises que nous obtenons des chèques ne sont pas toujours faciles à déchiffrer, même pour une personne.  Il est peu probable que vous sachiez quel type de produit portant le nom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">«UTRUSTA krnsht» a</a> été acheté dans l'un des magasins russes?  Les vrais connaisseurs du design suédois nous répondront certainement tout de suite: support pour le four d'Utrust, mais garder de tels spécialistes au siège coûte assez cher.  De plus, nous n'avions pas d'échantillon prêt à l'emploi, étiqueté et adapté à nos données, sur lequel nous pouvions former le modèle.  Par conséquent, nous allons d'abord parler de la façon dont, en l'absence de données pour la formation, nous avons appliqué des algorithmes de clustering et pourquoi nous ne l'avons pas aimé. <br><br>  Ces algorithmes sont basés sur la mesure des distances entre les objets, ce qui nécessite leur représentation vectorielle ou l'utilisation d'une métrique pour mesurer la similitude des mots (par exemple, la distance de Levenshtein).  À ce stade, la difficulté réside dans la représentation vectorielle significative des noms.  Il est problématique d'extraire des propriétés des noms qui décriront de manière complète et complète le produit et sa relation avec d'autres produits. <br><br>  L'option la plus simple consiste à utiliser Tf-Idf, mais dans ce cas, la dimension de l'espace vectoriel est assez grande et l'espace lui-même est rare.  De plus, cette approche n'extrait aucune information supplémentaire des noms.  Ainsi, dans un cluster, il peut y avoir de nombreux produits de différentes catégories, unis par un mot commun, comme par exemple «pomme de terre» ou «salade»: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pb/uh/bd/pbuhbdnf0bwmwvy0ywqwapil018.png"></div><br>  Nous ne pouvons pas non plus contrôler quels clusters seront assemblés.  La seule chose qui peut être indiquée est le nombre de clusters (si des algorithmes basés sur des pics de non-densité dans l'espace sont utilisés).  Mais si vous spécifiez une quantité trop petite, alors un énorme cluster est formé, qui contiendra tous les noms qui ne pourraient pas entrer dans d'autres clusters.  Si vous en spécifiez un suffisamment grand, après le fonctionnement de l'algorithme, nous devrons parcourir des centaines de clusters et les combiner manuellement en catégories sémantiques. <br><br>  Les tableaux ci-dessous fournissent des informations sur les clusters utilisant les algorithmes KMeans et Tf-Idf pour la représentation vectorielle.  De ces tableaux, nous voyons que les distances entre les centres des grappes sont inférieures à la distance moyenne entre les objets et les centres des grappes auxquels ils appartiennent.  Ces données peuvent s'expliquer par le fait que dans l'espace des vecteurs, il n'y a pas de pics de densité évidents et que les centres des grappes sont situés autour du cercle, où la plupart des objets sont situés à l'extérieur de ce cercle.  De plus, un cluster est formé, qui contient la plupart des vecteurs.  Dans ce groupe, il est fort probable que les noms contiennent des mots que l'on trouve plus souvent que d'autres parmi tous les produits de différentes catégories. <br><br><table><caption>  Tableau 1. Distances entre les clusters. </caption><tbody><tr><th>  Cluster </th><th>  C1 </th><th>  C2 </th><th>  C3 </th><th>  C4 </th><th>  C5 </th><th>  C6 </th><th>  C7 </th><th>  C8 </th><th>  C9 </th></tr><tr><th>  C1 </th><td>  0,0 </td><td>  0,502 </td><td>  0,354 </td><td>  0,475 </td><td>  0,481 </td><td>  0,527 </td><td>  0,498 </td><td>  0,501 </td><td>  0,524 </td></tr><tr><th>  C2 </th><td>  0,502 </td><td>  0,0 </td><td>  0,614 </td><td>  0,685 </td><td>  0,696 </td><td>  0,728 </td><td>  0,706 </td><td>  0,709 </td><td>  0,725 </td></tr><tr><th>  C3 </th><td>  0,354 </td><td>  0,614 </td><td>  0,0 </td><td>  0,590 </td><td>  0,597 </td><td>  0,635 </td><td>  0,610 </td><td>  0,613 </td><td>  0,632 </td></tr><tr><th>  C4 </th><td>  0,475 </td><td>  0,685 </td><td>  0,590 </td><td>  0,0 </td><td>  0,673 </td><td>  0,709 </td><td>  0,683 </td><td>  0,687 </td><td>  0,699 </td></tr><tr><th>  C5 </th><td>  0,481 </td><td>  0,696 </td><td>  0,597 </td><td>  0,673 </td><td>  0,0 </td><td>  0,715 </td><td>  0,692 </td><td>  0,694 </td><td>  0,711 </td></tr><tr><th>  C6 </th><td>  0,527 </td><td>  0,727 </td><td>  0,635 </td><td>  0,709 </td><td>  0,715 </td><td>  0,0 </td><td>  0,726 </td><td>  0,728 </td><td>  0,741 </td></tr><tr><th>  C7 </th><td>  0,498 </td><td>  0,706 </td><td>  0,610 </td><td>  0,683 </td><td>  0,692 </td><td>  0,725 </td><td>  0,0 </td><td>  0,707 </td><td>  0,714 </td></tr><tr><th>  C8 </th><td>  0,501 </td><td>  0,709 </td><td>  0,612 </td><td>  0,687 </td><td>  0,694 </td><td>  0,728 </td><td>  0,707 </td><td>  0,0 </td><td>  0,725 </td></tr><tr><th>  C9 </th><td>  0,524 </td><td>  0,725 </td><td>  0,632 </td><td>  0,699 </td><td>  0,711 </td><td>  0,741 </td><td>  0,714 </td><td>  0,725 </td><td>  0,0 </td></tr></tbody></table><br><table><caption>  Tableau 2. Informations succinctes sur les clusters </caption><tbody><tr><th>  Cluster </th><th>  Nombre d'objets </th><th>  Distance moyenne </th><th>  Distance minimale </th><th>  Distance maximale </th></tr><tr><th>  C1 </th><td>  62530 </td><td>  0,999 </td><td>  0,041 </td><td>  1,001 </td></tr><tr><th>  C2 </th><td>  2159 </td><td>  0,864 </td><td>  0,527 </td><td>  0,964 </td></tr><tr><th>  C3 </th><td>  1099 </td><td>  0,934 </td><td>  0,756 </td><td>  0,993 </td></tr><tr><th>  C4 </th><td>  1292 </td><td>  0,879 </td><td>  0,733 </td><td>  0,980 </td></tr><tr><th>  C5 </th><td>  746 </td><td>  0,875 </td><td>  0,731 </td><td>  0,965 </td></tr><tr><th>  C6 </th><td>  2451 </td><td>  0,847 </td><td>  0,719 </td><td>  0,994 </td></tr><tr><th>  C7 </th><td>  1133 </td><td>  0,866 </td><td>  0,724 </td><td>  0,986 </td></tr><tr><th>  C8 </th><td>  876 </td><td>  0,863 </td><td>  0,704 </td><td>  0,999 </td></tr><tr><th>  C9 </th><td>  1879 </td><td>  0,849 </td><td>  0,526 </td><td>  0,981 </td></tr></tbody></table><br><br>  Mais dans certains endroits, les grappes s'avèrent être assez décentes, comme, par exemple, dans l'image ci-dessous - là, presque tous les produits sont des aliments pour chats. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oh/uy/5p/ohuy5p_bgiignp9ah_gokvvbzs4.png"></div><br><br>  Doc2Vec est un autre des algorithmes qui vous permettent de représenter des textes sous forme vectorielle.  En utilisant cette approche, chaque nom sera décrit par un vecteur de dimension plus petite que l'utilisation de Tf-Idf.  Dans l'espace vectoriel qui en résulte, des textes similaires seront proches les uns des autres et différents loin. <br><br>  Cette approche peut résoudre le problème de la grande dimension et de l'espace déchargé obtenu par la méthode Tf-Idf.  Pour cet algorithme, nous avons utilisé l'option de tokenisation la plus simple: nous avons divisé le nom en mots séparés et pris leurs formes initiales.  Il a été formé aux données de cette manière: <br><br><pre><code class="python hljs">max_epochs = <span class="hljs-number"><span class="hljs-number">100</span></span> vec_size = <span class="hljs-number"><span class="hljs-number">20</span></span> alpha = <span class="hljs-number"><span class="hljs-number">0.025</span></span> model = doc2vec.Doc2Vec(vector_size=vec_size, alpha=alpha, min_alpha=<span class="hljs-number"><span class="hljs-number">0.00025</span></span>, min_count=<span class="hljs-number"><span class="hljs-number">1</span></span>, dm =<span class="hljs-number"><span class="hljs-number">1</span></span>) model.build_vocab(train_corpus) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(max_epochs): print(<span class="hljs-string"><span class="hljs-string">'iteration {0}'</span></span>.format(epoch)) model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter) <span class="hljs-comment"><span class="hljs-comment"># decrease the learning rate model.alpha -= 0.0002 # fix the learning rate, no decay model.min_alpha = model.epochs</span></span></code> </pre> <br>  Mais avec cette approche, nous avons obtenu des vecteurs qui ne portent pas d'informations sur le nom - avec le même succès, vous pouvez utiliser des valeurs aléatoires.  Voici un exemple du fonctionnement de l'algorithme: l'image montre des produits similaires de l'avis de l'algorithme au «pain Borodino de la forme n pn 0.45k». <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qd/m9/lp/qdm9lplwaidbilivtpb3jjskopo.png"></div><br>  Peut-être que le problème est dans la longueur et le contexte des noms: le laissez-passer dans le nom "__ club. Banane 200ml" peut être soit du yaourt, du jus ou une grande boîte de crème.  Vous pouvez obtenir un meilleur résultat en utilisant une approche différente de la tokenisation des noms.  Nous n'avions aucune expérience de l'utilisation de cette méthode, et au moment où les premières tentatives avaient échoué, nous avions déjà trouvé quelques ensembles marqués avec des noms de produits, nous avons donc décidé de laisser cette méthode pendant un certain temps et de passer aux algorithmes de classification. <br><br><h2>  Classification </h2><br><h3>  Prétraitement des données </h3><br>  Les noms des marchandises des chèques nous parviennent de manière pas toujours claire: le latin et le cyrillique sont mélangés dans les mots.  Par exemple, la lettre «a» peut être remplacée par «a» latin, ce qui augmente le nombre de noms uniques - par exemple, les mots «lait» et «lait» seront considérés comme différents.  Les noms contiennent également de nombreuses autres fautes de frappe et abréviations. <br><br>  Nous avons examiné notre base de données et trouvé des erreurs typiques dans les noms.  À ce stade, nous avons supprimé les expressions régulières, à l'aide desquelles nous avons nettoyé les noms et les avons amenés à une certaine vue d'ensemble.  En utilisant cette approche, le résultat est augmenté d'environ 7%.  Avec une simple option SGD Classifier basée sur la fonction de perte Huber avec des paramètres tordus, nous avons obtenu une précision de 81% pour F1 (précision moyenne pour toutes les catégories de produits). <br><br><pre> <code class="python hljs">sgd_model = SGDClassifier() parameters_sgd = { <span class="hljs-string"><span class="hljs-string">'max_iter'</span></span>:[<span class="hljs-number"><span class="hljs-number">100</span></span>], <span class="hljs-string"><span class="hljs-string">'loss'</span></span>:[<span class="hljs-string"><span class="hljs-string">'modified_huber'</span></span>], <span class="hljs-string"><span class="hljs-string">'class_weight'</span></span>:[<span class="hljs-string"><span class="hljs-string">'balanced'</span></span>], <span class="hljs-string"><span class="hljs-string">'penalty'</span></span>:[<span class="hljs-string"><span class="hljs-string">'l2'</span></span>], <span class="hljs-string"><span class="hljs-string">'alpha'</span></span>:[<span class="hljs-number"><span class="hljs-number">0.0001</span></span>] } sgd_cv = GridSearchCV(sgd_model, parameters_sgd,n_jobs=<span class="hljs-number"><span class="hljs-number">-1</span></span>) sgd_cv.fit(tf_idf_data, prod_cat) sgd_cv.best_score_, sgd_cv.best_params_</code> </pre> <br>  N'oubliez pas non plus que certaines catégories de personnes achètent plus souvent que d'autres: par exemple, «Thé et sucreries» et «Légumes et fruits» sont beaucoup plus populaires que «Services» et «Cosmétiques».  Avec une telle distribution de données, il est préférable d'utiliser des algorithmes qui vous permettent de définir des poids (degré d'importance) pour chaque classe.  Le poids de la classe peut être déterminé inversement avec la valeur égale au rapport du nombre de produits de la classe au nombre total de produits.  Mais vous n'avez pas à y penser, car dans la mise en œuvre de ces algorithmes, il est possible de déterminer automatiquement le poids des catégories. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ty/o9/pk/tyo9pkfhw-ibby5jopobc5okotc.png"></div><br><h2>  Obtention de nouvelles données pour la formation </h2><br>  Notre candidature nécessitait des catégories légèrement différentes de celles utilisées lors du concours, et les noms des produits de notre base de données étaient sensiblement différents de ceux présentés lors du concours.  Par conséquent, nous devions marquer les marchandises de nos reçus.  Nous avons essayé de le faire par nous-mêmes, mais nous avons réalisé que même si nous connectons toute notre équipe, cela prendra beaucoup de temps.  Par conséquent, nous avons décidé d'utiliser la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">«Toloka» de Yandex</a> . <br><br>  Là, nous avons utilisé cette forme de mission: <br><br><ul><li>  dans chaque cellule nous avons présenté un produit dont la catégorie doit être définie </li><li>  sa catégorie hypothétique définie par l'un de nos modèles précédents </li><li>  champ de réponse (si la catégorie proposée était incorrecte) </li></ul><br>  Nous avons créé des instructions détaillées avec des exemples qui expliquaient les caractéristiques de chaque catégorie, et avons également utilisé des méthodes de contrôle de la qualité: un ensemble avec des réponses standard qui ont été montrées avec les tâches habituelles (nous avons implémenté les réponses standard nous-mêmes, marquant plusieurs centaines de produits).  Selon les résultats des réponses à ces tâches, les utilisateurs qui ont incorrectement annoté les données ont été éliminés.  Cependant, pour l'ensemble du projet, nous n'avons interdit que trois des 600+ utilisateurs. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fx/ib/xt/fxibxt-v5h7vouodjoffwtl6egy.png"></div><br>  Avec les nouvelles données, nous avons obtenu un modèle qui convenait mieux à nos données, et la précision a augmenté un peu plus (de ~ 11%) et a déjà atteint 92%. <br><br><h2>  Modèle final </h2><br>  Nous avons commencé le processus de classification avec une combinaison de données de plusieurs ensembles de données avec Kaggle - 74%, après quoi nous avons amélioré le prétraitement - 81%, collecté un nouvel ensemble de données - 92% et finalement amélioré le processus de classification: initialement, en utilisant la régression logistique, nous obtenons des probabilités préliminaires d'appartenance des marchandises SGD a donné une plus grande précision aux catégories basées sur les noms de produits, mais avait toujours de grandes valeurs sur les fonctions de perte, ce qui a gravement affecté les résultats du classificateur final.  De plus, nous combinons les données obtenues avec d'autres données sur le produit (prix du produit, le magasin dans lequel il a été acheté, statistiques sur le magasin, chèque et autres méta-informations), et XGBoost est formé sur tout ce volume de données, ce qui a donné une précision de 98% (augmentation 6%).  Il s'est avéré que la plus grande contribution a été apportée par la qualité de l'échantillon de formation. <br><br><h2>  En cours d'exécution sur le serveur </h2><br>  Pour accélérer le déploiement, nous avons monté un serveur simple sur Flask vers Docker.  Il y avait une méthode qui recevait des marchandises du serveur qui devait être catégorisée et retournait déjà des marchandises avec des catégories.  Ainsi, nous nous sommes facilement intégrés au système existant, dont Tomcat était le centre, et nous n'avons pas eu à modifier l'architecture - nous y avons simplement ajouté un bloc de plus. <br><br><h2>  Date de sortie </h2><br>  Il y a quelques semaines, nous avons publié une version de catégorisation sur Google Play (elle apparaîtra sur l'App Store après un certain temps).  Il s'est avéré comme ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/h1/tj/ie/h1tjiekixykrb_liuwftfnd8ufy.png" width="50%"></div><br>  Dans les versions futures, nous prévoyons d'ajouter la possibilité de corriger les catégories, ce qui nous permettra de collecter rapidement les erreurs de catégorisation et de recycler le modèle de catégorisation (pendant que nous le faisons nous-mêmes). <br><br>  Concours mentionnés à Kaggle: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.kaggle.com/c/receipt-categorisation</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.kaggle.com/c/market-basket-analysis</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.kaggle.com/c/prod-price-prediction</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr430216/">https://habr.com/ru/post/fr430216/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr430204/index.html">Cours MIT "Sécurité des systèmes informatiques". Conférence 18: «Navigation Internet privée», partie 1</a></li>
<li><a href="../fr430206/index.html">Cours MIT "Sécurité des systèmes informatiques". Conférence 18: Navigation privée sur Internet, partie 2</a></li>
<li><a href="../fr430208/index.html">Cours MIT "Sécurité des systèmes informatiques". Conférence 18: «Navigation Internet privée», partie 3</a></li>
<li><a href="../fr430210/index.html">Testez ma patience par la Check Point Security Academy</a></li>
<li><a href="../fr430212/index.html">OpenSceneGraph: principes de base de la géométrie de scène</a></li>
<li><a href="../fr430218/index.html">Optimisation énergétique STM32: un guide pratique</a></li>
<li><a href="../fr430220/index.html">Comment transformer un hub USB «centenaire» en un smart managed et économiser 300 $</a></li>
<li><a href="../fr430222/index.html">Ingénieur senior en recherche de travail. Comment j'ai vécu 20 entretiens avec les RH et ce que j'en pense</a></li>
<li><a href="../fr430224/index.html">Trouble schizotypique: un regard intérieur</a></li>
<li><a href="../fr430226/index.html">De la var b à l'interview</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
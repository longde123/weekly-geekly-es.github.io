<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèΩ‚Äçü§ù‚ÄçüßëüèΩ üí¢ üö≥ Detec√ß√£o de emo√ß√£o contextual em conversas textuais usando redes neurais üâê üèáüèª üëêüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Atualmente, conversar com agentes de conversa√ß√£o est√° se tornando uma rotina di√°ria, e √© crucial que os sistemas de di√°logo gerem respostas o mais hum...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Detec√ß√£o de emo√ß√£o contextual em conversas textuais usando redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439850/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Atualmente, conversar com agentes de conversa√ß√£o est√° se tornando uma rotina di√°ria, e √© crucial que os sistemas de di√°logo gerem respostas o mais humanas poss√≠vel.  Como um dos aspectos principais, aten√ß√£o prim√°ria deve ser dada ao fornecimento de respostas emocionalmente conscientes aos usu√°rios.  Neste artigo, descreveremos <b>a arquitetura de rede neural recorrente para detec√ß√£o de emo√ß√µes em conversas textuais</b> , que participaram da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tarefa 3 SemEval-2019 "EmoContext"</a> , ou seja, um workshop anual sobre avalia√ß√£o sem√¢ntica.  O objetivo da tarefa √© classificar a emo√ß√£o (ou seja, feliz, triste, zangada e outras) em um conjunto de dados de conversa√ß√£o em tr√™s turnos. <br><a name="habracut"></a><br>  O restante do artigo est√° organizado da seguinte maneira.  A Se√ß√£o 1 fornece uma breve vis√£o geral da tarefa do EmoContext e dos dados fornecidos.  As se√ß√µes 2 e 3 enfocam o pr√©-processamento de textos e a incorpora√ß√£o de palavras, consequentemente.  Na se√ß√£o 4, descrevemos a arquitetura do modelo LSTM usado em nossa submiss√£o.  Em conclus√£o, s√£o apresentados o desempenho final do nosso sistema e o c√≥digo fonte.  O modelo √© implementado em Python usando a biblioteca Keras. <br><br><h2>  1. Dados de treinamento </h2><br>  A tarefa 3 do SemEval-2019 ‚ÄúEmoContext‚Äù est√° focada na detec√ß√£o de emo√ß√µes contextuais na conversa em texto.  No EmoContext, dada uma declara√ß√£o textual do usu√°rio juntamente com 2 turnos de contexto em uma conversa, devemos classificar se a emo√ß√£o da pr√≥xima frase do usu√°rio √© "feliz", "triste", "zangada" ou "outras" (Tabela 1).  Existem apenas dois participantes da conversa: uma pessoa an√¥nima (Tuen-1 e Turn-3) e o chatbot baseado em IA <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ruuh</a> (Turn-2).  Para uma descri√ß√£o detalhada, consulte ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabela 1. Exemplos mostrando o conjunto de dados EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Usu√°rio (Turn-1) </th><th>  Agente de conversa√ß√£o (Turn-1) </th><th>  Usu√°rio (Turn-2) </th><th>  Classe verdadeira </th></tr><tr><td>  Acabei de me qualificar para o est√°gio Nabard </td><td>  WOOT!  Essa √© uma √≥tima not√≠cia.  Parab√©ns! </td><td>  Comecei a chorar </td><td>  Feliz </td></tr><tr><td>  Como voc√™ ousa dar um tapa no meu filho </td><td>  Se voc√™ estragar o meu carro, eu tamb√©m farei isso </td><td>  Apenas tente fazer isso uma vez </td><td>  Zangado </td></tr><tr><td>  Eu fui machucado por voc√™ mais </td><td>  Voc√™ n√£o quis dizer isso. </td><td>  diga que me ama </td><td>  Triste </td></tr><tr><td>  Eu vou fazer a noite </td><td>  Tudo bem.  Mantenha-me informado. </td><td>  N√£o dando WhatsApp n√£o. </td><td>  Outros </td></tr></tbody></table></div><br>  Durante a competi√ß√£o, tivemos acesso a 30160 textos rotulados como humanos, fornecidos pelos organizadores das tarefas, onde cerca de 5000 amostras cada uma das classes ‚Äúzangado‚Äù, ‚Äútriste‚Äù, ‚Äúfeliz‚Äù e 15000 para a classe ‚Äúoutros‚Äù (Tabela 2).  Os conjuntos de desenvolvimento e teste, que tamb√©m foram fornecidos pelos organizadores, em contraste com o conjunto de trens, t√™m uma distribui√ß√£o na vida real, que √© de cerca de 4% para cada classe emocional e o restante para a classe "outros".  Os dados s√£o da Microsoft e podem ser encontrados no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">grupo oficial do LinkedIn</a> . <br><br>  <i>Tabela 2. Distribui√ß√£o do r√≥tulo da classe Emotion em conjuntos de dados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Conjunto de dados </th><th>  Feliz </th><th>  Triste </th><th>  Zangado </th><th>  Outros </th><th>  Total </th></tr><tr><td>  Trem <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30160 <br></td></tr><tr><td>  Dev <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Teste <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Distante <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900k <br></td></tr></tbody></table></div><br>  Al√©m desses dados, coletamos 900k tweets em ingl√™s para criar um conjunto de dados distante de 300k tweets para cada emo√ß√£o.  Para formar o conjunto de dados distante, baseamos-nos na estrat√©gia de Go et al.  (2009), sob o qual simplesmente associamos tweets √† presen√ßa de palavras relacionadas √† emo√ß√£o, como '#angry', '#annoyed', '#happy', '#sad,' #surprised 'etc.  A lista de termos de consulta foi baseada nos termos de consulta do SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Duppada et al., 2018</a> ). <br><br>  A principal m√©trica de desempenho do EmoContext √© uma pontua√ß√£o micro-m√©dia da F1 para tr√™s classes de emo√ß√µes, ou seja, 'triste', 'feliz' e 'zangada'. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Pr√©-processamento de textos </h2><br>  Antes de qualquer etapa do treinamento, os textos eram pr√©-processados ‚Äã‚Äãpela ferramenta Ekphrasis (Baziotis et al., 2017).  Essa ferramenta ajuda a executar corre√ß√£o ortogr√°fica, normaliza√ß√£o de palavras, segmenta√ß√£o e permite especificar quais tokens devem ser omitidos, normalizados ou anotados com tags especiais.  Usamos as seguintes t√©cnicas para o est√°gio de pr√©-processamento. <br><br><ul><li>  URLs, e-mails, data e hora, nomes de usu√°rios, porcentagem, moedas e n√∫meros foram substitu√≠dos pelas tags correspondentes. </li><li>  Termos repetidos, censurados, alongados e em mai√∫sculas foram anotados com as tags correspondentes. </li><li>  Palavras alongadas foram corrigidas automaticamente com base no corpus estat√≠stico de palavras incorporado. </li><li>  A descompacta√ß√£o de hashtags e contra√ß√µes (ou seja, segmenta√ß√£o de palavras) foi realizada com base no corpus estat√≠stico de palavras incorporado. </li><li>  Um dicion√°rio criado manualmente para substituir termos extra√≠dos do texto foi usado para reduzir uma variedade de emo√ß√µes. </li></ul><br>  Al√©m disso, o Emphasis fornece o tokenizador capaz de identificar a maioria dos emojis, emoticons e express√µes complicadas, como palavras censuradas, enfatizadas e alongadas, al√©m de datas, horas, moedas e acr√¥nimos. <br><br>  <i>Tabela 3. Exemplos de pr√©-processamento de texto.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texto original </th><th>  Texto pr√©-processado </th></tr><tr><td>  Eu sinto voc√™ ... estou quebrando em milh√µes de peda√ßos <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; eu sinto voc√™ &lt;/allcaps&gt;.  &lt;repetido&gt; estou quebrando em milh√µes de peda√ßos <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  cansado e eu tamb√©m senti sua falta :‚Äë( </td><td>  cansado e eu tamb√©m senti sua falta &lt;sad&gt; </td></tr><tr><td>  voc√™ deve ouvir isso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  voc√™ deve ouvir &lt;elongated&gt; o seguinte: &lt;url&gt; </td></tr><tr><td>  Meu apartamento cuida disso.  Meu aluguel √© de cerca de US $ 650. </td><td>  meu apartamento cuida disso.  meu aluguel √© em torno de &lt;dinheiro&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^„Éª^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëc'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‚Äë':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‚Äë["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Incorpora√ß√£o de palavras </h2><br>  A incorpora√ß√£o de palavras se tornou uma parte essencial de qualquer abordagem de aprendizado profundo para sistemas de PNL.  Para determinar os vetores mais adequados para a tarefa de detec√ß√£o de emo√ß√µes, experimentamos os modelos Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pennington et al., 2014</a> ) e FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Joulin et al., 2017</a> ), bem como os DataStories pr√©-treinados vetores de palavras ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Baziotis et al., 2017</a> ).  O conceito principal do Word2Vec √© localizar palavras, que compartilham contextos comuns no corpus de treinamento, nas proximidades do espa√ßo vetorial.  Os modelos Word2Vec e Glove aprendem codifica√ß√µes geom√©tricas de palavras a partir de suas informa√ß√µes de co-ocorr√™ncia, mas essencialmente o primeiro √© um modelo preditivo e o √∫ltimo √© um modelo baseado em contagem.  Em outras palavras, enquanto o Word2Vec tenta prever uma palavra de destino (arquitetura CBOW) ou um contexto (arquitetura de Skip-gram), ou seja, para minimizar a fun√ß√£o de perda, o GloVe calcula vetores de palavras fazendo redu√ß√£o de dimensionalidade na matriz de contagens de co-ocorr√™ncia.  O FastText √© muito semelhante ao Word2Vec, exceto pelo fato de que ele usa caracteres n-gramas para aprender vetores de palavras; portanto, ele √© capaz de resolver o problema de falta de vocabul√°rio. <br><br>  Para todas as t√©cnicas mencionadas acima, usamos os carrinhos de treinamento padr√£o fornecidos pelos autores.  N√≥s treinamos um modelo LSTM simples (dim = 64) com base em cada um desses embeddings e comparamos a efic√°cia usando a valida√ß√£o cruzada.  De acordo com o resultado, os casamentos pr√©-treinados do DataStories demonstraram a melhor pontua√ß√£o m√©dia na F1. <br><br>  Para enriquecer as combina√ß√µes de palavras selecionadas com a polaridade emocional das palavras, consideramos a execu√ß√£o de uma frase de pr√©-treinamento distante, ajustando as combina√ß√µes no conjunto de dados distantes rotulado automaticamente.  A import√¢ncia do uso do pr√©-treinamento foi demonstrada em ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deriu et al., 201</a> 7).  Usamos o conjunto de dados distante para treinar a rede LSTM simples para classificar tweets irritados, tristes e felizes.  A camada de encaixes foi congelada durante a primeira √©poca de treinamento, a fim de evitar altera√ß√µes significativas nos pesos dos encaixes e, em seguida, foi descongelada nas pr√≥ximas cinco √©pocas.  Ap√≥s a fase de treinamento, os ajustes foram salvos para as fases de treinamento adicionais e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">disponibilizados ao p√∫blico</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Arquitetura de Rede Neural </h2><br>  Uma rede neural recorrente (RNN) √© uma fam√≠lia de redes neurais artificiais especializada no processamento de dados seq√ºenciais.  Ao contr√°rio das redes neurais tradicionais, os RRNs s√£o projetados para lidar com dados seq√ºenciais compartilhando seus pesos internos ao processar a sequ√™ncia.  Para esse fim, o gr√°fico computacional de RRNs inclui ciclos, representando a influ√™ncia das informa√ß√µes anteriores sobre a atual.  Como uma extens√£o das RNNs, redes de mem√≥ria de curto prazo (LSTMs) foram introduzidas em 1997 ( <a href="">Hochreiter e Schmidhuber, 1997</a> ).  Nos LSTMs, as c√©lulas recorrentes s√£o conectadas de uma maneira espec√≠fica para evitar problemas de gradiente que desaparecem e explodem.  Os LSTMs tradicionais preservam apenas as informa√ß√µes do passado, pois processam a sequ√™ncia apenas em uma dire√ß√£o.  Os LSTMs bidirecionais combinam a sa√≠da de duas camadas ocultas de LSTM, movendo-se em dire√ß√µes opostas, onde uma avan√ßa no tempo e outra retrocede no tempo, permitindo capturar informa√ß√µes de estados passados ‚Äã‚Äãe futuros simultaneamente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Schuster e Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figura 1: A arquitetura de uma vers√£o menor da arquitetura proposta.</i>  <i>A unidade LSTM no primeiro e no terceiro turno t√™m pesos compartilhados.</i> <br><br>  Uma vis√£o geral de alto n√≠vel de nossa abordagem √© fornecida na Figura 1. A arquitetura proposta da rede neural consiste na unidade de incorpora√ß√£o e duas unidades LSTM bidirecionais (dim = 64).  A primeira unidade LSTM destina-se a analisar o enunciado do primeiro usu√°rio (ou seja, o primeiro turno e o terceiro turno da conversa), e o √∫ltimo se destina a analisar o enunciado do segundo usu√°rio (ou seja, o segundo turno).  Essas duas unidades aprendem n√£o apenas a representa√ß√£o de recursos sem√¢nticos e de sentimentos, mas tamb√©m como capturar recursos de conversa√ß√£o espec√≠ficos do usu√°rio, o que permite classificar emo√ß√µes com mais precis√£o.  Na primeira etapa, cada enunciado do usu√°rio √© alimentado em uma unidade LSTM bidirecional correspondente usando incorpora√ß√£o de palavras pr√©-treinadas.  Em seguida, esses tr√™s mapas de caracter√≠sticas s√£o concatenados em um vetor de caracter√≠stica achatada e depois passados ‚Äã‚Äãpara uma camada oculta totalmente conectada (dim = 30), que analisa as intera√ß√µes entre os vetores obtidos.  Finalmente, esses recursos prosseguem na camada de sa√≠da com a fun√ß√£o de ativa√ß√£o softmax para prever um r√≥tulo de classe final.  Para reduzir o sobreajuste, camadas de regulariza√ß√£o com ru√≠do gaussiano foram adicionadas ap√≥s a camada de incorpora√ß√£o, camadas de abandono ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Srivastava et al., 2014</a> ) foram adicionadas em cada unidade LSTM (p = 0,2) e antes da camada totalmente oculta e conectada (p = 0,1). <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Resultados </h2><br>  No processo de busca da arquitetura ideal, experimentamos n√£o apenas o n√∫mero de c√©lulas em camadas, fun√ß√µes de ativa√ß√£o e par√¢metros de regulariza√ß√£o, mas tamb√©m a arquitetura da rede neural.  As informa√ß√µes detalhadas sobre esta frase podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo original</a> . <br><br>  O modelo descrito na se√ß√£o anterior demonstrou as melhores pontua√ß√µes no conjunto de dados do desenvolvedor, por isso foi usado na etapa de avalia√ß√£o final da competi√ß√£o.  No conjunto de dados de teste final, obteve 72,59% da pontua√ß√£o micro-m√©dia da F1 para as classes emocionais, enquanto a pontua√ß√£o m√°xima entre todos os participantes foi de 79,59%.  No entanto, isso est√° bem acima da linha de base oficial divulgada pelos organizadores de tarefas, que foi de 58,68%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo fonte do modelo e a incorpora√ß√£o de palavras</a> est√£o dispon√≠veis no GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A vers√£o completa do artigo</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o documento de descri√ß√£o da tarefa</a> podem ser encontrados em ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O conjunto de dados de treinamento</a> est√° localizado no grupo oficial da competi√ß√£o no LinkedIn. <br><br>  Cita√ß√£o: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt439850/">https://habr.com/ru/post/pt439850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt439834/index.html">Vis√£o geral da tecnologia IPMI</a></li>
<li><a href="../pt439838/index.html">Aritm√©tica do mel: adi√ß√£o e subtra√ß√£o pelas abelhas</a></li>
<li><a href="../pt439840/index.html">Confer√™ncia DUMP-2019: convidamos voc√™ a falar nas se√ß√µes Design, Gerenciamento e Teste</a></li>
<li><a href="../pt439844/index.html">Por que os desenvolvedores do Dodo Pizza 250?</a></li>
<li><a href="../pt439848/index.html">Nem uma √∫nica VPN. Folha de dicas sobre como se proteger e seus dados</a></li>
<li><a href="../pt439852/index.html">Vers√£o do aplicativo de controle remoto: Aspia 1.1.0</a></li>
<li><a href="../pt439854/index.html">Ah, mais uma vez: o que fazer com um cliente no CRM depois que ele comprou</a></li>
<li><a href="../pt439856/index.html">Yandex! Obrigado por Uber</a></li>
<li><a href="../pt439858/index.html">Prometheus + Grafana + Exportador de n√≥s + Docker no Azure com notifica√ß√µes no Telegram</a></li>
<li><a href="../pt439860/index.html">Raiz do Ubuntu 18.04 no ZFS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧑🏽‍🤝‍🧑🏽 💢 🚳 Detecção de emoção contextual em conversas textuais usando redes neurais 🉐 🏇🏻 👐🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Atualmente, conversar com agentes de conversação está se tornando uma rotina diária, e é crucial que os sistemas de diálogo gerem respostas o mais hum...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Detecção de emoção contextual em conversas textuais usando redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439850/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Atualmente, conversar com agentes de conversação está se tornando uma rotina diária, e é crucial que os sistemas de diálogo gerem respostas o mais humanas possível.  Como um dos aspectos principais, atenção primária deve ser dada ao fornecimento de respostas emocionalmente conscientes aos usuários.  Neste artigo, descreveremos <b>a arquitetura de rede neural recorrente para detecção de emoções em conversas textuais</b> , que participaram da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tarefa 3 SemEval-2019 "EmoContext"</a> , ou seja, um workshop anual sobre avaliação semântica.  O objetivo da tarefa é classificar a emoção (ou seja, feliz, triste, zangada e outras) em um conjunto de dados de conversação em três turnos. <br><a name="habracut"></a><br>  O restante do artigo está organizado da seguinte maneira.  A Seção 1 fornece uma breve visão geral da tarefa do EmoContext e dos dados fornecidos.  As seções 2 e 3 enfocam o pré-processamento de textos e a incorporação de palavras, consequentemente.  Na seção 4, descrevemos a arquitetura do modelo LSTM usado em nossa submissão.  Em conclusão, são apresentados o desempenho final do nosso sistema e o código fonte.  O modelo é implementado em Python usando a biblioteca Keras. <br><br><h2>  1. Dados de treinamento </h2><br>  A tarefa 3 do SemEval-2019 “EmoContext” está focada na detecção de emoções contextuais na conversa em texto.  No EmoContext, dada uma declaração textual do usuário juntamente com 2 turnos de contexto em uma conversa, devemos classificar se a emoção da próxima frase do usuário é "feliz", "triste", "zangada" ou "outras" (Tabela 1).  Existem apenas dois participantes da conversa: uma pessoa anônima (Tuen-1 e Turn-3) e o chatbot baseado em IA <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ruuh</a> (Turn-2).  Para uma descrição detalhada, consulte ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabela 1. Exemplos mostrando o conjunto de dados EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Usuário (Turn-1) </th><th>  Agente de conversação (Turn-1) </th><th>  Usuário (Turn-2) </th><th>  Classe verdadeira </th></tr><tr><td>  Acabei de me qualificar para o estágio Nabard </td><td>  WOOT!  Essa é uma ótima notícia.  Parabéns! </td><td>  Comecei a chorar </td><td>  Feliz </td></tr><tr><td>  Como você ousa dar um tapa no meu filho </td><td>  Se você estragar o meu carro, eu também farei isso </td><td>  Apenas tente fazer isso uma vez </td><td>  Zangado </td></tr><tr><td>  Eu fui machucado por você mais </td><td>  Você não quis dizer isso. </td><td>  diga que me ama </td><td>  Triste </td></tr><tr><td>  Eu vou fazer a noite </td><td>  Tudo bem.  Mantenha-me informado. </td><td>  Não dando WhatsApp não. </td><td>  Outros </td></tr></tbody></table></div><br>  Durante a competição, tivemos acesso a 30160 textos rotulados como humanos, fornecidos pelos organizadores das tarefas, onde cerca de 5000 amostras cada uma das classes “zangado”, “triste”, “feliz” e 15000 para a classe “outros” (Tabela 2).  Os conjuntos de desenvolvimento e teste, que também foram fornecidos pelos organizadores, em contraste com o conjunto de trens, têm uma distribuição na vida real, que é de cerca de 4% para cada classe emocional e o restante para a classe "outros".  Os dados são da Microsoft e podem ser encontrados no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">grupo oficial do LinkedIn</a> . <br><br>  <i>Tabela 2. Distribuição do rótulo da classe Emotion em conjuntos de dados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Conjunto de dados </th><th>  Feliz </th><th>  Triste </th><th>  Zangado </th><th>  Outros </th><th>  Total </th></tr><tr><td>  Trem <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30160 <br></td></tr><tr><td>  Dev <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Teste <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Distante <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900k <br></td></tr></tbody></table></div><br>  Além desses dados, coletamos 900k tweets em inglês para criar um conjunto de dados distante de 300k tweets para cada emoção.  Para formar o conjunto de dados distante, baseamos-nos na estratégia de Go et al.  (2009), sob o qual simplesmente associamos tweets à presença de palavras relacionadas à emoção, como '#angry', '#annoyed', '#happy', '#sad,' #surprised 'etc.  A lista de termos de consulta foi baseada nos termos de consulta do SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Duppada et al., 2018</a> ). <br><br>  A principal métrica de desempenho do EmoContext é uma pontuação micro-média da F1 para três classes de emoções, ou seja, 'triste', 'feliz' e 'zangada'. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Pré-processamento de textos </h2><br>  Antes de qualquer etapa do treinamento, os textos eram pré-processados ​​pela ferramenta Ekphrasis (Baziotis et al., 2017).  Essa ferramenta ajuda a executar correção ortográfica, normalização de palavras, segmentação e permite especificar quais tokens devem ser omitidos, normalizados ou anotados com tags especiais.  Usamos as seguintes técnicas para o estágio de pré-processamento. <br><br><ul><li>  URLs, e-mails, data e hora, nomes de usuários, porcentagem, moedas e números foram substituídos pelas tags correspondentes. </li><li>  Termos repetidos, censurados, alongados e em maiúsculas foram anotados com as tags correspondentes. </li><li>  Palavras alongadas foram corrigidas automaticamente com base no corpus estatístico de palavras incorporado. </li><li>  A descompactação de hashtags e contrações (ou seja, segmentação de palavras) foi realizada com base no corpus estatístico de palavras incorporado. </li><li>  Um dicionário criado manualmente para substituir termos extraídos do texto foi usado para reduzir uma variedade de emoções. </li></ul><br>  Além disso, o Emphasis fornece o tokenizador capaz de identificar a maioria dos emojis, emoticons e expressões complicadas, como palavras censuradas, enfatizadas e alongadas, além de datas, horas, moedas e acrônimos. <br><br>  <i>Tabela 3. Exemplos de pré-processamento de texto.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texto original </th><th>  Texto pré-processado </th></tr><tr><td>  Eu sinto você ... estou quebrando em milhões de pedaços <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; eu sinto você &lt;/allcaps&gt;.  &lt;repetido&gt; estou quebrando em milhões de pedaços <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  cansado e eu também senti sua falta :‑( </td><td>  cansado e eu também senti sua falta &lt;sad&gt; </td></tr><tr><td>  você deve ouvir isso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  você deve ouvir &lt;elongated&gt; o seguinte: &lt;url&gt; </td></tr><tr><td>  Meu apartamento cuida disso.  Meu aluguel é de cerca de US $ 650. </td><td>  meu apartamento cuida disso.  meu aluguel é em torno de &lt;dinheiro&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^・^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑c'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‑':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‑["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Incorporação de palavras </h2><br>  A incorporação de palavras se tornou uma parte essencial de qualquer abordagem de aprendizado profundo para sistemas de PNL.  Para determinar os vetores mais adequados para a tarefa de detecção de emoções, experimentamos os modelos Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pennington et al., 2014</a> ) e FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Joulin et al., 2017</a> ), bem como os DataStories pré-treinados vetores de palavras ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Baziotis et al., 2017</a> ).  O conceito principal do Word2Vec é localizar palavras, que compartilham contextos comuns no corpus de treinamento, nas proximidades do espaço vetorial.  Os modelos Word2Vec e Glove aprendem codificações geométricas de palavras a partir de suas informações de co-ocorrência, mas essencialmente o primeiro é um modelo preditivo e o último é um modelo baseado em contagem.  Em outras palavras, enquanto o Word2Vec tenta prever uma palavra de destino (arquitetura CBOW) ou um contexto (arquitetura de Skip-gram), ou seja, para minimizar a função de perda, o GloVe calcula vetores de palavras fazendo redução de dimensionalidade na matriz de contagens de co-ocorrência.  O FastText é muito semelhante ao Word2Vec, exceto pelo fato de que ele usa caracteres n-gramas para aprender vetores de palavras; portanto, ele é capaz de resolver o problema de falta de vocabulário. <br><br>  Para todas as técnicas mencionadas acima, usamos os carrinhos de treinamento padrão fornecidos pelos autores.  Nós treinamos um modelo LSTM simples (dim = 64) com base em cada um desses embeddings e comparamos a eficácia usando a validação cruzada.  De acordo com o resultado, os casamentos pré-treinados do DataStories demonstraram a melhor pontuação média na F1. <br><br>  Para enriquecer as combinações de palavras selecionadas com a polaridade emocional das palavras, consideramos a execução de uma frase de pré-treinamento distante, ajustando as combinações no conjunto de dados distantes rotulado automaticamente.  A importância do uso do pré-treinamento foi demonstrada em ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deriu et al., 201</a> 7).  Usamos o conjunto de dados distante para treinar a rede LSTM simples para classificar tweets irritados, tristes e felizes.  A camada de encaixes foi congelada durante a primeira época de treinamento, a fim de evitar alterações significativas nos pesos dos encaixes e, em seguida, foi descongelada nas próximas cinco épocas.  Após a fase de treinamento, os ajustes foram salvos para as fases de treinamento adicionais e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">disponibilizados ao público</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Arquitetura de Rede Neural </h2><br>  Uma rede neural recorrente (RNN) é uma família de redes neurais artificiais especializada no processamento de dados seqüenciais.  Ao contrário das redes neurais tradicionais, os RRNs são projetados para lidar com dados seqüenciais compartilhando seus pesos internos ao processar a sequência.  Para esse fim, o gráfico computacional de RRNs inclui ciclos, representando a influência das informações anteriores sobre a atual.  Como uma extensão das RNNs, redes de memória de curto prazo (LSTMs) foram introduzidas em 1997 ( <a href="">Hochreiter e Schmidhuber, 1997</a> ).  Nos LSTMs, as células recorrentes são conectadas de uma maneira específica para evitar problemas de gradiente que desaparecem e explodem.  Os LSTMs tradicionais preservam apenas as informações do passado, pois processam a sequência apenas em uma direção.  Os LSTMs bidirecionais combinam a saída de duas camadas ocultas de LSTM, movendo-se em direções opostas, onde uma avança no tempo e outra retrocede no tempo, permitindo capturar informações de estados passados ​​e futuros simultaneamente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Schuster e Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figura 1: A arquitetura de uma versão menor da arquitetura proposta.</i>  <i>A unidade LSTM no primeiro e no terceiro turno têm pesos compartilhados.</i> <br><br>  Uma visão geral de alto nível de nossa abordagem é fornecida na Figura 1. A arquitetura proposta da rede neural consiste na unidade de incorporação e duas unidades LSTM bidirecionais (dim = 64).  A primeira unidade LSTM destina-se a analisar o enunciado do primeiro usuário (ou seja, o primeiro turno e o terceiro turno da conversa), e o último se destina a analisar o enunciado do segundo usuário (ou seja, o segundo turno).  Essas duas unidades aprendem não apenas a representação de recursos semânticos e de sentimentos, mas também como capturar recursos de conversação específicos do usuário, o que permite classificar emoções com mais precisão.  Na primeira etapa, cada enunciado do usuário é alimentado em uma unidade LSTM bidirecional correspondente usando incorporação de palavras pré-treinadas.  Em seguida, esses três mapas de características são concatenados em um vetor de característica achatada e depois passados ​​para uma camada oculta totalmente conectada (dim = 30), que analisa as interações entre os vetores obtidos.  Finalmente, esses recursos prosseguem na camada de saída com a função de ativação softmax para prever um rótulo de classe final.  Para reduzir o sobreajuste, camadas de regularização com ruído gaussiano foram adicionadas após a camada de incorporação, camadas de abandono ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Srivastava et al., 2014</a> ) foram adicionadas em cada unidade LSTM (p = 0,2) e antes da camada totalmente oculta e conectada (p = 0,1). <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Resultados </h2><br>  No processo de busca da arquitetura ideal, experimentamos não apenas o número de células em camadas, funções de ativação e parâmetros de regularização, mas também a arquitetura da rede neural.  As informações detalhadas sobre esta frase podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo original</a> . <br><br>  O modelo descrito na seção anterior demonstrou as melhores pontuações no conjunto de dados do desenvolvedor, por isso foi usado na etapa de avaliação final da competição.  No conjunto de dados de teste final, obteve 72,59% da pontuação micro-média da F1 para as classes emocionais, enquanto a pontuação máxima entre todos os participantes foi de 79,59%.  No entanto, isso está bem acima da linha de base oficial divulgada pelos organizadores de tarefas, que foi de 58,68%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O código fonte do modelo e a incorporação de palavras</a> estão disponíveis no GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A versão completa do artigo</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o documento de descrição da tarefa</a> podem ser encontrados em ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O conjunto de dados de treinamento</a> está localizado no grupo oficial da competição no LinkedIn. <br><br>  Citação: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt439850/">https://habr.com/ru/post/pt439850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt439834/index.html">Visão geral da tecnologia IPMI</a></li>
<li><a href="../pt439838/index.html">Aritmética do mel: adição e subtração pelas abelhas</a></li>
<li><a href="../pt439840/index.html">Conferência DUMP-2019: convidamos você a falar nas seções Design, Gerenciamento e Teste</a></li>
<li><a href="../pt439844/index.html">Por que os desenvolvedores do Dodo Pizza 250?</a></li>
<li><a href="../pt439848/index.html">Nem uma única VPN. Folha de dicas sobre como se proteger e seus dados</a></li>
<li><a href="../pt439852/index.html">Versão do aplicativo de controle remoto: Aspia 1.1.0</a></li>
<li><a href="../pt439854/index.html">Ah, mais uma vez: o que fazer com um cliente no CRM depois que ele comprou</a></li>
<li><a href="../pt439856/index.html">Yandex! Obrigado por Uber</a></li>
<li><a href="../pt439858/index.html">Prometheus + Grafana + Exportador de nós + Docker no Azure com notificações no Telegram</a></li>
<li><a href="../pt439860/index.html">Raiz do Ubuntu 18.04 no ZFS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
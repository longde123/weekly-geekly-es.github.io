<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õ±Ô∏è ü§ô üõåüèæ Neue VM-Images der Google Compute Engine f√ºr Deep Learning ‚õ¥Ô∏è ü•Ä üëÜüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mitautor des Artikels: Mike Cheng 


 Die Google Cloud-Plattform enth√§lt jetzt Images von virtuellen Maschinen in ihrem Portfolio, die speziell f√ºr di...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neue VM-Images der Google Compute Engine f√ºr Deep Learning</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/418249/"><p>  <em>Mitautor des Artikels: Mike Cheng</em> </p><br><p>  Die Google Cloud-Plattform enth√§lt jetzt Images von virtuellen Maschinen in ihrem Portfolio, die speziell f√ºr diejenigen entwickelt wurden, die an Deep Learning beteiligt sind.  Heute werden wir dar√ºber sprechen, was diese Bilder darstellen, welche Vorteile sie Entwicklern und Forschern bieten und wie man nat√ºrlich eine darauf basierende virtuelle Maschine erstellt. </p><a name="habracut"></a><br><p> Lyrischer Exkurs: Zum Zeitpunkt des Schreibens befand sich das Produkt noch in der Beta, es gelten keine SLAs. </p><br><h2 id="chto-eto-za-zver-takoy-obrazy-virtualnyh-mashin-dlya-deep-learning-ot-google">  Was f√ºr ein Biest ist das, Bilder von virtuellen Maschinen f√ºr Deep Learning von Google? </h2><br><p>  Virtual Machine-Images f√ºr Deep Learning von Google sind Debian 9-Images, die sofort alles enthalten, was Deep Learning ben√∂tigt.  Derzeit gibt es Versionen von Bildern mit TensorFlow-, PyTorch- und Allzweckbildern.  Jede Version ist in der Edition nur f√ºr CPU- und GPU-Instanzen vorhanden.  Um besser zu verstehen, welches Bild Sie ben√∂tigen, habe ich einen kleinen Spickzettel gezeichnet: </p><br><p><img src="https://habrastorage.org/webt/b-/ji/gp/b-jigplxvmb8yju_pt53sw8xjfa.png"></p><br><p>  Wie auf dem Spickzettel gezeigt, gibt es 8 verschiedene Bildfamilien.  Wie bereits erw√§hnt, basieren sie alle auf Debian 9. </p><br><h2 id="chto-zhe-imenno-predustanovleno-na-obrazy">  Was genau ist auf den Bildern vorinstalliert? </h2><br><p>  Alle Images haben Python 2.7 / 3.5 mit den folgenden vorinstallierten Paketen: </p><br><ul><li>  numpy </li><li>  sklearn </li><li>  scipy </li><li>  Pandas </li><li>  nltk </li><li>  Kissen </li><li>  Jupyter-Umgebungen (Labor und Notebook) </li><li>  und vieles mehr. </li></ul><br><p>  Konfigurierter Stack von Nvidia (nur in GPU-Images): </p><br><ul><li>  CUDA 9. * </li><li>  CuDNN 7.1 </li><li>  NCCL 2. * </li><li>  neuester nvidia treiber </li></ul><br><p>  Die Liste wird st√§ndig aktualisiert, bleiben Sie also <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf der offiziellen Seite auf dem Laufenden</a> . </p><br><h2 id="a-zachem-sobstvenno-eti-obrazy-nuzhny">  Und warum werden diese Bilder tats√§chlich ben√∂tigt? </h2><br><p>  Angenommen, Sie m√ºssen ein neuronales Netzwerkmodell mit Keras (mit TensorFlow) trainieren.  Die Lerngeschwindigkeit ist Ihnen wichtig und Sie entscheiden sich f√ºr die Verwendung der GPU.  Um die GPU verwenden zu k√∂nnen, m√ºssen Sie den Nvidia-Stack (Nvidia-Treiber + CUDA + CuDNN + NCCL) installieren und konfigurieren.  Dieser Prozess ist nicht nur an sich ziemlich kompliziert (insbesondere wenn Sie kein Systemingenieur, sondern ein Forscher sind), sondern umso komplizierter, als Sie die bin√§ren Abh√§ngigkeiten Ihrer Version der TensorFlow-Bibliothek ber√ºcksichtigen m√ºssen.  Beispielsweise wird die offizielle TensorFlow 1.9-Distribution mit CUDA 9.0 kompiliert und funktioniert nicht, wenn Sie einen Stack mit CUDA 9.1 oder 9.2 installiert haben.  Das Einrichten dieses Stapels kann ein "lustiger" Prozess sein. Ich denke, niemand kann damit streiten (insbesondere diejenigen, die es getan haben). </p><br><p>  Nehmen wir nun an, dass nach mehreren schlaflosen N√§chten alles eingerichtet ist und funktioniert.  Frage: Ist diese Konfiguration, die Sie konfigurieren konnten, f√ºr Ihre Hardware am besten geeignet?  Stimmt es beispielsweise, dass das installierte CUDA 9.0 und das offizielle TensorFlow 1.9-Bin√§rpaket die schnellste Geschwindigkeit auf einer Instanz mit einem SkyLake-Prozessor und einer Volta V100-GPU aufweisen? </p><br><p>  Es ist fast unm√∂glich zu antworten, ohne mit anderen Versionen von CUDA zu testen.  Um sicher zu antworten, m√ºssen Sie TensorFlow in verschiedenen Konfigurationen manuell neu erstellen und Ihre Tests ausf√ºhren.  All dies muss auf der teuren Hardware durchgef√ºhrt werden, auf der das Modell anschlie√üend trainiert werden soll.  Nun, und das allerletzte, all diese Messungen k√∂nnen weggeworfen werden, sobald die neue Version von TensorFlow oder der Nvidia-Stack ver√∂ffentlicht wird.  Es kann mit Sicherheit festgestellt werden, dass die meisten Forscher dies einfach nicht tun und einfach die Standard-TensorFlow-Baugruppe verwenden, die keine optimale Geschwindigkeit aufweist. </p><br><p>  Hier erscheinen die Bilder von Deep Learning von Google in der Szene.  Bilder mit TensorFlow verf√ºgen beispielsweise √ºber eine eigene TensorFlow-Baugruppe, die f√ºr die in der Google Cloud Engine verf√ºgbare Hardware optimiert ist.  Sie werden mit einer anderen Konfiguration des Nvidia-Stacks getestet und basieren auf der Konfiguration mit der h√∂chsten Leistung (Spoiler: Dies ist nicht immer die neueste).  Gut und vor allem - fast alles, was Sie f√ºr die Forschung ben√∂tigen, ist bereits vorinstalliert! </p><br><h2 id="kak-mozhno-sozdat-instans-na-baze-odnogo-iz-obrazov">  Wie kann ich eine Instanz basierend auf einem der Bilder erstellen? </h2><br><p>  Es gibt zwei M√∂glichkeiten, eine neue Instanz basierend auf diesen Bildern zu erstellen: </p><br><ul><li>  Verwenden der Google Cloud Marketplace-Weboberfl√§che </li><li>  Mit gcloud </li></ul><br><p>  Da ich ein gro√üer Fan der Terminal- und CLI-Dienstprogramme bin, werde ich in diesem Artikel √ºber diese Option sprechen.  Wenn Sie die Benutzeroberfl√§che m√∂gen, gibt es au√üerdem eine recht gute <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation, in der beschrieben wird, wie Sie eine Instanz mithilfe der Web-Benutzeroberfl√§che erstellen</a> . </p><br><p>  Bevor Sie fortfahren, installieren Sie das gcloud- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tool</a> (falls Sie es noch nicht installiert haben).  Optional k√∂nnen Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Cloud Shell verwenden</a> . Beachten Sie jedoch, dass die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">WebPreview-</a> Funktion in der Google Cloud Shell derzeit nicht unterst√ºtzt wird und Sie daher das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jupyter Lab</a> oder Notebook dort nicht verwenden k√∂nnen. </p><br><p>  Der n√§chste Schritt ist die Auswahl einer Bildfamilie.  Ich werde mir noch einmal erlauben, den Spickzettel mit der Wahl einer Bilderfamilie mitzubringen. </p><br><p><img src="https://habrastorage.org/webt/b-/ji/gp/b-jigplxvmb8yju_pt53sw8xjfa.png"></p><br><p>  Wir gehen beispielsweise davon aus, dass Ihre Wahl auf tf-latest-cu92 gefallen ist, und werden sie sp√§ter im Text verwenden. </p><br><h3 id="pogodite-no-chto-esli-mne-nuzhna-konkretnaya-versiya-tensorflow-a-ne-poslednyaya">  Warten Sie, aber was ist, wenn ich eine bestimmte Version von TensorFlow anstelle der ‚Äûneuesten‚Äú Version ben√∂tige? </h3><br><p>  Angenommen, wir haben ein Projekt, f√ºr das TensorFlow 1.8 erforderlich ist, aber gleichzeitig wurde bereits 1.9 ver√∂ffentlicht, und die Bilder in der neuesten tf-Familie haben bereits 1.9.  F√ºr diesen Fall haben wir eine Familie von Bildern, die immer eine bestimmte Version des Frameworks hat (in unserem Fall tf-1-8-cpu und tf-1-8-cu92).  Diese Bildfamilien werden aktualisiert, die Version von TensorFlow √§ndert sich jedoch nicht. </p><br><p>  <em>Da dies nur eine Beta-Version ist, unterst√ºtzen wir jetzt nur noch TensorFlow 1.8 / 1.9 und PyTorch 0.4.</em>  <em>Wir planen, zuk√ºnftige Versionen zu unterst√ºtzen, k√∂nnen jedoch derzeit die Frage, wie lange alte Versionen unterst√ºtzt werden, nicht eindeutig beantworten.</em> </p><br><h3 id="chto-esli-ya-hochu-sozdat-klaster-ili-ispolzovat-odin-i-tot-zhe-obraz">  Was ist, wenn ich einen Cluster erstellen oder dasselbe Image verwenden m√∂chte? </h3><br><p>  In der Tat kann es viele F√§lle geben, in denen es erforderlich ist, dasselbe Bild immer wieder zu verwenden (und nicht eine Familie von Bildern).  Genau genommen ist die direkte Verwendung von Bildern fast immer die bevorzugte Option.  Wenn Sie beispielsweise einen Cluster mit mehreren Instanzen ausf√ºhren, wird in diesem Fall nicht empfohlen, Bildfamilien direkt in Ihren Skripten anzugeben, da bei einer Aktualisierung der Familie zum Zeitpunkt der Ausf√ºhrung des Skripts wahrscheinlich unterschiedliche Clusterinstanzen aus unterschiedlichen Bildern erstellt werden (und kann verschiedene Versionen von Bibliotheken haben!).  In solchen F√§llen ist es vorzuziehen, zuerst einen bestimmten Namen f√ºr das Bild ihrer Familie zu erhalten und erst dann einen bestimmten Namen zu verwenden. </p><br><p>  <em>Wenn Sie sich f√ºr dieses Thema interessieren, k√∂nnen Sie meinen Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûSo verwenden Sie Bildfamilien richtig‚Äú lesen.</a></em> </p><br><p>  Sie k√∂nnen den Namen des letzten Bildes in der Familie mit einem einfachen Befehl anzeigen: </p><br><pre><code class="bash hljs">gcloud compute images describe-from-family tf-latest-cu92 \ --project deeplearning-platform-release</code> </pre> <br><p>  Angenommen, der Name eines bestimmten Bildes lautet tf-latest-cu92-1529452792. Sie k√∂nnen es bereits √ºberall verwenden: </p><br><h2 id="vremya-sozdat-nash-pervyy-instans">  Zeit, unsere erste Instanz zu erstellen! </h2><br><p>  F√ºhren Sie einfach einen einfachen Befehl aus, um eine Instanz aus einer Familie von Bildern zu erstellen: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> IMAGE_FAMILY=<span class="hljs-string"><span class="hljs-string">"tf-latest-cu92"</span></span> <span class="hljs-comment"><span class="hljs-comment">#     export ZONE="us-west1-b" export INSTANCE_NAME="my-instance" gcloud compute instances create $INSTANCE_NAME \ --zone=$ZONE \ --image-family=$IMAGE_FAMILY \ --image-project=deeplearning-platform-release \ --maintenance-policy=TERMINATE \ --accelerator='type=nvidia-tesla-v100,count=8' \ --metadata='install-nvidia-driver=True'</span></span></code> </pre> <br><p>  Wenn Sie den Bildnamen und nicht die Bildfamilie verwenden, m√ºssen Sie "- image-family = $ IMAGE_FAMILY" durch "- image = $ IMAGE-NAME" ersetzen. </p><br><p>  Wenn Sie eine Instanz mit einer GPU verwenden, m√ºssen Sie die folgenden Umst√§nde beachten: </p><br><p>  <strong>Sie m√ºssen die richtige Zone ausw√§hlen</strong> .  Wenn Sie eine Instanz mit einer bestimmten GPU erstellen, m√ºssen Sie sicherstellen, dass dieser GPU-Typ in der Zone verf√ºgbar ist, in der Sie die Instanz erstellen.  Hier finden Sie die Entsprechung von Zonen zu GPU-Typen.  Wie Sie sehen k√∂nnen, ist us-west1-b die einzige Zone, in der es alle drei m√∂glichen Arten von GPUs gibt (K80 / P100 / V100). </p><br><p>  <strong>Stellen Sie sicher, dass Sie √ºber gen√ºgend Kontingente verf√ºgen, um eine Instanz mit der GPU zu erstellen</strong> .  Selbst wenn Sie die richtige Region ausgew√§hlt haben, bedeutet dies nicht, dass Sie √ºber ein Kontingent zum Erstellen einer Instanz mit einer GPU in dieser Region verf√ºgen.  Standardm√§√üig ist das GPU-Kontingent in allen Regionen auf Null festgelegt, sodass alle Versuche, eine Instanz mit der GPU zu erstellen, fehlschlagen.  Eine gute Erkl√§rung zur Erh√∂hung der Quote finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . </p><br><p>  <strong>Stellen Sie sicher, dass sich in der Zone gen√ºgend GPUs befinden, um Ihre Anfrage zu erf√ºllen</strong> .  Selbst wenn Sie die richtige Region ausgew√§hlt haben und ein Kontingent f√ºr GPUs in dieser Region haben, bedeutet dies nicht, dass in dieser Zone eine f√ºr Sie interessante GPU vorhanden ist.  Leider wei√ü ich nicht, wie Sie sonst die Verf√ºgbarkeit der GPU √ºberpr√ºfen k√∂nnen, au√üer als Versuch, eine Instanz zu erstellen und zu sehen, was passiert =) </p><br><p>  <strong>W√§hlen Sie die richtige Anzahl von GPUs (abh√§ngig vom GPU-Typ)</strong> .  Tatsache ist, dass das "Beschleuniger" -Flag in unserem Team f√ºr den Typ und die Anzahl der GPUs verantwortlich ist, die der Instanz zur Verf√ºgung stehen: d.h.  "- Accelerator = 'type = nvidia-tesla-v100, count = 8'" erstellt eine Instanz mit acht verf√ºgbaren Nvidia Tesla V100 (Volta) -GPUs.  Jeder GPU-Typ verf√ºgt √ºber eine g√ºltige Liste von Z√§hlwerten.  Hier ist die Liste f√ºr jeden GPU-Typ: </p><br><ul><li>  nvidia-tesla-k80 kann z√§hlen: 1, 2, 4, 8 </li><li>  nvidia-tesla-p100 kann z√§hlen: 1, 2, 4 </li><li>  nvidia-tesla-v100 kann z√§hlen: 1, 8 </li></ul><br><p>  <strong>Geben Sie Google Cloud die Berechtigung, den Nvidia-Treiber zum Zeitpunkt des Starts der Instanz in Ihrem Namen zu installieren</strong> .  Der Fahrer aus Nvidia ist ein Muss.  Aus Gr√ºnden, die √ºber den Rahmen dieses Artikels hinausgehen, ist auf den Images kein Nvidia-Treiber vorinstalliert.  Sie k√∂nnen Google Cloud jedoch das Recht einr√§umen, es beim ersten Start der Instanz in Ihrem Namen zu installieren.  Dies erfolgt durch Hinzuf√ºgen des Flags "- metadata = 'install-nvidia-driver = True'".  Wenn Sie dieses Flag nicht angeben, werden Sie beim ersten Herstellen einer Verbindung √ºber SSH aufgefordert, den Treiber zu installieren. </p><br><p>  Leider dauert der Treiberinstallationsprozess beim ersten Start einige Zeit, da dieser Treiber heruntergeladen und installiert werden muss (und dies beinhaltet auch einen Neustart der Instanz).  Insgesamt sollte dies nicht l√§nger als 5 Minuten dauern.  Wir werden etwas sp√§ter dar√ºber sprechen, wie Sie die erste Startzeit reduzieren k√∂nnen. </p><br><h2 id="podklyuchenie-k-instansu-po-ssh">  Stellen Sie √ºber SSH eine Verbindung zu einer Instanz her </h2><br><p>  Dies ist einfacher als eine R√ºbe und kann mit einem Befehl ausgef√ºhrt werden: </p><br><pre> <code class="bash hljs">gcloud compute ssh <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span></code> </pre> <br><p>  gcloud erstellt ein Schl√ºsselpaar und l√§dt es automatisch in die neu erstellte Instanz hoch sowie erstellt Ihren Benutzer darauf.  Wenn Sie diesen Vorgang noch einfacher gestalten m√∂chten, k√∂nnen Sie eine Funktion verwenden, die dies ebenfalls vereinfacht: </p><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gssh</span></span></span></span>() { gcloud compute ssh <span class="hljs-variable"><span class="hljs-variable">$@</span></span> } gssh <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span></code> </pre> <br><p>  √úbrigens finden Sie hier alle meine gcloud-Bash-Funktionen.  Bevor wir uns der Frage zuwenden, wie schnell diese Bilder sind oder was damit gemacht werden kann, m√∂chte ich das Problem mit der Geschwindigkeit des Startens von Instanzen kl√§ren. </p><br><h2 id="kak-mozhno-umenshit-vremya-pervogo-zapuska">  Wie kann ich die Zeit des ersten Starts verk√ºrzen? </h2><br><p>  Technisch gesehen ist der Zeitpunkt des ersten Starts nichts.  Aber Sie k√∂nnen: </p><br><ul><li>  Erstellen Sie die billigste n1-Standard-1-Instanz mit einem K80. </li><li>  Warten Sie, bis der erste Download abgeschlossen ist. </li><li>  Stellen Sie sicher, dass der Nvidia-Treiber installiert ist (dies kann durch Ausf√ºhren von "nvidia-smi" erfolgen). </li><li>  Stoppen Sie die Instanz </li><li>  Erstellen Sie Ihr eigenes Image aus einer gestoppten Instanz </li><li>  Gewinn - Alle aus Ihrem abgeleiteten Image erstellten Instanzen haben eine legend√§re Startzeit von 15 Sekunden. </li></ul><br><p>  Aus dieser Liste wissen wir bereits, wie eine neue Instanz erstellt und eine Verbindung hergestellt wird. Au√üerdem wissen wir, wie die Treiber auf ihre Funktionsf√§higkeit √ºberpr√ºft werden.  Es bleibt nur zu besprechen, wie die Instanz gestoppt und daraus ein Image erstellt werden kann. </p><br><p>  F√ºhren Sie den folgenden Befehl aus, um die Instanz zu stoppen: </p><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ginstance_stop</span></span></span></span>() { gcloud compute instances stop - quiet <span class="hljs-variable"><span class="hljs-variable">$@</span></span> } ginstance_stop <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span></code> </pre> <br><p>  Und hier ist der Befehl zum Erstellen des Bildes: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> IMAGE_NAME=<span class="hljs-string"><span class="hljs-string">"my-awesome-image"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> IMAGE_FAMILY=<span class="hljs-string"><span class="hljs-string">"family1"</span></span> gcloud compute images create <span class="hljs-variable"><span class="hljs-variable">$IMAGE_NAME</span></span> \ --<span class="hljs-built_in"><span class="hljs-built_in">source</span></span>-disk <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span> \ --<span class="hljs-built_in"><span class="hljs-built_in">source</span></span>-disk-zone <span class="hljs-variable"><span class="hljs-variable">$ZONE</span></span> \ --family <span class="hljs-variable"><span class="hljs-variable">$IMAGE_FAMILY</span></span></code> </pre> <br><p>  Herzlichen Gl√ºckwunsch, jetzt haben Sie Ihr eigenes Image mit den installierten Nvidia-Treibern. </p><br><h2 id="kak-naschet-jupyter-lab">  Wie w√§re es mit Jupyter Lab? </h2><br><p>  Sobald Ihre Instanz ausgef√ºhrt wird, besteht der n√§chste logische Schritt darin, Jupyter Lab zu starten, um direkt zur Sache zu kommen :) Mit neuen Images ist dies sehr einfach.  Jupyter Lab wird bereits seit dem Start der Instanz ausgef√ºhrt.  Sie m√ºssen lediglich eine Verbindung zur Instanz herstellen und den Port weiterleiten, den Jupyter Lab √ºberwacht.  Und das ist Port 8080. Dies geschieht mit dem folgenden Befehl: </p><br><pre> <code class="bash hljs">gssh <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span> -- -L 8080:localhost:8080</code> </pre> <br><p>  Alles ist fertig, jetzt k√∂nnen Sie einfach Ihren Lieblingsbrowser √∂ffnen und zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http: // localhost: 8080 gehen</a> </p><br><h2 id="naskolko-bystree-tensorflow-iz-obrazov">  Wie viel schneller ist TensorFlow von Bildern? </h2><br><p>  Eine sehr wichtige Frage, da die Geschwindigkeit des Trainings des Modells echtes Geld ist.  Die vollst√§ndige Antwort auf diese Frage ist jedoch die l√§ngste, die bereits in diesem Artikel geschrieben wurde.  Also musst du auf den n√§chsten Artikel warten :) </p><br><p>  In der Zwischenzeit werde ich Sie mit einigen Zahlen verw√∂hnen, die ich in meinem kleinen pers√∂nlichen Experiment erhalten habe.  Die Trainingsgeschwindigkeit in ImageNet betrug also 6100 Bilder pro Sekunde (ResNet-50-Netzwerk).  Mein pers√∂nliches Budget erlaubte es mir nicht, das Modell vollst√§ndig zu trainieren. Bei dieser Geschwindigkeit gehe ich jedoch davon aus, dass es m√∂glich ist, mit ein wenig Genauigkeit von 5% in 5 Stunden zu erreichen. </p><br><h2 id="gde-poluchit-pomosch">  Wo bekomme ich Hilfe? </h2><br><p>  Wenn Sie Informationen zu neuen Bildern ben√∂tigen, k√∂nnen Sie: </p><br><ul><li>  Stellen Sie eine Frage zum Stackoverflow mit dem Tag google-dl-platform. </li><li>  Schreiben Sie an die √∂ffentliche <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google-Gruppe</a> . </li><li>  kann mir per Mail oder auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Twitter</a> schreiben. </li></ul><br><p>  Ihr Feedback ist sehr wichtig. Wenn Sie etwas zu den Bildern zu sagen haben, k√∂nnen Sie mich gerne auf eine f√ºr Sie geeignete Weise kontaktieren oder einen Kommentar unter diesem Artikel hinterlassen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418249/">https://habr.com/ru/post/de418249/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418239/index.html">48 Megapixel f√ºr Smartphone</a></li>
<li><a href="../de418241/index.html">Warum Gau√ü? (100 M√∂glichkeiten, das Gleichungssystem zu l√∂sen)</a></li>
<li><a href="../de418243/index.html">Die popul√§re Geschichte der Astronomie ist falsch</a></li>
<li><a href="../de418245/index.html">Wie man kein Projekt auf Bitrix entwickelt</a></li>
<li><a href="../de418247/index.html">Beschleunigen Sie die Float 4x4 Matrix Multiplikation mit SIMD</a></li>
<li><a href="../de418251/index.html">Computer Vision: Wie KI uns beobachtet</a></li>
<li><a href="../de418253/index.html">Der fr√ºhe Mond k√∂nnte Wasser, Atmosph√§re und Leben haben</a></li>
<li><a href="../de418255/index.html">Wie Verkehrsb√∂rsen Autosurfen weiterverkaufen und woher Millionen von Bots online kommen</a></li>
<li><a href="../de418257/index.html">Github.com weigert sich, jQuery zu verwenden und wechselt zu reinem JavaScript</a></li>
<li><a href="../de418261/index.html">Selbst gemachter Elektroschockerhandschuh - eine Waffe f√ºr einen Geek</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
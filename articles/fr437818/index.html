<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚óªÔ∏è üïµÔ∏è ü•ñ Nous enseignons √† un ordinateur √† distinguer les sons: se familiariser avec le concours DCASE et assembler votre classificateur audio en 30 minutes üßòüèΩ üë©‚Äçüíº üîñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cet article a √©t√© √©crit en collaboration avec ananaskelly . 
 Pr√©sentation 


 Bonjour √† tous, Habr! Travaillant au Center for Speech Technology √† Sai...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nous enseignons √† un ordinateur √† distinguer les sons: se familiariser avec le concours DCASE et assembler votre classificateur audio en 30 minutes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/speechpro/blog/437818/"><p> Cet article a √©t√© √©crit en collaboration avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">ananaskelly</a> . </p><br><h3 id="vvedenie">  Pr√©sentation </h3><br><p>  Bonjour √† tous, Habr!  Travaillant au Center for Speech Technology √† Saint-P√©tersbourg, nous avons acquis une petite exp√©rience dans la r√©solution des probl√®mes de classification et de d√©tection des √©v√©nements acoustiques et avons d√©cid√© que nous sommes pr√™ts √† les partager avec vous.  Le but de cet article est de vous pr√©senter quelques t√¢ches et de parler du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">concours de</a> traitement automatique du son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DCASE 2018</a> .  En vous parlant du concours, nous nous passerons de <u>formules et d√©finitions complexes</u> li√©es √† l'apprentissage automatique, de sorte que la signification g√©n√©rale de l'article sera comprise par un <u>large public</u> . </p><br><p>  Pour ceux qui √©taient <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">int√©ress√©s</a> par l' <b>assemblage du classificateur</b> , nous avons pr√©par√© un petit code python, et en utilisant le lien sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github,</a> vous pouvez trouver un cahier, o√π nous utilisons l'exemple de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deuxi√®me piste</a> du concours DCASE pour cr√©er un r√©seau convolutionnel simple sur des k√©ros pour classer des fichiers audio.  L√†, nous parlons un peu du r√©seau et des fonctionnalit√©s utilis√©es pour la formation, et comment utiliser une architecture simple pour obtenir un r√©sultat proche de la ligne de base ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MAP @ 3</a> = 0,6). </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cy/xk/ct/cyxkct2xgahwpajkvi4sxzvallu.png"></div><br><p>  De plus, les approches de base pour r√©soudre les probl√®mes (base) propos√©es par les organisateurs seront d√©crites ici.  √âgalement √† l'avenir, il y aura plusieurs articles o√π nous parlerons plus en d√©tail et en d√©tail √† la fois de notre exp√©rience de participation au concours et des solutions propos√©es par d'autres participants au concours.  Des liens vers ces articles appara√Ætront progressivement ici. </p><a name="habracut"></a><br><p>  Certes, beaucoup de gens n'ont absolument aucune id√©e d'une sorte de <b>¬´DCASE¬ª</b> , alors essayons de d√©terminer de quel type de fruit il s'agit et avec quoi il est mang√©.  Le <abbr title="D√©tection et classification des sc√®nes et √©v√©nements acoustiques (D√©tection et classification des sc√®nes et √©v√©nements acoustiques))">concours</abbr> ¬´ <abbr title="D√©tection et classification des sc√®nes et √©v√©nements acoustiques (D√©tection et classification des sc√®nes et √©v√©nements acoustiques))">DCASE</abbr> ¬ª a lieu chaque ann√©e, et chaque ann√©e plusieurs t√¢ches sont consacr√©es √† la r√©solution de probl√®mes dans le domaine de la classification des enregistrements audio et de la d√©tection des √©v√©nements acoustiques.  Tout le monde peut participer au concours, c'est gratuit, pour cela il suffit de s'inscrire simplement sur le site en tant que participant.  √Ä l'issue du concours, une conf√©rence est organis√©e sur les m√™mes th√®mes, mais contrairement au concours lui-m√™me, la participation est d√©j√† payante et nous n'en parlerons plus.  Les r√©compenses pour les meilleures d√©cisions ne sont g√©n√©ralement pas utilis√©es, mais il existe des exceptions (par exemple, la 3e t√¢che en 2018).  Cette ann√©e, les organisateurs ont propos√© les 5 t√¢ches suivantes: </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classification des sc√®nes acoustiques (subdivis√©es en 3 sous-t√¢ches)</a> <br>  A. Ensembles de donn√©es de formation et de test enregistr√©es sur le m√™me appareil <br>  Ensembles de donn√©es de formation et de test enregistr√©es sur diff√©rents appareils <br>  C. La formation est autoris√©e en utilisant des donn√©es non fournies par les organisateurs </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classification des √©v√©nements acoustiques</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D√©tection des chants d'oiseaux</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D√©tection d'√©v√©nements acoustiques dans la maison √† l'aide d'un ensemble de donn√©es faiblement √©tiquet√©</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classification de l'activit√© du m√©nage dans la pi√®ce selon l'enregistrement multicanal</a> </li></ol><br><h4 id="o-detektirovanii-i-klassifikacii">  √Ä propos de la d√©tection et de la classification </h4><br><p>  Comme nous pouvons le voir, les noms de toutes les t√¢ches contiennent l'un des deux mots: ¬´d√©tection¬ª ou ¬´classification¬ª.  Clarifions quelle est la diff√©rence entre ces concepts afin qu'il n'y ait pas de confusion. </p><br><p>  Imaginez que nous ayons un enregistrement audio sur lequel un chien aboie √† un moment, et un chat miaule √† un autre, et il n'y a tout simplement pas d'autres √©v√©nements l√†-bas.  Ensuite, si nous voulons comprendre exactement quand ces √©v√©nements se produisent, nous devons r√©soudre le probl√®me de la d√©tection d'un √©v√©nement acoustique.  Autrement dit, nous devons conna√Ætre les heures de d√©but et de fin de chaque √©v√©nement.  Apr√®s avoir r√©solu le probl√®me de d√©tection, nous savons exactement quand les √©v√©nements se produisent, mais nous ne savons pas exactement qui √©met les sons trouv√©s - alors nous devons r√©soudre le probl√®me de classification, c'est-√†-dire d√©terminer ce qui s'est exactement pass√© dans une p√©riode de temps donn√©e. </p><br><p>  Pour comprendre la description des t√¢ches du concours, ces exemples suffiront, ce qui signifie que la partie introductive est termin√©e, et nous pouvons proc√©der √† une description d√©taill√©e des t√¢ches elles-m√™mes. </p><br><hr><br><h3 id="anchortrack1anchortrack-1-klassifikaciya-akusticheskih-scen"><a name="Track1"></a>  Piste 1. Classification des sc√®nes acoustiques </h3><br><p>  La premi√®re t√¢che consiste √† d√©terminer l'environnement (sc√®ne acoustique) dans lequel le son a √©t√© enregistr√©, par exemple, ¬´Station de m√©tro¬ª, ¬´A√©roport¬ª ou ¬´Rue pi√©tonne¬ª.  La solution √† ce probl√®me peut √™tre utile pour √©valuer l'environnement avec un syst√®me d'intelligence artificielle, par exemple, dans les voitures avec pilote automatique. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/db/4g/ff/db4gffctu9tgvd4upbse_eaaiwg.jpeg"></div><br><p>  Dans cette t√¢che, les ensembles de donn√©es mobiles TUT Urban Acoustic Scenes 2018 et TUT Urban Acoustic Scenes 2018, qui ont √©t√© pr√©par√©s par l'Universit√© de technologie de Tampere (Finlande), ont √©t√© pr√©sent√©s pour la formation.  Une description d√©taill√©e de la pr√©paration de l'ensemble de donn√©es, ainsi que la solution de base, est d√©crite dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> . </p><br><p>  Au total, 10 sc√®nes acoustiques ont √©t√© pr√©sent√©es pour le concours, que les participants devaient pr√©voir. </p><br><h4 id="podzadacha-a">  Sous-t√¢che A </h4><br><p>  Comme nous l'avons d√©j√† dit, la t√¢che est divis√©e en 3 sous-t√¢ches, dont chacune diff√®re par la qualit√© des enregistrements audio.  Par exemple, dans la sous-t√¢che A, des microphones sp√©ciaux ont √©t√© utilis√©s pour l'enregistrement, qui √©taient situ√©s dans les oreilles humaines.  Ainsi, l'enregistrement st√©r√©o s'est rapproch√© de la perception humaine du son.  Les participants ont eu la possibilit√© d'utiliser cette approche de l'enregistrement afin d'am√©liorer la qualit√© de reconnaissance de la sc√®ne acoustique. </p><br><h4 id="podzadacha-v">  Sous-t√¢che B </h4><br><p>  Dans la sous-t√¢che B, d'autres appareils (par exemple, des t√©l√©phones portables) ont √©galement √©t√© utilis√©s pour l'enregistrement.  Les donn√©es de la sous-t√¢che A ont √©t√© converties en format mono, la fr√©quence d'√©chantillonnage a √©t√© r√©duite, il n'y a pas de simulation de ¬´l'audibilit√©¬ª du son par une personne dans l'ensemble de donn√©es pour cette t√¢che, mais il y a plus de donn√©es pour la formation. </p><br><h4 id="podzadacha-s">  Sous-t√¢che C </h4><br><p>  L'ensemble de donn√©es pour la sous-t√¢che C est le m√™me que pour la sous-t√¢che A, mais pour r√©soudre ce probl√®me, il est autoris√© d'utiliser toutes les donn√©es externes que le participant peut trouver.  Le but de r√©soudre ce probl√®me est de savoir s'il est possible d'am√©liorer le r√©sultat obtenu dans la sous-t√¢che A en utilisant des donn√©es tierces. </p><br><p>  La qualit√© des d√©cisions sur cette piste a √©t√© √©valu√©e par la m√©trique de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pr√©cision</a> . </p><br><p>  La ligne de base de cette t√¢che est un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©seau de neurones convolutionnels √†</a> deux couches qui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprend</a> des logarithmes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">petits spectrogrammes des</a> donn√©es audio originales.  L'architecture propos√©e utilise les techniques standard BatchNormalization et Dropout.  Le code sur GitHub peut √™tre vu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </p><br><hr><br><h3 id="anchortrack2anchortrack-2-klassifikaciya-akusticheskih-sobytiy"><a name="Track2"></a>  Piste 2. Classification des √©v√©nements acoustiques </h3><br><p>  Dans cette t√¢che, il est propos√© de cr√©er un syst√®me qui classe les √©v√©nements acoustiques.  Un tel syst√®me peut √™tre un ajout aux maisons intelligentes, augmenter la s√©curit√© dans les endroits surpeupl√©s ou faciliter la vie des personnes malentendantes. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ut/r5/9_/utr59_-ugehiq9jyhe_hgpgzbrm.jpeg"></div><br><p>  L'ensemble de donn√©es pour cette t√¢che se compose de fichiers extraits de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ensemble de donn√©es Freesound</a> et balis√©s √† l'aide de balises de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AudioSet</a> de Google.  Plus en d√©tail, le processus de pr√©paration de l'ensemble de donn√©es est d√©crit par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article</a> pr√©par√© par les organisateurs du concours. </p><br><p>  Revenons √† la t√¢che elle-m√™me, qui pr√©sente plusieurs fonctionnalit√©s. </p><br><p>  Tout d'abord, les participants ont d√ª cr√©er un mod√®le capable d'identifier les diff√©rences entre des √©v√©nements acoustiques de nature tr√®s diff√©rente.  L'ensemble de donn√©es est divis√© en classe 41, il pr√©sente divers instruments de musique, des sons √©mis par des humains, des animaux, des sons domestiques et plus encore. </p><br><p>  Deuxi√®mement, en plus du balisage habituel des donn√©es, il existe √©galement des informations suppl√©mentaires sur la v√©rification manuelle de l'√©tiquette.  Autrement dit, les participants savent quels fichiers de l'ensemble de donn√©es ont √©t√© v√©rifi√©s par la personne pour v√©rifier leur conformit√© √† l'√©tiquette, et lesquels ne le sont pas.  Comme la pratique l'a montr√©, les participants qui ont utilis√© ces informations suppl√©mentaires d'une mani√®re ou d'une autre ont remport√© des prix pour r√©soudre ce probl√®me. </p><br><p>  De plus, il faut dire que la dur√©e des enregistrements dans l'ensemble de donn√©es varie consid√©rablement: de 0,3 seconde √† 30 secondes.  Dans ce probl√®me, la quantit√© de donn√©es par classe, sur laquelle le mod√®le doit √™tre form√©, varie √©galement consid√©rablement.  Ceci est mieux repr√©sent√© sous forme d'histogramme, le code de construction qui est tir√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'ici</a> . </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tw/r4/gq/twr4gqwzkdivbpzkipwh6jesugi.jpeg"></div><br><p>  Comme vous pouvez le voir sur l'histogramme, le balisage manuel pour les classes pr√©sent√©es est √©galement d√©s√©quilibr√©, ce qui ajoute des difficult√©s si vous souhaitez utiliser ces informations lors de la formation des mod√®les. <br>  Les r√©sultats de cette piste ont √©t√© √©valu√©s √† l'aide de la m√©trique d'exactitude moyenne (pr√©cision moyenne moyenne, MAP @ 3), une d√©monstration assez simple du calcul de cette m√©trique avec des exemples et du code peut √™tre trouv√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </p><br><hr><br><h3 id="anchortrack3anchortrack-3-detektirovanie-ptichego-peniya"><a name="Track3"></a>  Piste 3. D√©tection du chant des oiseaux </h3><br><p>  La piste suivante est la d√©tection du chant des oiseaux.  Un probl√®me similaire se pose, par exemple, dans divers syst√®mes de surveillance automatique de la faune - c'est la premi√®re √©tape du traitement des donn√©es avant, par exemple, la classification.  De tels syst√®mes n√©cessitent souvent un r√©glage, sont instables aux nouvelles conditions acoustiques, donc l'objectif de cette piste est de faire appel √† la puissance de l'apprentissage automatique pour r√©soudre de tels probl√®mes. </p><br><p>  Cette piste est une version √©tendue du concours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Bird Audio Detection challenge¬ª</a> organis√© par St Mary‚Äôs University of London en 2017/2018.  Pour les personnes int√©ress√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> vous pouvez lire l'article des auteurs du concours, qui fournit des d√©tails sur la formation des donn√©es, l'organisation du concours lui-m√™me et une analyse des d√©cisions prises. </p><br><p>  Revenons cependant √† la t√¢che DCASE.  Les organisateurs ont fourni six ensembles de donn√©es - trois pour la formation, trois pour les tests - ils sont tous tr√®s diff√©rents - enregistr√©s dans diff√©rentes conditions acoustiques, √† l'aide de divers appareils d'enregistrement, et il y a divers bruits en arri√®re-plan.  Ainsi, le message principal est que le mod√®le ne doit pas d√©pendre de l'environnement ni pouvoir s'y adapter.  Malgr√© le fait que le nom signifie ¬´d√©tection¬ª, la t√¢che n'est pas de d√©terminer les limites de l'√©v√©nement, mais dans une classification simple - la solution finale est une sorte de classificateur binaire qui re√ßoit une courte entr√©e audio et d√©cide s'il y a ou non des chants d'oiseaux dessus. .  La m√©trique AUC a √©t√© utilis√©e pour √©valuer la pr√©cision. </p><br><p>  La plupart du temps, les participants ont essay√© de r√©aliser la g√©n√©ralisation et l'adaptation par diverses augmentations de donn√©es.  L'une des commandes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©crit l'</a> application de diverses techniques - modification de la r√©solution de fr√©quence dans les entit√©s extraites, r√©duction pr√©liminaire du bruit, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">m√©thode d'adaptation</a> bas√©e sur l'alignement des statistiques de second ordre pour diff√©rents ensembles de donn√©es.  Cependant, ces m√©thodes, ainsi que diff√©rents types d'augmentation, donnent une tr√®s faible augmentation par rapport √† la solution de base, comme le notent de nombreux participants. </p><br><p>  Comme solution de base, les auteurs ont pr√©par√© une modification de la solution la plus r√©ussie du concours original ¬´Bird Audio Detection challenge¬ª.  Le code, comme d'habitude, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">est disponible sur le github</a> . </p><br><hr><br><h3 id="anchortrack4anchortrack-4-detektirovanie-akusticheskih-sobytiy-v-bytovyh-usloviyah-s-ispolzovaniem-slabo-razmechennogo-nabora-dannyh"><a name="Track4"></a>  Piste 4. D√©tection d'√©v√©nements acoustiques dans la maison √† l'aide d'un ensemble de donn√©es faiblement √©tiquet√©. </h3><br><p>  Dans la quatri√®me piste, le probl√®me de d√©tection est d√©j√† r√©solu directement.  Les participants ont re√ßu un ensemble de donn√©es relativement petites de donn√©es balis√©es - un total de 1578 enregistrements audio de 10 secondes chacun, avec uniquement un marquage de classe: il est connu que le fichier contient un ou plusieurs √©v√©nements de ces classes, mais il n'y a pas de balisage temporaire.  En outre, deux grands ensembles de donn√©es de donn√©es non allou√©es ont √©t√© fournis - 14412 fichiers contenant des √©v√©nements cibles des m√™mes classes que dans les √©chantillons d'apprentissage et de test, ainsi que 39999 fichiers contenant des √©v√©nements arbitraires qui n'√©taient pas inclus dans les cibles.  Toutes les donn√©es sont un sous-ensemble de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©norme ensemble de donn√©es audio compil√© par google</a> . </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lx/td/h7/lxtdh7uaqxktdqu2bxzd4drrq0q.jpeg"></div><br><p>  Ainsi, les participants devaient cr√©er un mod√®le capable d'apprendre √† partir de donn√©es faiblement √©tiquet√©es pour trouver les horodatages du d√©but et de la fin des √©v√©nements (les √©v√©nements peuvent se chevaucher) et essayer de l'am√©liorer avec une grande quantit√© de donn√©es suppl√©mentaires non marqu√©es.  De plus, il convient de noter qu'une m√©trique assez rigide a √©t√© utilis√©e dans cette piste - il √©tait n√©cessaire de pr√©dire les √©tiquettes temporelles des √©v√©nements avec une pr√©cision de 200 ms.  En g√©n√©ral, les participants ont d√ª r√©soudre une t√¢che assez difficile de cr√©er un mod√®le ad√©quat, tout en n'ayant pratiquement pas de bonnes donn√©es pour la formation. <br>  La plupart des solutions √©taient bas√©es sur des r√©seaux de r√©currence convolutionnels - une architecture assez populaire dans le domaine de la d√©tection d'√©v√©nements acoustiques r√©cemment (un exemple peut √™tre lu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ). </p><br><p>  La solution de base des auteurs, √©galement sur les r√©seaux r√©cursifs convolutifs, est bas√©e sur deux mod√®les.  Les mod√®les ont presque la m√™me architecture: trois couches convolutives et une couche r√©cursive.  La seule diff√©rence est les r√©seaux de sortie.  Le premier mod√®le est form√© pour baliser les donn√©es non allou√©es pour √©tendre le jeu de donn√©es d'origine - ainsi, √† la sortie, nous avons des classes pr√©sentes dans le fichier d'√©v√©nements.  Le second sert √† r√©soudre directement le probl√®me de d√©tection, c'est-√†-dire qu'√† la sortie, nous obtenons un marquage temporaire pour le fichier.  Code pour le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> . </p><br><hr><br><h3 id="anchortrack5anchortrack-5-klassifikaciya-bytovoy-aktivnosti-v-pomeschenii-po-mnogokanalnoy-zapisi"><a name="Track5"></a>  Piste 5. Classification de l'activit√© du m√©nage dans la pi√®ce selon l'enregistrement multicanal. </h3><br><p>  La derni√®re piste diff√©rait des autres principalement par le fait que les participants se voyaient proposer des enregistrements multicanaux.  La t√¢che elle-m√™me √©tait dans la classification: il est n√©cessaire de pr√©dire la classe d'√©v√©nements qui se sont produits sur l'enregistrement.  Contrairement √† la piste pr√©c√©dente, la t√¢che est un peu plus simple - on sait qu'il n'y a qu'un seul √©v√©nement dans l'enregistrement. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hr/l1/ud/hrl1udue-onkcjfot9kptycgcw8.jpeg"></div><br><p>  L'ensemble de donn√©es est repr√©sent√© par environ 200 heures d'enregistrements sur un r√©seau de microphones lin√©aires de 4 microphones.  Les √©v√©nements sont toutes sortes d'activit√©s quotidiennes - cuisiner, laver la vaisselle, activit√©s sociales (parler au t√©l√©phone, visiter et converser personnellement), etc., la classe d'absence de tout √©v√©nement est √©galement mise en √©vidence. </p><br><p>  Les auteurs de la piste soulignent que les conditions de la t√¢che sont relativement simples pour que les participants se concentrent directement sur l'utilisation des informations spatiales √† partir d'enregistrements multicanaux.  Les participants ont √©galement eu la possibilit√© d'utiliser des donn√©es suppl√©mentaires et des mod√®les pr√©-form√©s.  La qualit√© a √©t√© √©valu√©e selon la mesure F1. </p><br><p>  Comme solution de base, les auteurs de la piste ont propos√© un r√©seau convolutionnel simple avec deux couches convolutionnelles.  Dans leur solution, l'information spatiale n'a pas √©t√© utilis√©e - les donn√©es de quatre microphones ont √©t√© utilis√©es pour l'entra√Ænement de mani√®re ind√©pendante, et les pr√©visions ont √©t√© moyenn√©es pendant les tests.  La description et le code sont disponibles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le lien</a> . </p><br><hr><br><h3 id="zaklyuchenie">  Conclusion </h3><br><p>  Dans l'article, nous avons essay√© de parler bri√®vement de la d√©tection d'√©v√©nements acoustiques et d'une comp√©tition telle que DCASE.  Peut-√™tre qu'ils ont pu int√©resser quelqu'un √† participer en 2019 - le concours commence en mars. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr437818/">https://habr.com/ru/post/fr437818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr437808/index.html">Perf et graphes de flamme</a></li>
<li><a href="../fr437810/index.html">R√©alit√© d'entreprise</a></li>
<li><a href="../fr437812/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 et autres b√™tas</a></li>
<li><a href="../fr437814/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 et autres versions b√™ta</a></li>
<li><a href="../fr437816/index.html">MPLS est partout. Comment est l'infrastructure r√©seau Yandex.Cloud</a></li>
<li><a href="../fr437820/index.html">50 nuances de s√©curit√© Drupal</a></li>
<li><a href="../fr437824/index.html">Extension universelle 1C pour Google Sheets et Docs - prendre et utiliser</a></li>
<li><a href="../fr437826/index.html">Comment nous avons migr√© la base de donn√©es de Redis et Riak KV vers PostgreSQL. Partie 1: le processus</a></li>
<li><a href="../fr437828/index.html">Webinaire ouvert "SELECT ordre d'ex√©cution des requ√™tes et plan de requ√™te dans MS SQL Server"</a></li>
<li><a href="../fr437830/index.html">Programmation fiable par langage - revue noob. Partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>